<!DOCTYPE HTML>
<html lang="zh-cn" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>TensorStack AI 计算平台 - 用户使用手册 - v20240206</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="theme/sidebar.css">
        <link rel="stylesheet" href="theme/custom.css">
        <link rel="stylesheet" href="theme/version-dropdown.css">

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="introduction.html">导言</a></li><li class="chapter-item expanded affix "><a href="overview.html">概述</a></li><li class="chapter-item expanded "><a href="get-started/index.html"><strong aria-hidden="true">1.</strong> 快速入门</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="get-started/training-first-model.html"><strong aria-hidden="true">1.1.</strong> 训练你的第一个模型</a></li><li class="chapter-item expanded "><a href="get-started/parallel-training.html"><strong aria-hidden="true">1.2.</strong> 进行并行训练</a></li><li class="chapter-item expanded "><a href="get-started/deploy-model.html"><strong aria-hidden="true">1.3.</strong> 部署模型</a></li></ol></li><li class="chapter-item expanded "><a href="modules/index.html"><strong aria-hidden="true">2.</strong> AI 开发和应用</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="modules/building/index.html"><strong aria-hidden="true">2.1.</strong> 模型构建</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="modules/building/notebook.html"><strong aria-hidden="true">2.1.1.</strong> Notebook</a></li><li class="chapter-item expanded "><a href="modules/building/tensorboard.html"><strong aria-hidden="true">2.1.2.</strong> TensorBoard</a></li><li class="chapter-item expanded "><a href="modules/building/autotune.html"><strong aria-hidden="true">2.1.3.</strong> AutoTune</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="modules/building/autotuneexperiment.html"><strong aria-hidden="true">2.1.3.1.</strong> AutoTuneExperiment</a></li><li class="chapter-item expanded "><a href="modules/building/autotune-search-space.html"><strong aria-hidden="true">2.1.3.2.</strong> 搜索空间</a></li><li class="chapter-item expanded "><a href="modules/building/hpo-algorithm.html"><strong aria-hidden="true">2.1.3.3.</strong> 超参数调优算法</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="modules/deployment/index.html"><strong aria-hidden="true">2.2.</strong> 模型部署</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="modules/deployment/simplemlservice.html"><strong aria-hidden="true">2.2.1.</strong> SimpleMLService</a></li><li class="chapter-item expanded "><a href="modules/deployment/mlservice.html"><strong aria-hidden="true">2.2.2.</strong> MLService</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="modules/deployment/mlservice-logger.html"><strong aria-hidden="true">2.2.2.1.</strong> 日志收集</a></li></ol></li><li class="chapter-item expanded "><a href="modules/deployment/storage.html"><strong aria-hidden="true">2.2.3.</strong> 模型存储</a></li></ol></li><li class="chapter-item expanded "><a href="modules/jobs/index.html"><strong aria-hidden="true">2.3.</strong> Job</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="modules/jobs/genericjob.html"><strong aria-hidden="true">2.3.1.</strong> GenericJob</a></li><li class="chapter-item expanded "><a href="modules/jobs/pytorchtrainingjob.html"><strong aria-hidden="true">2.3.2.</strong> PyTorchTrainingJob</a></li><li class="chapter-item expanded "><a href="modules/jobs/tensorflowtrainingjob.html"><strong aria-hidden="true">2.3.3.</strong> TensorFlowTrainingJob</a></li><li class="chapter-item expanded "><a href="modules/jobs/deepspeedjob.html"><strong aria-hidden="true">2.3.4.</strong> DeepSpeedJob</a></li><li class="chapter-item expanded "><a href="modules/jobs/colossalaijob.html"><strong aria-hidden="true">2.3.5.</strong> ColossalAIJob</a></li><li class="chapter-item expanded "><a href="modules/jobs/xgboosttrainingjob.html"><strong aria-hidden="true">2.3.6.</strong> XGBoostTrainingJob</a></li><li class="chapter-item expanded "><a href="modules/jobs/mpijob.html"><strong aria-hidden="true">2.3.7.</strong> MPIJob</a></li><li class="chapter-item expanded "><a href="modules/jobs/beamjob.html"><strong aria-hidden="true">2.3.8.</strong> BeamJob</a></li></ol></li><li class="chapter-item expanded "><a href="modules/asset-management.html"><strong aria-hidden="true">2.4.</strong> 资产管理</a></li><li class="chapter-item expanded "><a href="modules/experiment-management.html"><strong aria-hidden="true">2.5.</strong> 实验管理</a></li></ol></li><li class="chapter-item expanded "><a href="modules/security/index.html"><strong aria-hidden="true">3.</strong> 账户和安全</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="modules/security/account.html"><strong aria-hidden="true">3.1.</strong> 账户</a></li><li class="chapter-item expanded "><a href="modules/security/project.html"><strong aria-hidden="true">3.2.</strong> 项目</a></li></ol></li><li class="chapter-item expanded "><a href="modules/scheduling/index.html"><strong aria-hidden="true">4.</strong> 计算资源</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="modules/scheduling/use-gpu.html"><strong aria-hidden="true">4.1.</strong> 使用 GPU</a></li><li class="chapter-item expanded "><a href="modules/scheduling/quota.html"><strong aria-hidden="true">4.2.</strong> 资源配额</a></li><li class="chapter-item expanded "><a href="modules/scheduling/queue.html"><strong aria-hidden="true">4.3.</strong> 队列</a></li><li class="chapter-item expanded "><a href="modules/scheduling/podgroup.html"><strong aria-hidden="true">4.4.</strong> PodGroup</a></li><li class="chapter-item expanded "><a href="modules/scheduling/reclaim.html"><strong aria-hidden="true">4.5.</strong> 资源回收</a></li><li class="chapter-item expanded "><a href="modules/scheduling/resources-monitoring.html"><strong aria-hidden="true">4.6.</strong> 资源使用监控</a></li></ol></li><li class="chapter-item expanded "><a href="modules/storage/index.html"><strong aria-hidden="true">5.</strong> 存储</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="modules/storage/pvc.html"><strong aria-hidden="true">5.1.</strong> PVC</a></li><li class="chapter-item expanded "><a href="modules/storage/pvc-snapshot.html"><strong aria-hidden="true">5.2.</strong> PVC 快照</a></li><li class="chapter-item expanded "><a href="modules/storage/storageshim.html"><strong aria-hidden="true">5.3.</strong> StorageShim</a></li><li class="chapter-item expanded "><a href="modules/storage/explorer.html"><strong aria-hidden="true">5.4.</strong> Explorer</a></li></ol></li><li class="chapter-item expanded "><a href="modules/auxiliary/index.html"><strong aria-hidden="true">6.</strong> 辅助</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="modules/auxiliary/secret.html"><strong aria-hidden="true">6.1.</strong> Secret</a></li><li class="chapter-item expanded "><a href="modules/auxiliary/configmap.html"><strong aria-hidden="true">6.2.</strong> ConfigMap</a></li><li class="chapter-item expanded "><a href="modules/auxiliary/pod.html"><strong aria-hidden="true">6.3.</strong> Pod</a></li><li class="chapter-item expanded "><a href="modules/auxiliary/imagebuilder.html"><strong aria-hidden="true">6.4.</strong> ImageBuilder</a></li></ol></li><li class="chapter-item expanded "><a href="modules/workflows/index.html"><strong aria-hidden="true">7.</strong> 工作流</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="modules/workflows/workflowtemplate.html"><strong aria-hidden="true">7.1.</strong> WorkflowTemplate</a></li><li class="chapter-item expanded "><a href="modules/workflows/workflowrun.html"><strong aria-hidden="true">7.2.</strong> WorkflowRun</a></li><li class="chapter-item expanded "><a href="modules/workflows/cronworkflowrun.html"><strong aria-hidden="true">7.3.</strong> CronWorkflowRun</a></li><li class="chapter-item expanded "><a href="modules/workflows/workflowtrigger.html"><strong aria-hidden="true">7.4.</strong> WorkflowTrigger</a></li></ol></li><li class="chapter-item expanded "><a href="tasks/index.html"><strong aria-hidden="true">8.</strong> 操作指南</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tasks/model-building.html"><strong aria-hidden="true">8.1.</strong> 使用模型构建控制台</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tasks/create-notebook.html"><strong aria-hidden="true">8.1.1.</strong> 创建 Notebook</a></li><li class="chapter-item expanded "><a href="tasks/use-notebook.html"><strong aria-hidden="true">8.1.2.</strong> 使用 Notebook</a></li><li class="chapter-item expanded "><a href="tasks/ssh-notebook.html"><strong aria-hidden="true">8.1.3.</strong> 通过 SSH 远程使用 Notebook</a></li><li class="chapter-item expanded "><a href="tasks/create-tensorboard.html"><strong aria-hidden="true">8.1.4.</strong> 创建 TensorBoard</a></li><li class="chapter-item expanded "><a href="tasks/build-image.html"><strong aria-hidden="true">8.1.5.</strong> 构建镜像</a></li><li class="chapter-item expanded "><a href="tasks/debug-image.html"><strong aria-hidden="true">8.1.6.</strong> 调试镜像</a></li><li class="chapter-item expanded "><a href="tasks/manage-pvc.html"><strong aria-hidden="true">8.1.7.</strong> 管理 PVC</a></li><li class="chapter-item expanded "><a href="tasks/use-explorer.html"><strong aria-hidden="true">8.1.8.</strong> 使用 Explorer</a></li><li class="chapter-item expanded "><a href="tasks/use-storageshim-s3.html"><strong aria-hidden="true">8.1.9.</strong> 使用 StorageShim 适配 S3 服务</a></li><li class="chapter-item expanded "><a href="tasks/manage-secret.html"><strong aria-hidden="true">8.1.10.</strong> 管理 Secret</a></li><li class="chapter-item expanded "><a href="tasks/manage-configmap.html"><strong aria-hidden="true">8.1.11.</strong> 管理 ConfigMap</a></li></ol></li><li class="chapter-item expanded "><a href="tasks/model-training.html"><strong aria-hidden="true">8.2.</strong> 运行模型训练</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tasks/pytorch-training-parallel.html"><strong aria-hidden="true">8.2.1.</strong> 使用 PyTorchTrainingJob 进行数据并行训练</a></li><li class="chapter-item expanded "><a href="tasks/pytorch-training-ps.html"><strong aria-hidden="true">8.2.2.</strong> 使用 PyTorchTrainingJob 进行参数服务器训练</a></li><li class="chapter-item expanded "><a href="tasks/tensorflow-training-parallel.html"><strong aria-hidden="true">8.2.3.</strong> 使用 TensorFlowTrainingJob 进行数据并行训练</a></li><li class="chapter-item expanded "><a href="tasks/tensorflow-training-ps.html"><strong aria-hidden="true">8.2.4.</strong> 使用 TensorFlowTrainingJob 进行参数服务器训练</a></li><li class="chapter-item expanded "><a href="tasks/horovod-pytorch-parallel.html"><strong aria-hidden="true">8.2.5.</strong> 使用 Horovod 进行 PyTorch 模型的数据并行训练</a></li><li class="chapter-item expanded "><a href="tasks/horovod-keras-parallel.html"><strong aria-hidden="true">8.2.6.</strong> 使用 Horovod 进行 Keras 模型的数据并行训练</a></li><li class="chapter-item expanded "><a href="tasks/profile-model-training.html"><strong aria-hidden="true">8.2.7.</strong> 使用 Profiler 分析模型训练性能</a></li><li class="chapter-item expanded "><a href="tasks/debug-job.html"><strong aria-hidden="true">8.2.8.</strong> 调试 Job</a></li></ol></li><li class="chapter-item expanded "><a href="tasks/hyperparameter-tuning.html"><strong aria-hidden="true">8.3.</strong> 进行超参数优化</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tasks/autotune.html"><strong aria-hidden="true">8.3.1.</strong> 使用 AutoTune 进行超参数优化</a></li></ol></li><li class="chapter-item expanded "><a href="tasks/deploy-inference-service.html"><strong aria-hidden="true">8.4.</strong> 部署推理服务</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tasks/deploy-simplemlservice.html"><strong aria-hidden="true">8.4.1.</strong> 简单推理服务</a></li><li class="chapter-item expanded "><a href="tasks/deploy-mlservice.html"><strong aria-hidden="true">8.4.2.</strong> 推理服务</a></li><li class="chapter-item expanded "><a href="tasks/deploy-mlservice-transformer.html"><strong aria-hidden="true">8.4.3.</strong> 包含 Transformer 的推理服务</a></li></ol></li><li class="chapter-item expanded "><a href="tasks/manage-ai-assets.html"><strong aria-hidden="true">8.5.</strong> 管理 AI 资产</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tasks/manipulate-folder-asset.html"><strong aria-hidden="true">8.5.1.</strong> 操作文件夹、模型和数据集</a></li><li class="chapter-item expanded "><a href="tasks/access-asset-via-s3.html"><strong aria-hidden="true">8.5.2.</strong> 通过 S3 访问模型和数据集</a></li><li class="chapter-item expanded "><a href="tasks/modify-folder-asset.html"><strong aria-hidden="true">8.5.3.</strong> 修改文件夹、模型和数据集的基本信息</a></li><li class="chapter-item expanded "><a href="tasks/manipulate-asset-branch-tag.html"><strong aria-hidden="true">8.5.4.</strong> 操作模型和数据集的分支、tag 和 commit</a></li><li class="chapter-item expanded "><a href="tasks/manipulate-asset-objects.html"><strong aria-hidden="true">8.5.5.</strong> 操作模型和数据集的对象</a></li></ol></li><li class="chapter-item expanded "><a href="tasks/track-model-training.html"><strong aria-hidden="true">8.6.</strong> 追踪模型训练</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tasks/use-experiment-console.html"><strong aria-hidden="true">8.6.1.</strong> 在实验管理控制台查看和管理数据</a></li><li class="chapter-item expanded "><a href="tasks/record-using-python-sdk.html"><strong aria-hidden="true">8.6.2.</strong> 使用 Python SDK 记录和上传数据</a></li><li class="chapter-item expanded "><a href="tasks/record-single-device-training.html"><strong aria-hidden="true">8.6.3.</strong> 单设备训练场景</a></li><li class="chapter-item expanded "><a href="tasks/record-distributed-training.html"><strong aria-hidden="true">8.6.4.</strong> 分布式训练场景</a></li><li class="chapter-item expanded "><a href="tasks/view-autotune-in-experiment-console.html"><strong aria-hidden="true">8.6.5.</strong> 在实验管理控制台查看 AutoTune</a></li></ol></li><li class="chapter-item expanded "><a href="tasks/build-automation-workflow.html"><strong aria-hidden="true">8.7.</strong> 构建自动化工作流</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tasks/create-workflow-unit.html"><strong aria-hidden="true">8.7.1.</strong> 创建工作流的基本单元</a></li><li class="chapter-item expanded "><a href="tasks/create-task-workflow-unit.html"><strong aria-hidden="true">8.7.2.</strong> 创建执行各类任务的工作流单元</a></li><li class="chapter-item expanded "><a href="tasks/create-dependent-workflow.html"><strong aria-hidden="true">8.7.3.</strong> 创建存在依赖关系的工作流</a></li><li class="chapter-item expanded "><a href="tasks/build-automated-workflow.html"><strong aria-hidden="true">8.7.4.</strong> 建立从数据采样到模型导出的自动化工作流</a></li></ol></li><li class="chapter-item expanded "><a href="tasks/schedule-workload.html"><strong aria-hidden="true">8.8.</strong> 调度工作负载</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tasks/use-queue.html"><strong aria-hidden="true">8.8.1.</strong> 使用 Queue</a></li><li class="chapter-item expanded "><a href="tasks/use-podgroup.html"><strong aria-hidden="true">8.8.2.</strong> 使用 PodGroup</a></li></ol></li><li class="chapter-item expanded "><a href="tasks/use-platform-storage.html"><strong aria-hidden="true">8.9.</strong> 使用集群存储</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tasks/pvc-importing-and-exporting-files.html"><strong aria-hidden="true">8.9.1.</strong> 上传和下载文件</a></li></ol></li><li class="chapter-item expanded "><a href="tasks/manage-personal-account.html"><strong aria-hidden="true">8.10.</strong> 管理个人账户</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tasks/generate-api-key.html"><strong aria-hidden="true">8.10.1.</strong> 生成 API Key</a></li><li class="chapter-item expanded "><a href="tasks/use-api-key.html"><strong aria-hidden="true">8.10.2.</strong> 使用 API Key</a></li><li class="chapter-item expanded "><a href="tasks/add-project-member.html"><strong aria-hidden="true">8.10.3.</strong> 添加项目成员</a></li></ol></li><li class="chapter-item expanded "><a href="tasks/tricks.html"><strong aria-hidden="true">8.11.</strong> 小技巧</a></li></ol></li><li class="chapter-item expanded "><a href="tools/index.html"><strong aria-hidden="true">9.</strong> 命令行工具和 SDK</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tools/cli-t9k/index.html"><strong aria-hidden="true">9.1.</strong> 命令行工具：t9k</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tools/cli-t9k/guide.html"><strong aria-hidden="true">9.1.1.</strong> 用户指南</a></li><li class="chapter-item expanded "><a href="tools/cli-t9k/commands.html"><strong aria-hidden="true">9.1.2.</strong> 命令</a></li></ol></li><li class="chapter-item expanded "><a href="tools/cli-t9k-pf/index.html"><strong aria-hidden="true">9.2.</strong> 命令行工具：t9k-pf</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tools/cli-t9k-pf/guide.html"><strong aria-hidden="true">9.2.1.</strong> 用户指南</a></li><li class="chapter-item expanded "><a href="tools/cli-t9k-pf/commands.html"><strong aria-hidden="true">9.2.2.</strong> 命令</a></li></ol></li><li class="chapter-item expanded "><a href="tools/python-sdk-t9k/index.html"><strong aria-hidden="true">9.3.</strong> Python SDK：t9k</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tools/python-sdk-t9k/guide.html"><strong aria-hidden="true">9.3.1.</strong> 用户指南</a></li><li class="chapter-item expanded "><a href="tools/python-sdk-t9k/api/index.html"><strong aria-hidden="true">9.3.2.</strong> API</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tools/python-sdk-t9k/api/t9k-ah.html"><strong aria-hidden="true">9.3.2.1.</strong> t9k.ah</a></li><li class="chapter-item expanded "><a href="tools/python-sdk-t9k/api/t9k-ah-core.html"><strong aria-hidden="true">9.3.2.2.</strong> t9k.ah.core</a></li><li class="chapter-item expanded "><a href="tools/python-sdk-t9k/api/t9k-config.html"><strong aria-hidden="true">9.3.2.3.</strong> t9k.config</a></li><li class="chapter-item expanded "><a href="tools/python-sdk-t9k/api/t9k-em.html"><strong aria-hidden="true">9.3.2.4.</strong> t9k.em</a></li><li class="chapter-item expanded "><a href="tools/python-sdk-t9k/api/t9k-tuner.html"><strong aria-hidden="true">9.3.2.5.</strong> t9k.tuner</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="tools/codepack/index.html"><strong aria-hidden="true">9.4.</strong> Codepack</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tools/codepack/concepts.html"><strong aria-hidden="true">9.4.1.</strong> 概念</a></li><li class="chapter-item expanded "><a href="tools/codepack/definition.html"><strong aria-hidden="true">9.4.2.</strong> Codepack 定义</a></li><li class="chapter-item expanded "><a href="tools/codepack/cli.html"><strong aria-hidden="true">9.4.3.</strong> 命令行工具</a></li><li class="chapter-item expanded "><a href="tools/codepack/example.html"><strong aria-hidden="true">9.4.4.</strong> 示例</a></li><li class="spacer"></li></ol></li></ol></li><li class="chapter-item expanded "><a href="references/index.html"><strong aria-hidden="true">10.</strong> 参考</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="references/glossary.html"><strong aria-hidden="true">10.1.</strong> 术语表</a></li><li class="chapter-item expanded "><a href="references/api-reference/index.html"><strong aria-hidden="true">10.2.</strong> API 参考</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="references/api-reference/project.html"><strong aria-hidden="true">10.2.1.</strong> Project</a></li><li class="chapter-item expanded "><a href="references/api-reference/genericjob.html"><strong aria-hidden="true">10.2.2.</strong> GenericJob</a></li><li class="chapter-item expanded "><a href="references/api-reference/tensorflowtrainingjob.html"><strong aria-hidden="true">10.2.3.</strong> TensorFlowTrainingJob</a></li><li class="chapter-item expanded "><a href="references/api-reference/pytorchtrainingjob.html"><strong aria-hidden="true">10.2.4.</strong> PyTorchTrainingJob</a></li><li class="chapter-item expanded "><a href="references/api-reference/xgboosttrainingjob.html"><strong aria-hidden="true">10.2.5.</strong> XGBoostTrainingJob</a></li><li class="chapter-item expanded "><a href="references/api-reference/colossalaijob.html"><strong aria-hidden="true">10.2.6.</strong> ColossalAIJob</a></li><li class="chapter-item expanded "><a href="references/api-reference/deepspeedjob.html"><strong aria-hidden="true">10.2.7.</strong> DeepSpeedJob</a></li><li class="chapter-item expanded "><a href="references/api-reference/mpijob.html"><strong aria-hidden="true">10.2.8.</strong> MPIJob</a></li><li class="chapter-item expanded "><a href="references/api-reference/beamjob.html"><strong aria-hidden="true">10.2.9.</strong> BeamJob</a></li><li class="chapter-item expanded "><a href="references/api-reference/tensorboard.html"><strong aria-hidden="true">10.2.10.</strong> TensorBoard</a></li><li class="chapter-item expanded "><a href="references/api-reference/notebook.html"><strong aria-hidden="true">10.2.11.</strong> Notebook</a></li><li class="chapter-item expanded "><a href="references/api-reference/autotune.html"><strong aria-hidden="true">10.2.12.</strong> AutoTuneExperiment</a></li><li class="chapter-item expanded "><a href="references/api-reference/explorer.html"><strong aria-hidden="true">10.2.13.</strong> Explorer</a></li><li class="chapter-item expanded "><a href="references/api-reference/storageshim.html"><strong aria-hidden="true">10.2.14.</strong> StorageShim</a></li><li class="chapter-item expanded "><a href="references/api-reference/scheduler.html"><strong aria-hidden="true">10.2.15.</strong> Scheduler</a></li><li class="chapter-item expanded "><a href="references/api-reference/workflow.html"><strong aria-hidden="true">10.2.16.</strong> Workflow</a></li><li class="chapter-item expanded "><a href="references/api-reference/workflowtrigger.html"><strong aria-hidden="true">10.2.17.</strong> WorkflowTrigger</a></li><li class="chapter-item expanded "><a href="references/api-reference/simplemlservice.html"><strong aria-hidden="true">10.2.18.</strong> SimpleMLService</a></li><li class="chapter-item expanded "><a href="references/api-reference/mlservice.html"><strong aria-hidden="true">10.2.19.</strong> MLService</a></li></ol></li><li class="chapter-item expanded "><a href="references/standard-images.html"><strong aria-hidden="true">10.3.</strong> 标准镜像</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="examples/index.html"><strong aria-hidden="true">11.</strong> 示例</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="examples/start-llm-large-scale-pretraining.html"><strong aria-hidden="true">11.1.</strong> 启动 LLM 大规模预训练</a></li><li class="chapter-item expanded "><a href="examples/start-llm-finetuning.html"><strong aria-hidden="true">11.2.</strong> 启动 LLM 微调</a></li><li class="chapter-item expanded "><a href="examples/deploy-llm-using-fastchat.html"><strong aria-hidden="true">11.3.</strong> 使用 FastChat 部署 LLM 推理服务</a></li><li class="chapter-item expanded "><a href="examples/deploy-llm-using-vllm.html"><strong aria-hidden="true">11.4.</strong> 使用 vLLM 部署 LLM 推理服务</a></li><li class="chapter-item expanded "><a href="examples/deploy-hf-model-using-triton-python.html"><strong aria-hidden="true">11.5.</strong> 使用 Triton 部署 Hugging Face 模型（Python 后端）</a></li><li class="chapter-item expanded "><a href="examples/deploy-mlservice-tensorizer.html"><strong aria-hidden="true">11.6.</strong> 使用 Tensorizer 加速模型部署</a></li><li class="chapter-item expanded "><a href="examples/build-next-generation-llm-app-using-autogen.html"><strong aria-hidden="true">11.7.</strong> 使用 AutoGen 构建下一代 LLM 应用</a></li><li class="chapter-item expanded "><a href="examples/deploy-conversational-search-engine.html"><strong aria-hidden="true">11.8.</strong> 部署对话式搜索引擎</a></li><li class="chapter-item expanded "><a href="examples/deploy-sd-drawing-model.html"><strong aria-hidden="true">11.9.</strong> 部署 Stable Diffusion 图像生成模型</a></li><li class="chapter-item expanded "><a href="examples/lane-detection.html"><strong aria-hidden="true">11.10.</strong> 车道检测</a></li></ol></li><li class="chapter-item expanded "><a href="integrations/index.html"><strong aria-hidden="true">12.</strong> 集成</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="integrations/label-studio.html"><strong aria-hidden="true">12.1.</strong> Label Studio</a></li><li class="chapter-item expanded "><a href="integrations/vector-database-qdrant.html"><strong aria-hidden="true">12.2.</strong> 向量数据库：Qdrant</a></li><li class="chapter-item expanded "><a href="integrations/vector-database-pgvector.html"><strong aria-hidden="true">12.3.</strong> 向量数据库：PostgreSQL + pgvector</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="background.html">附录1：背景</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        <!-- custom code for adding release version dropdown menu -->
                        <div class="version-dropdown">
                            <button id="release-version" class="icon-button" type="button" title="Release version" aria-label="Release version" aria-haspopup="true" aria-expanded="false" aria-controls="release-versions">
                                <i class="fa fa-book"></i>
                            </button>
                            <div class="version-dropdown-content">
                                <a href="https://t9k.github.io/user-manuals/latest/index.html"target="_blank" rel="noopener noreferrer">latest</a>
                                <a href="https://t9k.github.io/user-manuals/v20240206/index.html"target="_blank" rel="noopener noreferrer">v20240206</a>
                            </div>
                        </div>
                    </div>

                    <h1 class="menu-title">TensorStack AI 计算平台 - 用户使用手册 - v20240206</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<aside class="note tip">
<div class="title">提示</div>
<p>着急的读者请 –&gt; <a href="./get-started/index.html">快速开始</a>。</p>
</aside>
<h1 id="导言"><a class="header" href="#导言">导言</a></h1>
<h2 id="目标读者"><a class="header" href="#目标读者">目标读者</a></h2>
<p>本书《TensorStack AI 计算平台 - 用户使用手册》 的目标读者是 “TensorStack AI 计算平台” 的使用者，包括：</p>
<ul>
<li>AI 研究人员</li>
<li>建模工程师</li>
<li>数据处理工程师</li>
<li>机器学习工程师</li>
<li>AI 应用开发工程师等</li>
</ul>
<p>系统管理员、运维人员需要参考另外的《TensorStack AI 计算平台 - 管理员手册》系列。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>本手册仍在不断完善中，如有任何问题，请谅解并随时 –&gt; <a href="introduction.html#%E5%8F%8D%E9%A6%88">反馈</a>。</p>
</aside>
<h2 id="如何使用"><a class="header" href="#如何使用">如何使用</a></h2>
<p><a href="./overview.html">概述</a> 介绍了产品的基本功能和使用模式。</p>
<p>用户首次使用可以跟从<a href="./get-started/index.html">快速开始</a>的内容，快速完成基本的体验。</p>
<p>然后，用户可以阅读 <a href="./modules/building/index.html">AI 开发和应用</a>章节，以学习 AI 开发相关的概念。</p>
<p>其他章节内容如下：</p>
<ul>
<li><a href="./modules/security/index.html">账户和安全</a> 讨论用户账户和系统安全问题。</li>
<li><a href="./modules/scheduling/index.html">计算资源</a> 讨论如何使用集群计算资源。</li>
<li><a href="./modules/storage/index.html">存储</a> 章节对平台的存储方面的支持进行了说明。</li>
<li><a href="./modules/auxiliary/index.html">辅助</a> 章节描述平台提供的一些重要辅助功能，例如如何处理敏感秘密信息，打包容器镜像等。</li>
<li><a href="./tools/index.html">命令行工具和 SDK</a> 讨论 TensorStack 平台的提供的命令行工具和 Python SDK 。</li>
<li><a href="./tasks/index.html">操作示例</a> 章节提供了一些具体的操作指南。</li>
<li><a href="./references/index.html">参考</a> 章节对 API 提供了完整的描述。</li>
<li><a href="./examples/index.html">示例</a> 章节提供了一些具体的应用示例，特别是对 LLM 领域的场景提供了全面的支持演示。</li>
<li><a href="./integrations/index.html">集成</a> 章节讨论了一些优秀的第三方工具在 TensorStack 平台上的集成及使用。</li>
<li><a href="./background.html">附录1：背景</a> 介绍了产品的技术架构和设计思路等。</li>
</ul>
<p>“TensorStack AI 计算平台” 是一个功能强大且灵活的产品，支持在大规模（10^3 节点）集群上进行各种 AI 场景的计算。用户在一定的时间的学习、使用、探索、积累之后，就能对其功能有深入的理解，并在上面完成各种优秀的工作。</p>
<p>本手册使用的例子一般存放在下列 repos：</p>
<ul>
<li><a href="https://github.com/t9k/examples">https://github.com/t9k/examples</a></li>
<li><a href="https://github.com/t9k/tutorial-examples">https://github.com/t9k/tutorial-examples</a></li>
</ul>
<h2 id="反馈"><a class="header" href="#反馈">反馈</a></h2>
<p>非常欢迎各种反馈，可在 <a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/user-manuals/issues">Github Issues 页面</a> 创建 issue。</p>
<h2 id="版权声明"><a class="header" href="#版权声明">版权声明</a></h2>
<p>© 2023-2024 TensorStack.</p>
<p>本书/网站的内容版权由 TensorStack 所有，欢迎使用。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="概述"><a class="header" href="#概述">概述</a></h1>
<h2 id="产品介绍"><a class="header" href="#产品介绍">产品介绍</a></h2>
<p>“TensorStack AI 计算平台” 是面向 AI 集群的系统软件，针对 AI 集群的硬件架构和 AI 领域的计算任务的特性和需求，提供稳定、可扩展的 AI 技术平台能力，服务 AI 技术研发和规模化落地。</p>
<p>AI 集群的拥有者可以使用这套软件，构建自己的 “AI 私有云” 或 “AI 混合云” 基础设施服务。</p>
<aside class="note info">
<div class="title">“TensorStack AI 计算平台” 的功能</div>
<p>作为基础设施软件，平台提供两方面的能力：</p>
<ol>
<li><strong>计算服务</strong>：针对 AI 集群使用者，向上支持各种 AI 计算场景，例如：云端开发环境、模型训练、部署推理服务、应用开发等；</li>
<li><strong>集群管理</strong>：针对 AI 集群的管理、运维人员，提供方便的机制，实施各种资源、安全、数据等管理策略。</li>
</ol>
</aside>
<p>通过先进的架构和丰富的 API + 系统服务，“TensorStack AI 计算平台” 合理地隐藏了分布式并行、异构计算、加速计算等技术的复杂细节，提高了抽象层次，并为 AI 领域的各种计算提供了针对性的支持，极大地提升了 AI 技术研究、开发、应用的工作效率。</p>
<figure class="architecture">
  <img alt="t9k-arch" src="./assets/overview/t9k-arch.png" />
  <figcaption>图 1：TensorStack AI 计算平台采用云原生架构，由 AI 引擎层（AI Engine, AIE）和 AI 基础层（AI Base, AIB）组成，为上层 AI 应用和底层 AI 算力建立有机连接，提供先进、可扩展的 AI 系统层面的能力。</figcaption>
</figure>
<h2 id="基本流程"><a class="header" href="#基本流程">基本流程</a></h2>
<p>用户使用 “TensorStack AI 计算平台” 的基本交互流程：</p>
<ol>
<li>管理员 - 创建 - <a href="./modules/security/project.html">项目（Project）</a>并设定项目管理员。
<ul>
<li>用户以项目管理员或者普通成员的方式使用项目。</li>
<li>用户可以同时使用多个项目。</li>
</ul>
</li>
<li>管理员 - 创建 - <a href="./modules/security/account.html">用户帐户</a>。</li>
<li>用户 - 使用其帐户 - 登录系统。</li>
<li>用户 - 在项目中 - 完成工作（创建各种计算任务）。</li>
</ol>
<figure class="architecture">
  <img alt="t9k-flow" src="./assets/overview/t9k-flow.drawio.svg" />
  <figcaption>图 2：用户登陆系统后在 “项目” 中创建计算任务以完成各种工作。</figcaption>
</figure>
<h2 id="使用功能"><a class="header" href="#使用功能">使用功能</a></h2>
<p>用户主要通过创建各种类型 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">CRD</a> 的实例（instance）使用产品的功能。例如：</p>
<ul>
<li>创建一个 <code>Notebook</code> CRD 的实例，以使用 Jupyter Notebook；</li>
<li>为了使用 DeepSpeed 进行大规模并行的 LLM 预训练，创建一个 <code>DeepSpeedJob</code> CRD 的实例；</li>
<li>为了部署一个模型推理服务，并支持服务规模的自动伸缩，创建一个 <code>MLService</code> CRD 的实例；</li>
</ul>
<figure class="architecture">
  <img alt="use-t9k" src="./assets/overview/use-t9k.drawio.svg" />
  <figcaption>图 3：用户可以通过命令行接口（CLI） 或者可视化的 Web 页面（UI） 创建这些 CRD 的实例。</figcaption>
</figure>
<aside class="note info">
<div class="title"> CRD </div>
<p><strong>CRD （Custom Resource Defintion，定制资源定义）</strong> 是 Kubernetes 提供的一种 API 扩展机制，可用于提供特定领域（例如 AI）的额外能力。</p>
<p>TensorStack 平台通过 CRD 提供了丰富的系统功能，包括存储系统、开发环境、数据处理、模型训练、推理服务等。
<code>Notebook</code> 是 TensorStack 提供的一个 CRD，用于支持在 TensorStack 平台上使用 JupyterLab，RStudio。</p>
<p>有关 CRD 机制的详细信息请参阅 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/using-api/api-concepts/"> Kubernetes API Concepts </a> 及 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"> Custom Resources </a>。</p>
</aside>
<aside class="note info">
<div class="title">TensorStack 通过 CRD 提供系统功能</div>
<p>平台目前提供了 ～30 个 CRD，以支持各种 AI 计算场景。用户可通过下列命令查看集群中部署的 TensorStack CRD：</p>
<pre><code class="language-bash">kubectl api-resources |grep tensorstack
</code></pre>
</aside>
<h3 id="cli"><a class="header" href="#cli">CLI</a></h3>
<p>CRD 实例（instance）的创建总是可以通过命令行实现，例如使用 <code>kubectl</code> 可以方便的创建一个 Notebook：</p>
<pre><code class="language-bash"># create a notebook
kubectle create -f notebook-tutorial.yaml 
</code></pre>
<details><summary><code class="hljs">notebook-tutorial.yaml</code></summary>
<pre><code class="language-yaml"># notebook-tutorial.yaml
apiVersion: tensorstack.dev/v1beta1
kind: Notebook
metadata:
  name: tutorial
spec:
  type: jupyter
  template:
    spec:
      containers:
        - name: notebook
          image: t9kpublic/torch-2.1.0-notebook:1.77.1
          volumeMounts:
            - name: workingdir
              mountPath: /t9k/mnt
          resources:
            requests:
              cpu: '8'
              memory: 16Gi
              nvidia.com/gpu: 1
            limits:
              cpu: '16'
              memory: 32Gi
              nvidia.com/gpu: 1
      volumes:
        - name: workingdir
          persistentVolumeClaim:
            claimName: tutorial
</code></pre>
</details>
<h3 id="ui"><a class="header" href="#ui">UI</a></h3>
<p>对于很多 CRD，TensorStack 的 Web 控制台（console）提供了通过表单（form）创建其实例的方式。</p>
<p>例如，可使用如下表单创建 Notebook 实例：</p>
<figure class="screenshot">
  <img alt="create-notebook-detail" src="./assets/get-started/training-first-model/create-notebook-detail.png" />
  <figcaption>图 4：使用 UI 创建 Notebook。 </figcaption>
</figure>
<h2 id="下一步"><a class="header" href="#下一步">下一步</a></h2>
<ul>
<li>跟从<a href="./get-started/index.html">快速开始</a>的内容，快速完成基本的体验。</li>
<li>阅读 <a href="./modules/building/index.html">AI 开发和应用</a>章节，以学习 AI 开发相关的概念。</li>
<li>阅读<a href="./background.html">背景</a>，了解产品的技术架构和设计思路等。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="快速入门"><a class="header" href="#快速入门">快速入门</a></h1>
<p>欢迎使用“TensorStack AI 平台”！</p>
<p>本节将带领你快速体验 “TensorStack AI 平台” 的基本功能，并完成一个简单的 AI 项目，涵盖模型的构建、训练、部署等。</p>
<p>使用 TensorStack AI 平台之前，你需要：</p>
<ul>
<li>拥有一个<a href="get-started/../modules/security/account.html">账户</a>，以登录系统。</li>
<li>成为一个<a href="get-started/../tasks/add-project-member.html">项目</a>的成员，以使用集群资源。</li>
</ul>
<aside class="note tip">
<div class="title">提示</div>
<p>如果你没有账户或不是任何项目的成员，请联系平台的管理员。</p>
</aside>
<aside class="note info">
<div class="title">项目</div>
<p><strong>项目（Project）</strong> 是 TensorStack AI 平台提供的一种机制，旨在有效利用集群资源，实现多用户、多项目共享使用集群。项目可被视为为用户准备的“虚拟集群”。详细信息请参阅<a href="get-started/../modules/security/project.html">项目</a>。</p>
</aside>
<h2 id="下一步-1"><a class="header" href="#下一步-1">下一步</a></h2>
<ul>
<li>使用 Notebook <a href="get-started/./training-first-model.html">训练你的第一个模型</a></li>
<li>使用 Job <a href="get-started/./parallel-training.html">进行并行训练</a></li>
<li>使用 SimpleMLService <a href="get-started/./deploy-model.html">部署模型</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="训练你的第一个模型"><a class="header" href="#训练你的第一个模型">训练你的第一个模型</a></h1>
<p>本教程带领你使用 <a href="get-started/../modules/building/notebook.html">Notebook</a>，来构建和训练一个 AI 模型。</p>
<h2 id="创建-notebook"><a class="header" href="#创建-notebook">创建 Notebook</a></h2>
<p>在 TensorStack AI 平台首页，点击<strong>模型构建</strong>进入构建控制台（Build Console）。</p>
<figure class="screenshot">
  <img alt="landing-page" src="get-started/../assets/get-started/training-first-model/landing-page.png" />
  <figcaption>图 1：平台首页。</figcaption>
</figure>
<p>构建控制台（Build Console）的总览页面展示了多种<strong>资源</strong>，你可以点击右上角的按钮切换 Project，也可以点击<strong>事件</strong>和<strong>配额</strong>标签页以查看当前 Project 最近发生的事件以及计算资源（CPU、内存、GPU 等）配额。</p>
<aside class="note info">
<div class="title"> API 资源 </div>
<p><strong>API 资源（resources）</strong>，<strong>Kubernetes 资源（resources）</strong>，或者简称<strong>资源（resources）</strong>：此术语用于统称 Kubernetes 管理的原生或通过 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">CRD</a> 扩展的实体（entity）类型（type，kind）。这些资源包括原生标准类型，如 <code>Pod</code>、<code>Deployment</code>、<code>Service</code>、<code>ConfigMap</code>，以及通过 CRD 定义的任何自定义资源，例如 TensorStack 提供的 <code>Notebook</code>。它们是 TensorStack AI 平台功能的基本构建模块。</p>
<p>需要注意的是，<strong>计算资源（compute resources）</strong>，例如 CPU、内存、GPU，也经常被简称为<strong>资源</strong>，但一般可根据上下文判断其具体所指。</p>
</aside>
<figure class="screenshot">
  <img alt="project" src="get-started/../assets/get-started/training-first-model/overview.png" />
  <figcaption>图 2：构建控制台（Build Console）。</figcaption>
</figure>
<h3 id="创建-pvc"><a class="header" href="#创建-pvc">创建 PVC</a></h3>
<p>在创建 Notebook 之前，首先需要创建一个用于存储文件的 PVC（持久卷）。在左侧的导航菜单中点击<strong>存储 &gt; 持久卷</strong>进入 PVC 管理页面，然后点击右上角的<strong>创建 PVC</strong>。</p>
<aside class="note info">
<div class="title">PVC</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/zh/docs/concepts/storage/persistent-volumes/">PVC（PersistentVolumeClaim，持久卷申领）</a>是一种 Kubernetes 原生 <strong>API 资源</strong>，表示用户对存储的请求。参阅<a href="get-started/../tasks/manage-pvc.html">管理 PVC</a> 以进一步了解如何在平台上使用 PVC。</p>
</aside>
<figure class="screenshot">
  <img alt="project" src="get-started/../assets/get-started/training-first-model/create-pvc.png" />
  <figcaption>图 3：创建 PVC。</figcaption>
</figure>
<p>在 PVC 创建页面，如下填写各个参数：</p>
<ul>
<li><strong>Name</strong> 填写 <code>mnist</code>。</li>
<li><strong>Size</strong> 填写 <code>1Gi</code>。</li>
</ul>
<p>其他参数保持默认即可。完成之后，点击<strong>创建</strong>。</p>
<figure class="screenshot">
  <img alt="project" src="get-started/../assets/get-started/training-first-model/create-pvc-detail.png" />
  <figcaption>图 4：填写 PVC 参数。</figcaption>
</figure>
<p>在跳转回到 PVC 管理页面之后，可点击右上角的<strong>刷新图标</strong>来手动刷新 PVC 状态。下图展示 PVC <code>mnist</code> 已经创建完成。</p>
<figure class="screenshot">
  <img alt="project" src="get-started/../assets/get-started/training-first-model/create-pvc-finish.png" />
  <figcaption>图 5：PVC 管理页面。</figcaption>
</figure>
<h3 id="创建-notebook-1"><a class="header" href="#创建-notebook-1">创建 Notebook</a></h3>
<p>在左侧的导航菜单中点击<strong>构建 &gt; Notebook</strong> 进入 Notebook 管理页面，然后点击右上角的<strong>创建 Notebook</strong>。</p>
<aside class="note info">
<div class="title">Notebook</div>
<p><a href="get-started/../modules/building/notebook.html">Notebook</a> 是一种 CRD 形式的 <strong>API 资源</strong>，用于在集群中运行在线交互式开发环境的服务（例如 JupyterLab、RStudio），同时提供 GPU 使用、SSH 访问等补充功能。</p>
</aside>
<figure class="screenshot">
  <img alt="create-notebook" src="get-started/../assets/get-started/training-first-model/create-notebook.png" />
  <figcaption>图 6：Notebook 创建页面。</figcaption>
</figure>
<p>在 Notebook 创建页面，如下填写各个参数：</p>
<ul>
<li><strong>名称</strong>填写 <code>mnist</code>。</li>
<li><strong>镜像类型</strong>选择 <code>Jupyter</code>，<strong>镜像</strong>选择 <code>t9kpublic/torch-2.1.0-notebook:1.77.1</code>。</li>
<li><strong>存储卷</strong>选择 <code>mnist</code>。</li>
<li><strong>调度器</strong>选择<strong>默认调度器</strong>，<strong>模板</strong>选择 <strong>large</strong>。</li>
</ul>
<p>完成之后，点击<strong>创建</strong>。</p>
<figure class="screenshot">
  <img alt="create-notebook-detail" src="get-started/../assets/get-started/training-first-model/create-notebook-detail.png" />
  <figcaption>图 7：Notebook 创建详情页面。</figcaption>
</figure>
<aside class="note info">
<div class="title">调度器</div>
<p>调度器负责将工作负载调度到合适的节点上以运行。平台支持 Kubernetes 的默认调度器 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler">kube-scheduler</a>，同时提供了更加强大的 T9k 调度器。详情请参阅<a href="get-started/../modules/scheduling/index.html">计算资源</a>。</p>
</aside>
<p>在跳转回到 Notebook 管理页面之后，等待刚才创建的 Notebook 准备就绪。第一次拉取镜像可能会花费较长的时间，具体取决于集群的网络状况。点击右上角的<strong>刷新图标</strong>来手动刷新 Notebook 状态，待 Notebook 开始运行之后，点击右侧的<strong>打开</strong>进入其前端页面。</p>
<figure class="screenshot">
  <img alt="connect-notebook" src="get-started/../assets/get-started/training-first-model/connect-notebook.png" />
  <figcaption>图 8：在 Notebook 管理页面打开 Notebook。</figcaption>
</figure>
<p>现在 Notebook 已经可以使用了，你可以在这里进行模型的开发与测试。</p>
<figure class="screenshot">
  <img alt="jupyter" src="get-started/../assets/get-started/training-first-model/jupyter.png" />
  <figcaption>图 9：使用 Notebook。</figcaption>
</figure>
<h2 id="使用-notebook-训练模型"><a class="header" href="#使用-notebook-训练模型">使用 Notebook 训练模型</a></h2>
<aside class="note tip">
<div class="title">提示</div>
<p>如果你之前从未使用过 JupyterLab，建议在使用之前先阅读<a target="_blank" rel="noopener noreferrer" href="https://jupyterlab.readthedocs.io/en/stable/">官方文档</a>以熟悉 JupyterLab 的功能特性以及基本操作。</p>
</aside>
<p>在 Notebook 的前端页面，点击左上角的 <strong>+</strong>，然后点击 Notebook 下的 <strong>Python3</strong> 以新建一个 <code>.ipynb</code> 文件。</p>
<figure class="screenshot">
  <img alt="jupyter-create-notebook" src="get-started/../assets/get-started/training-first-model/jupyter-create-notebook.png" />
  <figcaption>图 10：在 Notebook 中创建 .ipynb 文件。</figcaption>
</figure>
<p>复制下面的训练脚本到该 <code>.ipynb</code> 文件的代码框中。该脚本基于 PyTorch 框架，建立一个简单的卷积神经网络模型，并使用 MNIST 数据集的手写数字图像进行训练和测试。</p>
<details><summary><code class="hljs">torch_mnist.py</code></summary>
<pre><code class="language-python">import os
import shutil

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
from torchvision import datasets, transforms


class Net(nn.Module):

    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.conv3 = nn.Conv2d(64, 64, 3, 1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dense1 = nn.Linear(576, 64)
        self.dense2 = nn.Linear(64, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = F.relu(self.conv3(x))
        x = torch.flatten(x, 1)
        x = F.relu(self.dense1(x))
        output = F.softmax(self.dense2(x), dim=1)
        return output


def train():
    global global_step
    for epoch in range(1, epochs + 1):
        model.train()
        for step, (data, target) in enumerate(train_loader, 1):
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

            if step % 500 == 0:
                train_loss = loss.item()
                print('epoch {:d}/{:d}, batch {:5d}/{:d} with loss: {:.4f}'.
                      format(epoch, epochs, step, steps_per_epoch, train_loss))
                global_step = (epoch - 1) * steps_per_epoch + step

                writer.add_scalar('train/loss', train_loss, global_step)

        scheduler.step()
        global_step = epoch * steps_per_epoch
        test(val=True, epoch=epoch)


def test(val=False, epoch=None):
    label = 'val' if val else 'test'
    model.eval()
    running_loss = 0.0
    correct = 0

    with torch.no_grad():
        loader = val_loader if val else test_loader
        for data, target in loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            loss = criterion(output, target)
            running_loss += loss.item()
            prediction = output.max(1)[1]
            correct += (prediction == target).sum().item()

    test_loss = running_loss / len(loader)
    test_accuracy = correct / len(loader.dataset)
    msg = '{:s} loss: {:.4f}, {:s} accuracy: {:.4f}'.format(
        label, test_loss, label, test_accuracy)
    if val:
        msg = 'epoch {:d}/{:d} with '.format(epoch, epochs) + msg
    print(msg)

    writer.add_scalar('{:s}/loss'.format(label), test_loss, global_step)
    writer.add_scalar('{:s}/accuracy'.format(label), test_accuracy,
                      global_step)


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
kwargs = {
    'num_workers': 1,
    'pin_memory': True
} if torch.cuda.is_available() else {}

torch.manual_seed(1)

model = Net().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)

dataset_path = './data'
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5), (0.5))])
train_dataset = datasets.MNIST(root=dataset_path,
                               train=True,
                               download=True,
                               transform=transform)
train_dataset, val_dataset = torch.utils.data.random_split(
    train_dataset, [48000, 12000])
test_dataset = datasets.MNIST(root=dataset_path,
                              train=False,
                              download=True,
                              transform=transform)
train_loader = torch.utils.data.DataLoader(train_dataset,
                                           batch_size=32,
                                           shuffle=True,
                                           **kwargs)
val_loader = torch.utils.data.DataLoader(val_dataset,
                                         batch_size=400,
                                         shuffle=False,
                                         **kwargs)
test_loader = torch.utils.data.DataLoader(test_dataset,
                                          batch_size=1000,
                                          shuffle=False,
                                          **kwargs)

log_dir = './log'
if os.path.exists(log_dir):
    shutil.rmtree(log_dir, ignore_errors=True)
writer = SummaryWriter(log_dir)

global_step = 0
epochs = 10
steps_per_epoch = len(train_loader)
train()
test()

torch.save(model.state_dict(), 'model_state_dict.pt')
</code></pre>
</details>
<p>点击上方的运行按钮，可以看到训练开始进行：</p>
<figure class="screenshot">
  <img alt="jupyter-training" src="get-started/../assets/get-started/training-first-model/jupyter-training.png" />
  <figcaption>图 11：在 Notebook 中运行训练。</figcaption>
</figure>
<p>训练结束后，点击左上角的<strong>新建文件夹按钮</strong>，为新文件夹命名 <strong>first-model</strong>，并将当前教程产生的所有文件拖拽移动到其中。</p>
<figure class="screenshot">
  <img alt="create-folder" src="get-started/../assets/get-started/training-first-model/create-folder.png" />
  <figcaption>图 12：在 Notebook 中创建文件夹。</figcaption>
</figure>
<h2 id="下一步-2"><a class="header" href="#下一步-2">下一步</a></h2>
<ul>
<li>针对同样的模型，<a href="get-started/./parallel-training.html">使用 Job 进行并行训练</a></li>
<li>全面了解<a href="get-started/../modules/building/index.html">模型构建</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="进行并行训练"><a class="header" href="#进行并行训练">进行并行训练</a></h1>
<p>本教程带领你使用 <a href="get-started/../modules/jobs/pytorchtrainingjob.html">PyTorchTrainingJob</a>，将教程<a href="get-started/./training-first-model.html">训练你的第一个模型</a>中的模型训练改进为使用 GPU 加速的数据并行训练。</p>
<h2 id="在-notebook-中准备并行训练"><a class="header" href="#在-notebook-中准备并行训练">在 Notebook 中准备并行训练</a></h2>
<p>回到 Notebook <code>mnist</code>，在 HOME 目录（即左侧边栏文件浏览器显示的根目录 <code>/</code>）下，点击左上角的 <strong>+</strong>，然后点击 <strong>Other</strong> 下的 <strong>Python File</strong> 以新建一个 Python 脚本文件。</p>
<figure class="screenshot">
  <img alt="create-py-file" src="get-started/../assets/get-started/parallel-training/create-py-file.png" />
</figure>
<p>向该文件复制以下代码，并将其命名为 <code>torch_mnist_trainingjob.py</code>。该脚本在上一篇教程的脚本的基础上进行了修改以支持数据并行训练。</p>
<details><summary><code class="hljs">torch_mnist_trainingjob.py</code></summary>
<pre><code class="language-python">import argparse
import logging
import os
import shutil

import torch
import torch.distributed as dist
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.parallel import DistributedDataParallel as DDP
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
from torchvision import datasets, transforms

parser = argparse.ArgumentParser(
    description='DDP training of PyTorch model for MNIST.')
parser.add_argument(
    '--backend',
    type=str,
    help='Distributed backend',
    choices=[dist.Backend.GLOO, dist.Backend.NCCL, dist.Backend.MPI],
    default=dist.Backend.GLOO)
parser.add_argument('--log_dir',
                    type=str,
                    help='Path of the TensorBoard log directory.')
parser.add_argument('--save_path',
                    type=str,
                    help='Path of the saved model.')
parser.add_argument('--no_cuda',
                    action='store_true',
                    default=False,
                    help='Disable CUDA training.')
logging.basicConfig(format='%(message)s', level=logging.INFO)


class Net(nn.Module):

    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.conv3 = nn.Conv2d(64, 64, 3, 1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dense1 = nn.Linear(576, 64)
        self.dense2 = nn.Linear(64, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = F.relu(self.conv3(x))
        x = torch.flatten(x, 1)
        x = F.relu(self.dense1(x))
        output = F.softmax(self.dense2(x), dim=1)
        return output


def train():
    global global_step
    for epoch in range(1, epochs + 1):
        model.train()
        for step, (data, target) in enumerate(train_loader, 1):
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

            if step % (500 // world_size) == 0:
                train_loss = loss.item()
                logging.info(
                    'epoch {:d}/{:d}, batch {:5d}/{:d} with loss: {:.4f}'.
                    format(epoch, epochs, step, steps_per_epoch, train_loss))
                global_step = (epoch - 1) * steps_per_epoch + step

                if args.log_dir and rank == 0:
                    writer.add_scalar('train/loss', train_loss, global_step)

        scheduler.step()
        global_step = epoch * steps_per_epoch
        test(val=True, epoch=epoch)


def test(val=False, epoch=None):
    label = 'val' if val else 'test'
    model.eval()
    running_loss = 0.0
    correct = 0

    with torch.no_grad():
        loader = val_loader if val else test_loader
        for data, target in loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            loss = criterion(output, target)
            running_loss += loss.item()
            prediction = output.max(1)[1]
            correct += (prediction == target).sum().item()

    test_loss = running_loss / len(loader)
    test_accuracy = correct / len(loader.dataset)
    msg = '{:s} loss: {:.4f}, {:s} accuracy: {:.4f}'.format(
        label, test_loss, label, test_accuracy)
    if val:
        msg = 'epoch {:d}/{:d} with '.format(epoch, epochs) + msg
    logging.info(msg)

    if args.log_dir and rank == 0:
        writer.add_scalar('{:s}/loss'.format(label), test_loss, global_step)
        writer.add_scalar('{:s}/accuracy'.format(label), test_accuracy,
                          global_step)


if __name__ == '__main__':
    args = parser.parse_args()

    logging.info('Using distributed PyTorch with %s backend', args.backend)
    dist.init_process_group(backend=args.backend)
    rank = dist.get_rank()
    world_size = dist.get_world_size()
    local_rank = int(os.environ['LOCAL_RANK'])

    use_cuda = not args.no_cuda and torch.cuda.is_available()
    if use_cuda:
        logging.info('Using CUDA')
    device = torch.device('cuda:{}'.format(local_rank) if use_cuda else 'cpu')
    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}

    torch.manual_seed(1)

    dataset_path = os.path.join(os.path.dirname(os.path.realpath(__file__)),
                                'data')
    # rank 0 downloads datasets in advance
    if rank == 0:
        datasets.MNIST(root=dataset_path, train=True, download=True)

    model = Net().to(device)
    model = DDP(model)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001 * world_size)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)

    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5), (0.5))])
    train_dataset = datasets.MNIST(root=dataset_path,
                                   train=True,
                                   download=False,
                                   transform=transform)
    train_dataset, val_dataset = torch.utils.data.random_split(
        train_dataset, [48000, 12000])
    test_dataset = datasets.MNIST(root=dataset_path,
                                  train=False,
                                  download=False,
                                  transform=transform)
    train_loader = torch.utils.data.DataLoader(train_dataset,
                                               batch_size=32 * world_size,
                                               shuffle=True,
                                               **kwargs)
    val_loader = torch.utils.data.DataLoader(val_dataset,
                                             batch_size=400,
                                             shuffle=False,
                                             **kwargs)
    test_loader = torch.utils.data.DataLoader(test_dataset,
                                              batch_size=1000,
                                              shuffle=False,
                                              **kwargs)

    if args.log_dir and rank == 0:
        if os.path.exists(args.log_dir):
            shutil.rmtree(args.log_dir, ignore_errors=True)
        writer = SummaryWriter(args.log_dir)

    global_step = 0
    epochs = 10
    steps_per_epoch = len(train_loader)
    train()
    test()

    if rank == 0:
        torch.save(model.state_dict(), args.save_path)
</code></pre>
</details>
<h2 id="创建-job-进行并行训练"><a class="header" href="#创建-job-进行并行训练">创建 Job 进行并行训练</a></h2>
<p>回到模型构建控制台，在左侧的导航菜单中点击<strong>构建 &gt; Job</strong> 进入 Job 管理页面，然后点击右上角的<strong>创建 Job &gt; PyTorch</strong>。</p>
<aside class="note info">
<div class="title">Job</div>
<p><a href="get-started/(../modules/jobs/index.html">Job</a> 是 TensorStack 提供的一组 CRD，用于支持各种规模的批处理任务。</p>
<p>PyTorchTrainingJob 是服务于 PyTorch 并行训练框架的执行机器学习任务的 Job。</p>
</aside>
<figure class="screenshot">
  <img alt="create-job" src="get-started/../assets/get-started/parallel-training/create-job.png" />
</figure>
<p>为了简化操作，在 Job 创建页面，点击<strong>预览 YAML</strong>，然后直接复制下面的 YAML 配置文件并粘贴到编辑框中，然后点击<strong>创建</strong>。</p>
<details><summary><code class="hljs">job.yaml</code></summary>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: PyTorchTrainingJob
metadata:
  name: mnist                    # Job 名称
spec:
  tensorboardSpec:               # TensorBoard 服务器规约
    resources:
      limits:
        cpu: 1
        memory: 1Gi
    trainingLogFilesets:
      - t9k://pvc/mnist/log      # 日志文件路径
    image: tensorflow/tensorflow:2.14.0
                                 # TensorBoard 服务器使用的镜像
  torchrunConfig:
    enabled: true                # torchrun 启动
    maxRestarts: 3
    procPerNode: &quot;4&quot;             # 每个副本启动的进程数
    rdzvBackend: c10d
    extraOptions: []
  replicaSpecs:
    - type: node
      replicas: 1                # 副本数
      restartPolicy: ExitCode
      template:
        spec:
          securityContext:
            runAsUser: 1000
          containers:
            - name: pytorch
              image: t9kpublic/pytorch-1.13.0:sdk-0.5.2
                                       # 容器的镜像
              workingDir: /t9k/mnt     # 工作路径
              args:                    # `python`命令的参数
                - torch_mnist_trainingjob.py
                - &quot;--log_dir&quot;
                - &quot;log&quot;
                - &quot;--save_path&quot;
                - &quot;./model_state_dict.pt&quot;
                - &quot;--backend&quot;
                - &quot;nccl&quot;
              resources:               # 计算资源
                limits:                # 限制量
                  cpu: 8               # CPU
                  memory: 16Gi         # 内存
                  nvidia.com/gpu: 4    # GPU
                requests:              # 请求量
                  cpu: 4
                  memory: 8Gi
                  nvidia.com/gpu: 4
              volumeMounts:
                - name: data
                  mountPath: /t9k/mnt  # 挂载路径
                - name: dshm
                  mountPath: /dev/shm  # 挂载共享内存
          volumes:
            - name: data
              persistentVolumeClaim:
                claimName: mnist       # 要挂载的 PVC
            - name: dshm
              emptyDir:
                medium: Memory
</code></pre>
</details>
<figure class="screenshot">
  <img alt="create-job-detail" src="get-started/../assets/get-started/parallel-training/create-job-detail.png" />
</figure>
<p>在跳转回到 Job 管理页面之后，等待刚才创建的 Job 就绪。第一次拉取镜像可能会花费较长的时间，具体取决于集群的网络状况。点击右上角的<strong>刷新图标</strong>来手动刷新 Job 状态，待 Job 开始运行之后，点击其<strong>名称</strong>进入详情页面。</p>
<figure class="screenshot">
  <img alt="job-created" src="get-started/../assets/get-started/parallel-training/job-created.png" />
</figure>
<p>可以看到，Job 及其创建的 4 个 Worker（工作器）正在运行。</p>
<figure class="screenshot">
  <img alt="job-detail" src="get-started/../assets/get-started/parallel-training/job-detail.png" />
</figure>
<p>切换到<strong>副本</strong>标签页，点击副本的<strong>日志</strong>会显示其命令行输出，可以看到并行训练的当前进度。</p>
<figure class="screenshot">
  <img alt="job-log-view" src="get-started/../assets/get-started/parallel-training/job-log-view.png" />
</figure>
<figure class="screenshot">
  <img alt="job-log" src="get-started/../assets/get-started/parallel-training/job-log.png" />
</figure>
<p><code>torch_mnist_trainingjob.py</code> 训练脚本在训练过程中添加了 TensorBoard 回调并将日志保存在了 <code>log</code> 目录下，Job 相应地启动了一个 TensorBoard 服务器用于可视化展示这些数据。点击 TensorBoard 右侧的 <strong>Running</strong> 进入其前端页面。</p>
<figure class="screenshot">
  <img alt="tensorboard" src="get-started/../assets/get-started/parallel-training/tensorboard.png" />
</figure>
<p>一段时间之后，Job 的状态变为 <strong>Done</strong>，表示训练已经成功完成。回到 Notebook mnist，将当前教程产生的所有文件移动到名为 <code>parallel-training</code> 的新文件夹下。</p>
<h2 id="下一步-3"><a class="header" href="#下一步-3">下一步</a></h2>
<ul>
<li>将训练完成的模型<a href="get-started/./deploy-model.html">部署为推理服务</a></li>
<li>了解 <a href="get-started/../modules/jobs/index.html">Job</a></li>
<li>进一步学习如何<a href="get-started/../tasks/model-training.html">进行并行训练</a></li>
<li>学习如何<a href="get-started/../tasks/hyperparameter-tuning.html">进行超参数优化</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="部署模型"><a class="header" href="#部署模型">部署模型</a></h1>
<p>本教程带领你使用 <a href="get-started/../modules/deployment/simplemlservice.html">SimpleMLService</a>，部署模型为推理服务。</p>
<p>在教程<a href="get-started/./training-first-model.html">训练你的第一个模型</a>和<a href="get-started/./parallel-training.html">进行并行训练</a>中，训练完成的模型都被保存为文件 <code>model_state_dict.pt</code>，这两个模型文件所对应的模型是相同的。本教程将部署这个模型为推理服务。</p>
<h2 id="准备模型文件"><a class="header" href="#准备模型文件">准备模型文件</a></h2>
<p>这里我们使用 <a target="_blank" rel="noopener noreferrer" href="https://github.com/pytorch/serve">TorchServe</a> 部署 PyTorch 模型。回到 Notebook <code>mnist</code>，在 HOME 目录（即左侧边栏文件浏览器显示的根目录 <code>/</code>）下新建以下文件：</p>
<details><summary><code class="hljs">model.py</code></summary>
<pre><code class="language-python">import torch
from torch import nn
import torch.nn.functional as F


class Net(nn.Module):

    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.conv3 = nn.Conv2d(64, 64, 3, 1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dense1 = nn.Linear(576, 64)
        self.dense2 = nn.Linear(64, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = F.relu(self.conv3(x))
        x = torch.flatten(x, 1)
        x = F.relu(self.dense1(x))
        output = F.log_softmax(self.dense2(x), dim=1)
        return output
</code></pre>
</details>
<details><summary><code class="hljs">handler.py</code></summary>
<pre><code class="language-python">from torchvision import transforms
from ts.torch_handler.image_classifier import ImageClassifier
from torch.profiler import ProfilerActivity


class MNISTDigitClassifier(ImageClassifier):
    image_processing = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5), (0.5))])

    def __init__(self):
        super().__init__()
        self.profiler_args = {
            &quot;activities&quot;: [ProfilerActivity.CPU],
            &quot;record_shapes&quot;: True,
        }

    # def postprocess(self, data):
    #     return data.argmax(1).tolist()
</code></pre>
</details>
<p>点击左上角的 <strong>+</strong>，然后点击 Other 下的 <strong>Terminal</strong> 以新建一个终端。</p>
<figure class="screenshot">
  <img alt="create-terminal" src="get-started/../assets/get-started/deployment/create-terminal.png" />
</figure>
<p>执行以下命令以打包一个 torch 的模型包（model archive）：</p>
<pre><code class="language-bash"># 使用 Notebook 中训练的模型
torch-model-archiver --model-name mnist \
  --version 1.0 \
  --model-file model.py \
  --handler handler.py \
  --serialized-file first-model/model_state_dict.pt

# 如果使用 Job 中训练的模型，切换参数
# --serialized-file parallel-training/model_state_dict.pt
</code></pre>
<h2 id="部署推理服务"><a class="header" href="#部署推理服务">部署推理服务</a></h2>
<p>在 TensorStack AI 平台首页，点击<strong>Deploy</strong>进入模型部署控制台。</p>
<figure class="screenshot">
  <img alt="landing-page" src="get-started/../assets/get-started/deployment/landing-page.png" />
</figure>
<p>模型部署控制台的总览页面展示了当前部署服务的数量以及资源使用情况。在左侧的导航菜单中点击<strong>部署 &gt; SimpleMLService</strong>，点击右上角的 <strong>+</strong> 弹出创建对话框，然后复制下面的 YAML 配置文件并粘贴到编辑框中，最后点击<strong>创建</strong>。</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: SimpleMLService
metadata:
  name: mnist
spec:
  replicas: 1
  storage:
    pvc:
      containerPath: /var/lib/t9k/models
      name: mnist
      subPath: .
  pytorch:
    image: pytorch/torchserve:0.9.0-cpu
    modelsFlag: &quot;mnist=mnist.mar&quot;
    resources: 
      requests:
        cpu: 1
        memory: 1Gi
</code></pre>
<figure class="screenshot">
  <img alt="create-simplemlservice" src="get-started/../assets/get-started/deployment/create-simplemlservice.png" />
</figure>
<aside class="note info">
<div class="title">SimpleMLService</div>
<p><a href="get-started/../modules/deployment/simplemlservice.html">SimpleMLService</a> 是平台提供的用于部署模型推理服务的 CRD。与同样用于部署推理服务的 <a href="get-started/../modules/deployment/mlservice.html">MLService</a> 相比，SimpleMLService 更加精简，适用于快速测试。</p>
</aside>
<p>在跳转回到 SimpleMLService 管理页面之后，等待刚才创建的 SimpleMLService 准备就绪。</p>
<ul>
<li>第一次拉取镜像可能会花费较长的时间，具体取决于集群的网络状况。</li>
<li>点击右上角的<strong>刷新按钮</strong>以手动刷新 SimpleMLService 状态。</li>
</ul>
<h2 id="使用推理服务"><a class="header" href="#使用推理服务">使用推理服务</a></h2>
<h3 id="查看推理服务地址"><a class="header" href="#查看推理服务地址">查看推理服务地址</a></h3>
<p>待 SimpleMLService 就绪之后，点击其<strong>名称</strong>进入详情页面。</p>
<figure class="screenshot">
  <img alt="enter-simplemlservice" src="get-started/../assets/get-started/deployment/enter-simplemlservice.png" />
</figure>
<p>页面中展示的 DNS 即为推理服务地址，注意该地址只能从集群内部访问。</p>
<figure class="screenshot">
  <img alt="simplemlservice-detail" src="get-started/../assets/get-started/deployment/simplemlservice-detail.png" />
</figure>
<h3 id="访问推理服务"><a class="header" href="#访问推理服务">访问推理服务</a></h3>
<p>回到 Notebook <code>mnist</code>，在终端中执行以下命令以下载测试数据，并向推理服务发送请求。注意变量 <code>URL</code> 的值需要修改为实际部署的推理服务的地址。</p>
<pre><code class="language-sh"># 下载测试图像文件
wget https://t9k.github.io/user-manuals/assets/get-started/deployment/{0,1,2}.png

# 注意：此 URL 只适合在集群内当前项目（Project）内部（例如当前项目的 Notebook 中）访问使用
URL=&quot;http://mnist.demo.svc.cluster.local/v1/models/mnist:predict&quot;
curl -T 0.png $URL    # 或使用 `1.png`, `2.png`
</code></pre>
<p>响应体应是一个类似于下面的 JSON，其预测了图片最有可能是的 5 个数字以及相应的概率：</p>
<pre><code class="language-json">{
  &quot;0&quot;: 1.0,
  &quot;2&quot;: 1.7797361302828807e-16,
  &quot;9&quot;: 6.094195260341553e-19,
  &quot;6&quot;: 1.5410183526346253e-19,
  &quot;5&quot;: 7.889719768364669e-20
}
</code></pre>
<h2 id="清理"><a class="header" href="#清理">清理</a></h2>
<p>体验结束后，可将当前教程产生的所有文件移动到名为 <code>deployment</code> 的新文件夹下。</p>
<p>也可以将部署的推理服务删除：</p>
<pre><code class="language-bash"># optional, delete service if desired.
kubectl delete SimpleMLService mnist
</code></pre>
<h2 id="下一步-4"><a class="header" href="#下一步-4">下一步</a></h2>
<ul>
<li>了解<a href="get-started/../modules/deployment/index.html">模型部署</a></li>
<li>进一步学习如何<a href="get-started/../tasks/deploy-simplemlservice.html">部署简单推理服务</a></li>
<li>进一步学习如何<a href="get-started/../tasks/deploy-mlservice.html">部署用于生产环境的模型推理服务</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="ai-开发和应用"><a class="header" href="#ai-开发和应用">AI 开发和应用</a></h1>
<p>TensorStack AI 平台提供了一套完整、全面的工具和服务，对 AI 模型的构建、训练和部署提供全流程的支持，从而助力研究人员轻松、高效地实现 AI 项目，加速 AI 模型的研究、开发和应用。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>用户并不总是需要使用所有的功能模块。例如，用户可以直接使用集群的 “<a href="modules/./storage/index.html#%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8D%B7shared-filesystem-volumes">共享文件系统卷</a>” 来保存训练数据、模型本身等，而不需要使用 “<a href="modules/./asset-management.html">资产管理</a>” 模块。</p>
</aside>
<p>下图展示了在平台上开发一个深度学习模型的完整流程，以及各个模块发挥的功能：</p>
<figure>
  <img alt="ai-development" src="modules/../assets/modules/ai-development.drawio.svg" />
</figure>
<h2 id="下一步-5"><a class="header" href="#下一步-5">下一步</a></h2>
<ul>
<li>学习并使用：<a href="modules/./building/index.html">模型构建</a></li>
<li>部署模型为推理服务：<a href="modules/./deployment/index.html">模型部署</a></li>
<li>在集群中运行大规模计算：<a href="modules/./jobs/index.html">Job</a>、<a href="modules/./workflows/index.html">工作流</a></li>
<li>系统化 AI 计算的过程：<a href="modules/./asset-management.html">存储 AI 资产</a>、<a href="modules/./experiment-management.html">追踪 AI 实验</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="模型构建"><a class="header" href="#模型构建">模型构建</a></h1>
<p>一次完整的模型构建实验由许多步骤组成，包括准备实验数据、开发机器学习算法、选择训练超参数和执行训练等等。</p>
<p>TensorStack AI 平台的模型构建模块可以帮助你在分布式集群中快速方便地完成上述工作。模型构建模块的功能包括：</p>
<figure>
  <img alt="function" src="modules/building/../../assets/modules/building/function.drawio.svg" width="550" />
</figure>
<ul>
<li>Notebook：在线机器学习开发工具，你可以使用此模块直接在平台上开发机器学习脚本。</li>
<li>TensorBoard：机器学习可视化工具，实现训练过程可视化、模型可视化。</li>
<li>Job：一类任务型资源，其中包括 TensorFlowTrainingJob、MPIJob 等多种资源，使用各种机器学习框架、通信协议来进行分布式计算。其中 TensorFlowTrainingJob 和 PyTorchTrainingJob 集成了 TensorBoard 的创建功能，可以监控训练进程和查看训练结果。</li>
<li>AutoTune：超参数调优实验，在给定的搜索空间中查找最优的超参数组合以及机器学习网络结构。AutoTune 在进行超参数调优的过程中需要使用 TrainingJob（根据训练框架选用 TensorFlowTrainingJob、PyTorchTrainingJob 或 XGBoostTrainingJob）对超参数的效果进行验证。</li>
</ul>
<h2 id="架构"><a class="header" href="#架构">架构</a></h2>
<figure>
  <img alt="architecture" src="modules/building/../../assets/modules/building/architecture.drawio.svg" width="650" />
</figure>
<p>如上图所示：</p>
<ul>
<li>TensorStack CLI 是 TensorStack AI 平台所使用的命令行工具，可以用于操作几乎所有 TensorStack AI 平台的模块，包括模型构建。</li>
<li>Kubernetes API Server 是 Kubernetes 的重要组成部分，负责对外提供接口，接受对集群的操作请求。在此框架中，Kubernetes API Server 需要向模型构建模块提供集群中的资源信息，同时接收资源的创建、删除等请求。</li>
<li>红框中的内容为模型构建模块的组成部分：
<ul>
<li>控制台（Console）：模块的交互界面，你可以通过此界面使用模块的全部功能。</li>
<li>服务器（Server）：模块功能的提供者，为你提供查看、创建、修改和删除资源的接口。</li>
<li>控制器（Controller）：资源控制器，用于处理资源的创建和修改请求。</li>
</ul>
</li>
</ul>
<h2 id="下一步-6"><a class="header" href="#下一步-6">下一步</a></h2>
<ul>
<li>学习使用 <a href="modules/building/./notebook.html">Notebook</a></li>
<li>学习使用 <a href="modules/building/./tensorboard.html">TensorBoard</a></li>
<li>学习使用 <a href="modules/building/../jobs/index.html">T9k Job</a></li>
<li>学习使用 <a href="modules/building/./autotune.html">AutoTune</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="notebook"><a class="header" href="#notebook">Notebook</a></h1>
<p><a target="_blank" rel="noopener noreferrer" href="https://jupyterlab.readthedocs.io/en/latest/">JupyterLab</a> 是一款非常流行的机器学习开发工具，它通过友好易用的 Web 界面提供交互式计算环境，支持多种编程语言和执行环境，在机器学习、AI、数据处理、数值模拟、统计建模、数据可视化等领域被广泛使用。</p>
<p>用户可以使用 Notebook CRD 在集群中快速部署一个 JupyterLab 服务，同时本产品还提供 GPU 支持、SSH 访问支持等功能。</p>
</aside>
<aside class="note info">
<div class="title">信息</div>
<p>除了 Jupyter 系列的 Notebook，用户也可创建其他类型（<code>spec.type</code> 指定）的 Notebook，例如 RStudio。</p>
</aside>
<h2 id="创建-notebook-2"><a class="header" href="#创建-notebook-2">创建 Notebook</a></h2>
<p>下面是一个基本的 Notebook 配置示例：</p>
<pre><code class="language-yaml"># notebook-tutorial.yaml
apiVersion: tensorstack.dev/v1beta1
kind: Notebook
metadata:
  name: tutorial
spec:
  type: jupyter
  template:
    spec:
      containers:
        - name: notebook
          image: t9kpublic/torch-2.1.0-notebook:1.77.1
          volumeMounts:
            - name: workingdir
              mountPath: /t9k/mnt
          resources:
            requests:
              cpu: '8'
              memory: 16Gi
              nvidia.com/gpu: 1
            limits:
              cpu: '16'
              memory: 32Gi
              nvidia.com/gpu: 1
      volumes:
        - name: workingdir
          persistentVolumeClaim:
            claimName: tutorial
</code></pre>
<p>在该例中，<code>spec.template.spec</code> 字段定义所要创建的 Pod 的规约：</p>
<ol>
<li>指示 Pod 运行一个 <code>notebook</code> 容器 （<code>spec.template.containers</code>），该容器运行的镜像是 <code>t9kpublic/torch-2.1.0-notebook:1.77.1</code>，这是一个 <a href="modules/building/notebook.html#notebook%E9%95%9C%E5%83%8F">Notebook 镜像</a>；</li>
<li>通过 <code>spec.template.spec.volumes</code>，<code>spec.template.containers[].volumeMounts</code> 指示挂载网络文件系统 PVC <code>tutorial</code> 到 <code>/t9k/mnt</code>；</li>
<li>通过 <code>spec.template.spec.containers[].resources</code> 指定使用的 CPU、memory、GPU 资源 。</li>
</ol>
<h2 id="使用-gpu"><a class="header" href="#使用-gpu">使用 GPU</a></h2>
<p>Notebook 支持通过申请使用 GPU 资源，例如：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: Notebook
metadata:
  name: tutorial
spec:
  type: jupyter
  template:
    spec:
      containers:
        - name: notebook
          image: t9kpublic/torch-2.1.0-notebook:1.77.1
          volumeMounts:
            - name: workingdir
              mountPath: /t9k/mnt
          resources:
            limits:
              cpu: '16'
              memory: 32Gi
              nvidia.com/gpu: 1
          command: []
      volumes:
        - name: workingdir
          persistentVolumeClaim:
            claimName: tutorial
</code></pre>
<p>在该例中：</p>
<ul>
<li>申请使用 16 个 CPU、32Gi 内存以及一个 NVIDIA GPU；系统会自动将 Notebook 调度到集群中某个能提供这些资源的节点上。</li>
</ul>
<h2 id="ssh-访问"><a class="header" href="#ssh-访问">SSH 访问</a></h2>
<p>Notebook 提供运行 SSH Server 的支持。下面的 Notebook 示例运行一个支持 SSH 连接的 JupyterLab 镜像：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: Notebook
metadata:
  name: tutorial
spec:
  type: jupyter
  template:
    spec:
      containers:
        - name: notebook
          image: t9kpublic/torch-2.1.0-notebook:1.77.1
          volumeMounts:
            - name: workingdir
              mountPath: /t9k/mnt
          resources:
            limits:
              cpu: '16'
              memory: 32Gi
              nvidia.com/gpu: 1
      volumes:
        - name: workingdir
          persistentVolumeClaim:
            claimName: tutorial
  ssh:
    authorized_keys:
      - example-user
    enabled: true
    serviceType: ClusterIP
</code></pre>
<p>在该例中，用户：</p>
<ol>
<li>设置 <code>spec.ssh.enabled</code> 字段的值为 <code>true</code>，T9k 系统将会自动创建一个处理 SSH 请求的 <code>Service</code>；</li>
<li>通过 <code>spec.ssh.serviceType</code> 字段指定服务类型为 <code>ClusterIP</code>；</li>
<li>设置自动挂载存放在 <code>Secret/example-user</code> 中的用户 SSH key；</li>
</ol>
<p>使用此 SSH 服务需要通过 <a href="modules/building/../../tools/cli-t9k-pf/index.html">t9k-pf</a> 工具进行端口转发。</p>
<aside class="note">
<div class="title">注意</div>
<ol>
<li>Notebook 控制器会为所有 Notebook 创建名称前缀为 <code>managed-notebook-http</code> 的 Service，以支持用户通过 Web 访问 Juypter Notebook 的服务；</li>
<li>而前缀为 <code>managed-notebook-ssh</code> 的 Service 只会为 <code>spec.ssh.enabled</code> 字段的值为 <code>true</code> 的 Notebook 创建。</li>
</ol>
</aside>
<aside class="note info">
<div class="title">信息</div>
<p>SSH 访问支持允许用户直接在本地连接到 Notebook 环境，从而可以使用惯用的本地 IDE 进行开发工作。</p>
</aside>
<h2 id="资源回收"><a class="header" href="#资源回收">资源回收</a></h2>
<p>T9k 系统提供空闲 Notebook 资源回收的支持。系统在检测到 Notebook 处于空闲状态并超过一定时长时，就会自动删除工作负载以释放计算资源。目前，资源回收仅针对 Jupyter 类型的 Notebook，其他类型（例如 RStudio）的 Notebook 不会被回收。</p>
<p>管理员可设置回收策略，使得：</p>
<ul>
<li>Notebook 没有活跃运行超过 1h （管理员可修改此时长）后，标记该 Notebook 为 <code>Idle</code>。</li>
<li>Notebook 进入 <code>Idle</code> 状态超过 24h （管理员可修改此时长）后，删除该 Notebook 底层工作负载。</li>
</ul>
<p>如果需要再次使用该 Notebook，你可以在模型构建控制台中手动点击<strong>恢复</strong>按钮。</p>
<aside class="note info">
<div class="title">判定 Notebook 是否活跃</div>
<p>满足以下任一条件即为活跃：</p>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jupyter/jupyter/wiki/Jupyter-kernels">Jupyter ipykernel</a> 存在任务运行（即 .ipynb 文件中有代码块在运行）。</li>
<li>前端网页存在活动。</li>
<li>Notebook SSH 存在连接。</li>
</ul>
</aside>
<aside class="note info">
<div class="title">在不满足上述条件的情况下，保持 Notebook 活跃</div>
<ul>
<li>
<p>参考<a href="modules/building/../../tasks/develop-and-test-model/use-notebook.html#%E4%BD%BF%E7%94%A8-jupyter-notebook">使用 Jupyter Notebook</a> 创建 <code>active.ipynb</code> 文件并执行以下代码块：</p>
<pre><code class="language-python">import time

while True:
    time.sleep(60)
</code></pre>
</li>
</ul>
<p>如果你的任务运行完成，你可以手动停止该代码块的执行，以恢复空闲资源回收的功能。</p>
</aside>
<h2 id="notebook-镜像"><a class="header" href="#notebook-镜像">Notebook 镜像</a></h2>
<p>T9k 提供了一些预先构建的镜像，与 JupyterLab 原生镜像相比内置了更丰富的工具包，请参阅 <a href="modules/building/../../references/standard-images.html#notebook-%E6%A0%87%E5%87%86%E9%95%9C%E5%83%8F%E5%88%97%E8%A1%A8">Notebook 标准镜像列表</a>。</p>
<p>在这些镜像中：</p>
<ul>
<li>默认启动一个 JupyterLab 服务。</li>
<li>预装了 Python3 以及 <code>tensorflow</code>、<code>pytorch</code>、<code>keras</code>、<code>pandas</code>、<code>scikit-learn</code> 等常用 Python 包。</li>
<li>身份是一个名为 <code>t9kuser</code> 的非 <code>root</code> 用户（用户 ID 为 1000，组 ID 为 1000），<code>$HOME</code> 目录为 <code>/t9k/mnt</code>。</li>
<li>预装了 <code>tensorboard</code> 插件，你可以在网页中创建 <a target="_blank" rel="noopener noreferrer" href="https://www.tensorflow.org/tensorboard">TensorBoard</a> 以可视化数据。</li>
</ul>
<p>用户也可以自行构建镜像，并上载到镜像 registry 中供使用。</p>
<h2 id="下一步-7"><a class="header" href="#下一步-7">下一步</a></h2>
<p>用户可尝试如下功能：</p>
<ul>
<li><a href="modules/building/../../tasks/create-notebook.html">创建 Notebook</a></li>
<li><a href="modules/building/../../tasks/use-notebook.html">使用 Notebook</a></li>
<li><a href="modules/building/../../tasks/ssh-notebook.html">通过 SSH 远程使用 Notebook</a></li>
</ul>
<h2 id="参考"><a class="header" href="#参考">参考</a></h2>
<ul>
<li>T9k 提供的 <a href="modules/building/../../references/standard-images.html#notebook-%E6%A0%87%E5%87%86%E9%95%9C%E5%83%8F%E5%88%97%E8%A1%A8">Notebook 标准镜像列表</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://jupyterlab.readthedocs.io/en/stable/">JupyterLab 文档</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="tensorboard"><a class="header" href="#tensorboard">TensorBoard</a></h1>
<p>TensorBoard 是 TensorFlow 提供的一种可视化机器学习过程和结果的工具，功能强大且广泛应用于多种框架。</p>
<aside class="note info">
<div class="title">延伸阅读</div>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.tensorflow.org/tensorboard/get_started">TensorBoard 官方教程</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://pytorch.org/docs/stable/tensorboard.html">使用 TensorBoard 可视化 PyTorch 模型</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://keras.io/api/callbacks/tensorboard/">使用 TensorBoard 可视化 Keras 模型</a></li>
</ul>
</aside>
<p>你可以使用本产品在集群中一键部署 TensorBoard，可视化训练模型。</p>
<h2 id="创建-tensorboard"><a class="header" href="#创建-tensorboard">创建 TensorBoard</a></h2>
<p>下面是一个基本的 TensorBoard 配置示例：</p>
<pre><code class="language-yaml"># tensorboard-example.yaml
apiVersion: tensorstack.dev/v1beta1
kind: TensorBoard
metadata:
  name: pytorchtrainingjob-tensorboard
  namespace: t9k-example
spec:
  image: docker.mirrors.ustc.edu.cn/tensorflow/serving:2.6.0-gpu
  trainingLogFilesets:
  - t9k://pvc/pytorchtrainingjob-tensorboard-pvc/log
</code></pre>
<p>在该例中，TensorBoard 使用 <code>docker.mirrors.ustc.edu.cn/tensorflow/serving:2.6.0-gpu</code> 镜像，对名为 <code>pytorchtrainingjob-tensorboard-pvc</code> 的 PVC 中 <code>/log</code> 路径下的模型数据进行可视化。</p>
<h3 id="fileset"><a class="header" href="#fileset">FileSet</a></h3>
<p>FileSet 是一种特殊的资源定位符（URI），是一种用于定位多种存储技术中的资源的字符串。</p>
<p>FileSet 的格式为 <code>t9k://storage-type/storage-identity/path</code>，由下列四部分构成：</p>
<ul>
<li>协议：<code>t9k://</code>。</li>
<li>存储器类型：当前 FileSet 支持 PVC（在 FileSet 中写作 <code>pvc</code>） 和 MinIO（在 FileSet 中写作 <code>minio</code>) 两种存储器。</li>
<li>存储器定位方式：FileSet 使用 PVC 的名称来定位 PVC 存储器，使用记录了 MinIO 地址、用户名和密码的 Secret 来定位 MinIO 存储器。</li>
<li>数据在存储器中的路径：模型在存储器中的准确位置。</li>
</ul>
<p>下面是两个 FileSet 示例：</p>
<ul>
<li><code>t9k://pvc/pytorchtrainingjob-tensorboard-pvc/log/model</code> 表示：所指向的资源被存储在名为 <code>pytorchtrainingjob-tensorboard-pvc</code> 的 PVC 中的 <code>log/model</code> 路径下。</li>
<li><code>t9k://minio/secret-name/bucket1/log/model</code> 表示：所指向的资源被存储在一个 MinIO 中名为 <code>bucket1</code> 的 Bucket 中的 <code>log/model</code> 路径下，该 MinIO 的地址、用户名和密码被存储在名为 <code>secret-name</code> 的 Secret 中。</li>
</ul>
<aside class="note info">
<div class="title">信息</div>
<p>创建 MinIO Secret 的方法请参阅<a href="modules/building/../../tasks/manage-secret.html">管理 Secret</a>。</p>
<p>MinIO 的相关介绍（比如 Bucket 的含义）请参阅<a target="_blank" rel="noopener noreferrer" href="https://min.io/">官方介绍</a>。</p>
</aside>
<h2 id="trainingjob-自动创建-tensorboard"><a class="header" href="#trainingjob-自动创建-tensorboard">TrainingJob 自动创建 TensorBoard</a></h2>
<p>我们在 <a href="modules/building/../jobs/tensorflowtrainingjob.html#tensorboard-%E7%9A%84%E4%BD%BF%E7%94%A8">TensorFlowTrainingJob</a> 和 <a href="modules/building/../jobs/pytorchtrainingjob.html#tensorboard-%E7%9A%84%E4%BD%BF%E7%94%A8">PyTorchTrainingJob</a> 中集成了 TensorBoard 的创建，你可以在创建 TrainingJob 后直接进入 TensorBoard 监控训练进程和查看训练结果。</p>
<h2 id="资源回收-1"><a class="header" href="#资源回收-1">资源回收</a></h2>
<p>TensorBoard 提供空闲资源回收的支持，在检测到 TensorBoard 处于空闲状态并超过一定时长时，删除工作负载以释放计算资源。默认情况下（管理员可修改配置）：</p>
<ul>
<li>TensorBoard 无人使用超过 1h 后，标记该 TensorBoard 为 <code>Idle</code>。</li>
<li>TensorBoard 进入 <code>Idle</code> 状态超过 24h 后，删除该 TensorBoard 底层工作负载。</li>
</ul>
<p>如果需要再次使用该 TensorBoard，你可以在模型构建控制台中手动点击<strong>恢复</strong>按钮。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="autotune"><a class="header" href="#autotune">AutoTune</a></h1>
<p>为了降低 AI 开发门槛和逐渐实现机器学习自动化，TensorStack AI 平台提供了自动化机器学习 （AutoML）工具 AutoTune。AutoTune 具有以下特点：</p>
<ul>
<li>内置最新的自动机器学习算法，为用户自动地进行特征工程、神经网络架构搜索、超参调优和模型压缩。</li>
<li>提供可视化展示平台，实时跟踪超参数训练过程，以交互式图形和表格的形式刻画多个不同维度的信息，用户可以借此更好地比较、分析、决策出最优参数。</li>
<li>持海量实验数据的存储，让用户轻松地实现任意实验结果之间的比较。</li>
<li>融合领先的 AI 最佳实践，提供自动化、准确性和协作水平，提高企业 AI 生产效率。</li>
</ul>
<h2 id="基本结构"><a class="header" href="#基本结构">基本结构</a></h2>
<figure>
  <img alt="concept" src="modules/building/../../assets/modules/building/autotune/structure.drawio.svg" width="550" />
</figure>
<p>在上述结构图中：</p>
<ul>
<li>AutoTune Controller 是 AutoTuneExperiment 的控制器，可以看做是 AutoTune 实验的入口。用户在集群中创建 AutoTuneExperiment 资源后，由控制器创建 AutoTune Server 和 Web 来执行 AutoTune 实验。</li>
<li>AutoTune Server 是执行实验的主体，其中包括：
<ul>
<li>Optimizer：超参数调优器，在限定的搜索空间内用特定的调优算法选择合适的超参数组合。</li>
<li>Training Manager：训练任务管理器，使用 Optimizer 产生的超参数，创建 TrainingJob 进行训练，并将训练结果反馈给 Optimizer 用于下一次超参数选择。AutoTune 可以同时创建多组 TrainingJob 来测试不同的超参数组合以加快训练效率。目前 AutoTune 支持使用 <a href="modules/building/../jobs/tensorflowtrainingjob.html">TensorFlowTrainingJob</a>、<a href="modules/building/../jobs/pytorchtrainingjob.html">PyTorchTrainingJob</a> 和 <a href="modules/building/../jobs/xgboosttrainingjob.html">XGBoostTrainingJob</a> 进行训练。</li>
</ul>
</li>
<li>AutoTune Web 是 AutoTune 的可视化界面，你可以通过此界面实时查看实验状态，对比各组超参数对实验产生的影响。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="autotuneexperiment"><a class="header" href="#autotuneexperiment">AutoTuneExperiment</a></h1>
<p>你可以通过创建 AutoTuneExperiment 来实现自动优化模型超参数。</p>
<h2 id="创建-autotuneexperiment"><a class="header" href="#创建-autotuneexperiment">创建 AutoTuneExperiment</a></h2>
<p>下面是一个基本的 AutoTuneExperiment 示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: AutoTuneExperiment
metadata:
  name: experiment-sample
spec:
  maxExecSeconds: 7200
  maxTrialNum: 50
  trialConcurrency: 3
  searchSpace: |-
    {
      &quot;batch_size&quot;: {&quot;_type&quot;: &quot;choice&quot;, &quot;_value&quot;: [512, 1024, 2048, 4096, 8092]},
      &quot;learning_rate&quot;: {&quot;_type&quot;: &quot;choice&quot;, &quot;_value&quot;: [0.0001, 0.001, 0.01, 0.1]}
    }
  trainingConfig:
    type: tensorflow
    tasks:
      - type: worker
        replicas: 1
        template:
          spec:
            securityContext:
              runAsUser: 1000
            containers:
              - command:
                  - python3
                  - dist_mnist.py
                workingDir: /mnt/mnist-distributed
                imagePullPolicy: IfNotPresent
                image: t9kpublic/tensorflow-1.15.2:tuner-2.23
                name: tensorflow
  tuner:
    builtinTunerName: TPE
    classArgs: |-
      {
        &quot;optimize_mode&quot;: &quot;minimize&quot;, 
        &quot;constant_liar_type&quot;: &quot;min&quot;
      }
</code></pre>
<p>在该例中：</p>
<ul>
<li>使用 TensorFlowTrainingJob 进行训练（由 <code>trainingConfig</code> 字段指定，详细配置方法请参阅<a href="modules/building/autotuneexperiment.html#%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E6%94%AF%E6%8C%81">训练框架支持</a>）。</li>
<li>使用 TPE 算法进行超参数调优，算法的参数为 <code>{&quot;optimize_mode&quot;: &quot;minimize&quot;, &quot;constant_liar_type&quot;: &quot;min&quot;}</code>（由 <code>tuner</code> 字段指定，更多参数请参阅<a href="modules/building/./hpo-algorithm.html">超参数调优算法</a>）。</li>
<li>超参数的搜索空间为 <code>{&quot;batch_size&quot;: {&quot;_type&quot;: &quot;choice&quot;, &quot;_value&quot;: [512, 1024, 2048, 4096, 8092]},&quot;learning_rate&quot;: {&quot;_type&quot;: &quot;choice&quot;, &quot;_value&quot;: [0.0001, 0.001, 0.01, 0.1]}}</code>（由 <code>searchSpace</code> 字段指定，搜索空间的格式及含义请参阅<a href="modules/building/./autotune-search-space.html">搜索空间</a>）。</li>
<li>可以同时测试 3 组超参数，最大测试次数为 50（分别由 <code>trialConcurrency</code> 和 <code>maxTrialNum</code> 字段指定），实验的最大执行时间为 2 小时（7200 秒，由 <code>maxExecSeconds</code> 字段指定），如果时间超出，实验进入 <code>TIMEOUT</code> 状态。</li>
</ul>
<h2 id="aistore-的使用"><a class="header" href="#aistore-的使用">AIStore 的使用</a></h2>
<p>AutoTuneExperiment 支持将实验数据存储在 AIStore 中，通过设置 <code>spec.aistore</code> 字段以使用 AIStore 数据库，其中：</p>
<ul>
<li><code>spec.aistore.folder</code> 声明实验数据存储在哪个 AIStore 文件夹中，内容应填写文件夹的 ID。</li>
<li><code>spec.aistore.secret</code> 引用一个 K8s Secret，其中应记录 API Key，用于上传数据时进行身份验证。</li>
</ul>
<p>下面是一个存储 APIKey 的 Secret 示例：</p>
<pre><code class="language-yaml">apiVersion: v1
data:
  apikey: ZDQyMjJjZjUtMmI0Ni00Mjk2LWFiMzYtYWI4NmVhZGUwZjQx
kind: Secret
metadata:
  name: aistore-secret
type: Opaque
</code></pre>
<h2 id="搜索空间"><a class="header" href="#搜索空间">搜索空间</a></h2>
<p>搜索空间是实验过程中超参数的设置范围，AutoTuneExperiment 会在此范围中选择超参数进行训练，最后找出最优的超参数组合。</p>
<p>搜索空间是一个 JSON 结构，具体格式请参阅<a href="modules/building/./autotune-search-space.html">搜索空间</a>。</p>
<h2 id="训练框架支持"><a class="header" href="#训练框架支持">训练框架支持</a></h2>
<p>AutoTuneExperiment 支持对多种训练框架进行超参数的调优，包括 TensorFlow、PyTorch 和 XGBoost。</p>
<p>AutoTuneExperiment 通过设置 <code>spec.trainingConfig</code> 字段实现对上述框架的支持。其中：</p>
<ul>
<li><code>spec.trainingConfig.type</code> 可设置为 <code>tensorflow</code>、<code>pytorch</code> 和 <code>xgboost</code>，分别表示使用 TensorFlow、PyTorch 和 XGBoost 框架进行训练。</li>
<li><code>spec.trainingConfig.tasks</code> 字段的设置请根据所使用的框架种类分别参阅 <a href="modules/building/../jobs/tensorflowtrainingjob.html">TensorFlowTrainingJob</a>、<a href="modules/building/../jobs/pytorchtrainingjob.html">PyTorchTrainingJob</a> 和 <a href="modules/building/../jobs/xgboosttrainingjob.html">XGBoostTrainingJob</a>。</li>
</ul>
<h2 id="超参数调优算法"><a class="header" href="#超参数调优算法">超参数调优算法</a></h2>
<p>AutoTuneExperiment 在调参过程中需要使用超参数调优算法对超参数进行选择，对于不同的训练框架和不同的超参数种类，超参数调优算法的效率和效果也是不一样的。</p>
<p>算法根据功能和定义分为两类：</p>
<ul>
<li>Tuner 算法：超参数调优算法，用于选取合适的超参数组合。</li>
<li>Assessor 算法：训练评估算法，用于判断当前训练是否符合预期，如果不符合则终止训练。</li>
</ul>
<p>算法的详细介绍以及参数配置请参阅<a href="modules/building/./hpo-algorithm.html">超参数调优算法</a>。</p>
<h2 id="实验状态"><a class="header" href="#实验状态">实验状态</a></h2>
<p>AutoTuneExperiment 的生命周期包括以下五个阶段：</p>
<ul>
<li><code>PENDING</code>：AutoTune 的相关组件（包括 AutoTune Server 和 AutoTune Web）已经创建成功，等待控制器启动 AutoTuneExperiment。</li>
<li><code>RUNNING</code>：AutoTuneExperiment 运行中。</li>
<li><code>TIMEOUT</code>：如果达到最大执行时间（由 <code>spec.maxExecSeconds</code> 字段指定）后，实验仍未完成（实际训练次数小于 <code>maxTrialNum</code> 字段指定的训练次数），则实验超时，不再创建新的训练。</li>
<li><code>DONE</code>：AutoTuneExperiment 在最大执行时间内完成了 <code>maxTrialNum</code> 字段指定的训练次数（无论成功或失败），则实验完成。</li>
<li><code>ERROR</code>：AutoTuneExperiment 初始化阶段或运行阶段出现错误。</li>
</ul>
<figure>
  <img alt="phase" src="modules/building/../../assets/modules/building/autotune/phase.drawio.svg" width="350" />
</figure>
<h2 id="下一步-8"><a class="header" href="#下一步-8">下一步</a></h2>
<ul>
<li>了解如何<a href="modules/building/../../tasks/autotune.html">使用 AutoTune 进行超参数优化</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="搜索空间-1"><a class="header" href="#搜索空间-1">搜索空间</a></h1>
<p>搜索空间用于定义超参数的范围，AutoTune 会在这一范围内对超参数进行组合并测试，最后得到效果最好的一组训练。</p>
<h2 id="格式"><a class="header" href="#格式">格式</a></h2>
<pre><code class="language-json">{
  &quot;parameter1&quot;: {&quot;_type&quot;: &quot;choice&quot;, &quot;_value&quot;:[1, 2, 3, 4]},
  &quot;parameter2&quot;: {&quot;_type&quot;: &quot;randint&quot;, &quot;_value&quot;:[1, 10]},
  ...
}
</code></pre>
<p>在上述结构中：</p>
<ul>
<li>每一个条目都记录了一个超参数的名称和搜索方式：
<ul>
<li>每一个条目的键值（例如 <code>parameter1</code> 和 <code>parameter2</code>）表示超参数的名称。</li>
<li><code>_type</code> 是超参数搜索方法。</li>
<li><code>_value</code> 表示搜索方法所使用的参数。</li>
</ul>
</li>
<li><code>choice</code> 和 <code>randint</code> 表示超参数的搜索方法，其具体含义请参阅<a href="modules/building/autotune-search-space.html#%E6%90%9C%E7%B4%A2%E6%96%B9%E6%B3%95">搜索方法</a>。</li>
</ul>
<h2 id="搜索方法"><a class="header" href="#搜索方法">搜索方法</a></h2>
<div class="table-wrapper"><table><thead><tr><th>_type</th><th>_value 格式</th><th>详细描述</th></tr></thead><tbody>
<tr><td><code>choice</code></td><td>数组（数字或字符串）</td><td>每次训练选取数组 <code>_value</code> 中一个值作为超参数。例：<code>{&quot;learning_rate&quot;:{&quot;_type&quot;: &quot;choice&quot;, &quot;_value&quot;: [0.01, 0.02, 0.1, 0.2]}}</code>，进行超参数调优时，每一组训练会从四个值中选取一个。</td></tr>
<tr><td><code>randint</code></td><td><code>[lower, upper]</code></td><td>每次训练选取 <code>lower</code> 和 <code>upper</code> 之间中的一个随机整数（不包括 <code>upper</code>）作为超参数。例：<code>{&quot;learning_rate&quot;:{&quot;_type&quot;: &quot;randint&quot;, &quot;_value&quot;: [1, 10]}}</code>，进行超参数调优时，每一组训练可能取到的值有 <code>[1, 2, 3, 4, 5, 6, 7, 8, 9]</code>。</td></tr>
<tr><td><code>uniform</code></td><td><code>[low, high]</code></td><td>每次训练从 <code>lower</code> 到 <code>upper</code> 区间内均匀采样作为超参数。</td></tr>
<tr><td><code>quniform</code></td><td><code>[low, high, q]</code></td><td>取值方法为 <code>clip(round(uniform(low, high) / q) * q, low, high)</code>，此公式含义为：从 <code>low</code> 到 <code>high</code> 区间内均匀采样，然后将取值除以 <code>q</code>，并四舍五入为整数，然后将超出 <code>[low, high]</code> 区间的值舍弃，加上 <code>low</code> 和 <code>upper</code> 两个值，构成选值区间。例：<code>_value</code> 为 <code>[0, 10, 2.5]</code>，表示超参数的选值范围时 <code>[0, 2.5, 5, 7.5, 10]</code>；<code>_value</code> 为 <code>[2, 10, 5]</code>，表示超参数的选值范围时 <code>[2, 5, 10]</code>。</td></tr>
<tr><td><code>loguniform</code></td><td><code>[low, high]</code></td><td>取值方法为 <code>exp(uniform(log(low), log(high)))</code>，此公式含义为：从 <code>log(low)</code> 到 <code>log(high)</code> 区间内均匀采样得到样本 <code>x</code>，然后计算 <code>exp(x)</code> 得到超参数。</td></tr>
<tr><td><code>qloguniform</code></td><td><code>[low, high, q]</code></td><td>取值方法为 <code>clip(round(loguniform(low, high) / q) * q, low, high)</code>（其中 <code>loguniform(low, high)</code> 表示 <code>exp(uniform(log(low), log(high)))</code>），此公式含义参考 <code>quniform</code> 和 <code>loguniform</code> 条目。</td></tr>
<tr><td><code>normal</code></td><td><code>[mu, sigma]</code></td><td>超参数的取值满足正态分布 <code>N(mu, sigma^2)</code>。</td></tr>
<tr><td><code>qnormal</code></td><td><code>[mu, sigma, q]</code></td><td>取值方法为 <code>round(normal(mu, sigma) / q) * q</code>，此公式含义参考 <code>quniform</code> 条目。</td></tr>
<tr><td><code>lognormal</code></td><td><code>[mu, sigma]</code></td><td>取值方法为 <code>exp(normal(mu, sigma))</code>，此公式含义参考 <code>loguniform</code> 条目。</td></tr>
<tr><td><code>qlognoraml</code></td><td><code>[mu, sigma, q]</code></td><td>取值方法为 <code>round(exp(normal(mu, sigma)) / q) * q</code>，此公式含义参考 <code>quniform</code> 和 <code>loguniform</code> 条目。</td></tr>
</tbody></table>
</div><aside class="note info">
<div class="title">信息</div>
<p>不同算法可以支持不同种类的搜索方法：并不是在每一种调优算法中都可以使用以上所有搜索方法；也有些调优算法支持使用上述方法之外的搜索方法，例如 <a href="modules/building/./hpo-algorithm.html#ppotuner">PPO 算法</a>。</p>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="超参数调优算法-1"><a class="header" href="#超参数调优算法-1">超参数调优算法</a></h1>
<p>AutoTuneExperiment 在调参过程中需要使用超参数调优算法对超参数进行选择，对于不同的训练框架和不同的超参数种类，超参数调优算法的效率和效果也是不一样的。</p>
<p>算法根据功能和定义分为两类：</p>
<ul>
<li>Tuner 算法：超参数调优算法，用于选取合适的超参数组合。</li>
<li>Assessor 算法：训练评估算法，用于判断当前超参数的训练中间结果是否符合预期，如果不符合则终止训练。</li>
</ul>
<h2 id="tuner-算法"><a class="header" href="#tuner-算法">Tuner 算法</a></h2>
<h3 id="hyperopt-类算法"><a class="header" href="#hyperopt-类算法">HyperOpt 类算法</a></h3>
<p>HyperOpt 是一个用于超参数调优的 Python 库，其中主要包含三种超参数调优算法：<code>Random</code>、<code>Anneal</code> 和 <code>TPE</code>。三种算法之间的区别以及算法的使用方法请参阅 <a target="_blank" rel="noopener noreferrer" href="https://hyperopt.github.io/hyperopt/">HyperOpt 文档</a>。</p>
<p>算法支持使用的搜索方法有：<code>choice</code>、<code>randint</code>、<code>loguniform</code> 和 <code>qloguniform</code>。</p>
<p>下面是 AutoTuneExperiment 使用此算法的一个示例（示例中的 <code>classArgs</code> 字段包含当前算法所有参数，有些参数在实际使用中可以选择不指定）：</p>
<pre><code class="language-json">{
  &quot;tuner&quot;: {
    &quot;builtinTunerName&quot;: &quot;Anneal&quot;,
    &quot;classArgs&quot;: {
      &quot;optimize_mode&quot;: &quot;minimize&quot;, 
      &quot;constant_liar_type&quot;: &quot;min&quot;
    }
  }
}
</code></pre>
<h3 id="evolution"><a class="header" href="#evolution">Evolution</a></h3>
<p>进化算法（Evolution）是受生物进化启发得到的一种优化算法。进化算法的详细介绍请参阅 <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Evolutionary_algorithm">Evolutionary algorithm WIKI 文档</a>。</p>
<p>下面是 AutoTuneExperiment 使用此算法的一个示例（示例中的 <code>classArgs</code> 字段包含当前算法所有参数，有些参数在实际使用中可以选择不指定）：</p>
<pre><code class="language-json">{
  &quot;tuner&quot;: {
    &quot;builtinTunerName&quot;: &quot;Evolution&quot;,
    &quot;classArgs&quot;: {
      &quot;optimize_mode&quot;: &quot;minimize&quot;, 
      &quot;population_size&quot;: 32
    }
  }
}
</code></pre>
<h3 id="batch"><a class="header" href="#batch">Batch</a></h3>
<p>Batch 是一种最简单的选参算法，此算法只支持一种超参数的优化（搜索空间中只能有一个条目）且仅支持 <code>choice</code> 搜索方法。</p>
<p>下面是 AutoTuneExperiment 使用此算法的一个示例（Batch 算法不需要填写参数）：</p>
<pre><code class="language-json">{
  &quot;searchSpace&quot;: {
      &quot;learning_rate&quot;: {&quot;_type&quot;: &quot;choice&quot;, &quot;_value&quot;: [0.0001, 0.001, 0.01, 0.1]}
  },
  &quot;tuner&quot;: {
    &quot;builtinTunerName&quot;: &quot;Batch&quot;
  }
}
</code></pre>
<p>上述示例中，搜索空间中只有一个超参数，且 <code>_type</code> 为 <code>choice</code>；Batch 算法不需要传入参数，所以没有填写 <code>tuner.classArgs</code> 字段。</p>
<h3 id="gridsearch"><a class="header" href="#gridsearch">GridSearch</a></h3>
<p>一种基本的选参算法，根据搜索空间中的参数和范围，枚举所有可能的超参数组合，一一测试。</p>
<p>算法支持使用的搜索方法有：<code>choice</code>、<code>randint</code> 和 <code>quniform</code>。</p>
<p>下面是 AutoTuneExperiment 使用此算法的一个示例（GridSearch 算法不需要填写参数）：</p>
<pre><code class="language-json">{
  &quot;tuner&quot;: {
    &quot;builtinTunerName&quot;: &quot;GridSearch&quot;
  }
}
</code></pre>
<h3 id="metistuner"><a class="header" href="#metistuner">MetisTuner</a></h3>
<p>Metis 算法的详细介绍请参阅论文 <a target="_blank" rel="noopener noreferrer" href="https://www.microsoft.com/en-us/research/publication/metis-robustly-tuning-tail-latencies-cloud-systems/"><em>Metis: Robustly Optimizing Tail Latencies of Cloud Systems</em></a>。</p>
<p>算法支持使用的搜索方法有：<code>choice</code>、<code>randint</code>、<code>uniform</code> 和 <code>quniform</code>。</p>
<p>下面是 AutoTuneExperiment 使用此算法的一个示例（示例中的 <code>classArgs</code> 字段包含当前算法所有参数，有些参数在实际使用中可以选择不指定）：</p>
<pre><code class="language-json">{
  &quot;tuner&quot;: {
    &quot;builtinTunerName&quot;: &quot;MetisTuner&quot;,
    &quot;classArgs&quot;: {
      &quot;optimize_mode&quot;: &quot;maximize&quot;,
      &quot;no_resampling&quot;: true,
      &quot;no_candidates&quot;: false,
      &quot;selection_num_starting_points&quot;: 600,
      &quot;cold_start_num&quot;: 10,
      &quot;exploration_probability&quot;: 0.9
    }
  }
}
</code></pre>
<h3 id="gptuner"><a class="header" href="#gptuner">GPTuner</a></h3>
<p>GPT 是一种能够极大减少超参数优化步骤的贝叶斯优化算法。算法的详细介绍请参阅 <a target="_blank" rel="noopener noreferrer" href="https://nni.readthedocs.io/en/stable/Tuner/GPTuner.html">NNI GPTuner 文档</a>。</p>
<p>算法支持使用的搜索方法有：<code>randint</code>、<code>uniform</code>、<code>quniform</code>、<code>loguniform</code>、<code>qloguniform</code> 和数字形式的 <code>choice</code>。</p>
<p>下面是 AutoTuneExperiment 使用此算法的一个示例（示例中的 <code>classArgs</code> 字段包含当前算法所有参数，有些参数在实际使用中可以选择不指定）：</p>
<pre><code class="language-json">{
  &quot;tuner&quot;: {
    &quot;builtinTunerName&quot;: &quot;GPTuner&quot;,
    &quot;classArgs&quot;: {
      &quot;optimize_mode&quot;: &quot;maximize&quot;,
      &quot;utility&quot;: &quot;ei&quot;,
      &quot;kappa&quot;: 5,
      &quot;xi&quot;: 0,
      &quot;nu&quot;: 2.5,
      &quot;alpha&quot;: 1e-6,
      &quot;cold_start_num&quot;: 10,
      &quot;selection_num_warm_up&quot;: 100000,
      &quot;selection_num_starting_points&quot;: 250
    }
  }
}
</code></pre>
<h3 id="ppotuner"><a class="header" href="#ppotuner">PPOTuner</a></h3>
<p>PPO 算法继承了 <a target="_blank" rel="noopener noreferrer" href="https://github.com/openai/baselines/tree/master/baselines/ppo2">OpenAI 中 ppo2</a> 的主要逻辑，并适应 NAS 场景。</p>
<p>算法支持使用的搜索方法有：<code>layer_choice</code> 和 <code>input_choice</code>。下面是一个搜索空间设置的示例：</p>
<pre><code class="language-json">{
  &quot;first_conv&quot;: {&quot;_type&quot;: &quot;layer_choice&quot;, &quot;_value&quot;: [&quot;conv5x5&quot;, &quot;conv3x3&quot;]},
  &quot;mid_conv&quot;: {&quot;_type&quot;: &quot;layer_choice&quot;, &quot;_value&quot;: [&quot;0&quot;, &quot;1&quot;]},
  &quot;skip&quot;: {
    &quot;_type&quot;: &quot;input_choice&quot;,
    &quot;_value&quot;: {&quot;candidates&quot;: [&quot;&quot;, &quot;&quot;], &quot;n_chosen&quot;: 1}
  }
}
</code></pre>
<p>下面是 AutoTuneExperiment 使用此算法的一个示例（示例中的 <code>classArgs</code> 字段包含当前算法所有参数，有些参数在实际使用中可以选择不指定）：</p>
<pre><code class="language-json">{
  &quot;tuner&quot;: {
    &quot;builtinTunerName&quot;: &quot;PPOTuner&quot;,
    &quot;classArgs&quot;: {
      &quot;optimize_mode&quot;: &quot;maximize&quot;,
      &quot;trials_per_update&quot;: 20,
      &quot;epochs_per_update&quot;: 4,
      &quot;minibatch_size&quot;: 4,
      &quot;ent_coef&quot;: 0.0,
      &quot;lr&quot;: 3e-4,
      &quot;vf_coef&quot;: 0.5,
      &quot;max_grad_norm&quot;: 0.5,
      &quot;gamma&quot;: 0.99,
      &quot;lam&quot;: 0.95,
      &quot;cliprange&quot;: 0.2
    }
  }
}
</code></pre>
<h3 id="pbttuner"><a class="header" href="#pbttuner">PBTTuner</a></h3>
<p>PBT 算法得自 <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1711.09846"><em>Population Based Training of Neural Networks</em></a>。</p>
<p>下面是 AutoTuneExperiment 使用此算法的一个示例（示例中的 <code>classArgs</code> 字段包含当前算法所有参数，有些参数在实际使用中可以选择不指定）：</p>
<pre><code class="language-json">{
  &quot;tuner&quot;: {
    &quot;builtinTunerName&quot;: &quot;PBTTuner&quot;,
    &quot;classArgs&quot;: {
      &quot;optimize_mode&quot;: &quot;maximize&quot;,
      &quot;population_size&quot;: 10,
      &quot;factor&quot;: 0.2,
      &quot;resample_probability&quot;: 0.25,
      &quot;fraction&quot;: 0.2
    }
  }
}
</code></pre>
<h2 id="assessor-算法"><a class="header" href="#assessor-算法">Assessor 算法</a></h2>
<h3 id="medianstop"><a class="header" href="#medianstop">Medianstop</a></h3>
<p>Medianstop 算法的逻辑是：如果在某一步 <code>S</code>，当前运行的实验的最佳观测值比所有已经完成的训练的第 S 步前的观测值的中位数差，则停止此次训练。此策略出自论文 <a target="_blank" rel="noopener noreferrer" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46180.pdf"><em>Google Vizier: A Service for Black-Box Optimization</em></a> 。</p>
<p>下面是 AutoTuneExperiment 使用此算法的一个示例（示例中的 <code>classArgs</code> 字段包含当前算法所有参数，有些参数在实际使用中可以选择不指定）：</p>
<pre><code class="language-json">{
  &quot;assessor&quot;: {
    &quot;builtinAssessorName&quot;: &quot;Medianstop&quot;,
    &quot;classArgs&quot;: {
      &quot;optimize_mode&quot;: &quot;maximize&quot;,
      &quot;start_step&quot;: 0
    }
  }
}
</code></pre>
<p>在上述示例中，<code>start_step</code> 表示从第几步开始上传观测值（过早上传观测值，可能会错误的停止一些刚开始表现较差的训练）。</p>
<h3 id="curvefitting"><a class="header" href="#curvefitting">Curvefitting</a></h3>
<p>Curvefitting 算法使用学习曲线拟合算法来预测未来的学习曲线性能。其逻辑是：如果在某一步，当前训练的预测结果是收敛的并且比历史上的最佳结果差，则停止此次训练。Curvefitting 算法的详细介绍请参阅 <a target="_blank" rel="noopener noreferrer" href="https://nni.readthedocs.io/en/latest/Assessor/CurvefittingAssessor.html">NNI Curvefitting 文档</a>。</p>
<p>下面是 AutoTuneExperiment 使用此算法的一个示例（示例中的 <code>classArgs</code> 字段包含当前算法所有参数，有些参数在实际使用中可以选择不指定）：</p>
<pre><code class="language-json">{
  &quot;assessor&quot;: {
    &quot;builtinAssessorName&quot;: &quot;Curvefitting&quot;,
    &quot;classArgs&quot;: {
      &quot;optimize_mode&quot;: &quot;minimize&quot;,
      &quot;epoch_num&quot;: 20,
      &quot;start_step&quot;: 6,
      &quot;threshold&quot;: 0.95,
      &quot;gap&quot;: 1
    }
  }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="模型部署"><a class="header" href="#模型部署">模型部署</a></h1>
<p>TensorStack AI 平台的模型部署模块可以帮助你快速地将训练完成的 AI 模型部署为推理服务。</p>
<p>针对不同的应用场景，有以下两种 TensorStack API可供使用：</p>
<ul>
<li><strong><a href="modules/deployment/./mlservice.html">MLService</a></strong> 是完善的模型推理服务，可用于生产环境，具有以下特性：
<ul>
<li>基于 Serverless 架构，服务容量（serving capacity）可根据负载自动伸缩；</li>
<li>自动暴露服务到集群外部，快速上线。</li>
</ul>
</li>
<li><strong><a href="modules/deployment/./simplemlservice.html">SimpleMLService</a></strong> 是精简的模型推理服务，可用于快速测试、固定容量部署等场景。具有以下特性：
<ul>
<li>服务副本数目（replica）固定；</li>
<li>集群外部访问需要额外配置 Ingress 等资源。</li>
</ul>
</li>
</ul>
<p>同时，TensorStack AI 平台对模型部署提供自动化的运维支持，包括性能和资源的监控告警以及故障检测，以保障推理服务长期可靠运行。</p>
<h2 id="架构-1"><a class="header" href="#架构-1">架构</a></h2>
<p>模型部署模块的架构如下图：</p>
<figure class="architecture">
  <img alt="architecture" src="modules/deployment/../../assets/modules/deployment/architecture.drawio.svg" class="architecture">
</figure>
<p>根据用户提供的<a href="modules/deployment/storage.html">模型存储</a>位置和 AI 框架等设置，模型部署模块的控制器（controller）协调模型下载并启动模型推理服务。</p>
<h2 id="下一步-9"><a class="header" href="#下一步-9">下一步</a></h2>
<ul>
<li>了解 <a href="modules/deployment/simplemlservice.html">SimpleMLService</a></li>
<li>了解 <a href="modules/deployment/mlservice.html">MLService</a></li>
<li>了解 <a href="modules/deployment/storage.html">模型存储</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="simplemlservice"><a class="header" href="#simplemlservice">SimpleMLService</a></h1>
<p>SimpleMLService 用于在 TensorStack AI 平台上简单、快捷地部署 AI 模型推理服务，可用于小规模模型部署，快速测试等场景。</p>
<p>SimpleMLService 具有以下特性：</p>
<ul>
<li>直接支持 TensorFlow、PyTorch 框架，并允许用户自定义框架，具有良好的可扩展性。</li>
<li>支持 PVC、S3 模型存储方式。</li>
<li>直接支持从集群内部访问推理服务；集群外访问需要用户进行额外配置。</li>
<li>服务容量固定，不支持自动伸缩。</li>
</ul>
<h2 id="创建-simplemlservice"><a class="header" href="#创建-simplemlservice">创建 SimpleMLService</a></h2>
<p>下面是一个基本的 SimpleMLService 示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: SimpleMLService
metadata:
  name: mnist
spec:
  replicas: 1
  storage:
    s3:
      secretName: s3-secret
      uri: s3://models/mnist/
      containerPath: /var/lib/t9k/model
  tensorflow:
    image: t9kpublic/tensorflow-serving:2.6.0
    resources: 
      requests:
        cpu: 1
        memory: 1Gi
</code></pre>
<p>本示例的 spec 字段的子字段释义如下：</p>
<ul>
<li><code>replicas</code>: 定义运行推理服务的副本数量是 1。</li>
<li><code>storage.s3</code>: 设定使用 S3 存储模型，子字段的释义如下：
<ul>
<li><code>secretName</code>: Secret <code>s3-secret</code> 中存储 S3 配置信息，其详情参见：<a href="modules/deployment/simplemlservice.html#%E5%88%9B%E5%BB%BA-s3-secret">创建-s3-secret</a>。</li>
<li><code>uri</code>: 模型在 S3 中的存储路径是 <code>s3://models/mnist/</code>。</li>
<li><code>containerPath</code>: 模型被加载后，在容器中存储模型的文件系统路径是 <code>/var/lib/t9k/model</code>。</li>
</ul>
</li>
<li><code>tensorflow</code>: 设定使用 <code>tensorflow</code> 推理框架，子字段释义如下：
<ul>
<li><code>image</code>: 指定推理服务容器镜像 <code>t9kpublic/tensorflow-serving:2.6.0</code>。</li>
<li><code>resources</code>: 这顶一个副本 Pod 使用的资源量。</li>
</ul>
</li>
</ul>
<h2 id="直接支持的-ai-框架"><a class="header" href="#直接支持的-ai-框架">直接支持的 AI 框架</a></h2>
<p>SimpleMLService 目前直接支持 TensorFlow、PyTorch 两种框架。</p>
<h3 id="tensorflow"><a class="header" href="#tensorflow">TensorFlow</a></h3>
<p>可以通过设置 <code>spec.tensorflow</code> 字段来部署 TensorFlow 框架，参考示例：<a href="modules/deployment/simplemlservice.html#%E5%88%9B%E5%BB%BA-simplemlservice">创建 SimpleMLService</a>。</p>
<p>当使用 TensorFlow 时，控制器会在容器中设置下列启动命令：</p>
<pre><code class="language-bash">/usr/bin/tensorflow_model_server \
  --port=9090 \
  --rest_api_port=8080 \
  --model_name=&lt;SimpleMLService name&gt; \
  --model_base_path=&lt;model-dir-in-container&gt;
</code></pre>
<h3 id="pytorch"><a class="header" href="#pytorch">PyTorch</a></h3>
<p>可以通过设置 <code>spec.pytorch</code> 字段来部署 PyTorch 框架，示例如下：</p>
<pre><code class="language-yaml">spec:
  pytroch:
    image: &lt;pytorch-image&gt;
    modelsFlag: &quot;resnet-18=resnet-18.mar&quot;
    resources: 
      requests:
        cpu: 1
        memory: 1Gi
</code></pre>
<p>当使用 PyTorch 时，控制器会在容器中设置下列启动命令：</p>
<pre><code class="language-bash">torchserve \
  --start \
  --model-store=&lt;mode-dir&gt; \
  --models &lt;spec.pytorch.modelsFlag&gt;
</code></pre>
<h2 id="自定义框架"><a class="header" href="#自定义框架">自定义框架</a></h2>
<p>如果需要使用 PyTorch, TensorFlow 之外的框架，可以通过设置 <code>spec.custom</code> 字段来自定义框架。</p>
<p>用户可在 <code>spec.custom.spec</code> 字段中定义一个完整的 <a href="modules/deployment/../../references/api-reference/simplemlservice.html#customspec">PodSpec</a>，并需要满足下列要求：</p>
<ol>
<li>至少设置一个 <code>containers</code> 成员。</li>
<li>启动推理服务运行命令时，指定正确的模型路径。</li>
<li>未设置 <a href="modules/deployment/simplemlservice.html#%E6%9A%B4%E9%9C%B2%E6%9C%8D%E5%8A%A1">spec.service</a> 时，推理服务的服务端口应该使用 8080。</li>
</ol>
<p>示例如下：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: SimpleMLService
metadata:
  name: pvc-custom
spec:
  replicas: 1
  storage:
    s3:
      secretName: s3-secret
      uri: s3://models/mnist/
      containerPath: /custom/path
  custom:
    spec:
      containers:
      - name: user-container
        args:
        - --port=9000
        - --rest_api_port=8080
        - --model_name=mnist
        - --model_base_path=/custom/path
        command:
        - /usr/bin/tensorflow_model_server
        image: &quot;t9kpublic/tensorflow-serving:2.6.0&quot;
</code></pre>
<h2 id="副本数量"><a class="header" href="#副本数量">副本数量</a></h2>
<p>副本数量通过字段 <code>spec.replicas</code> 设置，用于定义 SimpleMLService 的 Pod 数量，默认值是 1。</p>
<h2 id="暴露服务"><a class="header" href="#暴露服务">暴露服务</a></h2>
<p>通过设置 <code>spec.service</code> 字段来选择将服务的哪个端口暴露出来。未设置时，默认将 Pod 的 8080 端口映射到 Service 的 80 端口。</p>
<p>下面是一个示例：</p>
<pre><code class="language-yaml">spec:
  service:
    ports:
    - name: http
      port: 80
      targetPort: 8080
      protocol: TCP
    type: ClusterIP
</code></pre>
<p>在该例中：</p>
<ul>
<li>将 Pod 的 8080 端口映射到 Service 的 80 端口，协议是 TCP。</li>
<li>Service 的 Type 是 <a href="https://kubernetes.io/docs/concepts/services-networking/service/#type-clusterip">ClusterIP</a>。</li>
</ul>
<h2 id="调度器"><a class="header" href="#调度器">调度器</a></h2>
<p>SimpleMLService 支持使用两种调度器：</p>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler">Kubernetes 默认调度器</a></li>
<li><a href="modules/deployment/../scheduling/index.html">T9k Scheduler 调度器</a></li>
</ul>
<p>通过 <code>spec.scheduler</code> 字段可以设置欲使用的调度器：</p>
<ul>
<li>不设置 <code>spec.scheduler</code> 字段，默认使用 Kubernetes 调度器。</li>
<li>设置 <code>spec.scheduler.t9kScheduler</code> 字段，使用 T9k Scheduler 调度器。</li>
</ul>
<p>在下面的示例中，SimpleMLService 使用 T9k Scheduler 调度器，并申请使用 <a href="modules/deployment/../scheduling/queue.html">队列</a> <code>default</code> 中的资源。</p>
<pre><code class="language-yaml">spec:
  scheduler:
    t9kScheduler:
      queue: default
</code></pre>
<h2 id="模型存储"><a class="header" href="#模型存储">模型存储</a></h2>
<p>SimpleMLService 支持使用 S3 或 <a href="modules/deployment/../storage/pvc.html">PVC</a> 中存储的模型。</p>
<h3 id="s3"><a class="header" href="#s3">S3</a></h3>
<p>如需使用 S3 服务中存储的模型：</p>
<ol>
<li>创建存储 S3 服务信息的 Secret</li>
<li>设置 SimpleMLService 的 <code>spec.storage.s3</code> 字段</li>
</ol>
<h4 id="创建-s3-secret"><a class="header" href="#创建-s3-secret">创建 S3 Secret</a></h4>
<p>存储 S3 信息的 Secret 需要满足下列条件：</p>
<ol>
<li>设置 label <code>tensorstack.dev/resource: s3</code>。</li>
<li>设置 <code>data[.s3cfg]</code> 字段，内容是 Base64 编码的 <a target="_blank" rel="noopener noreferrer" href="https://s3tools.org/s3cmd">s3cmd</a> config。</li>
</ol>
<p>YAML 示例如下：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: s3-sample
  labels:
    tensorstack.dev/resource: s3
type: Opaque
data:
  .s3cfg: aG9zdF9iYXNlID0gZXhhbXBsZS5zMwpob3N0X2J1Y2tldCA9IGV4YW1wbGUuczMKYnVja2V0X2xvY2F0aW9uID0gdXMtZWFzdC0xCnVzZV9odHRwcyA9IEZhbHNlCmFjY2Vzc19rZXkgPSB1c2VyCnNlY3JldF9rZXkgPSBwYXNzd29yZApzaWduYXR1cmVfdjIgPSBGYWxzZQo=
</code></pre>
<p>其中 <code>data[.s3cfg]</code> 字段 Base64 解码后如下：</p>
<pre><code>host_base = example.s3
host_bucket = example.s3
bucket_location = us-east-1
use_https = False
access_key = user
secret_key = password
signature_v2 = False
</code></pre>
<h4 id="设置-specstorages3"><a class="header" href="#设置-specstorages3">设置 <code>spec.storage.s3</code></a></h4>
<p>设置 SimpleMLService 的 <code>spec.storage.s3</code> 字段来使用存储在 S3 中的模型数据。<code>spec.storage.s3</code> 字段包含下列子字段: </p>
<ul>
<li><code>secretName</code>: 前述步骤创建的 S3 配置信息的 Secret 名称。</li>
<li><code>uri</code>: 模型在 S3 中的存储标识。</li>
<li><code>containerPath</code>: 模型在容器中的存储路径。</li>
</ul>
<p>示例如下：</p>
<pre><code class="language-yaml">spec:
  storage:
    s3:
      secretName: s3-secret
      uri: s3://models/mnist/
      containerPath: /var/lib/t9k/model
</code></pre>
<h3 id="pvc"><a class="header" href="#pvc">PVC</a></h3>
<p>通过配置 <code>spec.storage.pvc</code> 字段可以使用存储在 PVC 中的模型数据。<code>spec.storage.pvc</code> 字段包含下列子字段：</p>
<ul>
<li><code>name</code>: 存储模型数据的 PVC 的名称。</li>
<li><code>subPath</code>: 模型在 PVC 中的路径，不可以是绝对路径（即开头不能是 <code>/</code>）。</li>
<li><code>containerPath</code>: 模型在容器中的存储路径。</li>
</ul>
<p>示例如下：</p>
<pre><code class="language-yaml">spec:
  storage:
    pvc:
      name: demo
      subPath: path/mnist
      containerPath: /var/lib/custom
</code></pre>
<h2 id="服务状态"><a class="header" href="#服务状态">服务状态</a></h2>
<p>SimpleMLService 的状态记录在 <code>status</code> 字段中。</p>
<p><code>status.address</code> 字段记录了推理服务在集群内的访问地址，子字段如下：</p>
<ul>
<li><code>url</code>: 推理服务在集群内的访问地址</li>
<li><code>ports</code>: 推理服务可供访问的服务端口</li>
</ul>
<p><code>status.conditions</code> 字段表明了当前 SimpleMLService 的状态，包括下列 2 种类型：</p>
<ul>
<li><code>ModelDownloaded</code>: 模型是否成功地被下载到本地。</li>
<li><code>Ready</code>: 推理服务是否就绪。 </li>
</ul>
<p>在下面的示例中：</p>
<ul>
<li>访问推理服务的地址是 <code>sample.demo.svc.cluster.local</code></li>
<li>模型已经下载到容器本地</li>
<li>推理服务处于就绪状态</li>
</ul>
<pre><code class="language-yaml">status:
  address:
    url: sample.demo.svc.cluster.local
    ports:
    - port: 80
      protocol: TCP
  conditions:
  - lastTransitionTime: &quot;2023-12-27T06:52:39Z&quot;
    status: &quot;True&quot;
    type: ModelDownloaded
  - lastTransitionTime: &quot;2023-12-27T06:52:41Z&quot;
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: &quot;True&quot;
    type: Ready
</code></pre>
<h2 id="下一步-10"><a class="header" href="#下一步-10">下一步</a></h2>
<ul>
<li>了解如何部署一个<a href="modules/deployment/../../tasks/deploy-simplemlservice.html">简单推理服务</a></li>
<li>API 参考：<a href="modules/deployment/../../references/api-reference/simplemlservice.html">SimpleMLService</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="mlservice"><a class="header" href="#mlservice">MLService</a></h1>
<p>MLService 用于在 TensorStack AI 平台上部署 AI 推理服务，其功能全面，可用于生产环境。</p>
<h2 id="概述-1"><a class="header" href="#概述-1">概述</a></h2>
<p><code>MLService</code> 是推理服务的核心 API，由 <code>releases</code> 和 <code>transformer</code> 两部分构成：</p>
<ul>
<li><code>spec.releases</code> 定义一个或多个 <code>releases</code>，以提供多版本模型推理服务的支持。</li>
<li>可选的 <code>transformer</code> 定义前处理（pre-processing）和后处理（post-processing）计算。</li>
</ul>
<figure class="architecture">
  <img alt="mlservice-architecture" src="modules/deployment/../../assets/modules/deployment/mlservice-flow.drawio.svg" class="architecture">
  <figcaption> 图 1: MLService 的组成。一个 MLService 由一个或多个模型服务版本（releases） 及前后处理模块（transformer，非必需）构成；不同的 release 和 transformer 可独立进行规模伸缩。</figcaption>
</figure>
<p><code>MLService</code> 的主要特性包括：</p>
<ul>
<li>支持定义多个版本（<code>release</code>）的推理服务，每个 <code>release</code> 包含一个 <code>predictor</code>，其定义了：
<ul>
<li>模型存储（<code>storage</code>）</li>
<li>模型规约（<code>model</code>），包括 <code>modelUri</code>，<code>parameters</code>，<code>runtime</code>（引用 <code>MLServiceRuntime</code> 定义运行推理服务 <code>Pod</code> 的模版）</li>
<li>计算资源（<code>resources</code>）</li>
<li>其他部署参数（<code>minReplicas, maxRelicas, logger ...</code>）</li>
</ul>
</li>
<li>每个 <code>release</code> 服务的容量可独立自动伸缩，可通过 <code>minReplicas</code>、<code>maxReplicas</code> 设置容量的上下限。</li>
<li>支持<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Feature_toggle#Canary_release">金丝雀（canary release）</a>发布模式。</li>
<li>用户可定制 <code>transformer</code> 组件，以在调用推理服务时进行前处理（pre-processing），以及获得推理结果后进行后处理（post-processing）。</li>
<li><code>transformer</code> 的容量也可独立自动伸缩，可通过 <code>minReplicas</code>、<code>maxReplicas</code> 设置容量的上下限。</li>
</ul>
<h2 id="示例"><a class="header" href="#示例">示例</a></h2>
<p>下面是一个基本的 MLService 示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: MLService
metadata:
  name: torch-mnist
spec:
  default: version1
  releases:
    - name: version1
      predictor:
        minReplicas: 1
        maxReplicas: 3
        model:
          parameters:
            &quot;MODEL_PATH&quot;: &quot;mnist=model.mar&quot;
          runtime: torchserve
          modelUri: pvc://tutorial/tutorial-examples/deployment/pvc/mlservice-torch/
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>该示例部署的推理服务 <code>torch-mnist</code>，只包含一个推理服务版本（<code>release</code>） <code>version1</code>：</p>
<ul>
<li>推理服务定义使用了 MLServiceRuntime <code>torchserve</code>，其详细定义见下文。</li>
<li>模型存储在 PVC <code>tutorial</code> 中。</li>
<li>服务的部署规模（副本数量）会根据服务负载情况自动调节，最小为 1，最大为 3。</li>
<li>运行模型推理服务器的副本（容器，container）的资源为：<code>{&quot;limits&quot;: { &quot;cpu&quot;: &quot;500m&quot;, &quot;memory&quot;: &quot;1Gi&quot;}}</code>。</li>
</ul>
</aside>
<h2 id="mlserviceruntime"><a class="header" href="#mlserviceruntime">MLServiceRuntime</a></h2>
<p>在<a href="modules/deployment/mlservice.html#%E7%A4%BA%E4%BE%8B">示例</a>中，我们使用了 MLServiceRuntime <code>torchserve</code>。
MLServiceRuntime 定义了推理服务的模版，包含了推理服务的关键信息，例如镜像、启动命令、资源需求等，能够方便地帮助用户快速部署多种模型推理服务程序。</p>
<p>一个 MLServiceRuntime 可以被多个 MLService 使用。</p>
<h3 id="定义"><a class="header" href="#定义">定义</a></h3>
<p>一个基本的 MLServiceRuntime 的示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: MLServiceRuntime
metadata:
  name: torchserve
spec:
  enabled: true
  template:
    spec:
      containers:
      - name: user-container
        image: torchserve:0.9.0-cpu
        args:
          - torchserve
          - --start
          - --model-store=/var/lib/t9k/model
          - --models {{if .MODEL_PATH}}{{.MODEL_PATH}}{{else}}all{{end}}
        resources:
          limits:
            cpu: &quot;200m&quot;
            memory: 200Mi
        ports:
        - containerPort: 8080
          protocol: TCP
</code></pre>
<p>该 MLServiceRuntime 在 <code>spec.template</code> 中定义了推理服务的副本（Pod）的模版，以指定容器镜像 <code>torchserve:0.9.0-cpu</code>、启动命令 <code>torchserve</code> 及其他命令行参数等。</p>
<aside class="note info">
<div class="title">信息</div>
<p>MLServiceRuntime 中的 Pod 模版有以下规范必须遵守：</p>
<ol>
<li>必须要有一个名为 <code>user-container</code> 的容器，后续所介绍的<a href="modules/deployment/mlservice.html#%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%82%A8">模型存储</a>、<a href="modules/deployment/mlservice.html#%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86">日志收集</a>等功能都只对 <code>user-container</code> 生效。</li>
<li><code>user-container</code> 的容器中最多只能定义一个 <code>containerPort</code>，且其他的容器定义中不能有 <code>containerPort</code>。</li>
<li><code>user-container</code> 容器中定义的唯一 <code>containerPort</code> 就是推理服务对应的端口，如果没有定义，默认使用 <code>8080</code> 端口。</li>
</ol>
</aside>
<h3 id="使用"><a class="header" href="#使用">使用</a></h3>
<p>用户可以在 MLService 的 <code>predictor</code> 定义中指定要使用的 MLServiceRuntime 名称，例如：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: MLService
metadata:
  name: demo
spec:
  default: version1
  releases:
  - name: version1
    predictor:
      model:
        runtime: torchserve
        modelUri: &quot;&lt;your-model-registry/your-model-path&gt;&quot;
</code></pre>
<p>用户在 release <code>version1</code> 的 <code>.predictor.model.runtime</code> 中指定了 <code>torchserve</code>，系统在创建推理服务器副本（Pod）时，将会使用名称为 <code>torchserve</code> 的 MLServiceRuntime。</p>
<aside class="note">
<div class="title">注意</div>
<p>如果用户更新了一个 MLServiceRuntime，所有使用了该 MLServiceRuntime 的 MLService 所创建的副本（Pod）也会随之进行更新，但此更新采取 “懒惰” 策略：</p>
<ul>
<li>单纯的 MLServiceRuntime 修改并不会触发系统修改 MLServiceRuntime 更新之前创建的副本（Pod）。</li>
<li>只会在有必要时，例如伸缩 MLService 规模，或者其他 MLService 的变更，导致需要重新创建副本的场景时，系统才会使用新的 MLServiceRuntime。</li>
</ul>
</aside>
<h3 id="进一步的配置"><a class="header" href="#进一步的配置">进一步的配置</a></h3>
<p>除了直接使用 MLServiceRuntime 定义好的 Pod 模版，MLService 还支持对其进行进一步的配置和修改。</p>
<h4 id="parameters"><a class="header" href="#parameters">Parameters</a></h4>
<p>MLService 支持在 <code>predictor</code> 的 <code>.model.parameters</code> 设置参数，该字段是一个 map 类型，key 为参数名，value 为参数值。</p>
<p>在之前的 <a href="modules/deployment/mlservice.html#%E5%AE%9A%E4%B9%89">MLServiceRuntime 示例</a> 中包含了 <code>--models {{if .MODEL_PATH}}{{.MODEL_PATH}}{{else}}all{{end}}</code> 的内容。这里使用了 <a target="_blank" rel="noopener noreferrer" href="https://pkg.go.dev/text/template">golang template</a> 的语法，含义为：</p>
<ul>
<li>如果使用此 MLServiceRuntime 的 MLService 指定了 <code>MODEL_PATH</code>，这一行会被设置为 <code>--model &lt;用户指定的 MODEL_PATH&gt;</code></li>
<li>如果没有指定 <code>MODEL_PATH</code>，这一行会被设置为 <code>--model all</code></li>
</ul>
<p>如下所示，在 MLService 中设置 <code>MODEL_PATH</code>：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: MLService
metadata:
  name: demo
spec:
  default: version1
  releases:
  - name: version1
    predictor:
      model:
        parameters:
          &quot;MODEL_PATH&quot;: &quot;mnist=model.mar&quot;
        runtime: torchserve
        modelUri: &quot;&lt;your-model-registry/your-model-path&gt;&quot;
</code></pre>
<p>由上述 MLService 最终产生的副本（Pod）的 <code>args</code> 中会包含 <code>--model mnist=model.mar</code>，指定了使用模型的名称和文件。</p>
<h4 id="strategicmergepatch"><a class="header" href="#strategicmergepatch">StrategicMergePatch</a></h4>
<p>MLServiceRuntime 定义了 Pod 模版，但不一定能适用于所有场景。MLService 支持用户在 MLServiceRuntime 的基础上，进行进一步的叠加修改，例如：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: MLService
metadata:
  name: demo
spec:
  default: version1
  releases:
  - name: version1
    predictor:
      model:
        parameters:
          &quot;MODEL_PATH&quot;: &quot;mnist=model.mar&quot;
        runtime: torchserve
        modelUri: &quot;&lt;your-model-registry/your-model-path&gt;&quot;
      template:
        spec:
          containers:
            - name: user-container
              image: self-torchserve:latest
</code></pre>
<p>将上面 MLService 中 predictor <code>version1</code> 的 <code>template.spec</code> 和之前的 <a href="modules/deployment/mlservice.html#%E5%AE%9A%E4%B9%89">Runtime 定义示例</a> 相比，
可以发现他们都定义了一个名为 <code>user-container</code> 的 container，但是 <code>image</code> 不同。
于是最终生成的 Pod 中，MLService 中定义的 <code>image</code> 会覆盖 MLServiceRuntime 中的 <code>image</code>，但是 MLServiceRuntime 中 <code>args</code> 等其余设置都会被保留。</p>
<aside class="note warning">
<div class="title">警告</div>
<p>使用 StrategicMergePatch 在 MLService 中定义容器时，不可以设置 <code>ports</code> 字段。否则会导致合并后的 Pod 中定义了多个 <code>port</code>。</p>
</aside>
<aside class="note info">
<div class="title">信息</div>
<p>这里的覆盖合并原则采用的是 StrategicMergePatch。
用户可以通过阅览以下参考资料，进一步了解  StrategicMergePatch：</p>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/tasks/manage-kubernetes-objects/update-api-object-kubectl-patch/#use-a-strategic-merge-patch-to-update-a-deployment">Update API Objects in Place Using kubectl patch</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://pkg.go.dev/k8s.io/apimachinery/pkg/util/strategicpatch">strategicpatch - k8s.io/apimachinery/pkg/util/strategicpatch</a></li>
</ul>
<p>以下给出几个常用的示例：</p>
<ol>
<li>添加 container，containers 数组中不同名的都会被保留。</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>MLServiceRuntime</th><th>MLService</th><th>Result</th></tr></thead><tbody>
<tr><td>containers:<br>- name: user-container<br>  …</td><td>containers:<br>- name: proxy<br>  …</td><td>containers:<br>- name: user-container<br>  …<br>- name: proxy<br>  …</td></tr>
</tbody></table>
</div>
<ol start="2">
<li>修改 image，相同名称 container 的 image 会被覆盖。</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>MLServiceRuntime</th><th>MLService</th><th>Result</th></tr></thead><tbody>
<tr><td>containers:<br>- name: user-container<br>  image: torchserve:alpha</td><td>containers:<br>- name: user-container<br>  image: torchserve:beta</td><td>containers:<br>- name: user-container<br>  image: torchserve:beta</td></tr>
</tbody></table>
</div>
<ol start="3">
<li>修改 args，相同名称 container 的 args 数组会整个被覆盖。</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>MLServiceRuntime</th><th>MLService</th><th>Result</th></tr></thead><tbody>
<tr><td>containers:<br>- name: user-container<br>  args: [“–k1=v1”, “–k2=v2”]</td><td>containers:<br>- name: user-container<br>  args: [“–k2=v3”]</td><td>containers:<br>- name: user-container<br>  args: [“–k2=v3”]</td></tr>
</tbody></table>
</div></aside>
<p>上述的 <a href="modules/deployment/mlservice.html#strategicmergepatch">StrategicMergePatch</a> 给用户提供了完整的个性化改动方案。除此以外，针对改动频率更高的资源要求（resources），MLService 提供了更方便的个性化改动方案。用户可以直接通过 Predictor 中的 <code>resources</code> 覆盖 Runtime 的资源要求，例如：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: MLService
metadata:
  name: demo
spec:
  default: version1
  releases:
  - name: version1
    predictor:
      model:
        modelFormat:
          name: pytorch
        modelUri: &quot;&lt;your-model-registry/your-model-path&gt;&quot;
      resources:
        limits:
          cpu: 500m
          memory: 1Gi
</code></pre>
<h2 id="模型存储-1"><a class="header" href="#模型存储-1">模型存储</a></h2>
<p>MLService 支持 S3 和 PVC 两种存储模型的方式，用户需要根据模型存储的类型填写 MLService 的配置。</p>
<h3 id="pvc-1"><a class="header" href="#pvc-1">PVC</a></h3>
<p>在MLService中使用 <a href="modules/deployment/../storage/pvc.html">PVC</a> 存储模式需要在 <code>spec.releases[*].predictor.model.modelUri</code> 中设置包含前缀 <code>pvc://</code> 的模型路径。</p>
<p>例如，下面的示例指定模型存储在 PVC <code>tutorial</code> 的 <code>models/example/</code> 路径下：</p>
<pre><code class="language-yaml">...
  releases:
    - name: test1
      predictor:
        model:
          modelUri: &quot;pvc://tutorial/models/example&quot;
...
</code></pre>
<h3 id="s3-1"><a class="header" href="#s3-1">S3</a></h3>
<p>S3 是一种对象存储服务和协议，具有良好的可扩展性、数据可用性和安全性等优点，其协议被多种商业和开源产品支持，并且被广泛部署。</p>
<p>可在 MLService 中通过 <code>spec.releases[*].predictor.model.modelUri</code> 和
<code>spec.releases[*].predictor.storage.s3Storage.secretName</code> 设定 S3 的配置参数，其中：</p>
<ul>
<li><code>modelUri</code> 必需包含前缀 <code>s3://</code>。</li>
<li><code>secretName</code> 指向的Secret 存储的 S3 配置格式应当是 <a target="_blank" rel="noopener noreferrer" href="https://s3tools.org/s3cmd">s3cmd</a> 配置文件格式。</li>
</ul>
<p>例如，下面的示例指定模型在 S3 中的存储 <code>Uri</code> 前缀为 <code>s3://models/example/</code>，S3 的配置信息存储在 Secret <code>s3-model</code> 中：</p>
<pre><code class="language-yaml">...
  releases:
    - name: test1
      predictor:
        model:
          modelUri: &quot;s3://models/example/&quot;
        storage:
          s3Storage:
            secretName: s3-model
...
</code></pre>
<h2 id="更多配置"><a class="header" href="#更多配置">更多配置</a></h2>
<h3 id="发布策略"><a class="header" href="#发布策略">发布策略</a></h3>
<h4 id="多版本支持"><a class="header" href="#多版本支持">多版本支持</a></h4>
<p>一个 MLService 可以同时部署多个版本（release）的推理服务，以使用不同的模型文件，或者其他配置等。</p>
<p>在下面的示例中，MLService 同时部署了 <code>nov-02</code>（设置为默认）、<code>nov-05</code> 和 <code>nov-11</code> 三个版本的服务，这三个版本都使用同一个 MLServiceRuntime，但是使用的模型不同（不同的 <code>modelUri</code>）：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: MLService
metadata:
  name: multi-releases
spec:
  default: nov-02
  releases:
    - name: nov-02
      predictor:
        model:
          runtime: torchserve
          modelUri: pvc://tutorial/model-11-02
    - name: nov-05
      predictor:
        model:
          runtime: torchserve
          modelUri: pvc://tutorial/model-11-05
    - name: nov-11
      predictor:
        model:
          runtime: torchserve
          modelUri: pvc://tutorial/model-11-11
</code></pre>
<h4 id="金丝雀发布"><a class="header" href="#金丝雀发布">金丝雀发布</a></h4>
<p>MLService 支持金丝雀（canary release）发布策略。用户可以通过 <code>spec.canary</code> 字段设置金丝雀发布对应的模型版本（<code>release</code>），<code>spec.canaryTrafficPercent</code> 字段设置金丝雀发布的路由权重。<code>spec.default</code> 是必需字段，用于设置默认发布。</p>
<p>例如上一节中我们部署了 3 个版本的模型，我们想主要（<code>80%</code> 流量）使用 <code>nov-02</code> 这个版本，并且将刚刚训练好的 <code>nov-11</code> 作为金丝雀版本：</p>
<ul>
<li>默认发布：<code>nov-02</code>，路由权重为 80%。</li>
<li>金丝雀发布：<code>nov-11</code>，路由权重为 20%。</li>
</ul>
<pre><code class="language-yaml">...
spec:
  default: nov-02
  canary: nov-11
  canaryTrafficPercent: 20
...
</code></pre>
<h3 id="日志收集"><a class="header" href="#日志收集">日志收集</a></h3>
<p>MLService 支持对预测请求进行日志收集，详情见<a href="modules/deployment/./mlservice-logger.html">2.2.2.1日志收集</a></p>
<h3 id="前处理及后处理"><a class="header" href="#前处理及后处理">前处理及后处理</a></h3>
<p>MLService 支持部署含有 <code>transformer</code> 模块的前处理（pre-processing）及后处理（post-processing）的推理服务：</p>
<ul>
<li>预处理：用户发向推理服务的原始数据，先经过 transformer 预处理，然后再被发送到推理服务。</li>
<li>后处理：推理服务返回的预测结果，先经过 transformer 后处理，然后再返回给用户。</li>
</ul>
<p>用户可以使用 <a href="modules/deployment/../../../tools/python-sdk-t9k/index.html">Tensorstack SDK</a> 编写 transformer 代码，制作镜像，并基于该镜像创建含有 transformer 的推理服务。详细示例请参阅<a href="modules/deployment/../../tasks/deploy-mlservice-transformer.html">制作并部署含有 Transformer 的模型推理服务</a>。</p>
<p>下文展示了一个使用 transformer 的推理服务：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: MLService
metadata:
  name: pic-mnist
spec:
  default: origin
  transformer:
    minReplicas: 1
    minReplicas: 5
    template:
      spec:
        containers:
        - name: user-container
          image: t9kpublic/transformer-example:0.1.0
          resources:
            limits:
              cpu: &quot;500m&quot;
              memory: 500Mi
</code></pre>
<h3 id="容量伸缩"><a class="header" href="#容量伸缩">容量伸缩</a></h3>
<p>MLService 支持自动伸缩服务容量：即根据服务负载的变化，自动调节推理服务的部署规模（副本数量）。具体原理可以查看 <a target="_blank" rel="noopener noreferrer" href="https://knative.dev/docs/serving/autoscaling/">Knative Autoscaling</a>。</p>
<p>用户可以通过设置 <code>spec.releases[*].predictor.minReplicas</code> 字段和 <code>spec.releases[*].predictor.maxReplicas</code> 字段来指定 Predictor 工作负载数量的下限和上限。</p>
<p>同样的，如果用户启用了 Transformer，可以通过 <code>spec.transformer.minReplicas</code> 字段和 <code>spec.transformer.maxReplicas</code> 字段来指定 Transformer 工作负载数量的下限和上限。</p>
<p>以下是一些特殊情况：</p>
<ul>
<li><code>minReplicas</code> 不填时，工作负载数量的默认最小值为 1。</li>
<li><code>minReplicas</code> 等于 0 时，当没有流量请求时，MLService 会缩容到 0，不再占用系统资源。</li>
<li><code>maxReplicas</code> 不填或设为 0 时，工作负载数量没有上限。</li>
</ul>
<p>除了负载数量的限制，用户还可以在具体的 Runtime 或者组件（Predictor 或者 Transformer）的 Pod 定义中设置 Knative Autoscaling 相关的 Annotation，例如：</p>
<pre><code class="language-yaml">...
spec:
  releases:
    - name: version1
      minReplicas: 1
      maxReplicas: 3
      predictor:
        template:
          metadata:
            annotations: 
              autoscaling.knative.dev/metric: &quot;rps&quot;
              autoscaling.knative.dev/target: &quot;100&quot;
...
</code></pre>
<p>在上面的示例中，我们设置了工作负载数量的范围为 <code>[1,3]</code>，自动伸缩指标(metric)为 <code>rps</code>，自动伸缩目标(target)为 <code>100</code>。这意味着当每个工作负载每秒处理的请求数量（requests-per-second）达到 100 时，负载会开始扩容，且扩容最大数量为 3，最小数量为 1。</p>
<h3 id="调度器-1"><a class="header" href="#调度器-1">调度器</a></h3>
<p>MLService 支持使用两种调度器：Kubernetes 默认调度器（默认）和 <a href="modules/deployment/../../cluster/scheduling/index.html">T9k Scheduler</a>。MLService 通过 <code>spec.scheduler</code> 字段设置调度器：</p>
<ul>
<li>不设置 <code>spec.scheduler</code> 字段，则默认使用 Kubernetes 默认调度器。</li>
<li>设置 <code>spec.scheduler.t9kScheduler</code> 字段，则使用 T9k Scheduler 调度器。</li>
</ul>
<p>在下面的示例中，使用了 T9k Scheduler 调度器，且工作负载处于队列 <code>default</code> 中。</p>
<pre><code class="language-yaml">...
spec:
  scheduler:
    t9kScheduler:
      queue: default
...
</code></pre>
<h2 id="服务状态-1"><a class="header" href="#服务状态-1">服务状态</a></h2>
<p>通过 MLService 的状态字段可以获取如下信息：</p>
<ul>
<li>推理服务的全局状态及服务地址：<code>status.ready</code> 表明推理服务是否准备就绪，<code>status.address.url</code> 表明全局推理服务地址。</li>
<li>每个部署的模型的状态及服务地址：<code>status.releases[*].ready</code> 表明该版本推理服务是否准备就绪，<code>status.releases[*].url</code> 表明该版本的推理服务地址。</li>
<li>Transformer 的状态及服务地址：<code>status.ready</code> 表明 Transformer 服务是否准备就绪，<code>status.transformer.url</code> 表明 Transformer 服务地址。</li>
<li>推理服务没有就绪的原因：<code>status.conditions</code> 以及 <code>status.releases[*].message</code> 等字段中会记录相关报错信息。</li>
</ul>
<p>以<a href="modules/deployment/mlservice.html#%E5%A4%9A%E7%89%88%E6%9C%AC%E6%94%AF%E6%8C%81">多版本支持</a>的示例的状态为例，其 MLService 状态字段如下。从状态字段可以看出，该推理服务处于就绪状态，外部访问地址为 <code>http://multi-releases.&lt;project&gt;.&lt;domain&gt;</code>，某个 release 的访问地址为 <code>http://multi-releases-predict-&lt;release&gt;.&lt;project&gt;.&lt;domain&gt;</code></p>
<pre><code class="language-yaml">status:
  address:
    url: http://multi-releases.&lt;project&gt;.&lt;domain&gt;
  canaryRelease: nov-02
  conditions:
  - lastTransitionTime: &quot;2023-11-27T10:44:27Z&quot;
    status: &quot;False&quot;
    type: Paused
  - lastTransitionTime: &quot;2023-11-27T10:50:04Z&quot;
    status: &quot;True&quot;
    type: Ready
  defaultRelease: nov-05
  releases:
  - name: nov-02
    ready: true
    readyReplicas: 1
    totalReplicas: 1
    trafficPercent: 80
    url: http://multi-releases-predict-nov-02.&lt;project&gt;.&lt;domain&gt;
  - name: nov-05
    ready: true
    readyReplicas: 1
    totalReplicas: 1
    trafficPercent: 20
    url: http://multi-releases-predict-nov-05.&lt;project&gt;.&lt;domain&gt;
  - name: nov-11
    ready: true
    readyReplicas: 1
    totalReplicas: 1
    trafficPercent: 0
    url: http://multi-releases-predict-nov-11.&lt;project&gt;.&lt;domain&gt;
</code></pre>
<p>如果推理服务没有就绪，你可以通过查看 <code>status.conditions</code> 中 type 为 <code>Ready</code> 的 reason 以及 message 来查看具体信息，同时 Event 中也会有相关的错误信息。</p>
<h2 id="访问推理服务-1"><a class="header" href="#访问推理服务-1">访问推理服务</a></h2>
<p>MLService 部署成功后，通过状态字段 <code>status.address.url</code> 可以查询到全局推理服务的 Base URL，再加上部署模型对应的路径即可得到访问推理服务的地址。</p>
<p>以<a href="modules/deployment/mlservice.html#%E7%A4%BA%E4%BE%8B">示例</a>中的服务为例，推理服务地址的状态字段如下：</p>
<pre><code class="language-yaml">...
status:
  address:
    url: http://torch-mnist.&lt;project&gt;.&lt;domain&gt;
...
</code></pre>
<p>由于服务使用的是 TorchServe 框架，按照其<a target="_blank" rel="noopener noreferrer" href="https://pytorch.org/serve/inference_api.html"> API 规范</a>，用户可以通过下述命令查看服务状态：</p>
<pre><code class="language-bash">$ curl http://torch-mnist.&lt;project-name&gt;.&lt;domain-name&gt;/v1/models/mnist
{
    &quot;model_version_status&quot;: &lt;model-status&gt;
}
</code></pre>
<p>并调用推理服务：</p>
<pre><code class="language-bash"># 数据在 https://github.com/t9k/tutorial-examples/blob/master/deployment/pvc/mlservice-torch/test_data/0.png
$ curl -T test_data/0.png http://torch-mnist.&lt;project-name&gt;.&lt;domain-name&gt;/v1/models/mnist:predict
{
    &quot;predictions&quot;: &lt;predict-result&gt;
}
</code></pre>
<h2 id="下一步-11"><a class="header" href="#下一步-11">下一步</a></h2>
<ul>
<li>了解如何部署一个<a href="modules/deployment/../../tasks/deploy-mlservice.html">模型推理服务</a></li>
<li>了解如何部署一个<a href="modules/deployment/../../tasks/deploy-mlservice-transformer.html">包含 Transformer 的推理服务</a></li>
<li>应用示例：<a href="modules/deployment/../../examples/deploy-llm-using-vllm.html">使用 vLLM 部署 LLM 推理服务</a></li>
<li>应用示例：<a href="modules/deployment/../../examples/deploy-conversational-search-engine.html">部署对话式搜索引擎</a></li>
</ul>
<h2 id="参考-1"><a class="header" href="#参考-1">参考</a></h2>
<ul>
<li>API 参考：<a href="modules/deployment/../../references/api-reference/mlservice.html">MLService</a></li>
<li>API 参考：<a href="modules/deployment/../../references/api-reference/mlservice.html#mlserviceruntime">MLServiceRuntime</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://knative.dev/docs/serving/autoscaling/">Knative Autoscaling</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="日志收集-1"><a class="header" href="#日志收集-1">日志收集</a></h1>
<p>MLService 支持对 predictor 和 transformer 服务进行日志收集，包括接收到的 request 和返回的 response 消息。开启日志收集后，系统会为 MLService 添加日志发送能力，其根据配置的接收 URL，将日志发送到 URL 指定的服务。</p>
<h2 id="设置-mlservice"><a class="header" href="#设置-mlservice">设置 MLService</a></h2>
<p>用户可以为每个 predictor 和 transformer 设置日志收集功能：</p>
<ol>
<li>predictor： MLService 的 <code>spec.releases[*].predictor.logger</code> 字段来启用 predictor 的日志收集功能。</li>
<li>transformer：通过设置 MLService 的 <code>spec.transformer.logger</code> 字段启用 transformer 的日志收集功能。</li>
</ol>
<p>用户可以通过日志收集的下列字段，来设置日志收集配置：</p>
<ul>
<li><code>urls</code>：url 数组，系统会将收集到的日志发送到 url 对应的服务。</li>
<li><code>mode</code>：表示对哪些内容进行收集记录。可选值是 all, response, request，默认值是 all。
<ul>
<li>all：requests 和 response 都会被收集记录。</li>
<li>response：只记录收集 response。</li>
<li>request：只记录收集 requests。</li>
</ul>
</li>
</ul>
<h2 id="接收日志"><a class="header" href="#接收日志">接收日志</a></h2>
<p>日志数据通过 HTTP 协议被发送（HTTP POST）到用户提供的 URL。</p>
<p>日志数据格式是 <a target="_blank" rel="noopener noreferrer" href="https://cloudevents.io">CloudEvent</a>，如下例所示：</p>
<pre><code>Context Attributes,
  specversion: 1.0
  type: tensorstack.dev.mlservice.response
  source: torch-mnist-logger-predict-origin
  id: 0009174a-24a8-4603-b098-09c8799950e9
  time: 2021-04-10T00:23:26.080736102Z
  datacontenttype: application/json
Extensions,
  component: predict
  inferenceurl: /v1/models/mnist
  mlservicename: torch-mnist-logger
  namespace: example
  traceparent: 00-6d69e2d3917689ee301610780af06de8-be01c3cfdf8e446e-00
Data,
{
  &quot;0&quot;: 1.0,
  &quot;2&quot;: 1.3369853835154544e-10,
  &quot;6&quot;: 7.10219507987428e-14,
  &quot;5&quot;: 5.859705488843112e-14,
  &quot;9&quot;: 3.2580891499658536e-15
}
</code></pre>
<p>在上述示例中：</p>
<ul>
<li><code>type</code>：表明当前 CloudEvent 数据记录 response 内容。</li>
<li><code>source</code>：release 名称是 origin（source 命名规则是 <code>&lt;mlservice-name&gt;-&lt;component&gt;-&lt;release-name&gt;</code>）</li>
<li><code>component</code>：组件是 predict</li>
<li><code>inferenceurl</code>：URL path 是 <code>/v1/models/mnist</code></li>
<li><code>mlservicename</code>：MLService 的名称是 torch-mnist-logger</li>
<li><code>namespace</code>：MLService 所在的 namespace 是 example</li>
<li><code>Data</code>：MLService 向用户返回的 response 内容是 {“0”: 1.0,“2”: 1.3369…}</li>
</ul>
<p>在 HTTP Request 中：</p>
<ol>
<li>CloudEvent 的 Data 内容存在 Request Body 中</li>
<li>CloudEvent 的其他内容存在 Request Header 中</li>
</ol>
<p>可使用 CloudEvent 库来实现接收日志数据的 HTTP Server，具体实现可参考 <a target="_blank" rel="noopener noreferrer" href="https://github.com/cloudevents/sdk-go/blob/v2.10.0/samples/http/receiver-direct/main.go">CloudEvent Sample</a>。</p>
<h2 id="示例-1"><a class="header" href="#示例-1">示例</a></h2>
<h3 id="部署日志接收服务"><a class="header" href="#部署日志接收服务">部署日志接收服务</a></h3>
<aside class="note">
<div class="title">注意</div>
<p>实际生产使用，应当使用合适的 CloudEvent 接收服务。一些常见的接收服务可查看 <a target="_blank" rel="noopener noreferrer" href="https://cloudevents.io/#:~:text=the%20CloudEvents%20project!-,CloudEvents%20Adopters,-Adobe%20I/O">CloudEvents Adopters</a>。</p>
</aside>
<p>我们在集群内部署 <a target="_blank" rel="noopener noreferrer" href="https://github.com/knative/eventing-contrib/blob/v0.18.8/cmd/event_display/main.go">event-display</a> 服务来接受日志，注意：</p>
<ol>
<li>event-display 仅简单地将接收到的 CloudEvents 打印出来；</li>
<li>event-display 作为演示的目的。</li>
</ol>
<details><summary><code class="hljs">event-display.yaml</code></summary>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
 name: event-display
spec:
 replicas: 1
 selector:
   matchLabels:
     app: event-display
 template:
   metadata:
     labels:
       app: event-display
   spec:
     containers:
       - name: event-display
         image: t9kpublic/knative_event_display:1.0.0
         resources:
           limits:
             cpu: 100m
             memory: 100Mi
---
kind: Service
apiVersion: v1
metadata:
 name: event-display
spec:
 selector:
   app: event-display
 ports:
 - protocol: TCP
   port: 80
   targetPort: 8080
</code></pre>
</details>
<p>部署命令</p>
<pre><code class="language-bash">kubectl create -f event-display.yaml
</code></pre>
<h3 id="部署-mlservice"><a class="header" href="#部署-mlservice">部署 MLService</a></h3>
<p>请按照<a href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，基于<a href="https://github.com/t9k/tutorial-examples/tree/master/deployment/mlservice/torch-pvc">部署用于生产环境的模型推理服务</a>示例来部署 MLService logger-example。</p>
<p>首先将 mlservice.yaml 修改为下列内容，注意：</p>
<ol>
<li>event-display 和 MLService 需要部署在同一个 namespace/project 中。</li>
<li>这个 MLService 仅对 predictor 设置了 logger 服务。</li>
</ol>
<details><summary><code class="hljs">mlservice.yaml</code></summary>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: MLService
metadata:
 name: logger-example
spec:
 default: origin
 releases:
   - name: origin
     predictor:
       logger:
         mode: all
         resources:
           limits:
             cpu: &quot;1&quot;
             memory: 2Gi
           requests:
             cpu: &quot;0.5&quot;
             memory: 1Gi
         urls:
         - http://event-display
       minReplicas: 1
       model:
         parameters:
           &quot;MODEL_PATH&quot;: &quot;mnist=model.mar&quot;
         runtime: t9k-torchserve
         modelUri: pvc://tutorial/tutorial-examples/deployment/mlservice/torch-pvc/
       containersResources:
       - name: user-container
         resources:
           limits:
             cpu: &quot;500m&quot;
             memory: 1Gi
</code></pre>
</details>
<p>然后按照 <a href="https://github.com/t9k/tutorial-examples/blob/master/deployment/mlservice/torch-pvc/README.md#%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4">README 文档</a>的操作步骤进行操作。</p>
<h3 id="查看日志"><a class="header" href="#查看日志">查看日志</a></h3>
<p>查看 event-display 容器的日志，可看到日志中打印的 CloudEvent 记录了预测请求的详细信息：</p>
<details><summary><code class="hljs">terminal.log</code></summary>
<pre><code class="language-console">$ k get pod -l app=event-display
NAME                             READY   STATUS    RESTARTS   AGE
event-display-7d8d9f97db-lpgg2   1/1     Running   0          14m


$ k logs event-display-7d8d9f97db-lpgg2 
Context Attributes,
  specversion: 1.0
  type: tensorstack.dev.mlservice.request
  source: logger-example-predict-origin
  id: ff726d6b-7fd8-471e-9ddc-de03b201d882
  time: 2024-02-29T08:07:00.849119273Z
Extensions,
  component: predict
  inferenceurl: /v1/models/mnist:predict
  mlservicename: logger-example
  namespace: demo
Data,
  PNG
IHDWfHIDATxc`X`ˬUvo&gt;C0$ůشi˿_{ ZATI̶_Q%̓*y_:=U9;4ɺpJ^{oG8NIx$!K.w;@@4^0
                                                                                                                                     G$Qp֛q?{4g^B
                                                                                                                                                                      &lt;`Rr330
ztB?IENDB`
☁️  cloudevents.Event
Context Attributes,
  specversion: 1.0
  type: tensorstack.dev.mlservice.response
  source: logger-example-predict-origin
  id: ff726d6b-7fd8-471e-9ddc-de03b201d882
  time: 2024-02-29T08:07:01.468872477Z
Extensions,
  component: predict
  inferenceurl: /v1/models/mnist:predict
  mlservicename: logger-example
  namespace: demo
Data,
  {
  &quot;0&quot;: 1.0,
  &quot;2&quot;: 1.3369905182969433e-10,
  &quot;6&quot;: 7.102208632401436e-14,
  &quot;5&quot;: 5.859716330864836e-14,
  &quot;9&quot;: 3.2580891499658536e-15
}
</code></pre>
</details>
<h2 id="参考-2"><a class="header" href="#参考-2">参考</a></h2>
<ul>
<li>API 参考：<a href="modules/deployment/../../references/api-reference/mlservice.html">MLService</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://cloudevents.io/">CloudEvents </a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/knative/eventing-contrib/blob/v0.18.8/cmd/event_display/main.go">event display 源码</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="模型存储-2"><a class="header" href="#模型存储-2">模型存储</a></h1>
<p>AI 模型可以存储在集群的<a href="modules/deployment/../storage/index.html">文件系统</a>里，或者 S3 对象存储服务中。</p>
<p>SimpleMLService 和 MLService 采用相同的方式指定模型的存储细节，用户可以明确、方便地指定模型在集群文件系统或者 S3 对象存储服务中的位置，并设置模型在容器中的挂载路径。</p>
<h2 id="文件系统"><a class="header" href="#文件系统">文件系统</a></h2>
<p>通过配置 <code>storage.pvc</code> 字段可以通过 <a href="modules/deployment/../storage/pvc.html">PVC</a> 使用集群文件系统中的模型。<code>storage.pvc</code> 字段包含下列子字段：</p>
<ul>
<li><code>name</code>: 存储模型数据的 PVC 的名称。</li>
<li><code>subPath</code>: 模型在 PVC 中的路径，不可以是绝对路径（即开头不能是 <code>/</code>）。</li>
<li><code>mountPath</code>: 模型在容器中的挂载路径，必须是绝对路径。未设置时，默认值是 <code>/var/lib/t9k/model</code>。</li>
</ul>
<p>示例如下：</p>
<pre><code class="language-yaml">storage:
  pvc:
    name: demo
    subPath: path/mnist
    mountPath: /var/lib/custom
</code></pre>
<p>在上述示例中：</p>
<ul>
<li>PVC 名称是 <code>demo</code>。</li>
<li>模型在 PVC 中的路径是 <code>path/mnist</code>。</li>
<li>模型会被挂载到容器的路径 <code>/var/lib/custom</code> 下。</li>
</ul>
<h2 id="s3-2"><a class="header" href="#s3-2">S3</a></h2>
<p>当使用 S3 服务存储的模型数据时：</p>
<ul>
<li>SimpleMLService/MLService 需要先通过 initContainer 下载模型数据到容器本地，然后才能供给推理服务使用。如果下载失败，则推理服务无法启动。</li>
<li>当 SimpleMLService/MLService 设置了多个副本时，每个副本都需要单独下载模型数据，副本间无法共享模型数据。</li>
</ul>
<p>如果用户想使用存储在 S3 服务中的模型数据，需要：</p>
<ol>
<li>创建存储 S3 服务信息的 Secret</li>
<li>设置 <code>storage.s3</code> 字段</li>
</ol>
<h3 id="创建-s3-secret-1"><a class="header" href="#创建-s3-secret-1">创建 S3 Secret</a></h3>
<p>存储 S3 信息的 <a href="modules/deployment/../auxiliary/secret.html">Secret</a> 需要满足下列条件：</p>
<ol>
<li>设置 label <code>tensorstack.dev/resource: s3</code>。</li>
<li>设置 <code>data[.s3cfg]</code> 字段，内容是 Base64 编码的 <a target="_blank" rel="noopener noreferrer" href="https://s3tools.org/s3cmd">s3cmd</a> config。</li>
</ol>
<p>YAML 示例如下：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: s3-sample
  labels:
    tensorstack.dev/resource: s3
type: Opaque
data:
  .s3cfg: aG9zdF9iYXNlID0gczMuYXAtZWFzdC0xLmFtYXpvbmF3cy5jb20KaG9zdF9idWNrZXQgPSBleGFtcGxlLnMzLmFwLWVhc3QtMS5hbWF6b25hd3MuY29tCmJ1Y2tldF9sb2NhdGlvbiA9IGFwLWVhc3QtMQp1c2VfaHR0cHMgPSBGYWxzZQphY2Nlc3Nfa2V5ID0gdXNlcgpzZWNyZXRfa2V5ID0gcGFzc3dvcmQKc2lnbmF0dXJlX3YyID0gRmFsc2U=
</code></pre>
<p>其中 <code>data[.s3cfg]</code> 字段 Base64 解码后如下：</p>
<pre><code>host_base = s3.ap-east-1.amazonaws.com
host_bucket = example.s3.ap-east-1.amazonaws.com
bucket_location = ap-east-1
use_https = False
access_key = user
secret_key = password
signature_v2 = False
</code></pre>
<h3 id="设置-storages3"><a class="header" href="#设置-storages3">设置 <code>storage.s3</code></a></h3>
<p>设置 <code>storage.s3</code> 字段来使用存储在 S3 中的模型数据。<code>storage.s3</code> 字段包含下列子字段: </p>
<ul>
<li><code>secretRef</code>: 记录存储 S3 配置信息的 Secret。该字段有下列子字段：
<ul>
<li><code>name</code>：Secret 名称。</li>
</ul>
</li>
<li><code>uri</code>: 模型在 S3 中的存储标识。</li>
<li><code>mountPath</code>: 模型在容器中的挂载路径，必须是绝对路径。未设置时，默认值是 <code>/var/lib/t9k/model</code>。</li>
</ul>
<p>示例如下：</p>
<pre><code class="language-yaml">storage:
  s3:
    secretRef:
      name: s3-secret
    uri: s3://models/mnist/
    mountPath: /var/lib/custom
</code></pre>
<p>在上述示例中：</p>
<ul>
<li>Secret <code>s3-secret</code> 存储着 S3 配置信息。</li>
<li>模型在 S3 中的存储标识是 <code>s3://models/mnist/</code>。</li>
<li>模型会被挂载到容器的路径 <code>/var/lib/custom</code> 下。</li>
</ul>
<h2 id="存储类型比较"><a class="header" href="#存储类型比较">存储类型比较</a></h2>
<p>使用 PVC 存储模型数据：</p>
<ul>
<li>优点：
<ul>
<li>挂载速度快</li>
<li>多副本可以共享 PVC 数据</li>
</ul>
</li>
<li>缺点：
<ul>
<li>需要提前创建 PVC，并在 PVC 中准备好模型数据</li>
</ul>
</li>
</ul>
<p>使用 S3 存储模型数据：</p>
<ul>
<li>优点：
<ul>
<li>只需简单设置，就能 S3 服务存储的模型数据</li>
<li>跨项目共享使用模型很方便</li>
</ul>
</li>
<li>缺点：
<ul>
<li>S3 中的模型需要先被下载才能使用，启动时间一般较长</li>
<li>多副本间无法共享模型数据，每个副本都需要从 S3 下载模型数据</li>
</ul>
</li>
</ul>
<h2 id="下一步-12"><a class="header" href="#下一步-12">下一步</a></h2>
<ul>
<li>查看 <a href="modules/deployment/../../tasks/deploy-mlservice.html">MLService 部署示例</a>的模型存储设置</li>
<li>查看 <a href="modules/deployment/../../tasks/deploy-simplemlservice.html">SimpleMLService 部署示例</a>的模型存储设置</li>
</ul>
<h2 id="参考-3"><a class="header" href="#参考-3">参考</a></h2>
<ul>
<li><a href="https://aws.amazon.com/s3/">S3</a></li>
<li><a href="https://s3tools.org/s3cmd">s3cmd</a></li>
<li><a href="modules/deployment/../storage/pvc.html">PVC</a></li>
<li>API 参考：<a href="modules/deployment/../../references/api-reference/mlservice.html#storage">Storage in MLService</a></li>
<li>API 参考：<a href="modules/deployment/../../references/api-reference/simplemlservice.html#storage">Storage in SimpleMLService</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="job"><a class="header" href="#job">Job</a></h1>
<p>TensorStack 定义了一系列 CRD（称为 Job）以支持<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Batch_processing">批处理（Batch Processing）</a>计算任务，特别是 AI 领域的大规模分布式并行训练类型性质的计算。</p>
<figure class="architecture">
  <img alt="t9k-job" src="modules/jobs/../../assets/modules/jobs/jobs.drawio.svg" />
  <figcaption>图 1：Job 系统的基本原理。用户提交 Job 的定义；Job Controller 1）分析 Job 定义；2）请求计算资源（CPU、RAM、GPU、高速网络、存储...)；3）启动、监控、暂停、继续 、终止、调试 Job。</figcaption>
</figure>
<aside class="note info">
<div class="title">Job</div>
<p>Kubernetes 也定义了一个原生资源 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/job/">batch/v1 Job</a> 以支持通用计算性质的批处理任务。本手册提到 Job 时，一般可根据上下文区分；当上下文不足以提供区分时，本手册将会明确使用 <strong>T9k Job</strong> 或者 <strong>batch/v1 Job</strong>。</p>
</aside>
<h2 id="job-类型"><a class="header" href="#job-类型">Job 类型</a></h2>
<p>为了支持不同框架的计算任务，TensorStack 提供了一系列 Job：</p>
<ul>
<li>TrainingJob：一类使用分布式计算框架进行机器学习的 T9k Job。
<ul>
<li><a href="modules/jobs/./pytorchtrainingjob.html">PyTorchTrainingJob</a>：服务于 <a target="_blank" rel="noopener noreferrer" href="https://pytorch.org/">PyTorch</a> 分布式训练框架的 T9k Job。</li>
<li><a href="modules/jobs/./tensorflowtrainingjob.html">TensorFlowTrainingJob</a>：服务于 <a target="_blank" rel="noopener noreferrer" href="https://www.tensorflow.org/guide/distributed_training">TensorFlow</a> 分布式训练框架的 T9k Job。</li>
<li><a href="modules/jobs/./xgboosttrainingjob.html">XGBoostTrainingJob</a>：服务于 <a target="_blank" rel="noopener noreferrer" href="https://xgboost.readthedocs.io/en/latest/">XGBoost</a> 分布式计算框架的 T9k Job。</li>
<li><a href="modules/jobs/./colossalaijob.html">ColossalAIJob</a>：服务于 <a target="_blank" rel="noopener noreferrer" href="https://colossalai.org/">ColossalAI</a> 分布式训练框架的 T9k Job。</li>
<li><a href="modules/jobs/./deepspeedjob.html">DeepSpeedJob</a>：服务于 <a target="_blank" rel="noopener noreferrer" href="https://www.deepspeed.ai/">DeepSpeed</a> 分布式训练框架的 T9k Job。</li>
</ul>
</li>
<li><a href="modules/jobs/./mpijob.html">MPIJob</a>：MPIJob 使用户能够方便地在集群环境中使用 <a target="_blank" rel="noopener noreferrer" href="https://www.open-mpi.org/">OpenMPI</a> 进行并行计算。</li>
<li><a href="modules/jobs/./beamjob.html">BeamJob</a>：用于在集群中通过 <a target="_blank" rel="noopener noreferrer" href="https://beam.apache.org/documentation/sdks/python/">Apache Beam Python SDK</a> 运行分布式计算任务，并支持多种底层计算引擎（例如 Apache Spark, Apache Flink）。</li>
<li><a href="modules/jobs/./genericjob.html">GenericJob</a>：一个通用的 T9k Job 资源，支持各种并行计算场景及 T9k 高级调度策略。
<ul>
<li>GenericJob 十分灵活，用户可以使用 GenericJob 实现 MPIJob、PyTorchTrainingJob 等特定功能的 T9k Job；但其自动化程度低，需要手工设置很多参数。</li>
<li>GenericJob 的目的是提供一个总是可行的 “通用” 机制，以支持一些其他特定功能 T9k Jobs 还未支持的新的计算场景。 </li>
</ul>
</li>
</ul>
<h2 id="运行模式"><a class="header" href="#运行模式">运行模式</a></h2>
<p>T9k Job 支持多种运行模式（<code>spec.runMode</code>）：</p>
<ul>
<li>立即（Immediate）模式：默认、基本模式。Job 被分配资源后，将会立即开始运行。</li>
<li>调试（Debug）模式：帮助用户创建 Job 环境，但不立即执行，用户可以在训练环境中手动启动 Job 或者运行调试代码。</li>
<li>暂停（Pause）模式：暂停执行 Job；在一些场合下（如集群资源不足），用户可随时暂停 Job，待条件允许再继续执行 Job。</li>
<li>弹性（Elastic）伸缩模式：可以动态调整 Job 规模。</li>
</ul>
<p>以下是各类型 Job 支持的模式列表：</p>
<div class="table-wrapper"><table><thead><tr><th>Job 类型</th><th>立即模式</th><th>调试模式</th><th>暂停模式</th><th>弹性伸缩模式</th></tr></thead><tbody>
<tr><td>GenricJob</td><td>*</td><td>*</td><td>*</td><td></td></tr>
<tr><td>PyTorchTrainingJob</td><td>*</td><td>*</td><td>*</td><td>*</td></tr>
<tr><td>TensorFlowTrainingJob</td><td>*</td><td>*</td><td>*</td><td></td></tr>
<tr><td>XGBoostTrainingJob</td><td>*</td><td>*</td><td>*</td><td></td></tr>
<tr><td>MPIJob</td><td>*</td><td>*</td><td>*</td><td></td></tr>
<tr><td>ColossalAIJob</td><td>*</td><td>*</td><td>*</td><td></td></tr>
<tr><td>DeepSpeedJob</td><td>*</td><td>*</td><td>*</td><td>*</td></tr>
<tr><td>BeamJob</td><td>*</td><td></td><td></td><td></td></tr>
</tbody></table>
</div>
<p>各种模式的具体使用方式，请参考对应 Job 类型的文档。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="genericjob"><a class="header" href="#genericjob">GenericJob</a></h1>
<p>GenericJob 是最基本的 T9k Job 资源，支持使用 T9k 高级调度策略。GenericJob 的使用十分灵活，一个熟练的使用者可以通过 GenericJob 实现 MPIJob、PyTorchTrainingJob 等特定功能的 T9k Job。</p>
<h2 id="创建-genericjob"><a class="header" href="#创建-genericjob">创建 GenericJob</a></h2>
<p>下面是一个基本的 GenericJob 配置示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: GenericJob
metadata:
  name: generic-example
spec:
  successRules:
    - { &quot;worker&quot;: [0] }
  failureRules:
    - { &quot;worker&quot;: [0] }
    - { &quot;worker&quot;: [1] }
  replicaSpecs:
    - type: worker
      replicas: 4
      template:
        spec:
          containers:
            - command:
                - sleep
                - '365'
              image: nginx:latest
              name: sleep
</code></pre>
<p>在该例中：</p>
<ul>
<li>创建 4 个副本（由 <code>spec.replicaSpecs[0].replicas</code> 字段指定），这些副本的角色为 <code>worker</code>（由 <code>spec.replicaSpecs[0].type</code> 字段指定）。每个副本执行命令 <code>sleep 365</code>（由 <code>spec.replicaSpecs[0].template</code> 字段指定）。</li>
<li>GenericJob 的成功条件为序号为 0 且角色为 <code>worker</code> 的副本执行完成（由 <code>spec.successRules</code> 字段指定）。</li>
<li>GenericJob 的失败条件有两个，任意一个条件达成都会导致 GenericJob 失败（由 <code>spec.failureRules</code> 字段指定）：
<ul>
<li>序号为 0 且角色为 <code>worker</code> 的副本执行失败。</li>
<li>序号为 1 且角色为 <code>worker</code> 的副本执行失败。</li>
</ul>
</li>
</ul>
<h2 id="成功和失败"><a class="header" href="#成功和失败">成功和失败</a></h2>
<p>GenericJob 的成功和失败条件是通过 <code>spec.successRules</code> 和 <code>spec.failureRules</code> 字段指定的，其规则如下：</p>
<ul>
<li><code>spec.successRules</code> 数组包含 GenericJob 的所有成功条件，其中：
<ul>
<li>任意一个条件达成则 GenericJob 成功。</li>
<li>每个条件是一个由若干副本组成的集合，如果这些副本都执行完成，则该条件达成。</li>
</ul>
</li>
<li><code>spec.failureRules</code> 数组包含 GenericJob 的所有失败条件，其中
<ul>
<li>任意一个条件达成则 GenericJob 失败。</li>
<li>每个条件是一个由若干副本组成的集合，如果这些副本都失败或者重启次数耗尽，则该条件达成。</li>
</ul>
</li>
</ul>
<p>在下面的示例中，记录了 3 种 GenericJob 成功的判定条件：</p>
<ul>
<li>角色为 <code>master</code> 且序号为 0 的副本执行完成。</li>
<li>角色为 <code>worker</code> 且序号为 0、1、2 的三个副本全部执行完成。</li>
<li>角色为 <code>master</code> 且序号为 2 和角色为 <code>worker</code> 且序号为 0、1 的三个副本全部执行完成。</li>
</ul>
<p>和 1 种 GenericJob 失败的判定：</p>
<ul>
<li>角色为 <code>master</code> 且序号为 0 的副本执行失败。</li>
</ul>
<pre><code class="language-yaml">...
spec:
  successRules:
  - {&quot;master&quot;: [0]}
  - {&quot;worker&quot;: [0, 1, 2]}
  - {&quot;master&quot;: [2], &quot;worker&quot;: [0, 1]}
  failureRules:
  - {&quot;master&quot;: [0]}
</code></pre>
<h2 id="暴露副本的服务"><a class="header" href="#暴露副本的服务">暴露副本的服务</a></h2>
<p>在分布式计算中，有时需要不同的副本之间进行通信和数据交换。使用者可以通过设置 <code>spec.service</code> 字段来暴露副本的端口。</p>
<p>在下面的示例中，GenericJob 暴露出每一个副本的服务：端口为 <code>2222</code>，域名的格式为 <code>[job-name]-[type]-[rank]</code>，例如下例中角色为 <code>worker</code> 且序号为 0 的副本的域名为 <code>generic-example-worker-0</code>。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: GenericJob
metadata:
  name: generic-example
spec:
  service:
    ports:
      - name: http
        port: 2222
  replicaSpecs:
    - type: worker
      replicas: 1
...
</code></pre>
<h2 id="变量替换"><a class="header" href="#变量替换">变量替换</a></h2>
<p>在副本的配置信息中有时需要传入副本自身或其他副本的信息，包括序号、角色和副本的服务地址等。GenericJob 通过变量替换的方式提供这些信息，主要有以下 5 种变量：</p>
<ul>
<li><code>$(type)</code>：当前副本的角色。</li>
<li><code>$(rank)</code>：当前副本在同类副本中的序号。</li>
<li><code>$(replicas[_type_])</code>：扮演此角色的副本的数量。</li>
<li><code>$(service._type_[_rank_].host)</code>：各个副本的域名（当且仅当<a href="modules/jobs/genericjob.html#%E6%9A%B4%E9%9C%B2%E5%89%AF%E6%9C%AC%E7%9A%84%E6%9C%8D%E5%8A%A1">副本的服务被暴露出来</a>，此变量可用）。</li>
<li><code>$(service.port[_port-name_])</code>：<code>spec.service.ports</code> 字段中定义的服务端口号（当且仅当<a href="modules/jobs/genericjob.html#%E6%9A%B4%E9%9C%B2%E5%89%AF%E6%9C%AC%E7%9A%84%E6%9C%8D%E5%8A%A1">副本的服务被暴露出来</a>，此变量可用）。</li>
</ul>
<p>上述变量中 <code>_type_</code>、<code>_rank_</code> 和 <code>_port-name_</code> 需填入具体的<strong>角色</strong>、<strong>序号</strong>和<strong>端口名称</strong>（由 <code>spec.service.ports[*].name</code> 字段指定）。</p>
<p>变量替换可以被使用在下列字段中：</p>
<ul>
<li><code>spec.replicaSpecs[*].template.command</code></li>
<li><code>spec.replicaSpecs[*].template.args</code></li>
<li><code>spec.replicaSpecs[*].template.env</code></li>
</ul>
<p>以下是用 GenericJob 实现的 TensorFlow 分布式框架使用示例，其中 <code>TF_CONFIG</code> 环境变量需要填写所有副本的地址和当前副本的序号等信息，我们使用变量替换的方式添加：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: GenericJob
metadata:
  name: generic-example
spec:
  replicaSpecs:
    - type: worker
      replicas: 4
      template:
        spec:
          containers:
            - command:
                - python
                - /mnt/training.py
              image: tensorflow/tensorflow:2.11.0
              name: tensorflow
              env:
                - name: TF_CONFIG
                  value: '{&quot;task&quot;:{&quot;type&quot;:&quot;$(type)&quot;,&quot;index&quot;:$(rank)},&quot;cluster&quot;:{&quot;worker&quot;:[&quot;$(service.worker[0].host):$(service.port[http])&quot;,&quot;$(service.worker[1].host):$(service.port[http])&quot;,&quot;$(service.worker[2].host):$(service.port[http])&quot;,&quot;$(service.worker[3].host):$(service.port[http])&quot;]}}'
</code></pre>
<h2 id="重启机制"><a class="header" href="#重启机制">重启机制</a></h2>
<p>GenericJob 为副本提供以下重启机制：</p>
<ol>
<li><code>Never</code>：不重启</li>
<li><code>OnFailure</code>：错误即重启</li>
<li><code>Always</code>：总是重启（谨慎使用此策略，此策略可能导致 GenericJob 无法停止）</li>
</ol>
<p>GenericJob 重启机制通过 <code>spec.replicaSpecs[*].restartPolicy</code> 字段指定:</p>
<ul>
<li><code>spec.replicaSpecs[*].restartPolicy.policy</code> 表示当前副本所使用的重启策略，可以设置为 <code>Never</code>、<code>OnFailure</code> 或 <code>Always</code>。</li>
<li><code>spec.replicaSpecs[*].restartPolicy.limit</code> 表示当前副本的最大重启次数。</li>
</ul>
<p>不同的角色可以使用不同的重启策略，比如 <code>master</code> 使用 <code>Always</code>，<code>worker</code> 使用 <code>OnFailure</code>。</p>
<h2 id="清除策略"><a class="header" href="#清除策略">清除策略</a></h2>
<p>在 GenericJob 成功或失败后，控制器清理所创建的 Kubernetes 资源，使 GenericJob 不再浪费集群资源（内存、CPU 等）。GenericJob 提供三种策略，通过 <code>spec.cleanUpPolicy</code> 字段指定：</p>
<ul>
<li><code>All</code>：清除全部副本</li>
<li><code>None</code>：不清除副本</li>
<li><code>Unfinished</code>：清除未结束（处于 <code>Pending</code>、<code>Running</code> 或 <code>Unknown</code> 阶段）的副本</li>
</ul>
<aside class="note tip">
<div class="title">提示</div>
<p>已结束的副本不会继续消耗集群资源，因此在一定程度上，<code>Unfinished</code> 策略比 <code>All</code> 策略更优。但这并不总是适用，由于一个项目的资源配额的计算不考虑 Pod 是否已经结束，对于资源紧张的项目，如果确定不需要通过日志来调试 Job，则可以使用 <code>All</code> 策略。</p>
</aside>
<pre><code>`None` 策略主要用于训练脚本调试阶段。如果需要从副本中读取训练日志，则可以选用此策略。但由于这些副本可能占用资源并影响后续训练，建议你在调试完毕后手动删除这些副本或删除整个 GenericJob。
</code></pre>
<h2 id="调度器-2"><a class="header" href="#调度器-2">调度器</a></h2>
<p>目前 GenericJob 支持两种调度器：</p>
<ol>
<li>Kubernetes 的<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler">默认调度器</a></li>
<li><a href="modules/jobs/../scheduling/index.html">T9k Scheduler 调度器</a></li>
</ol>
<p>调度器通过 <code>spec.scheduler</code> 字段设置：</p>
<ul>
<li>不设置 <code>spec.scheduler</code> 字段，则默认使用 Kubernetes 的默认调度器。</li>
<li>设置 <code>spec.scheduler.t9kScheduler</code> 字段，则使用 T9k Scheduler 调度器。</li>
</ul>
<p>在下面的示例中，GenericJob 启用 T9k Scheduler 调度器，将副本插入 <code>default</code> 队列中等待调度，其优先级为 50。</p>
<pre><code class="language-yaml">...
spec:
  scheduler:
    t9kScheduler:
      queue: default
      priority: 50
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>队列和优先级都是 T9k Scheduler 的概念，具体含义请参阅 <a href="modules/jobs/../scheduling/index.html">T9k Scheduler</a>。</p>
</aside>
<h2 id="调试模式"><a class="header" href="#调试模式">调试模式</a></h2>
<p>GenericJob 支持调试模式。在该模式下，训练环境会被部署好，但不会启动训练，用户可以连入副本测试环境或脚本。</p>
<p>该模式可以通过 <code>spec.runMode.debug</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.debug.enabled</code> 表示是否启用调试模式。</li>
<li><code>spec.runMode.debug.replicaSpecs</code> 表示如何配置各个副本的调试模式：
<ul>
<li><code>spec.runMode.debug.replicaSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.debug.replicaSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.debug.replicaSpecs.command</code> 表示副本在等待调试的时候执行的命令，默认为 <code>sleep inf</code>。</li>
<li>如果不填写 <code>spec.runMode.debug.replicaSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了调试模式，并配置 worker 跳过 InitContainer，并执行 <code>/usr/bin/sshd</code>。</li>
<li>示例二：开启了调试模式，副本使用默认调试设置，即不跳过 InitContainer，并执行 <code>sleep inf</code>。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    debug:
      enabled: true
      replicaSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;/usr/bin/sshd&quot;]

---
# 示例二
...
spec:
  runMode:
    debug:
      enabled: true
</code></pre>
<h2 id="暂停模式"><a class="header" href="#暂停模式">暂停模式</a></h2>
<p>GenericJob 支持暂停模式。在该模式下，删除（或不创建）副本，停止训练。</p>
<p>该模式可以通过 <code>spec.runMode.pause</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.pause.enabled</code> 表示是否启用暂停模式。</li>
<li><code>spec.runMode.pause.resumeSpecs</code> 表示结束暂停后，如何恢复各个副本：
<ul>
<li><code>spec.runMode.pause.resumeSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.pause.resumeSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.pause.resumeSpecs.command</code> 和 <code>spec.runMode.pause.resumeSpecs.args</code> 表示副本在恢复运行时候执行的命令，默认使用 <code>spec.replicaSpecs[0].template</code> 中的命令。</li>
<li>如果不填写 <code>spec.runMode.pause.resumeSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>用户可以随时修改 <code>spec.runMode.pause.enabled</code> 来控制任务暂停，但是不可以更改 <code>spec.runMode.pause.resumeSpecs</code>，所以如果有暂停 GenericJob 的需求，请提前设置好恢复设置。</p>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了暂停模式，并配置 worker 跳过 InitContainer，并执行 <code>/usr/bin/sshd</code>。</li>
<li>示例二：开启了暂停模式，副本使用默认恢复设置，即不跳过 InitContainer，并执行 <code>spec.replicaSpecs[0].template</code> 中设置的命令。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    pause:
      enabled: true
      resumeSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;/usr/bin/sshd&quot;]

---
# 示例二
...
spec:
  runMode:
    pause:
      enabled: true
</code></pre>
<h2 id="genericjob-状态"><a class="header" href="#genericjob-状态">GenericJob 状态</a></h2>
<h3 id="genericjob-的状态和阶段"><a class="header" href="#genericjob-的状态和阶段">GenericJob 的状态和阶段</a></h3>
<p><code>status.conditions</code> 字段用于描述当前 GenericJob 的状态，包括以下 6 种类型：</p>
<ol>
<li><code>Initialized</code>：GenericJob 已经成功创建各子资源，完成初始化。</li>
<li><code>Running</code>：开始执行任务。</li>
<li><code>ReplicaFailure</code>：有一个或多个副本出现错误。</li>
<li><code>Completed</code>：GenericJob 成功。</li>
<li><code>Failed</code>：GenericJob 失败。</li>
<li><code>Paused</code>：GenericJob 进入暂停模式，所有副本都已删除或正在删除。</li>
</ol>
<p><code>status.phase</code> 字段用于描述当前 GenericJob 所处的阶段，GenericJob 的整个生命周期主要有以下7个阶段：</p>
<ol>
<li><code>Pending</code>：GenericJob 刚刚创建，等待副本启动。</li>
<li><code>Running</code>：副本创建成功，开始执行任务。</li>
<li><code>Paused</code>：GenericJob 进入暂停模式。</li>
<li><code>Resuming</code>：GenericJob 正从暂停模式中恢复运行。恢复运行后，切换为 <code>Running</code> 阶段。</li>
<li><code>Succeeded</code>：GenericJob 成功。</li>
<li><code>Failed</code>：GenericJob 失败。</li>
<li><code>Unknown</code>：控制器无法获得 GenericJob 的阶段。</li>
</ol>
<p>在下面的示例中，GenericJob 所有子资源创建成功，所以类型为 <code>Initalized</code> 的 <code>condition</code> 被设为 <code>True</code>；GenericJob 运行结束，所以类型为 <code>Completed</code> 的 <code>condition</code> 被设置为 <code>True</code>；但是 GenericJob 的训练结果是失败的，所以类型为 <code>Failed</code> 的 <code>condition</code> 被设置为 <code>True</code>（原因是 <code>The job is failed with rule: { &quot;worker&quot;: [0] }</code>）。当前 GenericJob 运行阶段为 <code>Failed</code>。</p>
<pre><code class="language-yaml">...
status:
  conditions:
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;True&quot;
      message: &quot;The job has been initialized successfully.&quot;
      reason: &quot;-&quot;
      type: Initializing
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;True&quot;
      message: &quot;All pods are running normally.&quot;
      reason: &quot;-&quot;
      type: Running
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;False&quot;
      message: &quot;All pods are running normally.&quot;
      reason: &quot;-&quot;
      type: ReplicaFailure
    - lastTransitionTime: &quot;2021-01-18T02:36:31Z&quot;
      status: &quot;False&quot;
      message: 'The job is failed with rule: { &quot;worker&quot;: [0] }'
      reason: &quot;Failed&quot;
      type: Completed
    - lastTransitionTime: &quot;2021-01-18T02:36:31Z&quot;
      status: &quot;True&quot;
      message: 'The job is failed with rule: { &quot;worker&quot;: [0] }'
      reason: &quot;Failed&quot;
      type: Failed
  phase: Failed
</code></pre>
<h3 id="副本的状态"><a class="header" href="#副本的状态">副本的状态</a></h3>
<p><code>status.tasks</code> 字段用来记录副本的状态，记录的内容主要包括：</p>
<ul>
<li>副本的重启次数（同一种角色的副本的重启次数之和）；</li>
<li>副本当前的运行阶段，此处的“运行阶段”在 K8s Pod 的 5 个阶段的基础上，添加了 <code>Creating</code> 和 <code>Deleted</code> 分别表示正在创建和已删除；</li>
<li>副本在集群中对应的 Pod 的索引信息。</li>
</ul>
<p>在下面的示例中，GenericJob 创建了 2 个角色为 <code>worker</code> 的副本，这 2 个副本的重启次数之和为 3，当前均处于 <code>Running</code> 阶段，分别运行在 <code>generic-example-worker-0</code> 和 <code>generic-example-worker-1</code> 这 2 个 Pod 上。</p>
<pre><code class="language-yaml">...
status:
  tasks:
  - type: worker
    restartCount: 3
    status:
    - phase: Running
      name: generic-example-worker-0
      uid: e3ec2ee3-6645-4e21-993f-1e472b94e0ae
      containers: []
    - phase: Running
      name: generic-example-worker-1
      uid: 908a93f0-7b8b-491e-85d5-3da0abcb4ca4
      containers: []
</code></pre>
<h3 id="副本状态统计"><a class="header" href="#副本状态统计">副本状态统计</a></h3>
<p><code>status.aggregate</code> 字段统计了各个阶段的副本数量。</p>
<p>在下面示例中，GenericJob 创建了 3 个副本，其中 1 个处于 <code>Pending</code> 阶段，另外两个处于 <code>Running</code> 阶段。</p>
<pre><code class="language-yaml">...
status:
  aggregate:
    creating: 0
    deleted: 0
    failed: 0
    pending: 1
    running: 2
    succeeded: 0
    unknown: 0
...
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="pytorchtrainingjob"><a class="header" href="#pytorchtrainingjob">PyTorchTrainingJob</a></h1>
<p>PyTorchTrainingJob 是服务于 <a target="_blank" rel="noopener noreferrer" href="https://pytorch.org/">PyTorch</a> 分布式训练框架的 T9k Job。</p>
<p>你可以较为方便地使用 PyTorchTrainingJob 为 PyTorch 训练脚本提供训练环境，并监控训练进程。</p>
<h2 id="创建-pytorchtrainingjob"><a class="header" href="#创建-pytorchtrainingjob">创建 PyTorchTrainingJob</a></h2>
<p>下面是一个基本的 PyTorchTrainingJob 配置示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: PyTorchTrainingJob
metadata:
  name: pytorch-example
spec:
  replicaSpecs:
  - replicas: 4
    restartPolicy: OnFailure
    template:
      spec:
        containers:
        - command:
          - python
          - dist_mnist.py
          image: pytorch/pytorch:2.0.0-cuda11.7-cudnn8-devel
          name: pytorch
    type: worker
</code></pre>
<p>在该例中：</p>
<ul>
<li>创建 4 个副本（由 <code>spec.replicaSpecs[*].replicas</code> 字段指定），副本的角色为 <code>worker</code>（由 <code>spec.replicaSpecs[*].type</code> 字段指定）。</li>
<li>每个副本使用 <code>pytorch/pytorch:2.0.0-cuda11.7-cudnn8-devel</code> 镜像，执行命令 <code>python dist_mnist.py</code>（由 <code>template</code> 字段指定，此处的填写方式参考 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/workloads/pods/#pod-templates">PodTemplate</a>）。</li>
<li>当副本失败后，会自动重启（由 <code>spec.replicaSpecs[*].restartPolicy</code> 字段指定）。</li>
</ul>
<aside class="note">
<div class="title">注意</div>
<p>PyTorchTrainingJob 中执行的脚本应使用 PyTorch 分布式训练框架，否则可能达不到训练效果。</p>
</aside>
<h2 id="使用-torchrun-启动训练"><a class="header" href="#使用-torchrun-启动训练">使用 torchrun 启动训练</a></h2>
<p>前面的示例中所使用的训练方法比较原始，即直接用 <code>python</code> 启动训练脚本，执行训练。</p>
<p>PyTorch 在后续提供了 <code>torch.distributed.launch</code> 包和 <code>torchrun</code> 工具来更好地启动和管理训练，具体优点包括：支持<strong>一机多进程</strong>、<strong>高容错</strong>、<strong>弹性伸缩训练规模</strong>等。PyTorchTrainingJob 也支持使用 <code>torchrun</code> 启动训练来继承这些优点。</p>
<pre><code class="language-yaml">spec:
  torchrunConfig:
    enabled: true
    maxRestarts: 10
    procPerNode: &quot;1&quot;
    rdzvBackend: c10d
    extraOptions: []
</code></pre>
<p>在 PyTorchTrainingJob 的定义中加入上述片段，来使用 <code>torchrun</code> 启动训练，其中：</p>
<ul>
<li><code>enabled</code>：是否启用 <code>torchrun</code>。</li>
<li><code>maxRestarts</code>：训练进程的最多重启次数。</li>
<li><code>procPerNode</code>：一个副本中启动多少个训练进程。除了可以指定一个数字字符串之外，还可以设置为 <code>gpu</code>，表示启动等同于副本所使用的 GPU 数量的训练进程。</li>
<li><code>rdzvBackend</code>：<code>torchrun</code> 所使用的汇合通信方式，可以设置为 <code>c10d</code>、<code>etcd</code> 或 <code>etcd-v2</code>，但是只有 <code>c10d</code> 是 <code>torch</code> 内置的。如果用户希望使用 <code>etcd</code> 需要自行搭建 <code>etcd</code> 服务器。</li>
<li><code>extraOptions</code>：<code>torchrun</code> 的其他参数，上面的参数是 <code>torchrun</code> 比较常用的设置，用户也可以通过 <code>extraOptions</code> 字段提供更多 <code>torchrun</code> 的其他设置。</li>
</ul>
<aside class="note">
<div class="title">注意</div>
<p>如果使用 torchrun 启动训练，容器的启动命令变为 <code>torchrun $torchrun_arg $training_script $training_args</code> 形式，其中 <code>training_script</code> 和 <code>training_args</code> 由字段 <code>spec.replicaSpecs[*].template.spec.containers[0].args</code> 指定，<code>spec.replicaSpecs[*].template.spec.containers[0].command</code> 将不再生效。</p>
<p>另外，PyTorchTrainingJob 使用 torchrun 前需要确定哪一个容器才是训练容器：如果有一个容器的 <code>name</code> 是 <code>python</code>，则这个容器是训练容器；否则序号为 0 的容器为训练容器。</p>
</aside>
<h3 id="弹性训练"><a class="header" href="#弹性训练">弹性训练</a></h3>
<p>使用 torchrun 启动的 PyTorchTrainingJob 支持弹性伸缩训练规模，通过 <code>spec.elastic</code> 设置伸缩范围和当前期望训练规模。</p>
<p>在下面的示例中，PyTorchTrainingJob 启用弹性训练功能，训练规模的伸缩范围是 [4,10]，当前期望训练规模为 7。</p>
<pre><code class="language-yaml">spec:
  elastic:
    enabled: true
    minReplicas: 4
    maxReplicas: 10
    expectedReplicas: 7
</code></pre>
<p>注：期望训练规模（<code>spec.elastic.expectedReplicas</code>）并不代表实际训练规模，当集群资源数量不足时，控制器可能无法创建足够的副本。</p>
<h3 id="最佳实践"><a class="header" href="#最佳实践">最佳实践</a></h3>
<pre><code class="language-yaml">...
spec:
  torchrunConfig:
    enabled: false
    minNodes: 1
    maxRestarts: 10
    procPerNode: &quot;1&quot;
    rdzvBackend: c10d
    extraOptions: []
  replicaSpecs:
  - replicas: 4
    restartPolicy: OnFailure
    template:
      spec:
        containers:
        - command:
          - python
          args:
          - dist_mnist.py
          image: pytorch/pytorch:2.0.0-cuda11.7-cudnn8-devel
          name: pytorch
    type: worker
...
</code></pre>
<p>在上面的示例中：<code>spec.replicaSpecs[*].template.spec.containers[0].command</code> 只填写 <code>python</code>，其他参数填写在 <code>spec.replicaSpecs[*].template.spec.containers[0].args</code> 中。这样可以实现以下效果：</p>
<ul>
<li>当 <code>spec.torchrunConfig.enabled</code> 设置为 <code>false</code> 时，控制器会为训练副本设置正确的环境变量，并通过 <code>python dist_mnist.py</code> 命令启动训练脚本。</li>
<li>当 <code>spec.torchrunConfig.enabled</code> 设置为 <code>true</code> 时，控制器会忽略 <code>python</code> 命令，而是改用 <code>torchrun</code> 命令，其格式为：<code>torchrun &lt;torchrun_args&gt; dist_mnist.py</code>。</li>
</ul>
<p>这样做的优点就是，在切换 <code>torchrun</code> 模式时，不需要对其他字段进行改动。</p>
<p>另外，如果用户使用 Python Module 作为训练脚本，可以参考以下配置：</p>
<pre><code class="language-yaml">...
spec:
  torchrunConfig:
    enabled: false
    ...
  replicaSpecs:
  - replicas: 4
    restartPolicy: OnFailure
    template:
      spec:
        containers:
        - command:
          - python
          args:
          - -m
          - training.module
          image: pytorch/pytorch:2.0.0-cuda11.7-cudnn8-devel
          name: pytorch
    type: worker
...
</code></pre>
<p>在上面的示例中，当 <code>spec.torchrunConfig.enabled</code> 设置为 <code>true</code> 时，<code>-m</code> 参数同样可以被 <code>torchrun</code> 使用。</p>
<h2 id="成功和失败-1"><a class="header" href="#成功和失败-1">成功和失败</a></h2>
<p>在 PyTorch 分布式训练框架中，需要设置 <code>MASTER_ADDR</code> 和 <code>MASTER_PORT</code>，PyTorchTrainingJob 会将第一个训练副本作为 master（主节点）。当分布式训练的主节点成功结束，PyTorch 分布式训练成功；反之，当分布式训练的主节点执行失败，PyTorch 分布式训练失败。</p>
<p>但是 master 的失败有时可能是因为环境因素导致的，比如集群网络断连、集群节点崩溃等等，此类原因导致的失败应该被允许自动恢复。针对这一情况，PyTorchTrainingJob 支持副本重启（请参阅<a href="modules/jobs/pytorchtrainingjob.html#%E9%87%8D%E5%90%AF%E6%9C%BA%E5%88%B6">重启机制</a>），并设定了重启次数限制（由 <code>spec.runPolicy.backoffLimit</code> 字段指定），当副本重启次数达到上限后，如果主节点再次失败，则训练失败。此外，PyTorchTrainingJob 可以设置最长执行时间（由 <code>spec.runPolicy.activeDeadlineSeconds</code> 字段指定），当超过这个执行时间后，训练失败。</p>
<p>如果 PyTorchTrainingJob 在没有超过重启次数和没有超过最长执行时间的情况下成功完成了主节点的运行，则训练成功。</p>
<h2 id="重启机制-1"><a class="header" href="#重启机制-1">重启机制</a></h2>
<p>PyTorchTrainingJob 的 <code>spec.replicaSpec[*].template</code> 字段使用 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/workloads/pods/#pod-templates">PodTemplate</a> 的规范填写，但是 Pod 的重启策略并不能满足 PyTorchTrainingJob 的需求，所以 PyTorchTrainingJob 会给副本的重启策略都设置为 Never，并由控制器根据 <code>spec.replicaSpec[*].restartPolicy</code> 字段处理副本的重启。</p>
<p>可选的重启策略有以下四种：</p>
<ul>
<li><code>Never</code>：不重启</li>
<li><code>OnFailure</code>：失败后重启</li>
<li><code>Always</code>：总是重启</li>
<li><code>ExitCode</code>：特殊退出码重启</li>
</ul>
<p>使用 <code>Never</code> 重启策略时，Job 的副本失败后不会重启。如果需要调试代码错误，可以选择此策略，便于从副本中读取训练日志。</p>
<p><code>ExitCode</code> 是一种比较特殊的重启策略，它将失败进程的返回值分为两类：一类是由于系统环境原因或用户操作导致的错误，此类错误可以通过重启解决；另一类是代码错误或者其他不可自动恢复的错误。可重启的退出码包括：</p>
<ul>
<li>130（128+2）：使用 <code>Control+C</code> 终止容器运行。</li>
<li>137（128+9）：容器接收到 <code>SIGKILL</code> 信号。</li>
<li>143（128+15）：容器接收到 <code>SIGTERM</code> 信号。</li>
<li>138：用户可以自定义这个返回值的含义。如果用户希望程序在某处退出并重启，可以在代码中写入这个返回值。</li>
</ul>
<h3 id="重启次数限制"><a class="header" href="#重启次数限制">重启次数限制</a></h3>
<p>如果因为某种原因（例如代码错误或者环境错误并且长时间没有修复），PyTorchTrainingJob 不断地失败重启却无法解决问题，这会导致集群资源的浪费。用户可以通过设置 <code>spec.runPolicy.backoffLimit</code> 字段（默认为 3）来设置副本的最大重启次数。重启次数为所有副本共享，即所有副本重启次数累计达到此数值后，副本将不能再次重启。</p>
<h2 id="清除策略-1"><a class="header" href="#清除策略-1">清除策略</a></h2>
<p>在训练结束后，可能有些副本仍处于运行状态。这些运行的副本仍然会占用集群资源，PyTorchTrainingJob 提供清除策略，在训练结束后删除这些副本。</p>
<p>PyTorchTrainingJob 提供以下三种策略：</p>
<ul>
<li><code>None</code>：不删除副本。</li>
<li><code>All</code>：删除所有副本。</li>
<li><code>Unfinished</code>：只删除未结束的副本。</li>
</ul>
<aside class="note tip">
<div class="title">提示</div>
<p>已结束的副本不会继续消耗集群资源，因此在一定程度上，<code>Unfinished</code> 策略比 <code>All</code> 策略更优。但这并不总是适用，由于一个项目的资源配额的计算不考虑 Pod 是否已经结束，对于资源紧张的项目，如果确定不需要通过日志来调试 Job，则可以使用 <code>All</code> 策略。</p>
</aside>
<pre><code>`None` 策略主要用于训练脚本调试阶段。如果需要从副本中读取训练日志，则可以选用此策略。但由于这些副本可能占用资源并影响后续训练，建议用户在调试完毕后手动删除这些副本或删除整个 PyTorchTrainingJob。
</code></pre>
<h2 id="调度器-3"><a class="header" href="#调度器-3">调度器</a></h2>
<p>目前 PyTorchTrainingJob 支持使用以下两种调度器：</p>
<ol>
<li>Kubernetes 的<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler">默认调度器</a></li>
<li><a href="modules/jobs/../scheduling/index.html">T9k Scheduler 调度器</a></li>
</ol>
<p>调度器通过 <code>spec.scheduler</code> 字段设置：</p>
<ul>
<li>不设置 <code>spec.scheduler</code> 字段，则默认使用 Kubernetes 的默认调度器。</li>
<li>设置 <code>spec.scheduler.t9kScheduler</code> 字段，则使用 T9k Scheduler 调度器。</li>
</ul>
<p>在下面的示例中，PyTorchTrainingJob 启用 T9k Scheduler 调度器，将副本插入 <code>default</code> 队列中等待调度，其优先级为 50。</p>
<pre><code class="language-yaml">...
spec:
  scheduler:
    t9kScheduler:
      queue: default
      priority: 50
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>队列和优先级都是 T9k Scheduler 的概念，具体含义请参阅 <a href="modules/jobs/../scheduling/index.html">T9k Scheduler</a>。</p>
</aside>
<h2 id="tensorboard-的使用"><a class="header" href="#tensorboard-的使用">TensorBoard 的使用</a></h2>
<p>PyTorchTrainingJob 支持使用 TensorBoard 对训练过程和结果进行实时可视化（由 <code>spec.tensorboardSpec</code> 字段设置）。</p>
<p>在下面的示例中，PyTorchTrainingJob 使用 <code>t9kpublic/tensorflow-2.11.0:cpu-sdk-0.5.2</code> 镜像创建一个 TensorBoard，可视化名为 <code>torch-tensorboard-pvc</code> 的 PVC 中 <code>/log</code> 路径下的模型数据。</p>
<pre><code class="language-yaml">...
spec:
  tensorboardSpec:
    image: t9kpublic/tensorflow-2.11.0:cpu-sdk-0.5.2
    trainingLogFilesets:
    - t9k://pvc/torch-tensorboard-pvc/log
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>TensorBoard 的详细介绍请参阅 <a href="modules/jobs/../building/tensorboard.html">TensorBoard</a>。</p>
</aside>
<h2 id="调试模式-1"><a class="header" href="#调试模式-1">调试模式</a></h2>
<p>PyTorchTrainingJob 支持调试模式。在该模式下，训练环境会被部署好，但不会启动训练，用户可以连入副本测试环境或脚本。</p>
<p>该模式可以通过 <code>spec.runMode.debug</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.debug.enabled</code> 表示是否启用调试模式。</li>
<li><code>spec.runMode.debug.replicaSpecs</code> 表示如何配置各个副本的调试模式：
<ul>
<li><code>spec.runMode.debug.replicaSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.debug.replicaSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.debug.replicaSpecs.command</code> 表示副本在等待调试的时候执行的命令，默认为 <code>sleep inf</code>。</li>
<li>如果不填写 <code>spec.runMode.debug.replicaSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了调试模式，并配置 worker 跳过 InitContainer，并执行 <code>/usr/bin/sshd</code>。</li>
<li>示例二：开启了调试模式，副本使用默认调试设置，即不跳过 InitContainer，并执行 <code>sleep inf</code>。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    debug:
      enabled: true
      replicaSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;/usr/bin/sshd&quot;]

---
# 示例二
...
spec:
  runMode:
    debug:
      enabled: true
</code></pre>
<h2 id="暂停模式-1"><a class="header" href="#暂停模式-1">暂停模式</a></h2>
<p>PyTorchTrainingJob 支持暂停模式。在该模式下，删除（或不创建）副本，停止训练。</p>
<p>该模式可以通过 <code>spec.runMode.pause</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.pause.enabled</code> 表示是否启用暂停模式。</li>
<li><code>spec.runMode.pause.resumeSpecs</code> 表示结束暂停后，如何恢复各个副本：
<ul>
<li><code>spec.runMode.pause.resumeSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.pause.resumeSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.pause.resumeSpecs.command</code> 和 <code>spec.runMode.pause.resumeSpecs.args</code> 表示副本在恢复运行时候执行的命令，默认使用 <code>spec.replicaSpecs[0].template</code> 中的命令。</li>
<li>如果不填写 <code>spec.runMode.pause.resumeSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>用户可以随时修改 <code>spec.runMode.pause.enabled</code> 来控制任务暂停，但是不可以更改 <code>spec.runMode.pause.resumeSpecs</code>，所以如果有暂停 PyTorchTrainingJob 的需求，请提前设置好恢复设置。</p>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了暂停模式，并配置 worker 跳过 InitContainer，并执行 <code>/usr/bin/sshd</code>。</li>
<li>示例二：开启了暂停模式，副本使用默认恢复设置，即不跳过 InitContainer，并执行 <code>spec.replicaSpecs[0].template</code> 中设置的命令。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    pause:
      enabled: true
      resumeSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;/usr/bin/sshd&quot;]

---
# 示例二
...
spec:
  runMode:
    pause:
      enabled: true
</code></pre>
<h2 id="pytorchtrainingjob-状态"><a class="header" href="#pytorchtrainingjob-状态">PyTorchTrainingJob 状态</a></h2>
<h3 id="pytorchtrainingjob-的状态和阶段"><a class="header" href="#pytorchtrainingjob-的状态和阶段">PyTorchTrainingJob 的状态和阶段</a></h3>
<p><code>status.conditions</code> 字段用于描述当前 PyTorchTrainingJob 的状态，包括以下 6 种类型：</p>
<ol>
<li><code>Initialized</code>：PyTorchTrainingJob 已经成功创建各子资源，完成初始化。</li>
<li><code>Running</code>：开始执行任务。</li>
<li><code>ReplicaFailure</code>：有一个或多个副本出现错误。</li>
<li><code>Completed</code>：PyTorchTrainingJob 成功。</li>
<li><code>Failed</code>：PyTorchTrainingJob 失败。</li>
<li><code>Paused</code>：PyTorchTrainingJob 进入暂停模式，所有副本都已删除或正在删除。</li>
</ol>
<p><code>status.phase</code> 字段用于描述当前 PyTorchTrainingJob 所处的阶段，PyTorchTrainingJob 的整个生命周期主要有以下7个阶段：</p>
<ol>
<li><code>Pending</code>：PyTorchTrainingJob 刚刚创建，等待副本启动。</li>
<li><code>Running</code>：副本创建成功，开始执行任务。</li>
<li><code>Paused</code>：PyTorchTrainingJob 进入暂停模式。</li>
<li><code>Resuming</code>：PyTorchTrainingJob 正从暂停模式中恢复运行。恢复运行后，切换为 <code>Running</code> 阶段。</li>
<li><code>Succeeded</code>：PyTorchTrainingJob 成功。</li>
<li><code>Failed</code>：PyTorchTrainingJob 失败。</li>
<li><code>Unknown</code>：控制器无法获得 PyTorchTrainingJob 的阶段。</li>
</ol>
<p>在下面的示例中，PyTorchTrainingJob 所有子资源创建成功，所以类型为 <code>Initalized</code> 的 <code>condition</code> 被设为 <code>True</code>；PyTorchTrainingJob 运行结束，所以类型为 <code>Completed</code> 的 <code>condition</code> 被设置为 <code>True</code>；PyTorchTrainingJob 的训练成功结束，所以类型为 <code>Completed</code> 的 <code>condition</code> 被设置为 <code>True</code>（原因是 <code>The job has finished successfully.</code>）。当前 PyTorchTrainingJob 运行阶段为 <code>Succeeded</code>。</p>
<pre><code class="language-yaml">...
status:
  conditions:
    - lastTransitionTime: &quot;2023-12-19T02:40:25Z&quot;
      message: The job has been initialized successfully.
      reason: '-'
      status: &quot;True&quot;
      type: Initialized
    - lastTransitionTime: &quot;2023-12-19T02:53:14Z&quot;
      message: The job has finished successfully.
      reason: Succeeded
      status: &quot;False&quot;
      type: Running
    - lastTransitionTime: &quot;2023-12-19T02:53:14Z&quot;
      message: The job has finished successfully.
      reason: Succeeded
      status: &quot;False&quot;
      type: Failed
    - lastTransitionTime: &quot;2023-12-19T02:53:14Z&quot;
      message: The job has finished successfully.
      reason: Succeeded
      status: &quot;True&quot;
      type: Completed
    - lastTransitionTime: &quot;2023-12-19T02:40:25Z&quot;
      message: All pods are running normally.
      reason: '-'
      status: &quot;False&quot;
      type: ReplicaFailure
  phase: Succeeded
</code></pre>
<h3 id="副本的状态-1"><a class="header" href="#副本的状态-1">副本的状态</a></h3>
<p><code>status.tasks</code> 字段用来记录副本的状态，记录的内容主要包括：</p>
<ul>
<li>副本的重启次数（同一种角色的副本的重启次数之和）；</li>
<li>副本当前的运行阶段，此处的“运行阶段”在 K8s Pod 的 5 个阶段的基础上，添加了 <code>Creating</code> 和 <code>Deleted</code> 分别表示正在创建和已删除；</li>
<li>副本在集群中对应的 Pod 的索引信息。</li>
</ul>
<p>在下面的示例中，PyTorchTrainingJob 创建了 1 个角色为 <code>worker</code> 的副本，当前均处于 <code>Succeeded</code> 阶段，运行在 <code>torch-mnist-trainingjob-5b373-worker-0</code> 这个 Pod 上。</p>
<pre><code class="language-yaml">...
status:
  tasks:
  - replicas:
    - containers:
      - exitCode: 0
        name: pytorch
        state: Terminated
      name: torch-mnist-trainingjob-5b373-worker-0
      phase: Succeeded
      uid: d39f91d6-9c48-4c57-bb71-4131226395b6
    type: worker
</code></pre>
<h3 id="副本状态统计-1"><a class="header" href="#副本状态统计-1">副本状态统计</a></h3>
<p><code>status.aggregate</code> 字段统计了各个阶段的副本数量。</p>
<p>在下面示例中，PyTorchTrainingJob 创建了 3 个副本，其中 1 个处于 <code>Pending</code> 阶段，另外两个处于 <code>Running</code> 阶段。</p>
<pre><code class="language-yaml">...
status:
  aggregate:
    creating: 0
    deleted: 0
    failed: 0
    pending: 1
    running: 2
    succeeded: 0
    unknown: 0
...
</code></pre>
<h3 id="tensorboard-状态"><a class="header" href="#tensorboard-状态">TensorBoard 状态</a></h3>
<p><code>status.tensorboard</code> 字段用来记录 TensorBoard 的状态。</p>
<p>在下面的示例中，PyTorchTrainingJob 创建了名为 <code>torch-mnist-trainingjob-5b373</code> 的 TensorBoard，TensorBoard 目前运行正常。</p>
<pre><code class="language-yaml">status:
  tensorboard:
    action: NOP
    dependent:
      apiVersion: tensorstack.dev/v1beta1
      kind: TensorBoard
      name: torch-mnist-trainingjob-5b373
      namespace: demo
      uid: b09378f3-2164-4f14-a425-a1340fa32d7d
    note: TensorBoard [torch-mnist-trainingjob-5b373] is ready
    ready: true
    reason: DependentReady
    type: Normal
</code></pre>
<h2 id="下一步-13"><a class="header" href="#下一步-13">下一步</a></h2>
<ul>
<li>了解如何<a href="modules/jobs/../../tasks/pytorch-training-parallel.html">使用 PyTorchTrainingJob 进行数据并行训练</a></li>
<li>了解如何<a href="modules/jobs/../../tasks/pytorch-training-ps.html">使用 PyTorchTrainingJob 进行参数服务器训练</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="tensorflowtrainingjob"><a class="header" href="#tensorflowtrainingjob">TensorFlowTrainingJob</a></h1>
<p>TensorFlowTrainingJob 是服务于 <a target="_blank" rel="noopener noreferrer" href="https://www.tensorflow.org/guide/distributed_training">TensorFlow</a> 分布式训练框架的 T9k Job。</p>
<p>你可以较为方便地使用 TensorFlowTrainingJob 为 TensorFlow 训练脚本提供训练环境，并监控训练进程。</p>
<h2 id="创建-tensorflowtrainingjob"><a class="header" href="#创建-tensorflowtrainingjob">创建 TensorFlowTrainingJob</a></h2>
<p>下面是一个基本的 TensorFlowTrainingJob 配置示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: TensorFlowTrainingJob
metadata:
  name: tensorflow-example
spec:
  replicaSpecs:
  - replicas: 4
    restartPolicy: OnFailure
    template:
      spec:
        containers:
        - command:
          - python
          - dist_mnist.py
          image: tensorflow/tensorflow:2.11.0
          name: tensorflow
          resources:
            limits:
              cpu: 1
              memory: 2Gi
            requests:
              cpu: 500m
              memory: 1Gi
    type: worker
</code></pre>
<p>在该例中：</p>
<ul>
<li>创建 4 个副本（由 <code>spec.replicaSpecs[*].replicas</code> 字段指定），副本的角色为 <code>worker</code>（由 <code>spec.replicaSpecs[*].type</code> 字段指定）。</li>
<li>每个副本使用 <code>tensorflow/tensorflow:2.11.0</code> 镜像，执行命令 <code>python dist_mnist.py</code>（由 <code>spec.replicaSpecs&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://kubernetes.io/docs/concepts/workloads/pods/#pod-templates&quot;&gt;*].template</code> 字段指定，此处的填写方式参考 [PodTemplate</a>）。</li>
<li>当副本失败后，会自动重启（由 <code>spec.replicaSpecs[*].restartPolicy</code> 字段指定）。</li>
</ul>
<aside class="note">
<div class="title">注意</div>
<p>TensorFlowTrainingJob 的 <code>spec.replicaSpecs[*].template</code> 字段一定要包含 <code>name</code> 为 <code>tensorflow</code> 的容器，以便控制器识别训练使用的主容器。</p>
<p>TensorFlowTrainingJob 中执行的脚本应使用 TensorFlow 分布式训练框架，否则可能达不到训练效果。</p>
</aside>
<h2 id="副本的角色"><a class="header" href="#副本的角色">副本的角色</a></h2>
<p>在 TensorFlow 分布式训练框架中，副本有 4 种类型：Chief、Worker、PS 和 Evaluator。</p>
<p>在 TensorFlowTrainingJob 中，副本的类型由 <code>spec.replicaSpecs[*].type</code> 字段指定，分别是 <code>chief</code>、<code>worker</code>、<code>ps</code> 和 <code>evaluator</code>。</p>
<h2 id="成功和失败-2"><a class="header" href="#成功和失败-2">成功和失败</a></h2>
<p>在 TensorFlow 分布式训练框架中，Chief 是主节点。如果没有指定 Chief，则会选择第一个 Worker 作为主节点。当分布式训练的主节点执行完成时，TensorFlow 分布式训练成功；反之，当分布式训练的主节点执行失败时，TensorFlow 分布式训练失败。</p>
<p>在 TensorFlowTrainingJob 中，如果没有 Chief 副本，则选取序号为 0 的 Worker 节点作为主节点。主节点的失败有时可能是因为环境因素导致的，比如集群网络断连、集群节点崩溃等等，此类原因导致的失败应该被允许自动恢复。针对这一情况，TensorFlowTrainingJob 允许副本重启（请参阅<a href="modules/jobs/tensorflowtrainingjob.html#%E9%87%8D%E5%90%AF%E6%9C%BA%E5%88%B6">重启机制</a>），并设定了重启次数限制（由 <code>spec.runPolicy.backoffLimit</code> 字段指定），当副本重启次数达到上限后，如果主节点再次失败，则 TensorFlowTrainingJob 失败。此外，TensorFlowTrainingJob 可以设置最长执行时间（由 <code>spec.runPolicy.activeDeadlineSeconds</code> 字段指定），当超过这个执行时间后，TensorFlowTrainingJob 失败。</p>
<p>如果 TensorFlowTrainingJob 在没有超过重启次数和没有超过最长执行时间的情况下成功完成了主节点的运行，则 TensorFlowTrainingJob 成功。</p>
<h2 id="重启机制-2"><a class="header" href="#重启机制-2">重启机制</a></h2>
<p>TensorFlowTrainingJob 的 <code>spec.replicaSpec[*].template</code> 字段使用 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/workloads/pods/#pod-templates">PodTemplate</a> 的规范填写，但是 Pod 的重启策略并不能完全满足 TensorFlowTrainingJob 的需求，所以 TensorFlowTrainingJob 使用 <code>spec.replicaSpec[*].restartPolicy</code> 字段覆盖 <code>spec.replicaSpec[*].template</code> 中指定的重启策略。</p>
<p>可选的重启策略有以下四种：</p>
<ul>
<li><code>Never</code>：不重启</li>
<li><code>OnFailure</code>：失败后重启</li>
<li><code>Always</code>：总是重启</li>
<li><code>ExitCode</code>：特殊退出码重启</li>
</ul>
<p>使用 <code>Never</code> 重启策略时，Job 的副本失败后不会重启。如果需要调试代码错误，可以选择此策略，便于从副本中读取训练日志。</p>
<p><code>ExitCode</code> 是一种比较特殊的重启策略，它将失败进程的返回值分为两类：一类是由于系统环境原因或用户操作导致的错误，此类错误可以通过重启解决；另一类是代码错误或者其他不可自动恢复的错误。可重启的退出码包括：</p>
<ul>
<li>130（128+2）：使用 <code>Control+C</code> 终止容器运行。</li>
<li>137（128+9）：容器接收到 <code>SIGKILL</code> 信号。</li>
<li>143（128+15）：容器接收到 <code>SIGTERM</code> 信号。</li>
<li>138：用户可以自定义这个返回值的含义。如果用户希望程序在某处退出并重启，可以在代码中写入这个返回值。</li>
</ul>
<h3 id="重启次数限制-1"><a class="header" href="#重启次数限制-1">重启次数限制</a></h3>
<p>如果因为某种原因（例如代码错误或者环境错误并且长时间没有修复），TensorFlowTrainingJob 不断地失败重启却无法解决问题，这会导致集群资源的浪费。用户可以通过设置 <code>spec.runPolicy.backoffLimit</code> 字段来设置副本的最大重启次数。重启次数为所有副本共享，即所有副本重启次数累计达到此数值后，副本将不能再次重启。</p>
<h2 id="清除策略-2"><a class="header" href="#清除策略-2">清除策略</a></h2>
<p>在训练结束后，可能有些副本仍处于运行状态，比如 TensorFlow 训练框架中的 PS 经常在训练完成后仍然保持运行。这些运行的副本仍然会占用集群资源，TensorFlowTrainingJob 提供清除策略，在训练结束后删除这些副本。</p>
<p>TensorFlowTrainingJob 提供以下三种策略：</p>
<ul>
<li><code>None</code>：不删除副本。</li>
<li><code>All</code>：删除所有副本。</li>
<li><code>Unfinished</code>：只删除未结束的副本。</li>
</ul>
<aside class="note tip">
<div class="title">提示</div>
<p>已结束的副本不会继续消耗集群资源，因此在一定程度上，<code>Unfinished</code> 策略比 <code>All</code> 策略更优。但这并不总是适用，由于一个项目的资源配额的计算不考虑 Pod 是否已经结束，对于资源紧张的项目，如果确定不需要通过日志来调试 Job，则可以使用 <code>All</code> 策略。</p>
</aside>
<pre><code>`None` 策略主要用于训练脚本调试阶段。如果需要从副本中读取训练日志，则可以选用此策略。但由于这些副本可能占用资源并影响后续训练，建议你在调试完毕后手动删除这些副本或删除整个 TensorFlowTrainingJob。
</code></pre>
<h2 id="调度器-4"><a class="header" href="#调度器-4">调度器</a></h2>
<p>目前 TensorFlowTrainingJob 支持使用以下两种调度器：</p>
<ol>
<li>Kubernetes 的<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler">默认调度器</a></li>
<li><a href="modules/jobs/../scheduling/index.html">T9k Scheduler 调度器</a></li>
</ol>
<p>调度器通过 <code>spec.scheduler</code> 字段设置：</p>
<ul>
<li>不设置 <code>spec.scheduler</code> 字段，则默认使用 Kubernetes 的默认调度器。</li>
<li>设置 <code>spec.scheduler.t9kScheduler</code> 字段，则使用 T9k Scheduler 调度器。</li>
</ul>
<p>在下面的示例中，TensorFlowTrainingJob 启用 T9k Scheduler 调度器，将副本插入 <code>default</code> 队列中等待调度，其优先级为 50。</p>
<pre><code class="language-yaml">...
spec:
  scheduler:
    t9kScheduler:
      queue: default
      priority: 50
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>队列和优先级都是 T9k Scheduler 的概念，具体含义请参阅 <a href="modules/jobs/../scheduling/index.html">T9k Scheduler</a>。</p>
</aside>
<h2 id="tensorboard-的使用-1"><a class="header" href="#tensorboard-的使用-1">TensorBoard 的使用</a></h2>
<p>TensorFlowTrainingJob 支持使用 TensorBoard 对训练过程和结果进行实时可视化（由 <code>spec.tensorboardSpec</code> 字段设置）。</p>
<p>在下面的示例中，TensorFlowTrainingJob 使用 <code>t9kpublic/tensorflow-2.11.0:cpu-sdk-0.5.2</code> 镜像创建一个 TensorBoard，可视化名为 <code>tensorflow-tensorboard-pvc</code> 的 PVC 中 <code>/log</code> 路径下的模型数据。</p>
<pre><code class="language-yaml">...
spec:
  tensorboardSpec:
    image: t9kpublic/tensorflow-2.11.0:cpu-sdk-0.5.2
    trainingLogFilesets:
    - t9k://pvc/tensorflow-tensorboard-pvc/log
...
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>TensorBoard 的详细介绍请参阅 <a href="modules/jobs/(../building/tensorboard.html">TensorBoard</a>。</p>
</aside>
<h2 id="调试模式-2"><a class="header" href="#调试模式-2">调试模式</a></h2>
<p>TensorFlowTrainingJob 支持调试模式。在该模式下，训练环境会被部署好，但不会启动训练，用户可以连入副本测试环境或脚本。</p>
<p>该模式可以通过 <code>spec.runMode.debug</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.debug.enabled</code> 表示是否启用调试模式。</li>
<li><code>spec.runMode.debug.replicaSpecs</code> 表示如何配置各个副本的调试模式：
<ul>
<li><code>spec.runMode.debug.replicaSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.debug.replicaSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.debug.replicaSpecs.command</code> 表示副本在等待调试的时候执行的命令，默认为 <code>sleep inf</code>。</li>
<li>如果不填写 <code>spec.runMode.debug.replicaSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了调试模式，并配置 worker 跳过 InitContainer，并执行 <code>/usr/bin/sshd</code>。</li>
<li>示例二：开启了调试模式，副本使用默认调试设置，即不跳过 InitContainer，并执行 <code>sleep inf</code>。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    debug:
      enabled: true
      replicaSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;/usr/bin/sshd&quot;]

---
# 示例二
...
spec:
  runMode:
    debug:
      enabled: true
</code></pre>
<h2 id="暂停模式-2"><a class="header" href="#暂停模式-2">暂停模式</a></h2>
<p>TensorFlowTrainingJob 支持暂停模式。在该模式下，删除（或不创建）副本，停止训练。</p>
<p>该模式可以通过 <code>spec.runMode.pause</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.pause.enabled</code> 表示是否启用暂停模式。</li>
<li><code>spec.runMode.pause.resumeSpecs</code> 表示结束暂停后，如何恢复各个副本：
<ul>
<li><code>spec.runMode.pause.resumeSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.pause.resumeSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.pause.resumeSpecs.command</code> 和 <code>spec.runMode.pause.resumeSpecs.args</code> 表示副本在恢复运行时候执行的命令，默认使用 <code>spec.replicaSpecs[0].template</code> 中的命令。</li>
<li>如果不填写 <code>spec.runMode.pause.resumeSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>用户可以随时修改 <code>spec.runMode.pause.enabled</code> 来控制任务暂停，但是不可以更改 <code>spec.runMode.pause.resumeSpecs</code>，所以如果有暂停 TensorFlowTrainingJob 的需求，请提前设置好恢复设置。</p>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了暂停模式，并配置 worker 跳过 InitContainer，并执行 <code>/usr/bin/sshd</code>。</li>
<li>示例二：开启了暂停模式，副本使用默认恢复设置，即不跳过 InitContainer，并执行 <code>spec.replicaSpecs[0].template</code> 中设置的命令。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    pause:
      enabled: true
      resumeSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;/usr/bin/sshd&quot;]

---
# 示例二
...
spec:
  runMode:
    pause:
      enabled: true
</code></pre>
<h2 id="tensorflowtrainingjob-状态"><a class="header" href="#tensorflowtrainingjob-状态">TensorFlowTrainingJob 状态</a></h2>
<h3 id="tensorflowtrainingjob-的状态和阶段"><a class="header" href="#tensorflowtrainingjob-的状态和阶段">TensorFlowTrainingJob 的状态和阶段</a></h3>
<p><code>status.conditions</code> 字段用于描述当前 TensorFlowTrainingJob 的状态，包括以下 6 种类型：</p>
<ol>
<li><code>Initialized</code>：TensorFlowTrainingJob 已经成功创建各子资源，完成初始化。</li>
<li><code>Running</code>：开始执行任务。</li>
<li><code>ReplicaFailure</code>：有一个或多个副本出现错误。</li>
<li><code>Completed</code>：TensorFlowTrainingJob 成功。</li>
<li><code>Failed</code>：TensorFlowTrainingJob 失败。</li>
<li><code>Paused</code>：TensorFlowTrainingJob 进入暂停模式，所有副本都已删除或正在删除。</li>
</ol>
<p><code>status.phase</code> 字段用于描述当前 TensorFlowTrainingJob 所处的阶段，TensorFlowTrainingJob 的整个生命周期主要有以下7个阶段：</p>
<ol>
<li><code>Pending</code>：TensorFlowTrainingJob 刚刚创建，等待副本启动。</li>
<li><code>Running</code>：副本创建成功，开始执行任务。</li>
<li><code>Paused</code>：TensorFlowTrainingJob 进入暂停模式。</li>
<li><code>Resuming</code>：TensorFlowTrainingJob 正从暂停模式中恢复运行。恢复运行后，切换为 <code>Running</code> 阶段。</li>
<li><code>Succeeded</code>：TensorFlowTrainingJob 成功。</li>
<li><code>Failed</code>：TensorFlowTrainingJob 失败。</li>
<li><code>Unknown</code>：控制器无法获得 TensorFlowTrainingJob 的阶段。</li>
</ol>
<p>在下面的示例中，TensorFlowTrainingJob 所有子资源创建成功，所以类型为 <code>Initalized</code> 的 <code>condition</code> 被设为 <code>True</code>；TensorFlowTrainingJob 运行结束，所以类型为 <code>Completed</code> 的 <code>condition</code> 被设置为 <code>True</code>；TensorFlowTrainingJob 的训练成功结束，所以类型为 <code>Completed</code> 的 <code>condition</code> 被设置为 <code>True</code>（原因是 <code>The job has finished successfully.</code>）。当前 TensorFlowTrainingJob 运行阶段为 <code>Succeeded</code>。</p>
<pre><code class="language-yaml">...
status:
  conditions:
    - lastTransitionTime: &quot;2023-12-19T02:40:25Z&quot;
      message: The job has been initialized successfully.
      reason: '-'
      status: &quot;True&quot;
      type: Initialized
    - lastTransitionTime: &quot;2023-12-19T02:53:14Z&quot;
      message: The job has finished successfully.
      reason: Succeeded
      status: &quot;False&quot;
      type: Running
    - lastTransitionTime: &quot;2023-12-19T02:53:14Z&quot;
      message: The job has finished successfully.
      reason: Succeeded
      status: &quot;False&quot;
      type: Failed
    - lastTransitionTime: &quot;2023-12-19T02:53:14Z&quot;
      message: The job has finished successfully.
      reason: Succeeded
      status: &quot;True&quot;
      type: Completed
    - lastTransitionTime: &quot;2023-12-19T02:40:25Z&quot;
      message: All pods are running normally.
      reason: '-'
      status: &quot;False&quot;
      type: ReplicaFailure
  phase: Succeeded
</code></pre>
<h3 id="副本的状态-2"><a class="header" href="#副本的状态-2">副本的状态</a></h3>
<p><code>status.tasks</code> 字段用来记录副本的状态，记录的内容主要包括：</p>
<ul>
<li>副本的重启次数（同一种角色的副本的重启次数之和）；</li>
<li>副本当前的运行阶段，此处的“运行阶段”在 K8s Pod 的 5 个阶段的基础上，添加了 <code>Creating</code> 和 <code>Deleted</code> 分别表示正在创建和已删除；</li>
<li>副本在集群中对应的 Pod 的索引信息。</li>
</ul>
<p>在下面的示例中，TensorFlowTrainingJob 创建了 1 个角色为 <code>worker</code> 的副本，当前均处于 <code>Succeeded</code> 阶段，运行在 <code>mnist-trainingjob-5b373-worker-0</code> 这个 Pod 上。</p>
<pre><code class="language-yaml">...
status:
  tasks:
  - replicas:
    - containers:
      - exitCode: 0
        name: pytorch
        state: Terminated
      name: mnist-trainingjob-5b373-worker-0
      phase: Succeeded
      uid: d39f91d6-9c48-4c57-bb71-4131226395b6
    type: worker
</code></pre>
<h3 id="副本状态统计-2"><a class="header" href="#副本状态统计-2">副本状态统计</a></h3>
<p><code>status.aggregate</code> 字段统计了各个阶段的副本数量。</p>
<p>在下面示例中，TensorFlowTrainingJob 创建了 3 个副本，其中 1 个处于 <code>Pending</code> 阶段，另外两个处于 <code>Running</code> 阶段。</p>
<pre><code class="language-yaml">...
status:
  aggregate:
    creating: 0
    deleted: 0
    failed: 0
    pending: 1
    running: 2
    succeeded: 0
    unknown: 0
...
</code></pre>
<h3 id="tensorboard-状态-1"><a class="header" href="#tensorboard-状态-1">TensorBoard 状态</a></h3>
<p><code>status.tensorboard</code> 字段用来记录 TensorBoard 的状态。</p>
<p>在下面的示例中，TensorFlowTrainingJob 创建了名为 <code>mnist-trainingjob-5b373</code> 的 TensorBoard，TensorBoard 目前运行正常。</p>
<pre><code class="language-yaml">status:
  tensorboard:
    action: NOP
    dependent:
      apiVersion: tensorstack.dev/v1beta1
      kind: TensorBoard
      name: mnist-trainingjob-5b373
      namespace: demo
      uid: b09378f3-2164-4f14-a425-a1340fa32d7d
    note: TensorBoard [mnist-trainingjob-5b373] is ready
    ready: true
    reason: DependentReady
    type: Normal
</code></pre>
<h2 id="下一步-14"><a class="header" href="#下一步-14">下一步</a></h2>
<ul>
<li>了解如何<a href="modules/jobs/../../tasks/tensorflow-training-parallel.html">使用 TensorFlowTrainingJob 进行数据并行训练</a></li>
<li>了解如何<a href="modules/jobs/../../tasks/tensorflow-training-ps.html">使用 TensorFlowTrainingJob 进行参数服务器训练</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="deepspeedjob"><a class="header" href="#deepspeedjob">DeepSpeedJob</a></h1>
<p>DeepSpeedJob 是服务于 <a target="_blank" rel="noopener noreferrer" href="https://www.deepspeed.ai/">DeepSpeed</a> 分布式训练框架的 T9k Job。</p>
<p>你可以较为方便地使用 DeepSpeedJob 为 DeepSpeed 训练脚本提供训练环境，并监控训练进程。</p>
<h2 id="创建-deepspeedjob"><a class="header" href="#创建-deepspeedjob">创建 DeepSpeedJob</a></h2>
<p>下面是一个基本的 DeepSpeedJob 配置示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: DeepspeedJob
metadata:
  name: deepspeed-example
spec:
  config:
    slotPerWorker: 1
    run:
      python: /t9k/mnt/train.py
  worker:
    replicas: 4
    template:
      spec:
        restartPolicy: OnFailure
        containers:
        - image: deepspeed/deepspeed:v072_torch112_cu117
          imagePullPolicy: IfNotPresent
          name: worker
          resources:
            limits:
              cpu: 4
              memory: 4Gi
            requests:
              cpu: 2
              memory: 2Gi
          volumeMounts:
          - mountPath: /t9k/mnt
            name: code
        volumes:
        - name: code
          persistentVolumeClaim:
            claimName: deepspeed
</code></pre>
<p>在该例中：</p>
<ul>
<li>创建 4 个训练副本，这些副本会启动 <code>sshd</code> 服务。</li>
<li>第一个副本会启动 <code>deepspeed</code> 程序，该程序会通过 <code>pdsh</code>（或其他方式）访问 4 个副本，并在每个副本上运行 <code>/t9k/mnt/train.py</code> 脚本。</li>
</ul>
<aside class="note">
<div class="title">注意</div>
<p>一个副本中可以创建多个容器，DeepSpeedJob 需要确定哪一个容器才是训练容器。如果 <code>spec.worker.template</code> 中包含 <code>name</code> 为 <code>worker</code> 的 container，则该容器为训练容器；如果没有，会选取第一个 container 作为训练容器。</p>
<p>DeepSpeedJob 中的执行程序应是使用 DeepSpeed 框架的程序，否则可能达不到训练效果。</p>
<p>用户挂载文件时，需要避开下列路径，否则会导致 DeepSpeedJob 不能正常运行：<code>/root/.ssh</code>、<code>/t9k/hostfile</code>、<code>/root/.deepspeed_env</code>。</p>
</aside>
<h2 id="训练配置"><a class="header" href="#训练配置">训练配置</a></h2>
<p>DeepSpeedJob 在 <code>spec.config</code> 中配置如何执行训练。有以下参数可以设置：</p>
<ul>
<li><code>run</code>：如何启动训练，以下三个参数只能填写一个，否则报错：
<ul>
<li><code>python</code>：使用 Python 脚本进行训练。指定 Python 文件以及启动参数。</li>
<li><code>module</code>：使用 Python module 进行训练。指定 Python module 以及启动参数。</li>
<li><code>exec</code>：使用可执行文件/命令进行训练。指定可执行文件以及启动参数。</li>
</ul>
</li>
<li><code>slotsPerWorker</code>：每一个副本上设置多少个“插槽”。“插槽”是继承自 MPI 中的概念，表示一个副本上可以运行多少个训练进程。一般来说该值被设为每个副本分配的 GPU 数量。例如当创建了一个 <code>replica</code> 为 4 的任务，并且给每个副本分配了 2 个 <code>nvidia.com/gpu</code>，则应该将 <code>slotsPerWorker</code> 设为 2，这样最后一共会运行 <code>4 * 2 = 8</code> 个训练进程。</li>
<li><code>localRank</code>：是否传递 <code>LOCAL_RANK</code> 环境变量，默认为 <code>true</code>。</li>
<li><code>autotune</code>：启用超参数调优，可以设置为 <code>none</code>、<code>run</code>、<code>tune</code>，默认为 <code>none</code>。<code>none</code> 为不启动超参数调优；<code>tune</code> 只查找最合适的超参数组合，但是不执行训练；<code>run</code> 查找最合适的超参数组合，并用该超参数执行训练。</li>
<li><code>otherArgs</code>：设置其他 DeepSpeed 参数，详见下文。</li>
</ul>
<h3 id="otherargs"><a class="header" href="#otherargs">otherArgs</a></h3>
<p>DeepSpeedJob 希望提供用户足够的灵活性，所以支持用户通过 <code>otherArgs</code> 字段设置传入 DeepSpeed 的参数。config 中的配置实际上也是通过 DeepSpeed 参数实现的，以下列出除了在配置文件中指定的参数之外的其他可用参数：</p>
<ul>
<li><code>--launcher</code>： 多节点训练使用的启动器后端，目前的选项包括 PDSH、OpenMPI、MVAPICH、SLURM、MPICH。（默认：<code>pdsh</code>）。目前 DeepSpeedJob 只支持 <code>pdsh</code>。</li>
<li><code>--no_ssh_check</code>：多节点训练时不执行 ssh 检查。</li>
<li><code>--save_pid</code>： 在 <code>/tmp/&lt;main-pid&gt;.ds</code> 处保存包含启动器进程 ID（pid），其中 <code>&lt;main-pid&gt;</code> 是第一个调用 DeepSpeed 的进程的 pid。PDSH 模式下不支持。</li>
<li><code>--enable_each_rank_log</code>： 将每个 Rank 的 stdout 和 stderr 重定向到不同的日志文件。PDSH 模式下不支持。</li>
<li><code>--bind_cores_to_rank</code>：将每个 Rank 绑定到主机的不同核心。PDSH 模式下不支持。</li>
<li><code>--bind_core_list</code>：要绑定的核心列表，以逗号分隔。例如 <code>1,3-5,7 =&gt; [1,3,4,5,7]</code>。 未指定时，系统上的所有核心都将被绑定。PDSH 模式下不支持。</li>
</ul>
<aside class="note info">
<div class="title">信息</div>
<p>config 中的配置实际上是通过 DeepSpeed 参数实现的，而 <code>otherArgs</code> 可以指定任意值，所以可能会造成冲突。以下列出了会导致冲突的参数，请勿在 <code>otherArgs</code> 中设置：</p>
<ul>
<li><code>--no_local_rank</code>：与 <code>spec.config.localRank</code> 字段冲突。</li>
<li><code>--autotuning</code>：与 <code>spec.config.autotune</code> 字段冲突。</li>
<li><code>--module</code> 和 <code>--no_python</code>：与 <code>spec.config.autotune</code> 字段冲突。</li>
</ul>
</aside>
<h2 id="训练的成功和失败判定"><a class="header" href="#训练的成功和失败判定">训练的成功和失败判定</a></h2>
<p>DeepSpeedJob 分布式训练框架中，第一个训练副本（下文记为 <code>worker-0</code>）是分布式任务的主节点。当 <code>worker-0</code> 成功结束，则 DeepSpeedJob 训练成功；反之，当 <code>worker-0</code> 执行失败，DeepSpeedJob 训练失败。</p>
<p>如果一次训练执行时间过长，用户可能需要考虑代码是否需要优化、是否需要分配更多资源等问题。DeepSpeedJob 可以设置最长执行时间（由 <code>spec.runPolicy.activeDeadlineSeconds</code> 字段指定），当超过这个执行时间后，训练失败。</p>
<h2 id="清除策略-3"><a class="header" href="#清除策略-3">清除策略</a></h2>
<p>在训练完毕后，可能有些副本仍处于运行状态。这些运行的副本仍然会占用集群资源，DeepSpeedJob 提供清除策略，可以在训练结束后删除这些训练副本。</p>
<p>DeepSpeedJob 提供以下三种策略：</p>
<ul>
<li><code>None</code>：不删除副本。</li>
<li><code>All</code>：删除所有副本。</li>
<li><code>Unfinished</code>：只删除未结束的副本。</li>
</ul>
<aside class="note tip">
<div class="title">提示</div>
<p>已结束的副本不会继续消耗集群资源，因此在一定程度上，<code>Unfinished</code> 策略比 <code>All</code> 策略更优。但这并不总是适用，由于一个项目的资源配额的计算不考虑 Pod 是否已经结束，对于资源紧张的项目，如果确定不需要通过日志来调试 Job，则可以使用 <code>All</code> 策略。</p>
</aside>
<pre><code>`None` 策略主要用于训练脚本调试阶段。如果需要从副本中读取训练日志，则可以选用此策略。但由于这些副本可能占用资源并影响后续训练，建议你在调试完毕后手动删除这些副本或删除整个 DeepSpeedJob。
</code></pre>
<h2 id="调度策略"><a class="header" href="#调度策略">调度策略</a></h2>
<p>目前 DeepSpeedJob 支持两种调度策略：</p>
<ol>
<li>Kubernetes 的<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler">默认调度器</a></li>
<li><a href="modules/jobs/../../../../t9k-scheduler/">T9k Scheduler</a></li>
</ol>
<p>调度策略通过 CRD 的 <code>spec.scheduler</code> 字段设置：</p>
<ul>
<li>不设置 <code>spec.scheduler</code> 字段，则默认使用 Kubernetes 的默认调度策略。</li>
<li>设置 <code>spec.scheduler.t9kScheduler</code> 字段，则使用 T9k Scheduler 调度器。</li>
</ul>
<p>在下面的示例中，MPIJob 启用 T9k Scheduler 调度器，将副本插入 <code>default</code> 队列中等待调度，其优先级为 50。</p>
<pre><code class="language-yaml">...
spec:
  scheduler:
    t9kScheduler:
      queue: default
      priority: 50
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>队列和优先级都是 T9k Scheduler 的概念，具体含义请参阅 <a href="modules/jobs/../scheduling/index.html">T9k Scheduler</a>。</p>
</aside>
<h2 id="调试模式-3"><a class="header" href="#调试模式-3">调试模式</a></h2>
<p>DeepSpeedJob 支持调试模式。在该模式下，训练环境会被部署好，但不会启动训练，用户可以连入副本测试环境或脚本。</p>
<p>该模式可以通过 <code>spec.runMode.debug</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.debug.enabled</code> 表示是否启用调试模式。</li>
<li><code>spec.runMode.debug.replicaSpecs</code> 表示如何配置各个副本的调试模式：
<ul>
<li><code>spec.runMode.debug.replicaSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.debug.replicaSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.debug.replicaSpecs.command</code> 表示副本在等待调试的时候执行的命令，默认为 <code>/usr/sbin/sshd -D</code>。</li>
<li>如果不填写 <code>spec.runMode.debug.replicaSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了调试模式，并配置 worker 跳过 InitContainer，并执行 <code>sleep inf</code>。</li>
<li>示例二：开启了调试模式，副本使用默认调试设置，即不跳过 InitContainer，并执行 <code>/usr/sbin/sshd -D</code>。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    debug:
      enabled: true
      replicaSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;sleep&quot;, &quot;inf&quot;]

---
# 示例二
...
spec:
  runMode:
    debug:
      enabled: true
</code></pre>
<h2 id="暂停模式-3"><a class="header" href="#暂停模式-3">暂停模式</a></h2>
<p>DeepSpeedJob 支持暂停模式。在该模式下，删除（或不创建）副本，停止训练。</p>
<p>该模式可以通过 <code>spec.runMode.pause</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.pause.enabled</code> 表示是否启用暂停模式。</li>
<li><code>spec.runMode.pause.resumeSpecs</code> 表示结束暂停后，如何恢复各个副本：
<ul>
<li><code>spec.runMode.pause.resumeSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.pause.resumeSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.pause.resumeSpecs.command</code> 和 <code>spec.runMode.pause.resumeSpecs.args</code> 表示副本在恢复运行时候执行的命令，默认使用 <code>spec.replicaSpecs[0].template</code> 中的命令。</li>
<li>如果不填写 <code>spec.runMode.pause.resumeSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>用户可以随时修改 <code>spec.runMode.pause.enabled</code> 来控制任务暂停，但是不可以更改 <code>spec.runMode.pause.resumeSpecs</code>，所以如果有暂停 DeepSpeedJob 的需求，请提前设置好恢复设置。</p>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了暂停模式，并配置 worker 跳过 InitContainer，并执行 <code>/usr/bin/sshd</code>。</li>
<li>示例二：开启了暂停模式，副本使用默认恢复设置，即不跳过 InitContainer，并执行 <code>spec.replicaSpecs[0].template</code> 中设置的命令。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    pause:
      enabled: true
      resumeSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;/usr/bin/sshd&quot;]

---
# 示例二
...
spec:
  runMode:
    pause:
      enabled: true
</code></pre>
<h2 id="deepspeedjob-状态"><a class="header" href="#deepspeedjob-状态">DeepSpeedJob 状态</a></h2>
<h3 id="deepspeedjob-的状态和阶段"><a class="header" href="#deepspeedjob-的状态和阶段">DeepSpeedJob 的状态和阶段</a></h3>
<p><code>status.conditions</code> 字段用于描述当前 DeepSpeedJob 的状态，包括以下 5 种类型：</p>
<ol>
<li><code>Initialized</code>：DeepSpeedJob 已经成功创建各子资源，完成初始化。</li>
<li><code>Running</code>：开始执行任务。</li>
<li><code>ReplicaFailure</code>：有一个或多个副本出现错误。</li>
<li><code>Completed</code>：DeepSpeedJob 成功。</li>
<li><code>Failed</code>：DeepSpeedJob 失败。</li>
</ol>
<p><code>status.phase</code> 字段用于描述当前 DeepSpeedJob 所处的阶段，DeepSpeedJob 的整个生命周期主要有以下几个阶段：</p>
<ol>
<li><code>Pending</code>：DeepSpeedJob 刚刚创建，等待副本启动。</li>
<li><code>Running</code>：副本创建成功，开始执行任务。</li>
<li><code>Succeeded</code>：DeepSpeedJob 成功。</li>
<li><code>Failed</code>：DeepSpeedJob 失败。</li>
<li><code>Unknown</code>：控制器无法获得 DeepSpeedJob 的阶段。</li>
</ol>
<p>在下面的示例中，DeepSpeedJob 所有子资源创建成功，所以类型为 <code>Initalized</code> 的 <code>condition</code> 被设为 <code>True</code>；DeepSpeedJob 运行结束，所以类型为 <code>Completed</code> 的 <code>condition</code> 被设置为 <code>True</code>；但是 DeepSpeedJob 的训练结果是失败的，所以类型为 <code>Failed</code> 的 <code>condition</code> 被设置为 <code>True</code>。当前 DeepSpeedJob 运行阶段为 <code>Failed</code>。</p>
<pre><code class="language-yaml">...
status:
  conditions:
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;True&quot;
      message: &quot;The job has been initialized successfully.&quot;
      reason: &quot;-&quot;
      type: Initializing
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;True&quot;
      message: &quot;All pods are running normally.&quot;
      reason: &quot;-&quot;
      type: Running
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;False&quot;
      message: &quot;All pods are running normally.&quot;
      reason: &quot;-&quot;
      type: ReplicaFailure
    - lastTransitionTime: &quot;2021-01-18T02:36:31Z&quot;
      status: &quot;False&quot;
      message: &quot;The job exited with an error code.&quot;
      reason: &quot;Failed&quot;
      type: Completed
    - lastTransitionTime: &quot;2021-01-18T02:36:31Z&quot;
      status: &quot;True&quot;
      message: &quot;The job exited with an error code.&quot;
      reason: &quot;Failed&quot;
      type: Failed
  phase: Failed
</code></pre>
<h3 id="副本的状态-3"><a class="header" href="#副本的状态-3">副本的状态</a></h3>
<p><code>status.tasks</code> 字段用来记录副本的状态，记录的内容主要包括：</p>
<ul>
<li>副本的重启次数（同一种角色的副本的重启次数之和）</li>
<li>副本当前的运行阶段</li>
<li>副本在集群中对应的 Pod 的索引信息</li>
</ul>
<p>在下面的示例中，DeepSpeedJob 创建了 2 个训练副本，当前均处于 <code>Running</code> 阶段，分别运行在 <code>deepspeed-example-worker-0</code> 和 <code>deepspeed-example-worker-1</code> 这 2 个 Pod 上。</p>
<pre><code class="language-yaml">...
status:
  tasks:
  - type: worker
    restartCount: 0
    status:
    - phase: Running
      name: deepspeed-example-worker-0
      uid: e3ec2ee3-6645-4e21-993f-1e472b94e0ae
      containers: []
    - phase: Running
      name: deepspeed-example-worker-1
      uid: 908a93f0-7b8b-491e-85d5-3da0abcb4ca4
      containers: []
</code></pre>
<h3 id="副本状态统计-3"><a class="header" href="#副本状态统计-3">副本状态统计</a></h3>
<p><code>status.aggregate</code> 字段统计了各个阶段的副本数量。</p>
<p>在下面的示例中，DeepSpeedJob 创建了 3 个副本，其中 1 个处于 <code>Pending</code> 阶段，另外两个处于 <code>Running</code> 阶段。</p>
<pre><code class="language-yaml">...
status:
  aggregate:
    creating: 0
    deleted: 0
    failed: 0
    pending: 1
    running: 2
    succeeded: 0
    unknown: 0
...
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="colossalaijob"><a class="header" href="#colossalaijob">ColossalAIJob</a></h1>
<p>ColossalAIJob 是服务于 <a target="_blank" rel="noopener noreferrer" href="https://colossalai.org/">ColossalAI</a> 分布式训练框架的 T9k Job。</p>
<p>你可以较为方便地使用 ColossalAIJob 为 ColossalAI 训练脚本提供训练环境，并监控训练进程。</p>
<h2 id="创建-colossalaijob"><a class="header" href="#创建-colossalaijob">创建 ColossalAIJob</a></h2>
<p>下面是一个基本的 ColossalAIJob 配置示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: ColossalAIJob
metadata:
  name: colossalai-example
spec:
  ssh:
    authMountPath: /root/.ssh
    sshdPath: /usr/sbin/sshd
  launcher:
    image: hpcaitech/colossalai:0.3.0
    workingDir: /workspace
    env: []
    resources: 
      limits:
        cpu: 1
        memory: 2Gi
      requests:
        cpu: 500m
        memory: 1Gi
  worker:
    replicas: 2
    procPerWorker: 1
    command:
      - train.py
      - arg1
    torchArgs: []
    template:
      spec:
        restartPolicy: OnFailure
        containers:
          - image: hpcaitech/colossalai:0.3.0
            imagePullPolicy: IfNotPresent
            name: worker
            resources:
              limits:
                cpu: 2
                memory: 8Gi
                nvidia.com/gpu: 1
              requests:
                cpu: 1
                memory: 4Gi
                nvidia.com/gpu: 1
            volumeMounts:
              - mountPath: /workspace
                name: code
        volumes:
          - name: code
            persistentVolumeClaim:
              claimName: colossalai
</code></pre>
<p>在该例中：</p>
<ul>
<li>创建 1 个启动副本，该启动副本是 ColossalAI 在训练中所必须的，启动副本的配置参考 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-template-v1/#PodTemplateSpec">PodTemplate</a>，这里不再赘述（启动副本的配置由 <code>spec.launcher</code> 字段指定）。</li>
<li>创建 2 个执行副本（由 <code>spec.worker.replicas</code> 字段指定），每个执行副本上启动 1 个训练进程（由 <code>spec.worker.procPerWorker</code> 字段指定），训练脚本和参数为 <code>train.py arg1</code>（由 <code>spec.worker.command</code> 字段指定），执行副本的其他配置参考 PodTemplate，这里不再赘述（这些配置由 <code>spec.worker.template</code> 字段指定）。</li>
<li>执行副本需要执行 sshd 程序，等待启动副本发来训练指令。sshd 的路径为 <code>/user/sbin/sshd</code>（由 <code>spec.ssh.sshdPath</code> 字段指定，使用该字段的原因是 sshd 程序必须使用绝对路径调用，所以需要其具体路径）。</li>
</ul>
<aside class="note">
<div class="title">注意</div>
<p>另外，ColossalAIJob 的执行副本定义中必须包含一个 <code>name</code> 是 <code>worker</code> 的容器，用来作为训练容器。</p>
<p>由于执行副本实际执行的命令是启动 <code>sshd</code>，所以执行副本的训练容器的 <code>command</code> 字段不再生效。</p>
</aside>
<h2 id="成功和失败-3"><a class="header" href="#成功和失败-3">成功和失败</a></h2>
<p>在 ColossalAIJob 分布式训练框架中：</p>
<ul>
<li>如果启动副本执行失败，ColossalAIJob 训练失败。</li>
<li>如果启动副本执行成功，ColossalAIJob 并不一定成功：启动副本的作用是启动训练和监测，无论是训练成功还是失败，启动副本都会正常结束，而不是报错。因此，如果要确定 ColossalAIJob 是否成功结束，需要检查启动副本的日志。</li>
</ul>
<h2 id="重启机制-3"><a class="header" href="#重启机制-3">重启机制</a></h2>
<p>与其他 TrainingJob 不同，ColossalAIJob 使用 <code>colossalairun</code> 作为启动命令，在这种情况下，Pod 失败重启后不会再加入到训练中。所以 ColossalAIJob 无法像其他 TrainingJob 那样支持 Pod 失败重启。</p>
<h2 id="清除策略-4"><a class="header" href="#清除策略-4">清除策略</a></h2>
<p>在 ColossalAIJob 训练结束后，ColossalAIJob 控制器可以清理所创建的 Kubernetes 资源，使 ColossalAIJob 不再浪费集群资源（内存、CPU 等）。一般来说，你需要查看启动副本的日志来确定训练结果，所以启动副本不在清理范围之内，ColossalAIJob 控制器只清理执行副本（通过 <code>spec.runPolicy.cleanUpWorkers</code> 字段设置）。</p>
<p>在下面的示例中，ColossalAIJob 在训练结束后会自动删除所有执行副本：</p>
<pre><code class="language-yaml">...
spec:
  runPolicy:
    cleanUpWorkers: true
</code></pre>
<h2 id="调度器-5"><a class="header" href="#调度器-5">调度器</a></h2>
<p>目前 ColossalAIJob 支持两种调度器：</p>
<ol>
<li>Kubernetes 的<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler">默认调度器</a></li>
<li><a href="modules/jobs/../scheduling/index.html">T9k Scheduler 调度器</a></li>
</ol>
<p>调度器通过 <code>spec.scheduler</code> 字段设置：</p>
<ul>
<li>不设置 <code>spec.scheduler</code> 字段，则默认使用 Kubernetes 的默认调度器。</li>
<li>设置 <code>spec.scheduler.t9kScheduler</code> 字段，则使用 T9k Scheduler 调度器。</li>
</ul>
<p>在下面的示例中，ColossalAIJob 启用 T9k Scheduler 调度器，将执行副本插入 <code>default</code> 队列中等待调度，其优先级为 50。</p>
<pre><code class="language-yaml">...
spec:
  scheduler:
    t9kScheduler:
      queue: default
      priority: 50
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>队列和优先级都是 T9k Scheduler 的概念，具体含义请参阅 <a href="modules/jobs/../scheduling/index.html">T9k Scheduler</a>。</p>
</aside>
<h2 id="调试模式-4"><a class="header" href="#调试模式-4">调试模式</a></h2>
<p>ColossalAIJob 支持调试模式。在该模式下，训练环境会被部署好，但不会启动训练，用户可以连入副本测试环境或脚本。</p>
<p>该模式可以通过 <code>spec.runMode.debug</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.debug.enabled</code> 表示是否启用调试模式。</li>
<li><code>spec.runMode.debug.replicaSpecs</code> 表示如何配置各个副本的调试模式：
<ul>
<li><code>spec.runMode.debug.replicaSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.debug.replicaSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.debug.replicaSpecs.command</code> 表示副本在等待调试的时候执行的命令，默认为 <code>sleep inf</code>。</li>
<li>如果不填写 <code>spec.runMode.debug.replicaSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了调试模式，并配置 worker 跳过 InitContainer，并执行 <code>/usr/bin/sshd</code>。</li>
<li>示例二：开启了调试模式，副本使用默认调试设置，即不跳过 InitContainer，并执行 <code>sleep inf</code>。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    debug:
      enabled: true
      replicaSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;/usr/bin/sshd&quot;]

---
# 示例二
...
spec:
  runMode:
    debug:
      enabled: true
</code></pre>
<h2 id="暂停模式-4"><a class="header" href="#暂停模式-4">暂停模式</a></h2>
<p>ColossalAIJob 支持暂停模式。在该模式下，删除（或不创建）副本，停止训练。</p>
<p>该模式可以通过 <code>spec.runMode.pause</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.pause.enabled</code> 表示是否启用暂停模式。</li>
<li><code>spec.runMode.pause.resumeSpecs</code> 表示结束暂停后，如何恢复各个副本：
<ul>
<li><code>spec.runMode.pause.resumeSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.pause.resumeSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.pause.resumeSpecs.command</code> 和 <code>spec.runMode.pause.resumeSpecs.args</code> 表示副本在恢复运行时候执行的命令，默认使用 <code>spec.replicaSpecs[0].template</code> 中的命令。</li>
<li>如果不填写 <code>spec.runMode.pause.resumeSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>用户可以随时修改 <code>spec.runMode.pause.enabled</code> 来控制任务暂停，但是不可以更改 <code>spec.runMode.pause.resumeSpecs</code>，所以如果有暂停 ColossalAIJob 的需求，请提前设置好恢复设置。</p>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了暂停模式，并配置 worker 跳过 InitContainer，并执行 <code>/usr/bin/sshd</code>。</li>
<li>示例二：开启了暂停模式，副本使用默认恢复设置，即不跳过 InitContainer，并执行 <code>spec.replicaSpecs[0].template</code> 中设置的命令。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    pause:
      enabled: true
      resumeSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;/usr/bin/sshd&quot;]

---
# 示例二
...
spec:
  runMode:
    pause:
      enabled: true
</code></pre>
<h2 id="colossalaijob-状态"><a class="header" href="#colossalaijob-状态">ColossalAIJob 状态</a></h2>
<h3 id="colossalaijob-的状态和阶段"><a class="header" href="#colossalaijob-的状态和阶段">ColossalAIJob 的状态和阶段</a></h3>
<p><code>status.conditions</code> 字段用于描述当前 ColossalAIJob 的状态，包括以下 5 种类型：</p>
<ol>
<li><code>Initialized</code>：ColossalAIJob 已经成功创建各子资源，完成初始化。</li>
<li><code>Running</code>：开始执行任务。</li>
<li><code>ReplicaFailure</code>：有一个或多个副本出现错误。</li>
<li><code>Completed</code>：ColossalAIJob 成功。</li>
<li><code>Failed</code>：ColossalAIJob 失败。</li>
<li><code>Paused</code>：ColossalAIJob 进入暂停模式，所有副本都已删除或正在删除。</li>
</ol>
<p><code>status.phase</code> 字段用于描述当前 ColossalAIJob 所处的阶段，ColossalAIJob 的整个生命周期主要有以下几个阶段：</p>
<ol>
<li><code>Pending</code>：ColossalAIJob 刚刚创建，等待副本启动。</li>
<li><code>Running</code>：副本创建成功，开始执行任务。</li>
<li><code>Paused</code>：ColossalAIJob 进入暂停模式。</li>
<li><code>Resuming</code>：ColossalAIJob 正从暂停模式中恢复运行。恢复运行后，切换为 <code>Running</code> 阶段。</li>
<li><code>Succeeded</code>：ColossalAIJob 成功。</li>
<li><code>Failed</code>：ColossalAIJob 失败。</li>
<li><code>Unknown</code>：控制器无法获得 ColossalAIJob 的阶段。</li>
</ol>
<p>在下面的示例中，ColossalAIJob 所有子资源创建成功，所以类型为 <code>Initalized</code> 的 <code>condition</code> 被设为 <code>True</code>；ColossalAIJob 运行结束，所以类型为 <code>Completed</code> 的 <code>condition</code> 被设置为 <code>True</code>；但是 ColossalAIJob 的训练结果是失败的，所以类型为 <code>Failed</code> 的 <code>condition</code> 被设置为 <code>True</code>。当前 ColossalAIJob 运行阶段为 <code>Failed</code>。</p>
<pre><code class="language-yaml">...
status:
  conditions:
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;True&quot;
      message: &quot;The job has been initialized successfully.&quot;
      reason: &quot;-&quot;
      type: Initializing
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;True&quot;
      message: &quot;All pods are running normally.&quot;
      reason: &quot;-&quot;
      type: Running
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;False&quot;
      message: &quot;All pods are running normally.&quot;
      reason: &quot;-&quot;
      type: ReplicaFailure
    - lastTransitionTime: &quot;2021-01-18T02:36:31Z&quot;
      status: &quot;False&quot;
      message: &quot;The job exited with an error code.&quot;
      reason: &quot;Failed&quot;
      type: Completed
    - lastTransitionTime: &quot;2021-01-18T02:36:31Z&quot;
      status: &quot;True&quot;
      message: &quot;The job exited with an error code.&quot;
      reason: &quot;Failed&quot;
      type: Failed
  phase: Failed
</code></pre>
<h3 id="副本的状态-4"><a class="header" href="#副本的状态-4">副本的状态</a></h3>
<p><code>status.tasks</code> 字段用来记录副本的状态，记录的内容主要包括：</p>
<ul>
<li>副本的重启次数（同一种角色的副本的重启次数之和）</li>
<li>副本当前的运行阶段</li>
<li>副本在集群中对应的 Pod 的索引信息</li>
</ul>
<p>在下面的示例中，ColossalAIJob 创建了 1 个启动副本和 2 个执行副本。执行副本当前均处于 <code>Running</code> 阶段，分别运行在 <code>colossalai-example-worker-0</code> 和 <code>colossalai-example-worker-1</code> 这 2 个 Pod 上；启动副本当前处于 <code>Running</code> 阶段，运行在 <code>colossalai-example-launcher</code> Pod 上。</p>
<pre><code class="language-yaml">...
status:
  tasks:
  - type: launcher
    restartCount: 0
    status:
    - phase: Running
      name: colossalai-example-launcher
      uid: 66634db2-35e7-4641-a4dc-adbd5479734e
      containers: []
  - type: worker
    restartCount: 0
    status:
    - phase: Running
      name: colossalai-example-worker-0
      uid: e3ec2ee3-6645-4e21-993f-1e472b94e0ae
      containers: []
    - phase: Running
      name: colossalai-example-worker-1
      uid: 908a93f0-7b8b-491e-85d5-3da0abcb4ca4
      containers: []
</code></pre>
<h3 id="副本状态统计-4"><a class="header" href="#副本状态统计-4">副本状态统计</a></h3>
<p><code>status.aggregate</code> 字段统计了各个阶段的副本数量。</p>
<p>在下面的示例中，ColossalAIJob 创建了 3 个副本，其中 1 个处于 <code>Pending</code> 阶段，另外两个处于 <code>Running</code> 阶段。</p>
<pre><code class="language-yaml">...
status:
  aggregate:
    creating: 0
    deleted: 0
    failed: 0
    pending: 1
    running: 2
    succeeded: 0
    unknown: 0
...
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="xgboosttrainingjob"><a class="header" href="#xgboosttrainingjob">XGBoostTrainingJob</a></h1>
<p>XGBoostTrainingJob 是服务于 <a target="_blank" rel="noopener noreferrer" href="https://xgboost.readthedocs.io/en/latest/">XGBoost</a> 分布式计算框架的 T9k Job。</p>
<p>你可以较为方便地使用 XGBoostTrainingJob 为 XGBoost 计算程序提供训练环境，并监控训练进程。</p>
<h2 id="创建-xgboosttrainingjob"><a class="header" href="#创建-xgboosttrainingjob">创建 XGBoostTrainingJob</a></h2>
<p>下面是一个基本的 XGBoostTrainingJob 配置示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: XGBoostTrainingJob
metadata:
  name: training-iris-xgb
spec:
  replicaSpecs:
    - type: master
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          containers:
            - name: xgboost
              image: t9kpublic/xgboost-dist-iris:3.7
              command:
                - python3
                - /mnt/main.py
                - --job_type=Train
                - --xgboost_parameter=objective:multi:softprob,num_class:3
                - --n_estimators=10
                - --learning_rate=0.1
                - --model_path=/mnt/xgboost_model/
                - --model_storage_type=local
    - type: worker
      replicas: 2
      restartPolicy: OnFailure
      template:
          containers:
            - name: xgboost
              image: t9kpublic/xgboost-dist-iris:3.7
              command:
                - python3
                - /mnt/main.py
                - --job_type=Train
                - --xgboost_parameter=objective:multi:softprob,num_class:3
                - --n_estimators=10
                - --learning_rate=0.1
                - --model_path=/mnt/xgboost_model/
                - --model_storage_type=local
</code></pre>
<p>在该例中：</p>
<ul>
<li>创建 1 个 <code>master</code> 副本和 2 个 <code>worker</code> 副本（由 <code>spec.replicaSpecs[*].replicas</code> 字段和 <code>spec.replicaSpecs[*].type</code> 字段指定）。</li>
<li>每个副本使用 <code>registry.tensorstack.cn/t9kmirror/xgboost-dist-iris:1.1</code> 镜像，执行命令 <code>python3 /mnt/main.py --job_type=Train --xgboost_parameter=objective:multi:softprob,num_class:3 --n_estimators=10 --learning_rate=0.1 --model_path=/mnt/xgboost_model/ --model_storage_type=local</code>（由 <code>spec.replicaSpecs&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://kubernetes.io/docs/concepts/workloads/pods/#pod-templates&quot;&gt;*].template</code> 字段指定，此处的填写方式参考 [PodTemplate</a>）。</li>
<li>当副本失败后，会自动重启（由 <code>spec.replicaSpecs[*].restartPolicy</code> 字段指定）。</li>
</ul>
<aside class="note">
<div class="title">注意</div>
<p>XGBoostTrainingJob 的 <code>template</code> 字段必须包含 <code>name</code> 为 <code>xgboost</code> 的容器，以便控制器识别训练使用的主容器。</p>
<p>XGBoostTrainingJob 的副本中 <code>master</code> 是必不可少的，如果缺少 <code>master</code> 将无法训练。</p>
<p>XGBoostTrainingJob 中执行的脚本应使用 XGBoost 分布式训练框架，否则可能达不到训练效果。</p>
</aside>
<h2 id="成功和失败-4"><a class="header" href="#成功和失败-4">成功和失败</a></h2>
<p>在 XGBoost 分布式训练框架中，副本有 2 种类型：Master 和 Worker，其中 Master 是主节点。当分布式训练的主节点成功结束时，XGBoost 分布式训练成功；反之，当分布式训练的主节点执行失败时，XGBoost 分布式训练失败。</p>
<p>但是主节点的失败有时可能是因为环境因素导致的，比如集群网络断连、集群节点崩溃等等，此类原因导致的失败应该被允许自动恢复。针对这一情况，XGBoostTrainingJob 允许副本重启（请参阅<a href="modules/jobs/xgboosttrainingjob.html#%E9%87%8D%E5%90%AF%E6%9C%BA%E5%88%B6">重启机制</a>），并设定了重启次数限制（由 <code>spec.runPolicy.backoffLimit</code> 字段指定），当副本重启次数达到上限后，如果主节点再次失败，则训练失败。此外，XGBoostTrainingJob 可以设置最长执行时间（由 <code>spec.runPolicy.activeDeadlineSeconds</code> 字段指定），当超过这个执行时间后，训练失败。</p>
<p>如果 XGBoostTrainingJob 在没有超过重启次数和没有超过最长执行时间的情况下成功完成了主节点的运行，则训练成功。</p>
<h2 id="重启机制-4"><a class="header" href="#重启机制-4">重启机制</a></h2>
<p>XGBoostTrainingJob 的 <code>spec.replicaSpec[*].template</code> 字段使用 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/workloads/pods/#pod-templates">PodTemplate</a> 的规范填写，但是 Pod 的重启策略并不能满足 XGBoostTrainingJob 的需求，所以 XGBoostTrainingJob 使用 <code>spec.replicaSpec[*].restartPolicy</code> 字段覆盖 <code>spec.replicaSpec[*].template</code> 中指定的重启策略。</p>
<p>可选的重启策略有以下四种：</p>
<ul>
<li><code>Never</code>：不重启</li>
<li><code>OnFailure</code>：失败后重启</li>
<li><code>Always</code>：总是重启</li>
<li><code>ExitCode</code>：特殊退出码重启</li>
</ul>
<p>使用 <code>Never</code> 重启策略时，Job 的副本失败后不会重启。如果需要调试代码错误，可以选择此策略，便于从副本中读取训练日志。</p>
<p><code>ExitCode</code> 是一种比较特殊的重启策略，它将失败进程的返回值分为两类：一类是由于系统环境原因或用户操作导致的错误，此类错误可以通过重启解决；另一类是代码错误或者其他不可自动恢复的错误。可重启的退出码包括：</p>
<ul>
<li>130（128+2）：使用 <code>Control+C</code> 终止容器运行。</li>
<li>137（128+9）：容器接收到 <code>SIGKILL</code> 信号。</li>
<li>143（128+15）：容器接收到 <code>SIGTERM</code> 信号。</li>
<li>138：用户可以自定义这个返回值的含义。如果用户希望程序在某处退出并重启，可以在代码中写入这个返回值。</li>
</ul>
<h3 id="重启次数限制-2"><a class="header" href="#重启次数限制-2">重启次数限制</a></h3>
<p>如果因为某种原因（例如代码错误或者环境错误并且长时间没有修复），XGBoostTrainingJob 不断地失败重启却无法解决问题，这会导致集群资源的浪费。用户可以通过设置 <code>spec.runPolicy.backoffLimit</code> 字段来设置副本的最大重启次数。重启次数为所有副本共享，即所有副本重启次数累计达到此数值后，副本将不能再次重启。</p>
<h2 id="清除策略-5"><a class="header" href="#清除策略-5">清除策略</a></h2>
<p>在训练结束后，可能有些副本仍处于运行状态。这些运行的副本仍然会占用集群资源，XGBoostTrainingJob 提供清除策略，在训练结束后删除这些训练节点。</p>
<p>XGBoostTrainingJob 提供以下三种策略：</p>
<ul>
<li><code>None</code>：不删除副本。</li>
<li><code>All</code>：删除所有副本。</li>
<li><code>Unfinished</code>：只删除未结束的副本。</li>
</ul>
<aside class="note tip">
<div class="title">提示</div>
<p>已结束的副本不会继续消耗集群资源，因此在一定程度上，<code>Unfinished</code> 策略比 <code>All</code> 策略更优。但这并不总是适用，由于一个项目的资源配额的计算不考虑 Pod 是否已经结束，对于资源紧张的项目，如果确定不需要通过日志来调试 Job，则可以使用 <code>All</code> 策略。</p>
</aside>
<pre><code>`None` 策略主要用于训练脚本调试阶段。如果需要从副本中读取训练日志，则可以选用此策略。但由于这些副本可能占用资源并影响后续训练，建议你在调试完毕后手动删除这些副本或删除整个 XGBoostTrainingJob。
</code></pre>
<h2 id="调度器-6"><a class="header" href="#调度器-6">调度器</a></h2>
<p>目前 XGBoostTrainingJob 支持使用以下两种调度器：</p>
<ol>
<li>Kubernetes 的<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler">默认调度器</a></li>
<li><a href="modules/jobs/../scheduling/index.html">T9k Scheduler 调度器</a></li>
</ol>
<p>调度器通过 <code>spec.scheduler</code> 字段设置：</p>
<ul>
<li>不设置 <code>spec.scheduler</code> 字段，则默认使用 Kubernetes 的默认调度器。</li>
<li>设置 <code>spec.scheduler.t9kScheduler</code> 字段，则使用 T9k Scheduler 调度器。</li>
</ul>
<p>在下面的示例中，XGBoostTrainingJob 启用 T9k Scheduler 调度器，将副本插入 <code>default</code> 队列中等待调度，其优先级为 50。</p>
<pre><code class="language-yaml">...
spec:
  scheduler:
    t9kScheduler:
      queue: default
      priority: 50
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>队列和优先级都是 T9k Scheduler 的概念，具体含义请参阅 <a href="modules/jobs/../scheduling/index.html">T9k Scheduler</a>。</p>
</aside>
<h2 id="调试模式-5"><a class="header" href="#调试模式-5">调试模式</a></h2>
<p>XGBoostTrainingJob 支持调试模式。在该模式下，训练环境会被部署好，但不会启动训练，用户可以连入副本测试环境或脚本。</p>
<p>该模式可以通过 <code>spec.runMode.debug</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.debug.enabled</code> 表示是否启用调试模式。</li>
<li><code>spec.runMode.debug.replicaSpecs</code> 表示如何配置各个副本的调试模式：
<ul>
<li><code>spec.runMode.debug.replicaSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.debug.replicaSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.debug.replicaSpecs.command</code> 表示副本在等待调试的时候执行的命令，默认为 <code>sleep inf</code>。</li>
<li>如果不填写 <code>spec.runMode.debug.replicaSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了调试模式，并配置 worker 跳过 InitContainer，并执行 <code>/usr/bin/sshd</code>。</li>
<li>示例二：开启了调试模式，副本使用默认调试设置，即不跳过 InitContainer，并执行 <code>sleep inf</code>。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    debug:
      enabled: true
      replicaSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;/usr/bin/sshd&quot;]

---
# 示例二
...
spec:
  runMode:
    debug:
      enabled: true
</code></pre>
<h2 id="暂停模式-5"><a class="header" href="#暂停模式-5">暂停模式</a></h2>
<p>XGBoostTrainingJob 支持暂停模式。在该模式下，删除（或不创建）副本，停止训练。</p>
<p>该模式可以通过 <code>spec.runMode.pause</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.pause.enabled</code> 表示是否启用暂停模式。</li>
<li><code>spec.runMode.pause.resumeSpecs</code> 表示结束暂停后，如何恢复各个副本：
<ul>
<li><code>spec.runMode.pause.resumeSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.pause.resumeSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.pause.resumeSpecs.command</code> 和 <code>spec.runMode.pause.resumeSpecs.args</code> 表示副本在恢复运行时候执行的命令，默认使用 <code>spec.replicaSpecs[0].template</code> 中的命令。</li>
<li>如果不填写 <code>spec.runMode.pause.resumeSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>用户可以随时修改 <code>spec.runMode.pause.enabled</code> 来控制任务暂停，但是不可以更改 <code>spec.runMode.pause.resumeSpecs</code>，所以如果有暂停 XGBoostTrainingJob 的需求，请提前设置好恢复设置。</p>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了暂停模式，并配置 worker 跳过 InitContainer，并执行 <code>/usr/bin/sshd</code>。</li>
<li>示例二：开启了暂停模式，副本使用默认恢复设置，即不跳过 InitContainer，并执行 <code>spec.replicaSpecs[0].template</code> 中设置的命令。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    pause:
      enabled: true
      resumeSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;/usr/bin/sshd&quot;]

---
# 示例二
...
spec:
  runMode:
    pause:
      enabled: true
</code></pre>
<h2 id="xgboosttrainingjob-状态"><a class="header" href="#xgboosttrainingjob-状态">XGBoostTrainingJob 状态</a></h2>
<h3 id="xgboosttrainingjob-的状态和阶段"><a class="header" href="#xgboosttrainingjob-的状态和阶段">XGBoostTrainingJob 的状态和阶段</a></h3>
<p><code>status.conditions</code> 字段用于描述当前 XGBoostTrainingJob 的状态，包括以下 6 种类型：</p>
<ol>
<li><code>Initialized</code>：XGBoostTrainingJob 已经成功创建各子资源，完成初始化。</li>
<li><code>Running</code>：开始执行任务。</li>
<li><code>ReplicaFailure</code>：有一个或多个副本出现错误。</li>
<li><code>Completed</code>：XGBoostTrainingJob 成功。</li>
<li><code>Failed</code>：XGBoostTrainingJob 失败。</li>
<li><code>Paused</code>：XGBoostTrainingJob 进入暂停模式，所有副本都已删除或正在删除。</li>
</ol>
<p><code>status.phase</code> 字段用于描述当前 XGBoostTrainingJob 所处的阶段，XGBoostTrainingJob 的整个生命周期主要有以下7个阶段：</p>
<ol>
<li><code>Pending</code>：XGBoostTrainingJob 刚刚创建，等待副本启动。</li>
<li><code>Running</code>：副本创建成功，开始执行任务。</li>
<li><code>Paused</code>：XGBoostTrainingJob 进入暂停模式。</li>
<li><code>Resuming</code>：XGBoostTrainingJob 正从暂停模式中恢复运行。恢复运行后，切换为 <code>Running</code> 阶段。</li>
<li><code>Succeeded</code>：XGBoostTrainingJob 成功。</li>
<li><code>Failed</code>：XGBoostTrainingJob 失败。</li>
<li><code>Unknown</code>：控制器无法获得 XGBoostTrainingJob 的阶段。</li>
</ol>
<p>在下面的示例中，XGBoostTrainingJob 所有子资源创建成功，所以类型为 <code>Initalized</code> 的 <code>condition</code> 被设为 <code>True</code>；XGBoostTrainingJob 运行结束，所以类型为 <code>Completed</code> 的 <code>condition</code> 被设置为 <code>True</code>；XGBoostTrainingJob 的训练成功结束，所以类型为 <code>Completed</code> 的 <code>condition</code> 被设置为 <code>True</code>（原因是 <code>The job has finished successfully.</code>）。当前 XGBoostTrainingJob 运行阶段为 <code>Succeeded</code>。</p>
<pre><code class="language-yaml">...
status:
  conditions:
    - lastTransitionTime: &quot;2023-12-19T02:40:25Z&quot;
      message: The job has been initialized successfully.
      reason: '-'
      status: &quot;True&quot;
      type: Initialized
    - lastTransitionTime: &quot;2023-12-19T02:53:14Z&quot;
      message: The job has finished successfully.
      reason: Succeeded
      status: &quot;False&quot;
      type: Running
    - lastTransitionTime: &quot;2023-12-19T02:53:14Z&quot;
      message: The job has finished successfully.
      reason: Succeeded
      status: &quot;False&quot;
      type: Failed
    - lastTransitionTime: &quot;2023-12-19T02:53:14Z&quot;
      message: The job has finished successfully.
      reason: Succeeded
      status: &quot;True&quot;
      type: Completed
    - lastTransitionTime: &quot;2023-12-19T02:40:25Z&quot;
      message: All pods are running normally.
      reason: '-'
      status: &quot;False&quot;
      type: ReplicaFailure
  phase: Succeeded
</code></pre>
<h3 id="副本的状态-5"><a class="header" href="#副本的状态-5">副本的状态</a></h3>
<p><code>status.tasks</code> 字段用来记录副本的状态，记录的内容主要包括：</p>
<ul>
<li>副本的重启次数（同一种角色的副本的重启次数之和）；</li>
<li>副本当前的运行阶段，此处的“运行阶段”在 K8s Pod 的 5 个阶段的基础上，添加了 <code>Creating</code> 和 <code>Deleted</code> 分别表示正在创建和已删除；</li>
<li>副本在集群中对应的 Pod 的索引信息。</li>
</ul>
<p>在下面的示例中，XGBoostTrainingJob 创建了 1 个角色为 <code>worker</code> 的副本，当前均处于 <code>Succeeded</code> 阶段，运行在 <code>mnist-trainingjob-5b373-worker-0</code> 这个 Pod 上。</p>
<pre><code class="language-yaml">...
status:
  tasks:
  - replicas:
    - containers:
      - exitCode: 0
        name: pytorch
        state: Terminated
      name: mnist-trainingjob-5b373-worker-0
      phase: Succeeded
      uid: d39f91d6-9c48-4c57-bb71-4131226395b6
    type: worker
</code></pre>
<h3 id="副本状态统计-5"><a class="header" href="#副本状态统计-5">副本状态统计</a></h3>
<p><code>status.aggregate</code> 字段统计了各个阶段的副本数量。</p>
<p>在下面示例中，XGBoostTrainingJob 创建了 3 个副本，其中 1 个处于 <code>Pending</code> 阶段，另外两个处于 <code>Running</code> 阶段。</p>
<pre><code class="language-yaml">...
status:
  aggregate:
    creating: 0
    deleted: 0
    failed: 0
    pending: 1
    running: 2
    succeeded: 0
    unknown: 0
...
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="mpijob"><a class="header" href="#mpijob">MPIJob</a></h1>
<p><a target="_blank" rel="noopener noreferrer" href="https://www.open-mpi.org/">OpenMPI</a> 是一个开源的 MPI（Message Passing Interface）协议的实现项目。</p>
<p>MPIJob 是一种使用 OpenMPI 进行分布式计算的 T9k Job，此资源让你能够方便地在集群环境中使用 OpenMPI 进行训练。</p>
<h2 id="创建-mpijob"><a class="header" href="#创建-mpijob">创建 MPIJob</a></h2>
<p>下面的 MPIJob 示例创建了 5 个执行副本，每个执行副本启动 3 个进程，运行随机游走程序：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: MPIJob
metadata:
  name: mpi-example
spec:
  worker:
    replicas: 5
    extraMPIArgs:
      - -N
      - &quot;3&quot;
      - --enable-recovery
      - --max-restarts
      - &quot;100&quot;
      - --allow-run-as-root
      - -bind-to
      - none
    cmd:
      - ./random_walk
      - &quot;20&quot;
      - &quot;40&quot;
      - &quot;2&quot;
    template:
      spec:
        containers:
          - name: mpi-worker
            image: t9kpublic/mpi-tutorial:2021022-2
            resources:
              limits:
                cpu: 100m
              requests:
                cpu: 50m
            workingDir: /usr/local/code
  mca:
    btl: ^openib
  runPolicy:
    cleanUpWorkers: true
  ssh:
    sshdPath: /usr/sbin/sshd
  mpiHome: /usr/local
</code></pre>
<p>在该例中：</p>
<ul>
<li>创建 5 个执行副本（由 <code>spec.worker.replicas</code> 字段指定）。</li>
<li><code>spec.worker.template</code> 字段沿用 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/workloads/pods/#pod-templates">PodTemplate</a> 的规约，配置执行副本和启动副本的环境。每个执行副本包含一个名为 <code>mpi-worker</code> 的容器（为了确定用于执行 MPI 进程的容器，执行副本定义中必须有一个名为 <code>mpi-worker</code> 的容器）。<code>mpi-worker</code> 容器创建后执行 <code>sshd</code> 命令并等待启动副本连接，所以此容器会忽略 <code>PodTemplate</code> 定义中的 <code>command</code> 和 <code>args</code> 字段（因此该例中没有填写这两个字段）。</li>
<li>在执行副本准备完毕后，启动副本向执行副本发送启动命令，令执行副本创建 3 个 MPI 进程，这些进程分别执行 <code>./random_walk 20 40 2</code>（由 <code>spec.worker.cmd</code> 字段指定）命令。</li>
<li>在训练过程中不使用 Infiniband 进行通信（由 <code>spec.mca.btl</code> 字段指定）。</li>
<li>在训练结束后自动清除副本（由 <code>spec.runPolicy.cleanUpWorkers</code> 字段指定）来释放集群资源。</li>
<li>sshd 的路径为 <code>/user/sbin/sshd</code>（由 <code>spec.ssh.sshdPath</code> 字段指定，使用该字段的原因是 sshd 程序必须使用绝对路径调用，所以需要其具体路径）。</li>
<li>MPI 安装在 <code>/usr/local</code> 处（由 <code>spec.mpiHome</code> 字段指定，使用该字段的原因是 <code>mpirun</code> 的有些功能需要知道 MPI 的根目录地址才能正确运行）。</li>
</ul>
<h2 id="运行-horovod-训练脚本"><a class="header" href="#运行-horovod-训练脚本">运行 Horovod 训练脚本</a></h2>
<p>使用 <a target="_blank" rel="noopener noreferrer" href="https://horovod.ai/">Horovod</a> 框架的分布式训练脚本也可以使用 MPIJob 进行训练。</p>
<aside class="note info">
<div class="title">信息</div>
<p>Horovod 框架的分布式训练脚本一般使用 <code>horovodrun</code> 命令启动；而由于 Horovod 是基于 OpenMPI 实现的，所以也可以使用 <code>mpirun</code> 命令启动。两条命令的关系为：<code>horovodrun</code> 命令等同于 <code>mpirun -bind-to none -map-by slot -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -mca pml ob1 -mca btl ^openib</code>。具体信息请参阅 <a target="_blank" rel="noopener noreferrer" href="https://github.com/horovod/horovod/blob/master/docs/mpi.rst">Horovod With MPI</a>。</p>
</aside>
<p>在 MPIJob 中需要执行以下操作：</p>
<ol>
<li>在 <code>spec.worker.template.spec.containers[mpi-worker].env</code> 字段中添加 <code>NCCL_DEBUG</code>；</li>
<li>在 <code>spec.mca</code> 字段中添加 <code>pml:ob1</code> 和 <code>btl:^openib</code>。</li>
</ol>
<p>下面是使用 MPIJob 执行 Horovod 框架的分布式训练脚本的示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: MPIJob
metadata:
  name: mpi-example
spec:
  mca:
    btl: ^openib
    pml: ob1
  worker:
    template:
      spec:
        containers:
          - name: mpi-worker
            env: 
            - name: &quot;NCCL_DEBUG&quot;
              value: &quot;INFO&quot;
...
</code></pre>
<h2 id="调度器-7"><a class="header" href="#调度器-7">调度器</a></h2>
<p>目前 MPIJob 支持使用以下两种调度器：</p>
<ol>
<li>Kubernetes 的<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler">默认调度器</a></li>
<li><a href="modules/jobs/../scheduling/index.html">T9k Scheduler</a></li>
</ol>
<p>调度策略通过 <code>spec.scheduler</code> 字段设置：</p>
<ul>
<li>不设置 <code>spec.scheduler</code> 字段，则使用 Kubernetes 的默认调度器。</li>
<li>设置 <code>spec.scheduler.t9kScheduler</code> 字段，则使用 T9k Scheduler 调度器。</li>
</ul>
<p>在下面的示例中，MPIJob 启用 T9k Scheduler 调度器，将执行副本插入 <code>default</code> 队列中等待调度，其优先级为 50。</p>
<pre><code class="language-yaml">...
spec:
  scheduler:
    t9kScheduler:
      queue: default
      priority: 50
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>队列和优先级都是 T9k Scheduler 的概念，具体含义请参阅 <a href="modules/jobs/../scheduling/index.html">T9k Scheduler</a>。</p>
</aside>
<h2 id="调试模式-6"><a class="header" href="#调试模式-6">调试模式</a></h2>
<p>MPIJob 支持调试模式。在该模式下，训练环境会被部署好，但不会启动训练，用户可以连入副本测试环境或脚本。</p>
<p>该模式可以通过 <code>spec.runMode.debug</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.debug.enabled</code> 表示是否启用调试模式。</li>
<li><code>spec.runMode.debug.replicaSpecs</code> 表示如何配置各个副本的调试模式：
<ul>
<li><code>spec.runMode.debug.replicaSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.debug.replicaSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.debug.replicaSpecs.command</code> 表示副本在等待调试的时候执行的命令，<code>launcher</code> 的默认命令为 <code>sleep inf</code>，<code>worker</code> 的默认命令为 <code>/usr/bin/sshd -D</code>。</li>
<li>如果不填写 <code>spec.runMode.debug.replicaSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了调试模式，并配置 worker 跳过 InitContainer，并执行 <code>sleep inf</code>。</li>
<li>示例二：开启了调试模式，副本使用默认调试设置，即 worker 不跳过 InitContainer，并执行 <code>/usr/bin/sshd -D</code>。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    debug:
      enabled: true
      replicaSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;sleep&quot;, &quot;inf&quot;]

---
# 示例二
...
spec:
  runMode:
    debug:
      enabled: true
</code></pre>
<h2 id="暂停模式-6"><a class="header" href="#暂停模式-6">暂停模式</a></h2>
<p>MPIJob 支持暂停模式。在该模式下，删除（或不创建）副本，停止训练。</p>
<p>该模式可以通过 <code>spec.runMode.pause</code> 字段来设置：</p>
<ul>
<li><code>spec.runMode.pause.enabled</code> 表示是否启用暂停模式。</li>
<li><code>spec.runMode.pause.resumeSpecs</code> 表示结束暂停后，如何恢复各个副本：
<ul>
<li><code>spec.runMode.pause.resumeSpecs.type</code> 表示作用于的副本类型。</li>
<li><code>spec.runMode.pause.resumeSpecs.skipInitContainer</code> 表示让副本的 InitContainer 失效，默认为 <code>false</code>。</li>
<li><code>spec.runMode.pause.resumeSpecs.command</code> 和 <code>spec.runMode.pause.resumeSpecs.args</code> 表示副本在恢复运行时候执行的命令，默认使用 <code>spec.replicaSpecs[0].template</code> 中的命令。</li>
<li>如果不填写 <code>spec.runMode.pause.resumeSpecs</code> 字段，则表示所有副本都使用默认设置。</li>
</ul>
</li>
</ul>
<p>用户可以随时修改 <code>spec.runMode.pause.enabled</code> 来控制任务暂停，但是不可以更改 <code>spec.runMode.pause.resumeSpecs</code>，所以如果有暂停 MPIJob 的需求，请提前设置好恢复设置。</p>
<p>在下面的示例中：</p>
<ul>
<li>示例一：开启了暂停模式，并配置 worker 跳过 InitContainer，并执行 <code>/usr/bin/sshd</code>。</li>
<li>示例二：开启了暂停模式，副本使用默认恢复设置，即不跳过 InitContainer，并执行 <code>spec.replicaSpecs[0].template</code> 中设置的命令。</li>
</ul>
<pre><code class="language-yaml"># 示例一
...
spec:
  runMode:
    pause:
      enabled: true
      resumeSpecs:
        - type: worker
          skipInitContainer: true
          command: [&quot;/usr/bin/sshd&quot;]

---
# 示例二
...
spec:
  runMode:
    pause:
      enabled: true
</code></pre>
<h2 id="mpijob-状态"><a class="header" href="#mpijob-状态">MPIJob 状态</a></h2>
<h3 id="mpijob-的状态和阶段"><a class="header" href="#mpijob-的状态和阶段">MPIJob 的状态和阶段</a></h3>
<p><code>status.conditions</code> 字段用于描述当前 MPIJob 的状态，包括以下 5 种类型：</p>
<ol>
<li><code>Initialized</code>：MPIJob 已经成功创建各子资源，完成初始化。</li>
<li><code>Running</code>：开始执行任务。</li>
<li><code>ReplicaFailure</code>：有一个或多个副本出现错误。</li>
<li><code>Completed</code>：MPIJob <strong>结束</strong>。</li>
<li><code>Failed</code>：MPIJob 失败。</li>
<li><code>Paused</code>：MPIJob 进入暂停模式，所有副本都已删除或正在删除。</li>
</ol>
<p><code>status.phase</code> 字段用于描述当前 MPIJob 所处的阶段，MPIJob 的整个生命周期主要有以下几个阶段：</p>
<ol>
<li><code>Pending</code>：MPIJob 刚刚创建，等待副本启动。</li>
<li><code>Running</code>：副本创建成功，开始执行任务。</li>
<li><code>Paused</code>：MPIJob 进入暂停模式。</li>
<li><code>Resuming</code>：MPIJob 正从暂停模式中恢复运行。恢复运行后，切换为 <code>Running</code> 阶段。</li>
<li><code>Succeeded</code>：MPIJob <strong>结束</strong>。</li>
<li><code>Failed</code>：MPIJob 失败。</li>
<li><code>Unknown</code>：控制器无法获得 MPIJob 的阶段。</li>
</ol>
<p>在下面的示例中，MPIJob 所有子资源创建成功，所以类型为 <code>Initalized</code> 的 <code>condition</code> 被设为 <code>True</code>；MPIJob 运行结束，所以类型为 <code>Completed</code> 的 <code>condition</code> 被设置为 <code>True</code>；但是 MPIJob 的训练结果是失败的，所以类型为 <code>Failed</code> 的 <code>condition</code> 被设置为 <code>True</code>。当前 MPIJob 运行阶段为 <code>Failed</code>。</p>
<pre><code class="language-yaml">...
status:
  conditions:
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;True&quot;
      message: &quot;The job has been initialized successfully.&quot;
      reason: &quot;-&quot;
      type: Initializing
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;True&quot;
      message: &quot;All pods are running normally.&quot;
      reason: &quot;-&quot;
      type: Running
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;False&quot;
      message: &quot;All pods are running normally.&quot;
      reason: &quot;-&quot;
      type: ReplicaFailure
    - lastTransitionTime: &quot;2021-01-18T02:36:31Z&quot;
      status: &quot;False&quot;
      message: &quot;The job exited with an error code.&quot;
      reason: &quot;Failed&quot;
      type: Completed
    - lastTransitionTime: &quot;2021-01-18T02:36:31Z&quot;
      status: &quot;True&quot;
      message: &quot;The job exited with an error code.&quot;
      reason: &quot;Failed&quot;
      type: Failed
  phase: Failed
</code></pre>
<aside class="note">
<div class="title">注意</div>
<p>上述 <code>conditions</code> 中的 <code>Completed</code> 和 <code>phase</code> 中的 <code>Succeeded</code> 并不表示 MPIJob 成功，仅仅表示 MPIJob 结束。</p>
<p>MPIJob 使用 <code>mpirun</code> 实现 MPI 计算，并将其移植到 Kubernetes 上，<code>mpirun</code> 的工作原理是：在本地运行 <code>mpirun</code>，向其他主机发送计算命令，并监听这些主机上所启动的进程运行状况，打印这些进程的日志，在所有进程结束（无论是成功还是失败）后退出，返回值为 0。在将 <code>mpirun</code> 移植到 Kubernetes 上之后，MPIJob 的控制器仅能看到 <code>mpirun</code> 是以什么方式结束的（返回值是零或非零），无法更准确地知道任务具体是成功还是失败，所以 MPIJob 以 <code>Completed</code> 记录任务结束的状态（而非 <code>Succeeded</code>）。</p>
<p>同理，<code>conditions</code> 和 <code>phase</code> 中的 <code>Failed</code> 表示的也不是 MPIJob 任务运行失败，而是启动副本、执行副本因为某些原因（集群故障、网络错误等）无法正确工作。</p>
<p>因此在 MPIJob 结束后，你需要通过查看启动副本的日志来确定任务的具体执行情况。</p>
</aside>
<h3 id="副本的状态-6"><a class="header" href="#副本的状态-6">副本的状态</a></h3>
<p><code>status.tasks</code> 字段用来记录副本的状态，记录的内容主要包括：</p>
<ul>
<li>副本的重启次数（同一种角色的副本的重启次数之和）</li>
<li>副本当前的运行阶段</li>
<li>副本在集群中对应的 Pod 的索引信息</li>
</ul>
<p>在下面的示例中，MPIJob 创建了 1 个启动副本和 2 个执行副本。当前均处于 <code>Running</code> 阶段，分别运行在 <code>mpi-example-worker-0</code> 和 <code>mpi-example-worker-1</code> 这 2 个 Pod 上；启动副本当前处于 <code>Running</code> 阶段，运行在 <code>mpi-example-launcher</code> Pod 上。</p>
<pre><code class="language-yaml">...
status:
  tasks:
  - type: launcher
    restartCount: 0
    status:
    - phase: Running
      name: mpi-example-launcher
      uid: 66634db2-35e7-4641-a4dc-adbd5479734e
      containers: []
  - type: worker
    restartCount: 0
    status:
    - phase: Running
      name: mpi-example-worker-0
      uid: e3ec2ee3-6645-4e21-993f-1e472b94e0ae
      containers: []
    - phase: Running
      name: mpi-example-worker-1
      uid: 908a93f0-7b8b-491e-85d5-3da0abcb4ca4
      containers: []
</code></pre>
<h3 id="副本状态统计-6"><a class="header" href="#副本状态统计-6">副本状态统计</a></h3>
<p><code>status.aggregate</code> 字段统计了各个阶段的副本数量。</p>
<p>在下面示例中，MPIJob 创建了 3 个副本，其中 1 个处于 <code>Pending</code> 阶段，另外两个处于 <code>Running</code> 阶段。</p>
<pre><code class="language-yaml">...
status:
  aggregate:
    creating: 0
    deleted: 0
    failed: 0
    pending: 1
    running: 2
    succeeded: 0
    unknown: 0
...
</code></pre>
<h2 id="下一步-15"><a class="header" href="#下一步-15">下一步</a></h2>
<ul>
<li>了解如何<a href="modules/jobs/../../tasks/horovod-keras-parallel.html">使用 Horovod 进行 Keras 模型的数据并行训练</a></li>
<li>了解如何<a href="modules/jobs/../../tasks/horovod-pytorch-parallel.html">使用 Horovod 进行 PyTorch 模型的数据并行训练</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="beamjob"><a class="header" href="#beamjob">BeamJob</a></h1>
<p>BeamJob 用于在集群中通过 <a target="_blank" rel="noopener noreferrer" href="https://beam.apache.org/documentation/sdks/python/">Apache Beam Python SDK</a> 运行分布式计算任务，并提供多种底层计算引擎，目前支持 <a target="_blank" rel="noopener noreferrer" href="https://flink.apache.org/">Apache Flink</a>，未来会支持 <a target="_blank" rel="noopener noreferrer" href="https://spark.apache.org/">Apache Spark</a>。</p>
<h2 id="创建-beamjob"><a class="header" href="#创建-beamjob">创建 BeamJob</a></h2>
<p>下面是一个基本的 BeamJob 配置示例，负责统计输入文件中的英文单词出现次数，并将结果存储在输出文件中：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: BeamJob
metadata:
  name: beamjob-example
spec:
  flinkClusterTemplate:
    spec:
      flinkVersion: 1.10.1
      image:
        name: t9kpublic/flink:1.10.1
      jobManager:
        accessScope: Cluster
        resources:
          limits:
            cpu: &quot;100m&quot;
            memory: &quot;1Gi&quot;
      taskManager:
        replicas: 2
        resources:
          limits:
            cpu: &quot;100m&quot;
            memory: &quot;2Gi&quot;
      flinkProperties:
        taskmanager.numberOfTaskSlots: &quot;1&quot;
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - image: t9kpublic/apache_beam_python3.7_sdk:2.22.0
            name: submit-job
            command:
              - &quot;python3&quot;
            args:
              - &quot;-m&quot;
              - &quot;apache_beam.examples.wordcount&quot;
              - &quot;--input&quot;
              - &quot;/mypvc/input.txt&quot;
              - &quot;--output&quot;
              - &quot;/mypvc/output.txt&quot;
            volumeMounts:
              - mountPath: &quot;/mypvc&quot;
                name: mypvc
          volumes:
            - name: mypvc
              persistentVolumeClaim:
                claimName: mypvc
          restartPolicy: OnFailure
</code></pre>
<p>在该例中：</p>
<ul>
<li>你需要准备好一个名为 <code>mypvc</code> 的 PVC，并将名为 <code>input.txt</code> 的输入文件存放在 PVC 的根路径下。</li>
<li><code>flinkClusterTemplate</code> 字段描述了所要创建的 Flink 集群，其中包含 1 个 <a target="_blank" rel="noopener noreferrer" href="https://nightlies.apache.org/flink/flink-docs-release-1.11/concepts/flink-architecture.html#jobmanager) 和 2 个 [Task Manager](https://nightlies.apache.org/flink/flink-docs-release-1.11/concepts/flink-architecture.html#taskmanagers">Job Manager</a>{target=_blank}，所使用的 Flink 版本为 1.10.1。</li>
<li><code>jobTemplate</code> 字段描述了用户如何将所要运行的任务提交给 Flink 集群，其中所使用的 Apache Beam Python SDK 版本为 2.22.0，所运行的程序为 Apache Beam Python SDK 自带的单词统计程序 <code>apache_beam.examples.wordcount</code>。</li>
</ul>
<h2 id="beamjob-状态"><a class="header" href="#beamjob-状态">BeamJob 状态</a></h2>
<h3 id="beamjob-的状态和阶段"><a class="header" href="#beamjob-的状态和阶段">BeamJob 的状态和阶段</a></h3>
<p><code>status.conditions</code> 字段用于描述当前 BeamJob 的状态，包括以下 2 种类型：</p>
<ul>
<li><code>ClusterRunning</code>：Flink 集群正在运行</li>
<li><code>JobRunning</code>：用户提交的任务正在运行</li>
</ul>
<p><code>status.phase</code> 字段用于描述当前 BeamJob 所处的阶段，BeamJob 的整个生命周期主要有以下几个阶段：</p>
<ol>
<li><code>Initializing</code>：BeamJob 刚刚创建，等待 Flink 集群启动。</li>
<li><code>Running</code>：Flink 集群已启动，用户提交的任务正在运行。</li>
<li><code>Succeeded</code>：BeamJob 成功。</li>
<li><code>Failed</code>：BeamJob 失败。</li>
<li><code>Unknown</code>：控制器执行错误，导致未能获取 BeamJob 当前运行阶段。</li>
</ol>
<p><code>status.jobURL</code> 字段是 Flink 集群的 Web UI 中用户提交的此次任务对应的详细信息页面。</p>
<p>在下面的示例中，Flink 集群已启动，所以类型为 <code>ClusterRunning</code> 的 <code>condition</code> 被设置为 <code>True</code>；用户所提交的任务正在运行，所以类型为 <code>JobRunning</code> 的 <code>condition</code> 被设置为 <code>True</code>。当前 BeamJob 运行阶段为 <code>Running</code>，如需在 Flink 集群的 Web UI 中查看任务的详细信息，请跳转至 <code>jobURL</code>。</p>
<pre><code class="language-yaml">...
status:
  conditions:
    - lastTransitionTime: &quot;2021-01-18T02:36:09Z&quot;
      status: &quot;True&quot;
      type: ClusterRunning
    - lastTransitionTime: &quot;2021-01-18T02:36:31Z&quot;
      status: &quot;True&quot;
      type: JobRunning
  phase: Running
  jobURL: /t9k/flink-cluster/beamjob-example-flinkcluster/namespace/t9k-example/#/job/c9f62e4d61d089f351ab1f8b29e1df32/overview/
</code></pre>
<h3 id="flink-集群的状态"><a class="header" href="#flink-集群的状态">Flink 集群的状态</a></h3>
<p><code>status.flinkClusterStatus</code> 字段用来记录 Flink 集群的状态，包括所有 Job Manager 和 Task Manager 的运行阶段以及对应的 Pod 索引。</p>
<p>在下面的示例中，BeamJob 创建的 Flink 集群包括 1 个 Job Manager 和 2 个 Task Manager，均处于 <code>Running</code> 阶段（记录在 <code>phase</code> 字段中），对应的 Pod 的索引信息记录在 <code>reference</code> 字段中（包括 Pod 的名称和 UID）。</p>
<pre><code class="language-yaml">...
status:
  flinkClusterStatus:
    jobManagerStatus:
    - phase: Running
      reference:
        name: beamjob-example-flinkcluster-jobmanager-0
        uid: 21c67b2d-88d4-4b0a-9044-2311edee5e83
    taskManagerStatus:
    - phase: Running
      reference:
        name: beamjob-example-flinkcluster-taskmanager-0
        uid: c120c704-0730-49c8-8995-5fb719840af7
    - phase: Running
      reference:
        name: beamjob-example-flinkcluster-taskmanager-1
        uid: f1326d53-c5b6-4869-b5e9-8c35b7a7637d
</code></pre>
<h3 id="用户提交任务的状态"><a class="header" href="#用户提交任务的状态">用户提交任务的状态</a></h3>
<p><code>status.jobStatus</code> 字段用来记录用户所提交的任务的状态，包括运行阶段以及对应的 Pod 索引。</p>
<p>在下面的示例中，BeamJob 创建的用户任务仅包含 1 个 Pod，处于 <code>Succeeded</code> 阶段（记录在 <code>phase</code> 字段中），对应的 Pod 的索引信息记录在 <code>reference</code> 字段中（包括 Pod 的名称和 UID）。用户所提交的任务运行可能出现错误并多次重试，因此 <code>status.jobStatus</code> 字段可能包含多个 Pod。</p>
<pre><code class="language-yaml">...
status:
  jobStatus:
  - phase: Succeeded
    reference:
      name: beamjob-example-batchjob-szsn8
      uid: 9aed0159-fe2a-4096-99a7-1c89af5a6f0e
</code></pre>
<h2 id="清除策略-6"><a class="header" href="#清除策略-6">清除策略</a></h2>
<p>在 BeamJob 成功或失败后，所创建的 Flink 集群仍然在运行，占据较多的计算资源。在下面的示例中，你可以在 <code>spec.runPolicy</code> 字段中将 <code>cleanUpCluster</code> 设置为 <code>true</code>，在 BeamJob 运行完毕（无论成功还是失败）之后删除 Flink 集群。</p>
<pre><code class="language-yaml">...
spec:
  runPolicy:
    cleanUpCluster: true
...
</code></pre>
<aside class="note">
<div class="title">注意</div>
<p>删除 Flink 集群会丢失任务运行相关的所有信息，且无法恢复。</p>
</aside>
<h2 id="调度器-8"><a class="header" href="#调度器-8">调度器</a></h2>
<p>目前 BeamJob 支持两种调度器：</p>
<ol>
<li>Kubernetes 的<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler">默认调度器</a></li>
<li><a href="modules/jobs/../scheduling/index.html">T9k Scheduler 调度器</a></li>
</ol>
<p>调度器通过 <code>spec.scheduler</code> 字段设置：</p>
<ul>
<li>不设置 <code>spec.scheduler</code> 字段，则默认使用 Kubernetes 的默认调度器。</li>
<li>设置 <code>spec.scheduler.t9kScheduler</code> 字段，则使用 T9k Scheduler 调度器。</li>
</ul>
<p>在下面的示例中，BeamJob 启用 T9k Scheduler 调度器，将副本插入 <code>default</code> 队列中等待调度，其优先级为 50。</p>
<pre><code class="language-yaml">...
spec:
  scheduler:
    t9kScheduler:
      queue: default
      priority: 50
...
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>队列和优先级都是 T9k Scheduler 的概念，具体含义请参阅 <a href="modules/jobs/../scheduling/index.html">T9k Scheduler</a>。</p>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="资产管理"><a class="header" href="#资产管理">资产管理</a></h1>
<p>所谓 AI 资产，指数据集和模型等人工智能相关的数据。</p>
<p>TensorStack AI 平台的资产管理模块（AssetHub，以下简称 AH）对模型和数据集提供完善的管理功能，包括版本管理、持续开发和协同开发等功能。</p>
<h2 id="产品架构"><a class="header" href="#产品架构">产品架构</a></h2>
<p><img src="modules/../assets/modules/ah/architecture.png" alt="structure" /></p>
<p>如上图所示，AH 使用 TensorStack AI 平台自研存储系统 AIStore 存储数据，用户可以通过 AH 控制台、命令行工具和 SDK 工具与 AIStore 连接，实现 AH 的各项功能。</p>
<h2 id="版本控制"><a class="header" href="#版本控制">版本控制</a></h2>
<p>AH 支持多版本模型管理，用户可以训练和提交多个临时版本模型，发布其中符合预期的模型。</p>
<p>多版本管理通过以下机制实现：</p>
<ul>
<li>Branch：分支，用户可以创建一个新分支来记录模型的临时版本；将新分支合并到主分支上，完成模型的发布。</li>
<li>Commit：“交付”，相当于版本快照，便于确定版本和追溯历史。</li>
<li>Tag：标签，用户可以为具有“特殊意义”的 Commit 标记标签，比如 best、v1 等。</li>
</ul>
<p>数据集同样支持 Branch、Commit 和 Tag 的管理方式，不过数据集不会如模型那样频繁产出，所以一般建议数据集只在主分支上持续更新。</p>
<h2 id="s3-接口"><a class="header" href="#s3-接口">S3 接口</a></h2>
<p>在训练（或部署服务）时，除了将数据集和模型下载到本地使用，大多数框架也支持直接从 S3 数据服务上动态获取数据文件。</p>
<p>AH 提供 S3 接口，用户可以在 AH 控制台上创建 S3 凭证，然后使用页面上生成的 S3 配置文件在训练过程中直接通过 S3 接口获取数据。</p>
<aside class="note">
<div class="title">注意</div>
<p>由于需要动态通过网络下载数据，S3 接口读取数据的速度要比提前下载到本地慢。因此，仅推荐在存储空间有限且对数据读取速度不敏感的条件下使用 S3 接口。</p>
</aside>
<h2 id="协同开发"><a class="header" href="#协同开发">协同开发</a></h2>
<p>AH 支持文件夹粒度的权限共享。用户可以将一组模型或数据集分享给其他人，实现多人共同开发和训练结果共享的目的。</p>
<p>可分享的权限包括查看权限或编辑权限，编辑权限包含查看权限。分享的目标可以是另一个用户、用户组或者公开给所有人。</p>
<h2 id="下一步-16"><a class="header" href="#下一步-16">下一步</a></h2>
<ul>
<li>了解如何使用 Asset Hub <a href="modules/../tasks/manage-ai-assets.html">管理 AI 资产</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="实验管理"><a class="header" href="#实验管理">实验管理</a></h1>
<p>TensorStack AI 平台的实验管理模块（Experiment Management，以下简称 EM）提供完善的实验数据追踪功能，能够收集实验元数据、实验中间产物，并可视化和比较实验结果，推动模型进步。</p>
<h2 id="产品架构-1"><a class="header" href="#产品架构-1">产品架构</a></h2>
<p><img src="modules/../assets/modules/em/architecture.png" alt="structure" /></p>
<p>如上图所示，EM 使用 TensorStack AI 平台自研存储系统 AIStore 存储数据，用户可以通过 EM 控制台、命令行工具和 SDK 工具与 AIStore 连接，实现 EM 的各项功能。</p>
<h2 id="存储结构"><a class="header" href="#存储结构">存储结构</a></h2>
<p>EM 使用树状结构组织一个用户的实验数据，在 Web UI 中体现为目录结构。</p>
<pre><code class="language-bash"># EM 目录结构示意图
user:demo
  ├── em-example/
  │   ├── mnist_dataset
  │   └── mnist_keras
  └── autotune/
      └── keras-tune
</code></pre>
<h3 id="节点类型"><a class="header" href="#节点类型">节点类型</a></h3>
<p>EM 树状结构中，节点根据存储方式分为四类，用 StorageType 表示：</p>
<ul>
<li>StorageType == 0：不存储数据文件，仅用于组织 EM 树状结构。EM 中文件夹即该类型节点。</li>
<li>StorageType == 1：存储一个文件数据。</li>
<li>StorageType == 2：存储一组数据文件。</li>
<li>StorageType == 3：该类型节点可以创建和管理多个版本，每一个版本中可以存储一组数据文件。</li>
</ul>
<p>在这四种存储类型的基础上，EM 根据用途实现以下 7 个节点类型：</p>
<ul>
<li>Folder：Storage Type == 0，文件夹结构，用来组织实验数据。</li>
<li>Shotrcut：Storage Type == 0，快捷方式，指向另一个节点。</li>
<li>Run：Storage Type == 2，记录实验元数据，包括实验基本信息、实验参数和实验指标。</li>
<li>Artifact：Storage Type == 2，记录实验的中间产物，也包括未发布的数据集和模型。</li>
<li>AutoTune：Storage Type == 2，记录超参数调优实验数据，参考<a href="modules/./building/autotune.html">超参数调优实验</a>。</li>
<li>Model：Storage Type == 3，记录机器学习模型。</li>
<li>Dataset：Storage Type == 3，记录机器学习所使用的数据集。</li>
</ul>
<p>Artifact 没有特定的文件组织结构，用户可根据需要组织上传。</p>
<p>Model 和 Dataset 由 TensorStack 平台的资产管理模块，具体请参考 <a href="modules/experiment-management.html#em-%E5%92%8C-assethub-%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB">EM 和 AssetHub 之间的关系</a> 。</p>
<p>Run 和 Autotune 是实验元数据的存储节点，具有特定的文件组织结构，EM Web 根据这些特定的文件组织结构进行实验数据的可视化。</p>
<h4 id="run-节点"><a class="header" href="#run-节点">Run 节点</a></h4>
<p>Run 记录实验元数据，包括实验基本信息、实验参数和实验指标。</p>
<p>Run 节点中包含一个 index.yaml 文件，其中记录其他实验数据在该节点中的相对路径：</p>
<pre><code>hyperparameters: hyperparameters.yaml
metrics:
  train: metrics/train.yaml
  val: metrics/val.yaml
  test: metrics/test.yaml
platform: platform.yaml
git: git.yaml
log: stdout.log
</code></pre>
<ul>
<li><code>hypterparameters</code>：机器学习超参数。</li>
<li><code>metrics</code>：训练指标，由于指标可能产生自不同阶段，同一阶段也可能有多种指标，所以使用上例中的结构记录多个指标文件。</li>
<li><code>platform</code>：平台信息，包括系统版本、python 包版本等。</li>
<li><code>git</code>：代码存储位置，我们一半会将机器学习脚本存储在 GitHub 中。</li>
<li><code>log</code>：日志文件。</li>
</ul>
<p>上述文件的生成可以由 em 工具自动完成，用户只需要了解如何使用 em 工具。参考 <a href="modules/../tools/python-sdk-t9k/api/t9k-em.html">em API 文档</a>。</p>
<h4 id="autotune-节点"><a class="header" href="#autotune-节点">AutoTune 节点</a></h4>
<p>AutoTune 记录超参数调优实验数据，包括实验的基本配置以及每一次训练的参数和指标。</p>
<p>AutoTune 节点的文件结构如下：</p>
<pre><code>.
├── profile.json
├── 17671/
│   ├── metadata.json
│   └── metrics.yaml
...
</code></pre>
<ul>
<li><code>profile.json</code>：记录超参数调优实验的训练配置、超参数搜索空间和调优配置等信息</li>
<li><code>17671</code>：超参数调优过程中，每一次训练都会创建一个文件夹用来记录训练数据，文件夹名称即训练的 ID（随机生成）。
<ul>
<li><code>metadata.json</code>：记录训练参数和训练状态。</li>
<li><code>metrics.yaml</code>：记录训练指标，超参数调优创建的训练都只会产生一个指标，调优控制器会根据该指标调整超参数。</li>
</ul>
</li>
</ul>
<h2 id="可视化"><a class="header" href="#可视化">可视化</a></h2>
<p>EM 支持使用以下方式对 Run 数据进行可视化：</p>
<ul>
<li>数据流图：Run 和 Artifact 之间是存在使用和产出关系的，比如一次实验（Run）使用一个 Artifact 作为训练数据，最后产出另一个 Artifact。这种使用和产出关系构成了一个数据流动路线图，即数据流图。用户可以通过数据流图快速跳转到对应数据节点。</li>
</ul>
<img src="modules/../assets/modules/em/run-dataflow.png" alt="image" width="500"/>
<ul>
<li>指标折线图</li>
</ul>
<img src="modules/../assets/modules/em/run-metric.png" alt="image"/>
<p>EM 支持使用以下方式对 AutoTune 数据进行可视化：</p>
<ul>
<li>“超参数-指标”图</li>
</ul>
<p><img src="modules/../assets/modules/em/autotune-pm.png" alt="autotune-pm" /></p>
<ul>
<li>指标优化曲线</li>
</ul>
<p><img src="modules/../assets/modules/em/autotune-opt.png" alt="autotune-opt" /></p>
<ul>
<li>各次训练的指标信息</li>
</ul>
<p><img src="modules/../assets/modules/em/autotune-trial-detail.png" alt="autotune-trial-detail" /></p>
<h2 id="权限管理"><a class="header" href="#权限管理">权限管理</a></h2>
<p>EM 支持节点粒度的权限控制：</p>
<ul>
<li>用户可以将一个节点分享给另一个用户、用户组或者公开给所有人。</li>
<li>可分享的权限包括查看权限或编辑权限，编辑权限包含查看权限。</li>
<li>文件夹权限修改会传递给所有子节点（当用户被分享了一个文件夹的编辑权限，则该用户自动拥有文件夹中所有节点的编辑权限；取消分享同理）。</li>
<li>当一个节点被移动到另一个文件夹中，节点完全继承该文件夹的权限，覆盖节点之前的权限设置。</li>
</ul>
<h2 id="em-和-assethub-之间的关系"><a class="header" href="#em-和-assethub-之间的关系">EM 和 AssetHub 之间的关系</a></h2>
<p>AssetHub 是 TensorStack AI 平台的<a href="modules/./asset-management.html">资产管理模块</a>，用于管理数据集和模型。</p>
<p>数据集和模型作为实验的输入和输出，也应当作为实验管理的一部分，所以在 EM 中也可以看到 AssetHub 中的数据集和模型数据，如下图所示：</p>
<pre><code class="language-bash"># EM 目录结构示意图
user:demo
  └── t9k-assethub/
      ├── model/
      │   ├── folder1
      │   │   ├── model1
      │   │   ...
      │   ├── folder2
      │   ...
      └── dataset/
</code></pre>
<p>数据集和模型分别记录在 EM 的 <code>./t9k-assethub/dataset</code> 和 <code>./t9k-assethub/model</code> 文件夹中，model 文件夹（dataset 文件夹同样）维护文件夹和模型两级结构，每一个模型都是一个具有版本管理功能的节点。</p>
<aside class="note">
<div class="title">注意</div>
<p>在使用 EM 的时候，非必要请勿修改 t9k-assethub 文件夹中的数据，以避免影响 AssetHub 的使用。</p>
</aside>
<h2 id="下一步-17"><a class="header" href="#下一步-17">下一步</a></h2>
<ul>
<li>了解如何使用 EM <a href="modules/../tasks/track-model-training.html">追踪模型训练</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="账户和安全"><a class="header" href="#账户和安全">账户和安全</a></h1>
<p>TensorStack AI 平台提供全面、系统性的安全支持，以保障平台本身、平台提供的各种工具（例如模型构建控制台）和用户的各种工作负载（例如训练任务）的安全。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="账户"><a class="header" href="#账户">账户</a></h1>
<p>账户是用户在 TensorStack AI 平台身份和权限的代表。</p>
<p>在使用 TensorStack AI 平台前，用户需要先联系集群管理员为其创建一个平台账户。</p>
<aside class="note info">
<div class="title"> 账户数据库 </div>
<p>平台支持使用外部已有的目录服务，例如支持 LDAP 协议的服务，存放账户信息。平台在安装时，管理员可设定用户数据的来源。</p>
</aside>
<h2 id="api-key"><a class="header" href="#api-key">API Key</a></h2>
<p>在使用浏览器场景下（例如使用模型构建控制台），用户能够直接、同步地参与到身份认证和授权流程。用户可以方便地通过交互式的方式提供安全凭证（用户名 + 密码）来完成认证和授权，并随后通过 Cookie + Access Token 建立安全的交互过程。</p>
<p>但是，还有其他环境或者场景不适合采用前述方式。例如，用户通过命令行（环境受限，无法使用浏览器）或者在自动化脚本中向服务器发送请求，此时要求“用户同步进行交互”来获得访问令牌是非常不便捷的；或者，在此过程中需要通过客户程序输入密码，可能造成密码泄漏。同时，有些场景下，我们希望能够只授予客户端部分权限，但直接使用前述 access token 或者 Cookie 并不能更进一步缩小权限。</p>
<p>API Key 是 TensorStack AI 平台应对上述问题的解决方案。它是一种可撤销的、异步的、持久的安全授权方式，具有以下特点：</p>
<ul>
<li>可以长期持有（适合在脚本中使用）</li>
<li>不会泄漏账户信息（无需使用用户名和密码）</li>
<li>可以选择性地包含账户的部分权限 </li>
<li>方便在脚本程序、命令行工具等“非交互场景”进行集成使用</li>
<li>可以随时方便地取消该授权</li>
</ul>
<h2 id="下一步-18"><a class="header" href="#下一步-18">下一步</a></h2>
<ul>
<li>了解如何为账户<a href="modules/security/../../tasks/generate-api-key.html">生成 API Key</a></li>
<li>了解在不同场景<a href="modules/security/../../tasks/use-api-key.html">使用 API Key</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="项目"><a class="header" href="#项目">项目</a></h1>
<p>项目（Project）是 TensorStack AI 平台为了有效使用集群资源，实现多用户、多项目同时、安全、共享使用集群而提供的机制；它是一个 CRD。</p>
<p>它具有以下特征：</p>
<ul>
<li>每个项目有一个<strong>项目管理员</strong>，他可以管理项目的<strong>成员</strong>。</li>
<li>只有项目的管理员和成员可以在项目中执行操作。</li>
<li>每个项目对应一个同名的 Kubernetes 命名空间（Namespace），项目的成员拥有当前命名空间中几乎所有 K8s 资源的操作权限。</li>
</ul>
<aside class="note info">
<div class="title"> 集群管理员和项目管理员的区别 </div>
<p><strong>集群管理员</strong>拥有 TensorStack AI 平台的管理权限，包括但不限于创建、修改和删除用户、用户组、项目和队列。集群管理员也具有所有项目的项目管理员和成员的设置权限。</p>
<p><strong>项目管理员</strong>具有一个项目的成员管理权限。每一个项目只能设置一个项目管理员，由集群管理员在创建项目时设置或在创建后修改。</p>
<p>需要说明的是：集群管理员虽然有集群管理的权限，但是在项目的使用上，集群管理员同样要遵循项目授权的规则，即如果集群管理员不是项目的成员，则集群管理员不能使用这个项目。当然，集群管理员可以通过将自己设置为项目成员的方式来使用项目。</p>
<p>本节所有“普通用户”指的都是除“集群管理员”之外的用户，也包括项目管理员。</p>
</aside>
<h2 id="项目定义"><a class="header" href="#项目定义">项目定义</a></h2>
<p>以下是一个项目的定义（Custom Resource）示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: Project
metadata:
spec:
  networkPolicy:
    template:
      spec:
        egress:
          - to:
              - namespaceSelector:
                  matchLabels:
                    kubernetes.io/metadata.name: t9k-system
                podSelector:
                  matchLabels:
                    app: security-console-server
        ingress:
          - from:
              - namespaceSelector:
                  matchLabels:
                    kubernetes.io/metadata.name: t9k-system
        policyTypes:
          - Ingress
          - Egress
    useDefaultTemplate: false
  quotaProfile: demo
  resourceQuota:
    template:
      spec:
        hard:
          cpu: '200'
          memory: 1280Gi
          nvidia.com/gpu: '18'
          persistentvolumeclaims: 200Gi
          pods: 1k
</code></pre>
<p>注：普通用户（包括项目管理员）不可修改上述项目配置，这里仅用该配置进行演示和讲解。</p>
<p>在上述示例中：</p>
<ul>
<li>该项目中设置以下网络策略：
<ul>
<li>该项目中的工作负载可以访问 <code>t9k-system</code> 命名空间中的 <code>security-console-server</code> 服务（由字段 <code>spec.networkPolicy.template.spec.egress</code> 字段指定）。</li>
<li>该项目中的服务可以被 <code>t9k-system</code> 命名空间的任一工作负载访问（由字段 <code>spec.networkPolicy.template.spec.ingress</code> 字段指定）。</li>
</ul>
</li>
<li>该项目使用 <code>demo</code> 资源配额模版。</li>
</ul>
<h3 id="资源配额与配额模版"><a class="header" href="#资源配额与配额模版">资源配额与配额模版</a></h3>
<p>一个项目的资源配额（由 <code>spec.resourceQuota</code> 字段指定）表示：当前项目中所能使用的资源上限，包括但不限于 CPU、内存、GPU 和 Pod 数量。</p>
<p>值得说明的一点：项目的资源配额中关于 CPU、内存、GPU、Pod 等资源数量的限制都直接作用于 Pod。即如果你创建一个 T9k Job，它即将创建的 pod 需要申请超过项目资源配额的资源数量，则 T9k Job 会被成功创建，但是 T9k Job 创建 Pod 的请求会被拒绝。</p>
<p>管理员可以使用<strong>配额模版</strong>批量设置或修改项目的资源配额。项目控制器会自动查找配额模版（由 <code>spec.quotaProfile</code> 字段指定）的内容，据此同步项目的资源配额。</p>
<h3 id="网络策略"><a class="header" href="#网络策略">网络策略</a></h3>
<p>管理员可以通过项目的网络策略（由字段 <code>spec.networkPolicy</code> 字段指定）实现以下功能：</p>
<ol>
<li>禁止普通用户访问系统级应用，避免保密信息泄漏和系统遭到恶意攻击。</li>
<li>阻断项目间通信，避免项目之间的互相干扰。</li>
<li>限定项目的访客 IP，构建安全的项目环境。</li>
</ol>
<h2 id="项目授权"><a class="header" href="#项目授权">项目授权</a></h2>
<p>项目授权信息存储在特定的授权服务器而非项目定义中。</p>
<p>普通用户（包括项目管理员）可以在安全控制台（Security Console）查看自己所在和所管理的项目以及项目的成员。</p>
<p>项目管理员可以通过安全控制台编辑项目成员。</p>
<h3 id="项目的使用范围"><a class="header" href="#项目的使用范围">项目的使用范围</a></h3>
<p>项目可以被应用到 TensorStack AI 平台的模型构建、模型部署和工作流三个模块，集群管理员可以设置一个项目的使用范围。</p>
<p>目前项目可选的使用范围包括：</p>
<ul>
<li><code>build</code>：用户可以在模型构建和工作流模块中使用此项目。</li>
<li><code>deploy</code>：用户可以在模型部署模块中使用此项目。</li>
</ul>
<p>一个项目可以同时设置上述两个使用范围。</p>
<h3 id="项目成员管理"><a class="header" href="#项目成员管理">项目成员管理</a></h3>
<p>项目管理员可以在安全控制台设置项目成员：</p>
<ul>
<li>项目成员可以是用户或用户组，一个用户组被设置为项目成员表示该组中的所有用户都可以使用该项目。</li>
<li>设置项目成员时，可以对每一个成员单独设置项目的使用范围，对成员设置的项目使用范围应为项目所有使用范围的子集。</li>
</ul>
<h2 id="下一步-19"><a class="header" href="#下一步-19">下一步</a></h2>
<ul>
<li>了解项目管理员如何：<a href="modules/security/../../tasks/add-project-member.html">添加 Project 成员</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="计算资源"><a class="header" href="#计算资源">计算资源</a></h1>
<p>用户在向集群提交计算任务，使用计算资源时，需要遵循管理员设置的各种策略。</p>
<ul>
<li><a href="modules/scheduling/index.html#%E8%B5%84%E6%BA%90%E9%85%8D%E9%A2%9D">资源配额</a>：用户提交的工作负载需要满足集群的配额策略；</li>
<li><a href="modules/scheduling/index.html#t9k-scheduler">使用 t9k-scheduler</a>：可能需要通过特定的 scheduler 才能使用特定的资源。</li>
</ul>
<h2 id="资源配额"><a class="header" href="#资源配额">资源配额</a></h2>
<p>管理员可在 <code>Project</code> 和 <code>Queue</code> 分别设置资源（CPU、Memory、GPU、Storage 等）配额。</p>
<ul>
<li>针对 <code>Project</code> 的配额限制单个 Project 里的各种计算资源使用上限；</li>
<li>设置在 <code>Queue</code> 上的配额则允许管理员设置特定容量的资源池供用户使用。</li>
</ul>
<h2 id="t9k-scheduler"><a class="header" href="#t9k-scheduler">t9k-scheduler</a></h2>
<p><code>t9k-scheduler</code> 调度器专为大规模分布式并行计算及异构资源集群设计，可以更加有效地管理 AI 集群的计算资源和计算任务。相比于 K8s 的默认调度器 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler"><code>kube-scheduler</code></a>，<code>t9k-scheduler</code> 在对 AI 计算场景的支持方面进行了增强，并增加了额外的机制以对集群进行更加精细化管理。</p>
<h3 id="适用场景"><a class="header" href="#适用场景">适用场景</a></h3>
<p>为并行计算性质的工作负载分配资源，当用户需要部署多个 Pod 协同工作以运行任务时，推荐使用 <code>t9k-scheduler</code>。</p>
<h3 id="queue--podgroup"><a class="header" href="#queue--podgroup">Queue &amp; PodGroup</a></h3>
<p><code>t9k-scheduler</code> 有两个重要的机制：</p>
<ul>
<li><a href="modules/scheduling/./queue.html">Queue</a>：<code>t9k-scheduler</code> 提供 queue 让用户工作负载申请集群资源，每一个使用 <code>t9k-scheduler</code> 的 Pod 都可指定一个 queue 为其分配资源。队列的创建/修改由集群管理员负责。</li>
<li><a href="modules/scheduling/./podgroup.html">PodGroup</a>：PodGroup 是支持 <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Coscheduling"> coscheduling </a> 机制重要组成部分。它代表一组 Pod，并定义了这组 Pod 在资源方面的限制条件。当限制条件被满足时，PodGroup 中的 Pod 才会被分配计算资源。</li>
</ul>
<h3 id="使用-1"><a class="header" href="#使用-1">使用</a></h3>
<p>当用户创建 Pod 使用 t9k-scheduler 时，需要进行下列操作：</p>
<ol>
<li>将 Pod 使用的调度器名称设置为 t9k-scheduler；</li>
<li>设置 Pod 所属的队列。</li>
</ol>
<p>当用户创建一组 Pod 协同完成一项任务，并使用 t9k-scheduler，需要进行下列操作 （用户一般通过使用 T9k-Job 自动化地使用 PodGroup）：</p>
<ol>
<li>创建一个 PodGroup，并在 PodGroup 中设置所属的队列；</li>
<li>将 Pod 使用的调度器名称设置为 t9k-scheduler；</li>
<li>设置 Pod 属于步骤一创建的 PodGroup。</li>
</ol>
<h2 id="下一步-20"><a class="header" href="#下一步-20">下一步</a></h2>
<ul>
<li>了解<a href="modules/scheduling/./quota.html">资源配额</a></li>
<li>了解<a href="modules/scheduling/./queue.html">队列</a></li>
<li>了解 <a href="modules/scheduling/./podgroup.html">PodGroup</a></li>
<li>了解动化的<a href="modules/scheduling/./reclaim.html">资源回收</a>机制</li>
<li>学习<a href="modules/scheduling/../../tasks/use-queue.html">使用队列</a></li>
<li>学习<a href="modules/scheduling/../../tasks/use-podgroup.html">使用 PodGroup</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-gpu-1"><a class="header" href="#使用-gpu-1">使用 GPU</a></h1>
<p>用户提交的工作负载，如果需要使用 GPU，需要在工作负载的计算资源配置中指定 GPU 扩展资源。</p>
<h2 id="gpu-使用模式"><a class="header" href="#gpu-使用模式">GPU 使用模式</a></h2>
<h3 id="独占使用"><a class="header" href="#独占使用">独占使用</a></h3>
<p>独占模式是指在特定时间段，GPU 卡分配给单一工作负载单独使用。</p>
<p>适用场景：GPU 被满负荷使用，并且计算需要尽快完成。例如 AI 模型的训练。</p>
<h3 id="共享使用"><a class="header" href="#共享使用">共享使用</a></h3>
<p>共享模式是指单个物理 GPU 可以同时被多个工作负载使用。</p>
<p>适用场景：对于有些计算，例如交互式的 Notebook，小规模或者低使用量的模型推理服务，经常只需要使用 GPU 的部分计算能力。在这些情况下，让多个计算任务共享使用 GPU，将能极大地提高 GPU 的利用率，进而获得有益的投资回报率。</p>
<h3 id="共享-nvidia--gpu"><a class="header" href="#共享-nvidia--gpu">共享 NVIDIA  GPU</a></h3>
<p>以 NVIDIA GPU 为例，下面是 NVIDIA 提供的多种 GPU 共享和并发使用的机制，以支持不同的场景。</p>
<aside class="note tip">
<div class="title">GPU 并发机制</div>
<figure>
  <img alt="simplemlservice-detail" src="modules/scheduling/../../assets/modules/scheduling/nv-gpu-sharing.png" />
</figure>
<p>NVIDIA GPU 的并发（concurrency）使用机制。包括：1）应用程序级别（需要修改应用代码才能使用）的 CUDA streams API；2）对应用程序透明的系统软件和硬件分区（partitioning）技术，例如 MPS、Time-slicing、MIG、虚拟化。Source: NVIDIA。</p>
</aside>
<h4 id="mps"><a class="header" href="#mps">MPS</a></h4>
<p>CUDA <a target="_blank" rel="noopener noreferrer" href="https://docs.nvidia.com/deploy/mps/index.html">MPS</a>（多进程服务 / Multi-Process Service）是 CUDA API 的客户端-服务器架构的实现，用于提供同一 GPU 同时给多个进程使用。MPS 是一个 “AI 史前”（深度学习尚未在 GPU 上运行）的方案，是 NVIDIA 为了解决在科学计算领域单个 MPI 进程无法有效利用 GPU 的计算能力而推出的技术。</p>
<p>与时间切片（Time Slicing）相比，MPS 通过在多个客户端之间共享一个 CUDA Context 消除了多个 CUDA 应用之间上下文切换的开销，从而带来更好的计算性能。 此外，MPS 为每个 CUDA 程序提供了单独的内存地址空间，因而可以实现对单个 CUDA 程序实施内存大小使用限制，克服了 Time Slicing 机制在这方面的不足。</p>
<p>优点：</p>
<ul>
<li>可以控制单个应用的内存大小使用限制；</li>
<li>由于消除了多个 CUDA 应用之间 context swtich 的代价，具有更好的性能；</li>
<li>是一个 CUDA 层面的方案，不依赖于 GPU 的特定架构，支持较早的 GPU 硬件。</li>
</ul>
<p>缺点：</p>
<ul>
<li>CUDA 应用之间隔离不足：单个应用的错误可以导致整个 GPU 重置（reset）；</li>
<li>NVIDIA 还未（截止2024/01）正式在 K8s 环境下提供支持。</li>
</ul>
<aside class="note tip">
<div class="title">提示</div>
<p>一些第三方，例如  <a target="_blank" rel="noopener noreferrer" href="https://github.com/nebuly-ai/nos">neuly-ai/nos</a> 提供了在 K8s 环境下使用 MPS 的方案.</p>
</aside>
<h4 id="time-slicing"><a class="header" href="#time-slicing">Time Slicing</a></h4>
<p><a target="_blank" rel="noopener noreferrer" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-sharing.html">时间切片（Time Slicing）</a> 也称为时间共享（Temporal Sharing）是指把多个 CUDA 程序分配到同一个 GPU 上运行，即一个简单的超额订阅（oversubscription）策略。NVIDIA 在 Pascal 架构（GP100，2016 年首发）之上提供了对此技术的支持。这些 GPU 卡上的调度器提供了指令粒度（不再需要等待 CUDA kernel 执行完成）的计算抢占（Compute Premption）技术。当抢占发生时， 当前 CUDA 程序的执行上下文（execution context：寄存器、共享内存等）被交换（swapped）到 GPU DRAM，以便另一个 CUDA 程序运行。</p>
<p>优点：</p>
<ul>
<li>非常容易设置；</li>
<li>对分区数量无限制；</li>
<li>可在众多 GPU 架构上部署。 </li>
</ul>
<p>缺点：</p>
<ul>
<li>上下文切换引起的效率降低；</li>
<li>共享 GPU 设备导致的的隔离不足、潜在的 GPU OOM 等；</li>
<li>时间片周期恒定，且无法为每个工作负载设置可用资源的优先级或大小。</li>
</ul>
<h4 id="mig"><a class="header" href="#mig">MIG</a></h4>
<p><a target="_blank" rel="noopener noreferrer" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html">MIG</a> 可以把一个 GPU 划分为最多 7 个独立的 GPU 实例，从而为多个 CUDA 程序提供专用的 GPU 资源，包括流式多处理器 (Streaming Multiprocessors) 和 GPU 引擎。这些 MIG 实例可以为不同的 GPU 客户端（例如进程、容器或 VM）提供更加高级的故障隔离能力和 QoS。</p>
<p>优点：</p>
<ul>
<li>硬件隔离，并发进程安全运行且互不影响；</li>
<li>在分区级别提供监控和遥测（monitoring &amp; telemetry）数据；</li>
<li>每个分区可以叠加使用其他共享技术，例如 vGPU，time-slicing, MPS。</li>
</ul>
<p>缺点：</p>
<ul>
<li>仅在最新的 GPU 架构（Ampere, Hopper）上提供；</li>
<li>重新配置分区布局需在 GPU 空闲（驱逐所有正在运行的进程）时；</li>
<li>一些分区配置会导致部分 SM / DRAM 无法被利用。</li>
</ul>
<h4 id="vgpu"><a class="header" href="#vgpu">vGPU</a></h4>
<p>NVIDIA vGPU 是 NVIDIA 在数据中心提供的 GPU 虚拟化技术，它对具有完整输入输出内存管理单元 (IOMMU) 保护的 VM 提供支持，使得这些 VM 能够同时、直接地访问单个物理 GPU。</p>
<p>除了安全性之外，NVIDIA vGPU 还有其他优势，例如：</p>
<ul>
<li>支持实时虚拟机迁移（live VM migration）；</li>
<li>可设置不同的调度策略，包括 best-effort、equal-share 和 fixed-sharez：
<ul>
<li>当使用 fixed-share 调度器时可提供可预知的性能；</li>
</ul>
</li>
<li>运行混合的 VDI (Virtual Desktop Infrastructure) 和计算工作负载的能力；</li>
<li>与业界广泛使用的虚拟机管理程序（hypervisor，如 vmware）的集成能力。</li>
</ul>
<p>缺点:</p>
<ul>
<li>部署 vGPU 需要额外的软件授权费用；</li>
<li>分区仍然通过时间片（time-slicing）完成。</li>
</ul>
<h2 id="扩展资源名称"><a class="header" href="#扩展资源名称">扩展资源名称</a></h2>
<p>如果用户想知道用户所使用的集群有哪些代表 GPU 的扩展资源名称，请咨询集群管理员。下面列举了一些常见的代表 GPU 的扩展资源。</p>
<h3 id="nvidia-gpu"><a class="header" href="#nvidia-gpu">NVIDIA GPU</a></h3>
<p>当集群安装有 NVIDIA GPU 硬件资源时，通常有下列扩展资源名称：</p>
<ul>
<li><code>nvidia.com/gpu</code>：一个扩展资源对应一个 NVIDIA GPU 硬件资源。可以申请使用多个 GPU 资源。例如当声明资源 <code>nvidia.com/gpu: 8</code> 时，会有 8 个 NVIDIA GPU 分配给这个工作负载使用。</li>
<li><code>nvidia.com/gpu.shared</code>：通过这个扩展资源，多个工作负载可以共享使用一个 NVIDIA GPU。需要注意，当共享机制是通过 time slicing 实现时，用户为工作负载设置<code> nvidia.com/gpu.shared</code> 扩展资源的数量不能超过 1（参考）。</li>
</ul>
<p>NVIDIA 还有其他形式的设备名称，例如，当部署了 MIG 技术时，常见的资源名称有：</p>
<ul>
<li><code>nvidia.com/mig-3g.20gb</code>：一个扩展资源对应的计算能力是物理 GPU 的 3/7，显存大小是 20GB。</li>
<li><code>nvidia.com/mig-2g.10gb</code>：一个扩展资源对应的计算能力是物理 GPU  的 2/7，显存大小是 10GB。</li>
<li><code>nvidia.com/mig-1g.5gb</code>：一个扩展资源对应的计算能力是物理 GPU 的 1/7，显存大小是 5GB。</li>
</ul>
<h3 id="amd-gpu"><a class="header" href="#amd-gpu">AMD GPU</a></h3>
<p>当集群安装有 AMD GPU 硬件资源时，通常有下列扩展资源名称：</p>
<ul>
<li><code>amd.com/gpu</code>：一个扩展资源对应一个 AMD GPU 硬件资源。同样的，可申请多个 GPU，例如 <code>amd.com/gpu: 2</code> 。</li>
</ul>
<h3 id="其他"><a class="header" href="#其他">其他</a></h3>
<p>请参考对应厂商的 device plugin 文档。</p>
<h2 id="gpu-使用示例"><a class="header" href="#gpu-使用示例">GPU 使用示例</a></h2>
<h3 id="独占-gpu"><a class="header" href="#独占-gpu">独占 GPU</a></h3>
<p>集群中部署了 NVIDIA GPU 后，一般配置扩展资源 <code>nvidia.com/gpu</code> 支持独占使用 GPU。</p>
<p>下面是一个使用 GPU 的 <code>PytorchTrainingJob</code> YAML 示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: PyTorchTrainingJob
metadata:
 name: pytorch-example
spec:
 replicaSpecs:
 - replicas: 4
   restartPolicy: OnFailure
   template:
     spec:
       containers:
       - command:
         - python
         - dist_mnist.py
         image: pytorch/pytorch:2.0.0-cuda11.7-cudnn8-devel
         name: pytorch
         resources:
           limits:
             nvidia.com/gpu: 4
           requests:
             cpu: 10
             memory: 5Gi
   type: worker
</code></pre>
<p>在该例中，<code>spec.replicaSpecs[0].template.spec.containers[0].resources.limits</code> 字段设置了资源量  <code>nvidia.com/gpu: 4</code>，表明一个 replica 会独占使用 4 个 NVIDIA GPU。由于设置了 <code>PyTorchTraiiningJob</code> 的 replica 数量为 4，所以 <code>PyTorchTraiiningJob</code> 总共会占用 16 个 NVIDIA GPU。</p>
<aside class="note">
<div class="title">注意</div>
<p><code>resources</code> 字段的一些规则：</p>
<ol>
<li>代表 GPU 的扩展资源的数量必须设为整数。</li>
<li>扩展资源填写在 <code>resources.limits</code> 字段下即可，但不能只填写在 <code>resources.requests</code> 字段下。</li>
<li>如果在 <code>resources.limits</code> 和 <code>resources.requests</code> 字段中同时设置了同一个扩展资源，两者数量必须相等。</li>
</ol>
</aside>
<h3 id="共享-gpu"><a class="header" href="#共享-gpu">共享 GPU</a></h3>
<p>扩展资源 <code>nvidia.com/gpu.shared</code> 代表共享 GPU。</p>
<p>下面是一个以共享方式使用 GPU 的 Notebook YAML 示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: Notebook
metadata:
  name: tutorial
spec:
  type: jupyter
  template:
    spec:
      containers:
        - name: notebook
          image: t9kpublic/torch-2.1.0-notebook:1.77.1
          volumeMounts:
            - name: workingdir
              mountPath: /t9k/mnt
          resources:
            requests:
              cpu: '8'
              memory: 16Gi
              nvidia.com/gpu.shared: 1
            limits:
              cpu: '16'
              memory: 32Gi
              nvidia.com/gpu.shared: 1
      volumes:
        - name: workingdir
          persistentVolumeClaim:
            claimName: tutorial

</code></pre>
<p>在该例中：<code>spec.template.spec.containers[0].resources.limits</code> 字段定义了资源量 <code>nvidia.com/gpu.shared: 1</code> ，表明这个 Notebook 以共享方式使用一个 NVIDIA GPU。</p>
<h3 id="指定-gpu-型号"><a class="header" href="#指定-gpu-型号">指定 GPU 型号</a></h3>
<p>不同节点上安装的 GPU 型号经常是不同的，同一厂家的 GPU 对应的扩展资源名称常常是相同的，例如：对于 NVIDIA GPU，在不考虑共享 GPU 的情况下，A100 和 A40 型号对应的扩展资源名称都是 <code>nvidia.com/gpu</code>。</p>
<p>调度器为工作负载分配资源时忽略型号信息，如果用户想让工作负载使用特定型号的 GPU，例如：<code>NVIDIA A100-80GB</code>、<code>NVIDIA A40</code>，用户可以参考下列方式配置工作负载，使其能被分配到安装有特定型号 GPU 的节点上。</p>
<h4 id="设置-nodeselector"><a class="header" href="#设置-nodeselector">设置 <code>nodeSelector</code></a></h4>
<p>安装有 GPU 硬件的节点会通过节点标签来表明节点上安装的 GPU 型号。用户在创建工作负载时，可以为其设置 <code>nodeSelector</code>。 <code>nodeSelector</code> 的作用是通过节点标签来筛选节点，从而工作负载会被分配到期望的节点上。</p>
<p>如果用户将工作负载的 <code>nodeSelector</code> 设置为指定型号 GPU 对应的节点标签，并且为工作负载设置了代表 GPU 的扩展资源数量，那么工作负载就可以使用指定型号的 GPU。</p>
<p><strong>常见的节点标签</strong></p>
<p>如果用户想知道用户所使用的集群有哪些表明 GPU 型号的节点标签，请咨询管理员。</p>
<p>下面是一些表明 GPU 型号的节点标签示例：</p>
<div class="table-wrapper"><table><thead><tr><th>GPU 型号</th><th>节点标签</th></tr></thead><tbody>
<tr><td>NVIDIA A100-40GB</td><td><code>nvidia.com/gpu.product: NVIDIA-A100-PCIE-40GB</code></td></tr>
<tr><td>NVIDIA A100-80GB</td><td><code>nvidia.com/gpu.product: NVIDIA-A100-PCIE-80GB</code></td></tr>
<tr><td>NVIDIA GTX 1070</td><td><code>nvidia.com/gpu.product: NVIDIA-GeForce-GTX-1070</code></td></tr>
<tr><td>NVIDIA TITAN-X</td><td><code>nvidia.com/gpu.product: NVIDIA-TITAN-X</code></td></tr>
</tbody></table>
</div>
<p><strong>常见工作负载的 <code>nodeSelector</code> 字段</strong></p>
<p>下面列举了常见的工作负载，以及工作负载用于设置 <code>nodeSelector</code> 的字段：</p>
<div class="table-wrapper"><table><thead><tr><th>工作负载</th><th>字段</th></tr></thead><tbody>
<tr><td>GenericJob</td><td>spec.replicaSpecs[*].template.spec.nodeSelector</td></tr>
<tr><td>PyTorchTrainingJob</td><td>spec.replicaSpecs[*].template.spec.nodeSelector</td></tr>
<tr><td>TensorFlowTrainingJob</td><td>spec.replicaSpecs[*].template.spec.nodeSelector</td></tr>
<tr><td>XGBoostTrainingJob</td><td>spec.replicaSpecs[*].template.spec.nodeSelector</td></tr>
<tr><td>DeepSpeedJob</td><td>spec.worker.template.spec.nodeSelector</td></tr>
<tr><td>ColossalAIJob</td><td>spec.worker.template.spec.nodeSelector</td></tr>
<tr><td>MPIJob</td><td>spec.worker.template.spec.nodeSelector</td></tr>
<tr><td>BeamJob</td><td>spec.jobTemplate.spec.template.spec.nodeSelector</td></tr>
<tr><td>Notebook</td><td>spec.template.spec.nodeSelector</td></tr>
<tr><td>SimpleMLService</td><td>只有使用自定义框架时，才能通过字段 spec.custom.nodeSelector 设置 nodeSelector</td></tr>
<tr><td>MLService predictor</td><td>spec.releases[*].predictor.template.spec.nodeSelector</td></tr>
<tr><td>MLService transformer</td><td>spec.transformer.template..spec.nodeSelector</td></tr>
<tr><td>Pod</td><td>spec.nodeSelector</td></tr>
</tbody></table>
</div>
<p><strong>示例</strong></p>
<p>下面是一个设置了 nodeSelector 的 notebook 示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: Notebook
metadata:
 name: tutorial-nodeselector
spec:
 type: jupyter
 template:
   spec:
     containers:
       - name: notebook
         image: t9kpublic/torch-2.1.0-notebook:1.77.1
         volumeMounts:
           - name: workingdir
             mountPath: /t9k/mnt
         resources:
           limits:
             cpu: '16'
             memory: 32Gi
             nvidia.com/gpu: 1
     nodeSelector:
       nvidia.com/gpu.product: NVIDIA-A100-PCIE-40GB
     volumes:
       - name: workingdir
         persistentVolumeClaim:
           claimName: tutorial

</code></pre>
<p>在该例中：
Notebook 的资源量设置了 <code>nvidia.com/gpu: 1</code>，表明 Notebook 要使用一个 GPU。
Notebook 的 <code>nodeSelector</code> 被设置为 <code>nvidia.com/gpu.product: NVIDIA-A100-PCIE-40GB</code>，所以 Notebook 的 Pod 会被分配到含有标签 <code>nvidia.com/gpu.product: NVIDIA-A100-PCIE-40GB</code> 的节点上运行。
从而 Notebook 会被分配一个 NVIDIA GPU A100-40GB。</p>
<h4 id="设置队列"><a class="header" href="#设置队列">设置队列</a></h4>
<p>通过 <code>nodeSelector</code> 机制选择特定型号的 GPU 过程繁琐，而且管理员也缺乏对 GPU 使用权限的方便控制。TensorStack 提供了更加便捷的<a href="modules/scheduling/../scheduling/queue.html">队列</a>机制方便用户使用特定类型的资源。</p>
<p>当满足下列两个要求时，用户可以通过设置队列的方法来使用特定型号的 GPU：</p>
<ol>
<li>管理员为集群提供了恰当的配置。例如，设置了队列 <code>A100</code> 以选择安装有 A100 GPU 的计算节点；</li>
<li>用户有权限使用这个队列。</li>
</ol>
<aside class="note">
<div class="title">注意</div>
<ol>
<li>如果用户想知道集群中有哪些队列及其对应的 GPU 硬件，请咨询管理员。</li>
<li>队列是 t9k-scheduler 提供的高级功能，需要通过 <a href="modules/scheduling/../scheduling/queue.html">t9k-schduler</a> 使用。</li>
</ol>
</aside>
<p>用户在创建工作负载时，可以进行下列操作，选择特定型号的 GPU：</p>
<ul>
<li>使用 <code>t9k-scheduler</code> ；</li>
<li>设置合适队列名称，例如 A100；</li>
<li>设置使用 GPU 扩展资源，例如 <code>nvidia.com/gpu</code>。</li>
</ul>
<p><strong>示例</strong></p>
<p>假设管理员在集群中配置了两个队列，名称分别是：</p>
<ul>
<li><code>a100</code>：队列可以使用的节点上都安装有 GPU NVIDIA A100-80GB</li>
<li><code>a40</code>：队列可以使用的节点上都安装有 GPU NVIDIA A40-40GB</li>
</ul>
<p>并且，用户有权限使用这两个队列。</p>
<p>如果用户想创建一个使用 NVIDIA A100-80GB 的 Notebook，用户可以创建下列 Notebook:</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: Notebook
metadata:
 name: tutorial
spec:
 type: jupyter
 scheduler:
   t9kScheduler:
     queue: a100
 template:
   spec:
     containers:
       - name: notebook
         image: t9kpublic/torch-2.1.0-notebook:1.77.1
         volumeMounts:
           - name: workingdir
             mountPath: /t9k/mnt
         resources:
           limits:
             cpu: '16'
             memory: 32Gi
             nvidia.com/gpu: 1
     volumes:
       - name: workingdir
         persistentVolumeClaim:
           claimName: tutorial

</code></pre>
<p>在该例中：</p>
<ul>
<li>Notebook 的资源量设置了 <code>nvidia.com/gpu: 1</code>，表明 Notebook 要使用一个 GPU。</li>
<li>字段 <code>spec.scheduler.t9kScheduler.queue</code> 被设置为 a100，表明 Notebook 使用 T9k Scheduler 进行资源调度，并且使用队列 a100。</li>
</ul>
<p>用户通过队列的方式使用更加简洁、方便。同时，集群管理员可使用权限等机制，更加方便地实施集群资源管理策略。</p>
<h2 id="参考-4"><a class="header" href="#参考-4">参考</a></h2>
<p>K8s Extended resources<br />
<a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#extended-resources">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#extended-resources</a></p>
<p>Consuming extended resources<br />
<a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#consuming-extended-resources">https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#consuming-extended-resources</a></p>
<p>Schedule GPUs | Kubernetes<br />
<a href="https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/">https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/</a></p>
<p>Device Plugins<br />
<a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/">https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/</a></p>
<p>Assigning Pods to Nodes<br />
<a href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/">https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/</a></p>
<p>Improving GPU Utilization in Kubernetes<br />
<a href="https://developer.nvidia.com/blog/improving-gpu-utilization-in-kubernetes">https://developer.nvidia.com/blog/improving-gpu-utilization-in-kubernetes</a></p>
<p>MIG：NVIDIA Multi-Instance GPU User Guide<br />
<a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-mig.html#configuring-mig-profiles">https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-mig.html#configuring-mig-profiles</a></p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="资源配额-1"><a class="header" href="#资源配额-1">资源配额</a></h1>
<p>为保证集群资源的合理分配和使用，管理员会在以下两个方面限制普通用户的资源使用（CPU、内存、GPU、Storage 等）：</p>
<ol>
<li>项目配额：限制用户在一个 Project（项目）中可以使用的资源总量。</li>
<li>队列配额：限制一个 Queue（队列中）的工作负载可以使用的资源总量。</li>
</ol>
<p>用户创建的工作负载（如 T9k Job）不能超过上述两种配额的限制，否则工作负载将被拒绝接受。</p>
<p>具体请参考 “<a href="modules/scheduling/../security/project.html#%E8%B5%84%E6%BA%90%E9%85%8D%E9%A2%9D%E4%B8%8E%E9%85%8D%E9%A2%9D%E6%A8%A1%E7%89%88">项目资源配额</a>” 和 “<a href="modules/scheduling/./queue.html#%E8%B5%84%E6%BA%90%E9%85%8D%E9%A2%9D">队列资源配额</a>”。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="队列"><a class="header" href="#队列">队列</a></h1>
<h2 id="概述-2"><a class="header" href="#概述-2">概述</a></h2>
<p>队列（Queue）是 T9k-Scheduler 提供的集群资源管理机制。</p>
<p>如果使用了 T9k-Scheduler，用户创建工作负载时，则可以选择使用一个特定的 Queue 申请集群资源。</p>
<h2 id="队列设置"><a class="header" href="#队列设置">队列设置</a></h2>
<p>管理员创建在集群中创建多个 Queue ，并可设置：</p>
<ul>
<li>Queue 的使用权限，以规定那些人员/组/项目可使用此 queue;</li>
<li>Queue 对应的计算节点集合，以方便地管理计算节点的使用；</li>
<li>资源配额，限制通过此 Queue 使用的资源上限。</li>
</ul>
<h3 id="使用权限"><a class="header" href="#使用权限">使用权限</a></h3>
<p>Queue 的使用权限用于控制哪些用户、组、项目可以使用这个队列。队列的使用权限通过两种方式进行设置：</p>
<ul>
<li>管理员直接设置有权使用队列的用户/用户组。</li>
<li>管理员设置队列的 <code>spec.namespaceSelector</code>（类型是 <a target="_blank" rel="noopener noreferrer" href="https://github.com/kubernetes/apimachinery/blob/v0.29.0/pkg/apis/meta/v1/types.go#L1213">labelSelector</a>）字段。</li>
</ul>
<p>当项目满足下列任一条件时，用户有权在项目下创建使用某个队列的工作负载：</p>
<ul>
<li>队列设置了 <code>spec.namespaceSelector</code>，并且项目对应的 namespace 的标签符合这个 <code>namespaceSelector</code>。</li>
<li>项目的用户有权使用这个队列。</li>
</ul>
<h3 id="节点限制"><a class="header" href="#节点限制">节点限制</a></h3>
<p>队列的节点限制用于指定队列可用的集群工作节点（worker node），T9k-Scheduler 只会将队列内的工作负载分配到这些特定的节点上。</p>
<p>队列的 <code>spec.nodeSelector</code> （类型是 <a target="_blank" rel="noopener noreferrer" href="https://github.com/kubernetes/apimachinery/blob/v0.29.0/pkg/apis/meta/v1/types.go#L1213">labelSelector</a>）字段用于设置队列的节点权限：</p>
<ul>
<li>字段未设置时，队列可以使用集群内所有的节点</li>
<li>字段设置后，队列可以使用节点标签满足 nodeSelector 的节点。</li>
</ul>
<p>在下面的节点权限示例中：说明队列可以使用节点标签包含 <code>topology.kubernetes.io/zone: peking</code> 或 <code>topology.kubernetes.io/zone: tianjin</code> 的节点。</p>
<pre><code class="language-yaml">spec:
  nodeSelector:
    matchExpressions:
    - key: topology.kubernetes.io/zone
      operator: In
      values:
      - peking
      - tianjin
</code></pre>
<h3 id="资源配额-2"><a class="header" href="#资源配额-2">资源配额</a></h3>
<p>队列的资源配额用于限制队列可以使用的资源上限，如果用户创建的工作负载（例如 Job，Pod 等）会导致队列超出资源配额限制，那么系统会拒绝接受此工作负载。</p>
<p>队列的 <code>spec.quota</code> 字段定义队列的资源配额，队列的 <code>status.allocated</code> 字段表明队列已经使用的资源量。</p>
<p>在下面的示例中：</p>
<ul>
<li>工作负载的 CPU 资源请求量（<code>requests</code>）总和不能超过 40；</li>
<li>Queue 已经被分配了 38 个 CPU。</li>
</ul>
<pre><code class="language-yaml">spec:
  quota:
    requests:
      cpu: 40
status:
  allocated:
    cpu: &quot;38&quot;
</code></pre>
<h3 id="优先级"><a class="header" href="#优先级">优先级</a></h3>
<p><code>spec.priority</code> 字段定义队列的优先级，值类型是 int，范围是 [0,100]，数值越大代表队列的优先级越高。队列的优先级会影响下列事件：</p>
<ul>
<li>优先级较高的队列会被优先分配资源。</li>
<li>如果 T9k-Scheduler 开启了资源抢占行为，优先级较高的队列有权抢占低优先级队列使用的资源。</li>
</ul>
<h3 id="是否可被抢占资源"><a class="header" href="#是否可被抢占资源">是否可被抢占资源</a></h3>
<p><code>spec.preemptible</code> 字段定义队列是否可以被其他队列抢占资源，字段值类型是 <code>bool</code>：</p>
<ul>
<li><code>false</code> ，队列无法被抢占资源；</li>
<li><code>true</code> ，队列可以被抢占资源。</li>
</ul>
<h3 id="开启关闭"><a class="header" href="#开启关闭">开启/关闭</a></h3>
<p><code>spec.closed</code> 字段定义队列是否处于关闭状态，当队列被关闭了，用户无法创建使用该队列的工作负载。字段值类型是 <code>bool</code>：</p>
<ul>
<li>字段未设置或被设置为 <code>false</code> 时，队列处于开启状态；</li>
<li>字段被设置为 <code>true</code> 时，队列处于关闭状态。</li>
</ul>
<h3 id="最大运行时长"><a class="header" href="#最大运行时长">最大运行时长</a></h3>
<p>最大运行时长会限制队列中 Pod 的运行时长，如果 Pod 的存在时长（存在时长=当前时间 - Pod 创建时间）超过最大运行时长，Pod 会被删除。</p>
<p>队列的 <code>spec.maxDuration</code> 字段设置了队列的最大运行时长：</p>
<ul>
<li>值类型是 string，并且需要满足正则表达式 <code>^(0|(([0-9]+)y)?(([0-9]+)w)?(([0-9]+)d)?(([0-9]+)h)?(([0-9]+)m)?(([0-9]+)s)?(([0-9]+)ms)?)$</code>。</li>
<li>支持的时间单位：y, w（周）, d, h, m, s, ms。</li>
<li>示例：“3w”,  “2h45m”。</li>
<li>未设置时，队列不受最大运行时长约束。</li>
</ul>
<h3 id="资源尺寸"><a class="header" href="#资源尺寸">资源尺寸</a></h3>
<p>资源尺寸（resource shape）会限制队列中工作负载请求资源量的上限，当用户创建超过资源尺寸的工作负载时，工作负载会被系统拒绝。</p>
<p>队列的 <code>spec.resourceShapeProfile</code> 字段设置了队列使用的资源尺寸模版，模型对应的资源尺寸详情存储在 ConfigMap <code>t9k-system/resource-shapes</code> 中。用户可以通过 T9k 产品前端查看队列的资源尺寸设置。</p>
<h2 id="下一步-21"><a class="header" href="#下一步-21">下一步</a></h2>
<ul>
<li>了解如何<a href="modules/scheduling/../../tasks/use-queue.html">使用队列</a></li>
<li>队列 <a href="modules/scheduling/../../references/api-reference/scheduler.html#queue">API Reference</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="podgroup"><a class="header" href="#podgroup">PodGroup</a></h1>
<h2 id="概述-3"><a class="header" href="#概述-3">概述</a></h2>
<p>PodGroup 关联一组协同工作的 Pod，它们共同完成一项计算任务（例如分布式并行模型训练），因此需要作为一个整体来分配资源。通常情况下，用户可以通过创建 <a href="modules/scheduling/../jobs/index.html">T9k Job</a> 类的工作负载来间接使用 PodGroup，而不需要直接创建 PodGroup。</p>
<p>PodGroup 是 T9k 支持 <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Coscheduling"> coscheduling </a> 机制的关键组成部分，可以为并行计算提供更好的支持，包括避免死锁场景和提高资源利用率。</p>
<h2 id="规范"><a class="header" href="#规范">规范</a></h2>
<p>下面是一个基本的 PodGroup 示例：</p>
<pre><code class="language-yaml">apiVersion: scheduler.tensorstack.dev/v1beta1
kind: PodGroup
metadata:
  name: chorus
  namespace: default
spec:
  minMember: 3
  priority: 50
  queue: default
</code></pre>
<p>在该例中：</p>
<ul>
<li>最少运行数量是 3 个成员 Pod（由 <code>spec.minMember</code> 字段指定）。</li>
<li>PodGroup 的优先级是 50（由 <code>spec.priority</code> 字段指定）。</li>
<li>PodGroup 使用 <code>default</code> 队列（由 <code>spec.queue</code> 字段指定）申请资源。</li>
</ul>
<h3 id="队列-1"><a class="header" href="#队列-1">队列</a></h3>
<p><code>spec.queue</code> 设置 PodGroup 欲使用的资源队列，默认值是 <code>default。</code></p>
<h3 id="优先级-1"><a class="header" href="#优先级-1">优先级</a></h3>
<p><code>spec.priority</code> 字段设置 PodGroup 的优先级 ，值类型是 <code>int</code>，范围是 [0,100]，默认值是 0，数值越大表明优先级越高。在同一个队列中，优先级高的 PodGroup 会被优先分配资源。</p>
<h3 id="最少成员限制"><a class="header" href="#最少成员限制">最少成员限制</a></h3>
<p>成员数量限制包括两部分，必须同时满足，调度器才会为 PodGroup 分配资源：</p>
<ul>
<li>最少数量（minMember）；</li>
<li>角色最少数量（role minMember），但非必须字段。当未填写时，则自动满足。</li>
</ul>
<h4 id="最少数量"><a class="header" href="#最少数量">最少数量</a></h4>
<p><code>spec.minMember</code> 设置 PodGroup 的最小运行数量，表明 PodGroup 的 Pod 数量（不包括失败的 Pod）达到最小运行数量时，调度器才会为 PodGroup 分配资源。</p>
<p>本文开头的示例中设置的最小运行数量是 3，但未设置角色最少数量。</p>
<h4 id="角色最少数量"><a class="header" href="#角色最少数量">角色最少数量</a></h4>
<p>基于角色（role）的最小运行数量通过字段 <code>spec.roles</code> 的子字段设置。</p>
<ul>
<li><code>spec.roles</code> 是一个记录角色名称和该角色的最小运行数量的数组；</li>
<li>PodGroup 的 Pod 通过标签来指定自己的角色。</li>
</ul>
<p>下面是一个示例：</p>
<pre><code class="language-yaml">spec:
  roles:
  - name: master
    minMember: 1
  - name: worker
    minMember: 3
</code></pre>
<p>在该示例中，PodGroup 包含两类角色 <code>master</code> 和 <code>worker</code>。当可运行的 <code>master</code> Pod 数量达到 1，<code>worker</code> Pod 数量达到 3 时，调度器才会为 PodGroup 分配资源。</p>
<aside class="note info">
<div class="title"> 指定 Pod 的 Role </div>
<p>PodGroup 中 Pod 的角色（role）通过标签 <code>scheduler.tensorstack.dev/role</code> 指定。Job 控制器会自动为其创建的 Pod 设置 role。</p>
<p>例如：</p>
<ul>
<li>贴有标签 <code>scheduler.tensorstack.dev/role: master</code> 的 Pod 的角色是 <code>master</code></li>
<li>贴有标签 <code>scheduler.tensorstack.dev/role: worker</code> 的 Pod 的角色是 <code>worker</code></li>
</ul>
</aside>
<h2 id="状态"><a class="header" href="#状态">状态</a></h2>
<p>PodGroup 的状态记录在 <code>status</code> 字段中。</p>
<aside class="note">
<div class="title">注意</div>
<p>PodGroup 只负责关联一组 Pod，其 <code>status</code> 记录信息有限。如果用户想知道 PodGroup 关联的工作负载整体的详细状态一般需要通过 PodGroup 的父资源，例如 T9k Job 的 <code>status</code> 获取；单独 Pod 的状态则须查看此 Pod 的 <code>status</code>。</p>
</aside>
<p><code>status.conditions</code> 字段记录了当前 PodGroup 的状态，包括下列 2 种类型：</p>
<ul>
<li><code>GroupScheduled</code>: PodGroup 是否已经被分配过资源</li>
<li><code>SufficientGroupMember</code>: PodGroup 的 Pod 数量是否满足最小运行需求</li>
</ul>
<p><code>status.allocated</code> 字段记录了当前 PodGroup 使用的资源量。</p>
<p>PodGroup 的 Pod 的数量：</p>
<ul>
<li><code>status.pending</code>：处于 Pending phase 的 Pod 数量</li>
<li><code>status.running</code>：处于 Running phase 的 Pod 数量</li>
<li><code>status.succeeded</code>：处于 Succeeded phase 的 Pod 数量</li>
<li><code>status.failed</code>：处于 Failed phase 的 Pod 数量</li>
<li><code>status.unknown</code>：处于 Unknown phase 的 Pod 数量</li>
</ul>
<h3 id="示例-2"><a class="header" href="#示例-2">示例</a></h3>
<p>下面的 YAML 片段展示了一个正常运行中的 PodGroup 的 <code>status</code> 字段：</p>
<ul>
<li><code>allocated</code>：podgroup 被分配的资源总和；</li>
<li><code>running</code>: 3 个 pod 处于 running 状态；</li>
<li>condition <code>SufficientGroupMember</code> 为 <code>True</code>，表示 PodGroup 满足最小成员约束，可以被分配资源；</li>
<li>condition <code>GroupScheduled</code> 为 <code>True</code>，表示整个 PodGroup 已经被分配资源；</li>
</ul>
<pre><code class="language-yaml">status:
  allocated:
    cpu: 3
    memory: 600M
  conditions:
  - lastTransitionTime: &quot;2023--17T13:54:02Z&quot;
    reason: SufficientMemberPods
    status: &quot;True&quot;
    transitionID: 82ce5bf5-313d-4294-b44b-9b44ffd52213
    type: SufficientGroupMember
  - lastTransitionTime: &quot;2023-12-17T13:48:16Z&quot;
    message: Resources have been allocated to PodGroup
    reason: PodGroupScheduled
    status: &quot;True&quot;
    transitionID: c5a70cac-769c-44c4-a6ba-f4b1227cb135
    type: GroupScheduled
  running: 3
</code></pre>
<h2 id="下一步-22"><a class="header" href="#下一步-22">下一步</a></h2>
<ul>
<li>了解如何<a href="modules/scheduling/../../tasks/use-podgroup.html">使用 PodGroup</a></li>
<li>PodGroup <a href="modules/scheduling/../../references/api-reference/scheduler.html#podgroup">API Reference</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="资源回收-2"><a class="header" href="#资源回收-2">资源回收</a></h1>
<p>一些交互式工作负载（例如 <a href="modules/scheduling/../building/notebook.html">Notebook</a>、<a href="modules/scheduling/../building/tensorboard.html">TensorBoard</a> 和 <a href="modules/scheduling/../storage/explorer.html">Explorer</a>）的计算资源经常被闲置。例如在非工作时间，用户创建的 Notebook 服务虽然没有用户使用，但仍占用大量集群计算资源，造成资源浪费。</p>
<p>为充分利用集群资源，TensorStack AI 平台提供资源回收机制，自动检测并暂停空闲的 Notebook、TensorBoard 和 Explorer 等服务，释放占用的资源。</p>
<h2 id="原理"><a class="header" href="#原理">原理</a></h2>
<p>以 Notebook 为例，介绍资源回收的原理（TensorBoard、 Explorer 或者其他工作负载同理）。</p>
<p><img src="modules/scheduling/../../assets/modules/scheduling/reclaim.structure.drawio.svg" alt="structure" /></p>
<p>如上图所示：</p>
<ol>
<li>集群管理员设置 “资源回收配置” 策略；</li>
<li>根据配置，Resource Keeper 监听启用回收功能的项目（Project 2）中的 Notebook 状态；</li>
<li>当 Notebook 空闲时间达到配置中规定的阈值，则 Resource Keeper 对该资源实施暂停操作，以释放资源。</li>
</ol>
<h3 id="状态检测"><a class="header" href="#状态检测">状态检测</a></h3>
<p>很多在 TensorStack AI 平台上运行的服务，使用 PEP Proxy 来处理身份验证和授权。由于其 proxy 所有客户端请求，这个 PEP Proxy 也可以作为检查服务是否空闲的信息来源。</p>
<p><img src="modules/scheduling/../../assets/modules/scheduling/pepproxy.drawio.svg" alt="pepproxy" /></p>
<p>对于 TensorBoard 和 Explorer，对应控制器会向 PEP Proxy 发送请求，检查其上一次请求的时间，如果给定时间内（比如 1 小时，由集群管理员配置）没有再次请求，则控制器判定其为空闲状态。</p>
<p>Jupyter Notebook 本身的 server 就提供了状态查询功能。因此，对于 Notebook 类型的工作负载，Notebook 的控制器会先尝试向 Notebook server 发送请求检查空闲状态。如果处于空闲或请求失败（可能 Notebook 使用的不是 Jupyter 内核，主要发生在自定义 Notebook 上），则继续向 PEP Proxy 发送请求，查询 PEP Proxy 观测到的服务使用情况：例如，如果 1 小时内（由管理员配置）没有请求，则控制器判定其为空闲状态。</p>
<p>对于 RStudio Notebook，目前没有空闲状态的判定，控制器将其视为永远处于活跃状态。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="资源使用监控"><a class="header" href="#资源使用监控">资源使用监控</a></h1>
<p>在 Tensorstack AI 平台创建工作负载后，用户可以通过控制台或命令行工具查看工作负载的资源使用情况。</p>
<h2 id="控制台"><a class="header" href="#控制台">控制台</a></h2>
<p>用户可以在下列控制台的工作负载的详情页面查看资源监测图表：</p>
<ul>
<li>模型构建（Build Console）：
<ul>
<li>Notebook</li>
<li>T9k Job</li>
<li>Tensorboard</li>
<li>Pod</li>
</ul>
</li>
<li>模型部署（Deploy Console）：
<ul>
<li>MLService</li>
</ul>
</li>
</ul>
<p>当用户定义工作负载时可以选择性地为每个容器设定所需要的资源数量，最常见的可设定资源是 CPU、内存和扩展资源。</p>
<p>以 PyTorchTrainingJob 为例，用户可以查看下面几类资源的使用情况。</p>
<h3 id="cpu--memory--扩展资源"><a class="header" href="#cpu--memory--扩展资源">CPU / Memory / 扩展资源</a></h3>
<p>CPU（内存）的资源监测图如下所示，图中包含三条折线：</p>
<ul>
<li>请求量：工作负载声明的 <code>resources.requests.cpu</code>（<code>resources.requests.memory</code>）</li>
<li>上限：工作负载声明的 <code>resources.limits.cpu</code>（<code>resources.limits.memory</code>）</li>
<li>使用量：工作负载实际使用的 CPU（内存）资源量</li>
</ul>
<figure class="screenshot">
  <img alt="cpu" src="modules/scheduling/../../assets/modules/scheduling/monitoring/cpu.png"/>
</figure>
<figure class="screenshot">
  <img alt="memory" src="modules/scheduling/../../assets/modules/scheduling/monitoring/memory.png"/>
</figure>
<p>当工作负载声明扩展资源时，显示扩展资源的资源监测图。</p>
<p>在本例中，PytorchTrainingJob 声明了扩展资源 <code>nvidia.com/gpu: 2</code>，页面显示了工作负载声明的 <code>resources.limits.&quot;nvidia.com/gpu&quot;</code> 资源量。</p>
<figure class="screenshot">
  <img alt="nvidia.com/gpu" src="modules/scheduling/../../assets/modules/scheduling/monitoring/nvidia.com:gpu.png"/>
</figure>
<h3 id="nvidia-gpu-1"><a class="header" href="#nvidia-gpu-1">NVIDIA GPU</a></h3>
<p>当工作负载声明的扩展资源是 <code>nvidia.com/gpu</code> 时，资源监测图会展示额外的 GPU 相关指标，包括：利用率、温度、功率、显存使用率、已用显存量、SM Clock、TensorCore 利用率。</p>
<p>下面是展示 GPU 利用率和显存使用率的图表：</p>
<figure class="screenshot">
  <img alt="gpu-utilization" src="modules/scheduling/../../assets/modules/scheduling/monitoring/gpu-utilization.png"/>
</figure>
<figure class="screenshot">
  <img alt="gpu-memory-utilization" src="modules/scheduling/../../assets/modules/scheduling/monitoring/gpu-memory-utilization.png"/>
</figure>
<h3 id="网络带宽"><a class="header" href="#网络带宽">网络带宽</a></h3>
<p>网络带宽显示下面两项指标：</p>
<ul>
<li>接收带宽：所有容器接收数据的网络带宽总计。</li>
<li>发送带宽：所有容器发送数据的网络带宽总计。</li>
</ul>
<figure class="screenshot">
  <img alt="network-receive" src="modules/scheduling/../../assets/modules/scheduling/monitoring/network-receive.png"/>
</figure>
<figure class="screenshot">
  <img alt="network-transmit" src="modules/scheduling/../../assets/modules/scheduling/monitoring/network-transmit.png"/>
</figure>
<h3 id="存储-io"><a class="header" href="#存储-io">存储 I/O</a></h3>
<p>存储 I/O 显示下面两项指标：</p>
<ul>
<li>IOPS（读+写）：所有容器在节点的物理磁盘上，进行读写的操作次数之和。</li>
<li>吞吐量（读+写）：所有容器在节点的物理磁盘上，读写数据的吞吐量。</li>
</ul>
<figure class="screenshot">
  <img alt="storage-iops" src="modules/scheduling/../../assets/modules/scheduling/monitoring/storage-iops.png"/>
</figure>
<figure class="screenshot">
  <img alt="storage-throughput" src="modules/scheduling/../../assets/modules/scheduling/monitoring/storage-throughput.png"/>
</figure>
<h2 id="命令行工具"><a class="header" href="#命令行工具">命令行工具</a></h2>
<p>用户可以在 Notebook 的终端中，使用 <code>kubectl top</code> 命令查看 Pod 的 CPU、内存使用情况。例如：</p>
<pre><code class="language-bash">(base) [/t9k/mnt t9kuser@managed-notebook-933f6-0]
$ kubectl top pods
NAME                                         CPU(cores)   MEMORY(bytes)   
managed-notebook-933f6-0                     25m          153Mi           
managed-project-event-ctl-854b96f4dd-f6hn8   1m           29Mi 
</code></pre>
<h2 id="下一步-23"><a class="header" href="#下一步-23">下一步</a></h2>
<ul>
<li>监控 <a href="modules/scheduling/../../tasks/pytorch-training-parallel.html#%E6%A3%80%E6%9F%A5%E8%AE%AD%E7%BB%83%E6%97%A5%E5%BF%97%E5%92%8C%E6%8C%87%E6%A0%87">T9k Job 的资源使用</a></li>
<li>监控<a href="modules/scheduling/../../tasks/deploy-mlservice.html#%E7%9B%91%E6%8E%A7%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1">推理服务的资源使用</a></li>
<li>监控 Notebook 的资源使用（TODO: 完成 <code>查看 Notebook 资源使用</code> 相关用户文档）</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="存储"><a class="header" href="#存储">存储</a></h1>
<p>TensorStack 平台支持多种类型的存储服务：Block Storage Volumes（块存储卷），Shared Filesystem Volumes (共享文件系统卷)，及基于 S3 协议的对象存储。</p>
<h2 id="存储卷storage-volumes"><a class="header" href="#存储卷storage-volumes">存储卷（Storage Volumes）</a></h2>
<p>用户可申请使用两种类型的存储卷（Storage Volumes）：<a href="modules/storage/index.html#%E5%9D%97%E5%AD%98%E5%82%A8%E5%8D%B7block-storage-volumes">块存储卷</a>，或者<a href="modules/storage/index.html#%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8D%B7shared-filesystem-volumes">共享文件系统卷</a>。</p>
<p>这两种高性能的网络存储卷服务，可为各种类型的工作负载，如 Notebook、T9k Jobs、推理服务等提供持久化存储卷（Persistent Volumes）服务。</p>
<ul>
<li>支持在集群中使用不同性能等级的存储服务。例如，管理员可设置集群同时提供高性能的 SSD 和海量的 HDD 两种等级的存储服务；</li>
<li>所有 SSD 和 HDD 等级均可创建为 Block Volumes（块存储卷）或 Shared Filesystem Volumes （共享文件系统存储卷）；</li>
<li>可随时调整 Volume 大小以增加容量；</li>
<li>存储与计算分开管理，并且可以在不同实例和硬件类型之间移动；</li>
<li>支持存储卷的快照、备份及恢复。</li>
<li>可通过 UI 或 命令行工具 <code>kubectl</code> 轻松管理；</li>
</ul>
<h3 id="块存储卷block-storage-volumes"><a class="header" href="#块存储卷block-storage-volumes">块存储卷（Block Storage Volumes）</a></h3>
<p>Block Storage Volumes （块存储卷）可作为高性能虚拟存储盘挂载到各种类型的工作负载上。这些卷被呈现为通用 Block Device (块设备)，操作系统将其视为物理连接存储设备，并且独占使用。</p>
<p>如果集群部署了高性能的 NVMe 的存储节点，并使用了足够快的网络，这种类型的存储卷的性能将会超过本地 SATA 接口的 SSD，并且可以扩展到 PB 级别容量。</p>
<h3 id="共享文件系统卷shared-filesystem-volumes"><a class="header" href="#共享文件系统卷shared-filesystem-volumes">共享文件系统卷（Shared Filesystem Volumes）</a></h3>
<p>遵守 POSIX 标准的 Filesystem Volumes（文件系统卷）可以挂载到各种工作负载上，以提供原生共享文件系统。</p>
<p>同时，这些卷可以同时附加到多个工作负载实例上，非常适合作在 Notebook、大规模并行计算 Job、推理服务等场景的存储卷。</p>
<h2 id="对象存储"><a class="header" href="#对象存储">对象存储</a></h2>
<p>平台提供基于 S3 协议的对象存储服务，支持方便、通用的数据共享机制及低成本的数据归档服务。</p>
<h2 id="使用-2"><a class="header" href="#使用-2">使用</a></h2>
<p>TensorStack 的存储卷（Storage Volumes）系统支持建立在 Kubernetes 的 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/storage/">Storage API</a> 基础之上，通过 API <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">Persistent Volumes</a>，<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/storage/storage-classes/">Storage Class</a> 等提供用户接口。</p>
<p>同时，为了支持一些特定场景的使用，TensorStack 提供 CRD <a href="modules/storage/storageshim.html">StorageShim</a>，<a href="modules/storage/explorer.html">Explorer</a> 以提供扩展支持。</p>
<p>例 1：获得集群中的存储类型：</p>
<pre><code class="language-bash">$ kubectl get sc
</code></pre>
<p>例 2：创建存储请求：</p>
<pre><code class="language-yaml"># 使用 StorageClass `generic-hdd` 的 Filesystem Volumes (文件系统卷)
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-example
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: 100Gi
  storageClassName: generic-hdd
  volumeMode: Filesystem
</code></pre>
<h2 id="crd-资源"><a class="header" href="#crd-资源">CRD 资源</a></h2>
<p>存储系统中普通用户相关的 CRD 资源，列表如下：</p>
<div class="table-wrapper"><table><thead><tr><th></th><th>来源</th><th>说明</th></tr></thead><tbody>
<tr><td><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims">PVC</a></td><td>Kubernetes</td><td>动态申请集群持久存储；用户可日常创建此 Resource 以申请存储资源</td></tr>
<tr><td><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/storage/storage-classes/">Storage Class</a></td><td>Kubernetes</td><td>指明存储的类别；管理员创建，用户创建 PVC 时引用</td></tr>
<tr><td><a href="modules/storage/../../references/api-reference/storageshim.html">StorageShim</a></td><td>TensorStack</td><td>对各种存储系统的便捷支持，为用户自动创建 PVC；用户可日常创建此 Resource</td></tr>
<tr><td><a href="modules/storage/../../references/api-reference/explorer.html">Explorer</a></td><td>TensorStack</td><td>文件浏览器，查看和管理 PVC 中的文件</td></tr>
</tbody></table>
</div>
<h2 id="参考-5"><a class="header" href="#参考-5">参考</a></h2>
<ul>
<li>API reference <a href="modules/storage/../../references/api-reference/explorer.html">Explorer</a></li>
<li>API reference <a href="modules/storage/../../references/api-reference/storageshim.html">StorageShim</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="pvc持久卷"><a class="header" href="#pvc持久卷">PVC（持久卷）</a></h1>
<p>PVC 是一种 Kubernetes 原生资源，是对存储的需求声明，它抽象了底层存储细节，允许用户请求特定大小和访问模式的存储，而不必关心存储的具体实现。</p>
<h2 id="创建-pvc-1"><a class="header" href="#创建-pvc-1">创建 PVC</a></h2>
<p>下面是一个基本的 PVC 配置示例：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-demo
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
  storageClassName: cephfs-hdd
</code></pre>
<p>在该例中：</p>
<ul>
<li><code>spec.resources.requests.storage</code> 字段定义了所申请的存储空间容量大小为 <code>1Gi</code>。</li>
<li><code>spec.accessModes</code> 字段定义了访问模式为 <code>ReadWriteMany</code>，表示该 PVC 能够同时被多个节点上的 Pod 使用。</li>
<li><code>spec.storageClassName</code> 字段定义了所使用的存储类名称为 <code>cephfs-hdd</code>，集群中可用的存储类由管理员提供。</li>
</ul>
<h2 id="使用-pvc"><a class="header" href="#使用-pvc">使用 PVC</a></h2>
<p>下面是在 Pod 中使用 PVC 的示例：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: pod-demo
spec:
  containers:
  - name: myfrontend
    image: nginx
    volumeMounts:
    - mountPath: &quot;/var/www/html&quot;
      name: data
  volumes:
    - name: data
      persistentVolumeClaim:
        claimName: pvc-demo
</code></pre>
<p>在该例中，<code>pod-demo</code> 将 <code>pvc-demo</code> 作为一个数据卷（volume）来使用，其中容器 <code>myfrontend</code> 将该数据卷挂载到 <code>/var/www/html</code> 目录下。</p>
<p>在 TensorStack AI 平台中，PVC 是通用的持久化存储资源，你在 <a href="modules/storage/../building/notebook.html">Notebook</a>、<a href="modules/storage/../jobs/index.html">Job</a>、<a href="modules/storage/../deployment/index.html">MLService</a>、<a href="modules/storage/../workflows/index.html">Workflow</a> 等 TensorStack 资源中都可以使用 PVC。以 Notebook 为例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: Notebook
metadata:
  name: notebook-demo
spec:
  type: jupyter
  template:
    spec:
      containers:
      - image: t9kpublic/torch-2.0.0-notebook:1.72.0
        name: notebook
        resources:
          limits:
            cpu: &quot;4&quot;
            memory: 4Gi
          requests:
            cpu: &quot;0.5&quot;
            memory: 500Mi
        volumeMounts:
        - name: workingdir
          mountPath: /t9k/mnt
      volumes:
      - name: workingdir
        persistentVolumeClaim:
          claimName: pvc-demo
</code></pre>
<p>在该例中，<code>notebook-demo</code> 将 <code>pvc-demo</code> 作为一个数据卷（volume）来使用，其中容器 <code>notebook</code> 将该数据卷挂载到 <code>/t9k/mnt</code> 目录下。</p>
<h2 id="生命周期"><a class="header" href="#生命周期">生命周期</a></h2>
<p>PVC 有以下几种状态：</p>
<ul>
<li><code>Pending</code>：PVC 正在由对应的存储类处理。</li>
<li><code>Bound</code>：PVC 创建成功，可以被使用。</li>
<li><code>Unknown</code>：无法获取 PVC 状态。</li>
</ul>
<h3 id="pvc-与-pod"><a class="header" href="#pvc-与-pod">PVC 与 Pod</a></h3>
<p>PVC 的生命周期独立于 Pod。一个 PVC 可以被多个 Pod 使用。当 PVC 正在被 Pod 使用时，它无法被删除。</p>
<h3 id="pvc-与-storageshim"><a class="header" href="#pvc-与-storageshim">PVC 与 StorageShim</a></h3>
<p>在 TensorStack AI 平台中，你可以：</p>
<ol>
<li>创建一个独立的 PVC，申请全新的存储空间。</li>
<li>创建一个 <a href="modules/storage/./storageshim.html">StorageShim</a>，将已有存储系统的某个子目录挂载为一个 PVC。此时 StorageShim 控制器将为所创建的 StorageShim 创建一个同名的 PVC，此 PVC 的生命周期由 StorageShim 管理。</li>
</ol>
<h2 id="容量请求"><a class="header" href="#容量请求">容量请求</a></h2>
<p>创建 PVC 时，<code>spec.resources.requests.storage</code> 字段用于指定 PVC 的容量，你无法在 PVC 中存储超过此容量限制的文件。</p>
<aside class="note">
<div class="title">注意</div>
<p>当 PVC 由 StorageShim 管理时，由于具体容量限制由底层存储系统决定，<code>spec.resources.requests.storage</code> 字段可能没有意义。</p>
</aside>
<h2 id="访问模式"><a class="header" href="#访问模式">访问模式</a></h2>
<p>创建 PVC 时，<code>spec.accessModes</code> 字段用于指定 PVC 的访问模式，可选择以下几种访问模式：</p>
<ul>
<li><code>ReadWriteMany</code>：PVC 能被多个节点上的 Pod 读写。</li>
<li><code>ReadWriteOnce</code>：PVC 只能被一个节点上的 Pod 读写。</li>
<li><code>ReadOnlyMany</code>：PVC 只能被多个节点上的 Pod 读。</li>
</ul>
<p>一般选择 <code>ReadWriteMany</code> 即可。</p>
<h2 id="存储类"><a class="header" href="#存储类">存储类</a></h2>
<p>创建 PVC 时，<code>spec.storageClassName</code> 字段用于指定 PVC 的存储类，集群中可用的存储类由管理员提供。</p>
<p>例如，一个集群可能提供两个存储类，名为 <code>cephfs-hdd</code> 和 <code>cephfs-ssd</code>，分别提供基于 HDD 机械硬盘和 SSD 固态硬盘的存储空间，用于不同的数据存储目的。</p>
<h2 id="下一步-24"><a class="header" href="#下一步-24">下一步</a></h2>
<ul>
<li>了解 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">PVC 的概念</a></li>
<li>了解 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/">PVC 的定义</a></li>
<li>如何<a href="modules/storage/../../tasks/pvc-importing-and-exporting-files.html">上传和下载文件</a>到 PVC</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="pvc-快照"><a class="header" href="#pvc-快照">PVC 快照</a></h1>
<p>如果 <a href="modules/storage/./pvc.html">PVC</a> 存放了重要的数据，用户可适时制作快照（snapshot），以方便恢复。</p>
<h2 id="crd-资源-1"><a class="header" href="#crd-资源-1">CRD 资源</a></h2>
<p>存储系统中与快照相关的 CRD 资源，列表如下：</p>
<div class="table-wrapper"><table><thead><tr><th></th><th>来源</th><th>说明</th></tr></thead><tbody>
<tr><td><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims">PVC</a></td><td>Kubernetes</td><td>动态申请集群持久存储；用户可日常创建此 Resource 以申请存储资源</td></tr>
<tr><td><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/storage/volume-snapshots/">Volume Snapshot</a></td><td>Kubernetes</td><td>针对某一个 PVC 进行快照；用户可日常创建此 Resource</td></tr>
<tr><td><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/storage/volume-snapshot-classes/">Volume Snapshot Class</a></td><td>Kubernetes</td><td>指明快照的类别，与 StorageClass 一一对应；管理员创建，用户创建 Volume Snapshot 时引用</td></tr>
</tbody></table>
</div>
<h2 id="创建快照"><a class="header" href="#创建快照">创建快照</a></h2>
<p>下面是一个基本的 PVC 配置示例：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-demo
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
  storageClassName: cephfs-hdd
</code></pre>
<p>为了对该 PVC 进行快照，用户需要创建如下 VolumeSnapshot 资源：</p>
<pre><code class="language-yaml">apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: pvc-demo-snapshot
spec:
  volumeSnapshotClassName: cephfs-hdd-snapshotclass
  source:
    persistentVolumeClaimName: pvc-demo
</code></pre>
<p>其中：</p>
<ul>
<li><code>spec.volumeSnapshotClassName</code> 定义了所使用的快照类为 <code>cephfs-hdd-snapshotclass</code>，每个 StorageClass 都有对应的 VolumeSnapshotClass，由管理员负责创建；VolumeSnapshot 指定的 <code>spec.volumeSnapshotClassName</code> 应当与 PVC 的 <code>spec.storageClassName</code> 对应。</li>
<li><code>spec.source.persistentVolumeClaimName</code> 定义了所要快照的 PVC 名称为 <code>pvc-demo</code>。</li>
</ul>
<p>创建完成后，用户可以对 PVC 中的数据进行继续修改；若需要放弃修改，则可方便地使用快照恢复到修改前的数据。</p>
<h2 id="从快照中恢复"><a class="header" href="#从快照中恢复">从快照中恢复</a></h2>
<p>如果想将 PVC 中的数据恢复至快照创建时刻的状态，用户需要创建一个新的 PVC（之前的 PVC 仍然可以使用，两个 PVC 之间互不影响）：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-demo-restore
spec:
  accessModes:
  - ReadWriteMany
  dataSource:
    name: pvc-demo-snapshot
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  resources:
    requests:
      storage: 1Gi
  storageClassName: cephfs-hdd
</code></pre>
<p>其中：</p>
<ul>
<li><code>spec.accessModes</code> 必须与原 PVC 一致。</li>
<li><code>spec.dataSource</code> 引用了所要恢复的名为 <code>pvc-demo-snapshot</code> 的快照，本 PVC 中的数据将与该快照中的数据完全一致。</li>
<li><code>spec.resources.requests.storage</code> 必须与原 PVC 一致。</li>
<li><code>spec.storageClassName</code> 必须与原 PVC 一致。</li>
</ul>
<h2 id="下一步-25"><a class="header" href="#下一步-25">下一步</a></h2>
<ul>
<li>了解 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/storage/volume-snapshots/">VolumeSnapshot 的概念</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="storageshim"><a class="header" href="#storageshim">StorageShim</a></h1>
<p>StorageShim 用于将已有的存储系统以 PVC 的形式提供给用户使用，例如 S3 bucket 的某个子路径可以作为一个 PVC，分布式文件系统的某个子目录可以作为一个 PVC。通过 StorageShim，用户能够方便地访问已经上传到各类存储系统中的数据，而无需进行复制。目前支持的存储系统包括 <a target="_blank" rel="noopener noreferrer" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html">S3</a> 和 <a target="_blank" rel="noopener noreferrer" href="https://docs.ceph.com/en/quincy/cephfs/">CephFS</a>，未来可能支持更多的存储系统类型。</p>
<h2 id="创建-storageshim"><a class="header" href="#创建-storageshim">创建 StorageShim</a></h2>
<h3 id="s3-类型"><a class="header" href="#s3-类型">S3 类型</a></h3>
<p>下面是一个 S3 类型的 StorageShim 配置示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: StorageShim
metadata:
  name: storageshim-s3-demo
spec:
  type: s3
  s3:
    uri: &quot;s3://bucket/path/subpath&quot;
    readOnly: false
    secretRef:
      name: s3-secret-demo
</code></pre>
<p>其中所引用的 Secret <code>s3-secret-demo</code> 配置如下：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: s3-secret-demo
  labels:
    tensorstack.dev/resource: s3-cfg
stringData:
  .s3cfg: &lt;s3cfg&gt;
</code></pre>
<p>在该例中，StorageShim <code>storageshim-s3-demo</code> 被创建后，StorageShim 控制器将创建一个同名的 PVC <code>storageshim-s3-demo</code>，该 PVC 的根目录对应 S3 路径 <code>s3://bucket/path/subpath</code>，访问该 S3 路径的登录凭证存储在 Secret <code>s3-secret-demo</code> 中，该 Secret 必须为 <a href="modules/storage/./secret.html#secret-%E7%94%A8%E9%80%94">S3-cfg 类型</a>。</p>
<h3 id="cephfs-类型"><a class="header" href="#cephfs-类型">CephFS 类型</a></h3>
<p>下面是一个 CephFS 类型的 StorageShim 配置示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta2
kind: StorageShim
metadata:
  name: storageshim-cephfs-demo
spec:
  type: cephfs
  cephfs:
    path: /cephfs/data/user/mydata
    client:
      secretRef:
        name: ceph-client-key-demo
    server:
      configMapRef:
        name: ceph-cluster-config-demo
</code></pre>
<p>其中所引用的 Secret <code>ceph-client-key-demo</code> 配置示例如下：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: ceph-client-key-demo
  labels:
    tensorstack.dev/resource: ceph-client
stringData:
  userID: &lt;user-id&gt;
  userKey: &lt;user-key&gt;
</code></pre>
<p>其中所引用的 ConfigMap <code>ceph-cluster-config-demo</code> 配置示例如下：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: ceph-cluster-config-demo
  labels:
    tensorstack.dev/resource: ceph-cluster
data:
  driver: &lt;driver-name&gt;
  clusterID: &lt;cluster-id&gt;
  fsName: &lt;fs-name&gt;
</code></pre>
<p>在该例中，StorageShim <code>storageshim-cephfs-demo</code> 被创建后，StorageShim 控制器将创建一个同名的 PVC <code>storageshim-cephfs-demo</code>，该 PVC 的根目录对应 CephFS 文件系统的子目录 <code>/cephfs/data/user/mydata</code>，访问该子目录的登录凭证存储在 Secret <code>ceph-client-key-demo</code> 中，该 Secret 必须为 <a href="modules/storage/./secret.html#secret-%E7%94%A8%E9%80%94">S3-cfg 类型</a>，该 CephFS 文件系统的相关信息存储在 ConfigMap <code>ceph-cluster-config-demo</code> 中。</p>
<h2 id="下一步-26"><a class="header" href="#下一步-26">下一步</a></h2>
<ul>
<li><a href="modules/storage/../../tasks/use-storageshim-s3.html">使用 StorageShim 适配 S3 服务</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="explorer"><a class="header" href="#explorer">Explorer</a></h1>
<p>Explorer 提供几种展示和管理集群中数据的方法。</p>
<h2 id="创建-explorer"><a class="header" href="#创建-explorer">创建 Explorer</a></h2>
<p>下面是一个基本的 Explorer 配置示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: Explorer
metadata:
  name: example
spec:
  storageName: test
  storageType: pvc
</code></pre>
<p>在该例中，Explorer 展示和管理名为 <code>test</code> 的持久卷（Persistent Volume）中的数据。</p>
<h2 id="存储方式"><a class="header" href="#存储方式">存储方式</a></h2>
<p>Explorer 目前仅支持展示存储在 PVC 中的文件（即 <code>spec.storageType</code> 字段暂时只能设置为 <code>pvc</code>）。</p>
<h2 id="展示和管理方式"><a class="header" href="#展示和管理方式">展示和管理方式</a></h2>
<p>Explorer 会自动以多种方式展示和管理文件，目前支持文件浏览器和代码编辑器两种。</p>
<h3 id="文件浏览器"><a class="header" href="#文件浏览器">文件浏览器</a></h3>
<p>使用第三方软件 <a target="_blank" rel="noopener noreferrer" href="https://github.com/filebrowser/filebrowser">File Browser</a> 提供文件管理器形式的界面，支持文件系统浏览、文件上传、文件下载、基本的文件编辑等功能。</p>
<h3 id="代码编辑器"><a class="header" href="#代码编辑器">代码编辑器</a></h3>
<p>使用第三方软件 <a target="_blank" rel="noopener noreferrer" href="https://github.com/cdr/code-server">VS Code</a> 提供云端集成开发环境（IDE）的支持。开发者可以方便地运行网页版 VS Code，进行远程项目开发。</p>
<h2 id="资源回收-3"><a class="header" href="#资源回收-3">资源回收</a></h2>
<p>Explorer 提供空闲资源回收的支持，在检测到 Explorer 处于空闲状态并超过一定时长时，删除工作负载以释放计算资源。默认情况下（管理员可修改配置）：</p>
<ul>
<li>Explorer 无人使用超过 1h 后，标记该 Explorer 为 <code>Idle</code>。</li>
<li>Explorer 进入 <code>Idle</code> 状态超过 24h 后，删除该 Explorer 底层工作负载。</li>
</ul>
<p>如果需要再次使用该 Explorer，你可以在模型构建控制台中手动点击<strong>恢复</strong>按钮。</p>
<h2 id="下一步-27"><a class="header" href="#下一步-27">下一步</a></h2>
<ul>
<li><a href="modules/storage/../../tasks/use-explorer.html">使用 Explorer</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="辅助"><a class="header" href="#辅助">辅助</a></h1>
<p>TensorStack AI 平台提供了一些辅助性资源，它们为其他资源提供支持，或者为用户提供便捷、实用的功能。下表总结了所有辅助性资源：</p>
<div class="table-wrapper"><table><thead><tr><th>资源</th><th>来源</th><th>作用</th></tr></thead><tbody>
<tr><td><a href="modules/auxiliary/./secret.html">Secret</a></td><td>Kubernetes</td><td>存储敏感信息并用于配置</td></tr>
<tr><td><a href="modules/auxiliary/./configmap.html">ConfigMap</a></td><td>Kubernetes</td><td>存储非敏感信息并用于配置</td></tr>
<tr><td><a href="modules/auxiliary/./pod.html">Pod</a></td><td>Kubernetes</td><td>运行容器，测试镜像和应用程序</td></tr>
<tr><td><a href="modules/auxiliary/./imagebuilder.html">ImageBuilder</a></td><td>TensorStack</td><td>构建自定义镜像</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="secret"><a class="header" href="#secret">Secret</a></h1>
<p>Secret 是一种 Kubernetes 原生资源，用于存储少量敏感信息，比如密码、OAuth 令牌、SSH 密钥等。使用 Secret 可以避免将敏感数据直接写入到 Pod 的定义中或者应用程序代码里，从而提高了安全性。</p>
<h2 id="创建-secret"><a class="header" href="#创建-secret">创建 Secret</a></h2>
<p>下面是一个基本的 Secret 配置示例：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: secret-demo
type: Opaque
data:
  key1: dmFsdWUxCg==
  key2: dmFsdWUyCg==
</code></pre>
<p>在该例中，<code>secret-demo</code> 存储了两对键值对，其中值经过了 base64 编码。</p>
<h2 id="使用-secret"><a class="header" href="#使用-secret">使用 Secret</a></h2>
<p>与 <a href="modules/auxiliary/./pvc.html">PVC</a> 类似，Secret 可以以同样的方式作为数据卷被 Pod、Notebook、Job 等资源挂载。以 PyTorchTrainingJob 为例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: PyTorchTrainingJob
metadata:
  name: pytorchtrainingjob-demo
spec:
  replicaSpecs:
    - type: worker
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          containers:
            - image: pytorch/pytorch:2.0.0-cuda11.7-cudnn8-devel
              name: pytorch
              command:
                - python
                - dist_mnist.py
              resources:
                limits:
                  cpu: '1'
                  memory: 1Gi
                requests:
                  cpu: 500m
                  memory: 500Mi
              volumeMounts:
                - name: data
                  mountPath: /data
                - name: secret
                  mountPath: /secret
          volumes:
            - name: data
              persistentVolumeClaim:
                claimName: pvc-demo
            - name: secret
              secret:
                name: secret-demo
</code></pre>
<p>在该例中，<code>pytorchtrainingjob-demo</code> 将 <code>pvc-demo</code> 和 <code>secret-demo</code> 均作为数据卷（volume）来使用，其中容器 <code>pytorch</code> 将两个数据卷分别挂载到 <code>/data</code> 和 <code>/secret</code> 目录下。因此，容器 <code>pytorch</code> 的 <code>/secret</code> 目录下将存在两个文件 <code>/secret/key1</code> 和 <code>/secret/key2</code>，文件内容是经过 base64 解码后的对应的值。</p>
<h2 id="secret-用途"><a class="header" href="#secret-用途">Secret 用途</a></h2>
<p>TensorStack AI 平台通过 label <code>tensorstack.dev/resource</code> 来标识 Secret 的用途，主要有以下几种：</p>
<ul>
<li>API Key：拥有 label <code>tensorstack.dev/resource: apikey</code>，用于存放 API Key，可在安全管理控制台创建 API Key。</li>
<li>S3-cfg：拥有 label <code>tensorstack.dev/resource: s3-cfg</code>，用于存放 S3 配置文件的内容，可从本地的 <code>$HOME/.s3cfg</code> 文件中获取。</li>
<li>S3-env：拥有 label <code>tensorstack.dev/resource: s3-env</code>，用于存放 S3 配置文件的每个字段，请从本地的 <code>$HOME/.s3cfg</code> 文件中获取。</li>
<li>Docker：拥有 label <code>tensorstack.dev/resource: docker</code>，用于存放 Docker 配置文件的内容，可从本地的 <code>$HOME/.docker/config.json</code> 文件中获取。</li>
<li>SSH Public Key：拥有 label <code>tensorstack.dev/resource: ssh</code>，用于存放 SSH 公钥，可从本地的 <code>$HOME/.ssh/id_rsa.pub</code> 文件中获取。</li>
<li>Ceph Client：拥有 label <code>tensorstack.dev/resource: ceph-client</code>，用于存放 Ceph 客户端配置，可从管理员处获取。</li>
<li>Custom：拥有 label <code>tensorstack.dev/resource: other</code>，自定义用途。</li>
</ul>
<p>例如：</p>
<ul>
<li>SSH Public Key 类型的 Secret 可用于 <a href="modules/auxiliary/../building/notebook.html#ssh-%E8%AE%BF%E9%97%AE">Notebook SSH 访问</a></li>
<li>Docker 类型的 Secret 可用于 <a href="modules/auxiliary/./imagebuilder.html">ImageBuilder</a> 构建并上传镜像</li>
<li>S3-cfg 类型的 Secret 可用于创建 <a href="modules/auxiliary/./storageshim.html#s3-%E7%B1%BB%E5%9E%8B">S3 类型的 StorageShim</a></li>
<li>Ceph Client 类型的 Secret 可用于创建 <a href="modules/auxiliary/./storageshim.html#cephfs-%E7%B1%BB%E5%9E%8B">CephFS 类型的 StorageShim</a></li>
</ul>
<h2 id="下一步-28"><a class="header" href="#下一步-28">下一步</a></h2>
<ul>
<li>了解 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/configuration/configmap/">Secret 的概念</a></li>
<li>了解 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/secret-v1/">Secret 的定义</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="configmap"><a class="header" href="#configmap">ConfigMap</a></h1>
<p>ConfigMap 是一种 Kubernetes 原生资源，用于存储非机密性配置信息，它可以用来保存配置文件、命令行参数和环境变量等数据。ConfigMap使得容器化应用程序的配置与镜像内容分离，从而提高了应用的可移植性和灵活性。</p>
<h2 id="创建-configmap"><a class="header" href="#创建-configmap">创建 ConfigMap</a></h2>
<p>下面是一个基本的 ConfigMap 配置示例：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: configmap-demo
data:
  key1: value1
  key2: value2
</code></pre>
<p>在该例中，<code>configmap-demo</code> 明文存储了两对键值对。</p>
<h2 id="使用-configmap"><a class="header" href="#使用-configmap">使用 ConfigMap</a></h2>
<p>与 <a href="modules/auxiliary/./pvc.html">PVC</a> 类似，ConfigMap 可以以同样的方式作为数据卷被 Pod、Notebook、Job 等资源挂载。以 PyTorchTrainingJob 为例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: PyTorchTrainingJob
metadata:
  name: pytorchtrainingjob-demo
spec:
  replicaSpecs:
    - type: worker
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          containers:
            - image: pytorch/pytorch:2.0.0-cuda11.7-cudnn8-devel
              name: pytorch
              command:
                - python
                - dist_mnist.py
              resources:
                limits:
                  cpu: '1'
                  memory: 1Gi
                requests:
                  cpu: 500m
                  memory: 500Mi
              volumeMounts:
                - name: data
                  mountPath: /data
                - name: configuration
                  mountPath: /config
          volumes:
            - name: data
              persistentVolumeClaim:
                claimName: pvc-demo
            - name: configuration
              configMap:
                name: configmap-demo
</code></pre>
<p>在该例中，<code>pytorchtrainingjob-demo</code> 将 <code>pvc-demo</code> 和 <code>configmap-demo</code> 均作为数据卷（volume）来使用，其中容器 <code>pytorch</code> 将两个数据卷分别挂载到 <code>/data</code> 和 <code>/config</code> 目录下。因此，容器 <code>pytorch</code> 的 <code>/config</code> 目录下将存在两个文件 <code>/config/key1</code> 和 <code>/config/key2</code>，文件内容分别是 <code>value1</code> 和 <code>value2</code>。</p>
<h2 id="下一步-29"><a class="header" href="#下一步-29">下一步</a></h2>
<ul>
<li>了解 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/configuration/configmap/">ConfigMap 的概念</a></li>
<li>了解 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/config-map-v1/">ConfigMap 的定义</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="pod"><a class="header" href="#pod">Pod</a></h1>
<p>Pod 是可以在 Kubernetes 中创建和管理的、最小的可部署的计算单元。</p>
<p>Pod 是一组（一个或多个）容器；这些容器共享存储、网络、以及怎样运行这些容器的声明。Pod 中的内容总是并置的并且一同调度，在共享的上下文中运行。Pod 模拟一个特定应用的“逻辑主机”，其中包含一个或多个应用容器，这些容器相对紧密地耦合在一起。在非云环境中，在相同的物理机或虚拟机上运行的应用类似于在同一逻辑主机上运行的云应用。</p>
<p>除了应用容器，Pod 还可以包含在 Pod 启动期间运行的 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/">Init 容器</a>。你也可以在集群支持临时性容器的情况下，为调试的目的注入<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/workloads/pods/ephemeral-containers/">临时性容器</a>。</p>
<p>通常你不需要直接创建 Pod，甚至单实例 Pod。你会使用诸如 Deployment 或 Job 这类工作负载资源来创建 Pod。如果 Pod 需要跟踪状态，可以考虑 StatefulSet 资源。</p>
<p>Kubernetes 集群中的 Pod 主要有两种用法：</p>
<ul>
<li>运行单个容器的 Pod：最常见的 Kubernetes 用例； 在这种情况下，可以将 Pod 看作单个容器的包装器，并且 Kubernetes 直接管理 Pod，而不是容器。</li>
<li>运行多个协同工作的容器的 Pod：Pod 可能封装由多个紧密耦合且需要共享资源的共处容器组成的应用程序。这些位于同一位置的容器可能形成单个内聚的服务单元 —— 一个容器将文件从共享卷提供给公众，而另一个单独的 sidecar 容器则刷新或更新这些文件。Pod 将这些容器和存储资源打包为一个可管理的实体。</li>
</ul>
<p>每个 Pod 都旨在运行给定应用程序的单个实例。如果希望横向扩展应用程序（例如，运行多个实例以提供更多的资源），则应该每个实例使用一个 Pod。在 Kubernetes 中，这通常被称为副本。通常使用一种工作负载资源及其控制器来创建和管理一组 Pod 副本。</p>
<h2 id="pod-示例"><a class="header" href="#pod-示例">Pod 示例</a></h2>
<p>以下是一个 Pod 的 YAML 示例：</p>
<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: test-sdk
spec:
  containers:
    - name: sdk
      image: t9kpublic/t9k-sdk:0.6.0-torch-2.0.1
      command:
        - sleep
        - inf
      resources:
        limits:
          cpu: 500m
          memory: 200Mi
</code></pre>
<p>在上述示例中：</p>
<ul>
<li>Pod 使用 <code>t9kpublic/t9k-sdk:0.6.0-torch-2.0.1</code>（由 <code>spec.containers[0].image</code> 字段指定）镜像启动容器 <code>sdk</code>（由 <code>spec.containers[0].name</code> 字段指定）。</li>
<li>容器中执行 <code>sleep inf</code>（由 <code>spec.containers[0].command</code> 字段指定）命令。</li>
<li><code>sdk</code> 容器最多可使用 <code>0.5</code> 个 CPU 和 <code>200Mi</code> 内存（由 <code>spec.containers[0].resources.limits</code> 字段指定）。</li>
</ul>
<h2 id="应用场景"><a class="header" href="#应用场景">应用场景</a></h2>
<p>在 TensorStack AI 平台，你可以使用 Pod 实现以下操作：</p>
<ul>
<li>测试镜像：在你使用 ImageBuilder 构建镜像后，可通过创建 Pod 并进入 Pod 终端来验证镜像是否符合预期。</li>
<li>存储卷预处理：在训练前，需提前下载好数据，此时可以通过创建 Pod 绑定对应 PVC，在 Pod 终端向其中下载数据。</li>
<li>测试代码：你在 Notebook 中开发后的脚本在训练镜像中并不一定能正常运行，可以用训练镜像创建一个 Pod，来测试训练脚本在新镜像中是否可用。</li>
</ul>
<h2 id="下一步-30"><a class="header" href="#下一步-30">下一步</a></h2>
<ul>
<li>了解 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/workloads/pods/">Pod 的概念</a>。</li>
<li>了解 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/">Pod 的定义</a>。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="imagebuilder"><a class="header" href="#imagebuilder">ImageBuilder</a></h1>
<p>TensorStack 平台提供 CRD <code>ImageBuilder</code>，方便用户在集群中构建容器镜像。</p>
<h2 id="创建-imagebuilder"><a class="header" href="#创建-imagebuilder">创建 ImageBuilder</a></h2>
<p>下面是一个基本的 <code>ImageBuilder</code> 定义示例：</p>
<pre><code class="language-yaml"># image-builder-example.yaml
apiVersion: tensorstack.dev/v1beta1
kind: ImageBuilder
metadata:
  name: imagebuilder-example
spec:
  dockerConfig:
    secret: docker-config
  tag: t9kpublic/kaniko-executor:v1.19.2
  workspace:
    pvc:
      name: kaniko
      dockerfilePath: ./Dockerfile
      contextPath: &quot;.&quot;
  builder:
    kaniko: {}
</code></pre>
<p>在该例中：</p>
<ul>
<li><code>spec.dockerConfig.secret</code> 字段指定使用 Secret <code>docker-config</code> 中记录的 docker 配置，以上传镜像。</li>
<li><code>spec.tag</code> 字段指定目标镜像的名称和标签为 <code>t9kpublic/kaniko-executor:v1.19.2</code>。</li>
<li><code>spec.workspace</code> 字段指定构建镜像使用 PVC <code>kaniko</code>  作为工作空间，其中：
<ul>
<li>在 PVC 相对路径 <code>./Dockerfile</code> 中存放构建镜像所需的 Dockerfile。</li>
<li>在 PVC 相对路径 <code>.</code> 中存放构建镜像所需要的上下文。</li>
</ul>
</li>
<li><code>spec.builder</code> 字段指定使用 <code>kaniko</code> 来构建镜像。</li>
</ul>
<h2 id="构建工具"><a class="header" href="#构建工具">构建工具</a></h2>
<p>目前 ImageBuilder 支持使用 <a target="_blank" rel="noopener noreferrer" href="https://github.com/GoogleContainerTools/kaniko">kaniko</a> 工具来构建镜像。</p>
<h3 id="kaniko"><a class="header" href="#kaniko">kaniko</a></h3>
<p>用户可以通过 <code>spec.builder.kaniko</code> 字段来设置 kaniko 的参数。</p>
<p>在下面示例中，ImageBuilder 使用 <code>t9kpublic/kaniko-executor:v1.19.2</code> 启动 kaniko，并在该容器中构建用户镜像；ImageBuilder 不额外设置 kaniko 参数。</p>
<pre><code>spec:
  builder:
    kaniko:
      image: t9kpublic/kaniko-executor:v1.19.2
      args: []
</code></pre>
<p><code>spec.builder.kaniko</code> 的参数介绍：</p>
<ul>
<li><code>image</code>：如忽略，ImageBuilder 控制器会指定一个默认镜像，所以一般来说可以不设置该字段。</li>
<li><code>args</code>：如忽略，ImageBuilder 构建镜像时执行 <code>kaniko --destination=[image-tag] --context=[context-path] --dockerfile=[dockerfile-path]</code> 命令。如果用户需要使用其他参数，可以在该字段中指定。参考 <a target="_blank" rel="noopener noreferrer" href="https://github.com/GoogleContainerTools/kaniko?tab=readme-ov-file#additional-flags">kaniko additional flags</a>。</li>
</ul>
<h2 id="参考-6"><a class="header" href="#参考-6">参考</a></h2>
<p>更加详细的 ImageBuilder API 可直接在集群中查询：</p>
<pre><code class="language-bash">kubectl explain imagebuilder
</code></pre>
<h2 id="下一步-31"><a class="header" href="#下一步-31">下一步</a></h2>
<ul>
<li>使用控制台：<a href="modules/auxiliary/../../tasks/build-image.html">构建镜像</a></li>
<li>Github 上的 <a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/build-image/build-image-on-platform">ImagerBuilder 示例</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/GoogleContainerTools/kaniko">kaniko 的详细参考</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="工作流"><a class="header" href="#工作流">工作流</a></h1>
<p>AI 应用由很多基础计算步骤构成，具有很大灵活性，在不同场景需要做各种定制计算处理。例如，一个模型训练过程可能包含数据取样、数据转换、模型训练、模型质检、模型导出等步骤。</p>
<p>为此 TensorStack AI 平台提供了一个灵活的工作流服务，将这些计算步骤组合在一起，集中进行管理和调度，自动化复杂的流程。</p>
<h2 id="架构-2"><a class="header" href="#架构-2">架构</a></h2>
<p>工作流模块提供了 <a href="modules/workflows/./workflowtemplate.html">WorkflowTemplate</a>、<a href="modules/workflows/./workflowrun.html">WorkflowRun</a>、<a href="modules/workflows/./cronworkflowrun.html">CronWorkflowRun</a> 等自定义扩展资源，以及控制台、服务器、操作器等组件。整体架构如下图所示：</p>
<figure> 
<img alt="architecture" src="modules/workflows/../../assets/modules/workflow/architecture.drawio.svg"/>
</figure>
<p>其中：</p>
<ul>
<li>控制台（Console）提供前端界面，方便用户对 WorkflowTemplate、WorkflowRun 等资源进行创建、查看、删除等操作。
<ul>
<li>用户也可以直接使用命令行工具 <code>kubectl</code> 创建 workflow 的资源。</li>
</ul>
</li>
<li>服务器（Server）向工作流控制台提供 API 接口，帮助获取 WorkflowTemplate、WorkflowRun 等资源的详细信息。</li>
<li>控制器（Controller），负责监控集群中的 WorkflowTemplate、WorkflowRun 等资源，并执行一些与资源相关的操作，使资源当前的状态与其理想状态一致。</li>
</ul>
<h2 id="与其他模块的关系"><a class="header" href="#与其他模块的关系">与其他模块的关系</a></h2>
<p>如下图所示，Workflow 可以将分布式并行作业、非并行作业组合在一起成为复合作业，而且复合作业中可以嵌套复合作业，并通过 T9k 调度器进行计算资源的匹配，最终完成复杂的多步骤计算。</p>
<figure> 
<img alt="workflow-and-jobs" src="modules/workflows/../../assets/modules/workflow/workflow-and-jobs.drawio.svg"/>
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="workflowtemplate"><a class="header" href="#workflowtemplate">WorkflowTemplate</a></h1>
<p>WorkflowTemplate 用于在 Kubernetes 中有序、高效、方便地组织运行各类工作负载，例如机器学习流水线中的数据处理、模型训练、推理测试等具有依赖关系的多个步骤。WorkflowTemplate 是一个静态模板，指定了任务的详细规范，最终由 <a href="modules/workflows/./workflowrun.html">WorkflowRun</a> 实例化并真正开始运行。</p>
<h2 id="创建-workflowtemplate"><a class="header" href="#创建-workflowtemplate">创建 WorkflowTemplate</a></h2>
<p>下面的 WorkflowTemplate 示例创建并运行一个 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/zh/docs/concepts/workloads/pods/">Kubernetes Pod</a>。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: workflowtemplate-sample
spec:
  description: This WorkflowTemplate creates and runs a Pod.
  type: Pod
  pod:
    containers:
      - name: hello
        image: ubuntu:latest
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        command: [&quot;echo&quot;]
        args: [&quot;Hello TensorStack!&quot;]
</code></pre>
<p>在该例中：</p>
<ul>
<li><code>description</code> 字段简要介绍了该 WorkflowTemplate 的用途，会在控制台中展示。</li>
<li>WorkflowTemplate 的类型（由 <code>type</code> 字段指定）是 Pod，表示 WorkflowTemplate 会创建并运行一个 Pod。</li>
<li><code>pod</code> 字段定义所要创建的 Pod 的规约，指示 Pod 运行一个 <code>hello</code> 容器，该容器运行镜像 <code>ubuntu:latest</code> 并打印一个字符串 <code>Hello TensorStack!</code>。</li>
</ul>
<h2 id="workflowtemplate-类型"><a class="header" href="#workflowtemplate-类型">WorkflowTemplate 类型</a></h2>
<p>WorkflowTemplate 的 <code>spec.type</code> 字段用于指定 WorkflowTemplate 的类型，可能的取值有：</p>
<ul>
<li><a href="modules/workflows/workflowtemplate.html#pod-workflowtemplate"><code>Pod</code></a></li>
<li><a href="modules/workflows/workflowtemplate.html#seqpod-workflowtemplate"><code>SeqPod</code></a></li>
<li><a href="modules/workflows/workflowtemplate.html#resource-workflowtemplate"><code>Resource</code></a></li>
<li><a href="modules/workflows/workflowtemplate.html#dag-workflowtemplate"><code>DAG</code></a></li>
<li><a href="modules/workflows/workflowtemplate.html#t9k-jobs-workflowtemplate"><code>GenericJob</code></a></li>
<li><a href="modules/workflows/workflowtemplate.html#t9k-jobs-workflowtemplate"><code>TensorFlowTrainingJob</code></a></li>
<li><a href="modules/workflows/workflowtemplate.html#t9k-jobs-workflowtemplate"><code>PyTorchTrainingJob</code></a></li>
<li><a href="modules/workflows/workflowtemplate.html#t9k-jobs-workflowtemplate"><code>XGBoostTrainingJob</code></a></li>
<li><a href="modules/workflows/workflowtemplate.html#t9k-jobs-workflowtemplate"><code>ColossalAIJob</code></a></li>
<li><a href="modules/workflows/workflowtemplate.html#t9k-jobs-workflowtemplate"><code>DeepSpeedJob</code></a></li>
<li><a href="modules/workflows/workflowtemplate.html#t9k-jobs-workflowtemplate"><code>MPIJob</code></a></li>
<li><a href="modules/workflows/workflowtemplate.html#t9k-jobs-workflowtemplate"><code>BeamJob</code></a></li>
</ul>
<h3 id="pod-workflowtemplate"><a class="header" href="#pod-workflowtemplate">Pod WorkflowTemplate</a></h3>
<p>Pod WorkflowTemplate 用于创建一个原生的 Kubernetes Pod。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: pod-workflowtemplate-sample
spec:
  type: Pod
  pod:
    containers:
      - name: hello
        image: ubuntu
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        command: [&quot;sh&quot;, &quot;-c&quot;]
        args: [&quot;echo Hello World!&quot;]
</code></pre>
<p><code>spec.pod</code> 中可以填写的字段与 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podspec-v1-core">Kubernetes Pod</a> 相同。</p>
<h3 id="seqpod-workflowtemplate"><a class="header" href="#seqpod-workflowtemplate">SeqPod WorkflowTemplate</a></h3>
<p>SeqPod WorkflowTemplate 用于创建一个经过包装的 Pod，在 Pod 中按顺序执行一些步骤。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: seqpod-workflowtemplate-sample
spec:
  type: SeqPod
  seqPod:
    steps:
      - name: hello
        image: ubuntu
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        command: [&quot;sh&quot;, &quot;-c&quot;]
        args: [&quot;echo Hello World!&quot;]
      - name: working
        image: ubuntu
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        command: [&quot;sh&quot;, &quot;-c&quot;]
        args: [&quot;echo I am working!&quot;]
      - name: bye
        image: ubuntu
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        command: [&quot;sh&quot;, &quot;-c&quot;]
        args: [&quot;echo Goodbye!&quot;]
</code></pre>
<p>SeqPod 中的每个步骤（step）对应 Kubernetes Pod 中的一个容器，但 SeqPod 会按照顺序依次执行每个步骤，直到所有的步骤成功运行完毕，或者其中某个步骤失败（后续的步骤不会再运行）。</p>
<p>在 <code>pod.containers[*].command</code>、<code>pod.containers[*].args</code>、<code>seqPod.steps[*].command</code>、<code>seqPod.steps[*].args</code> 等字段中，你有时候可能需要填写带有引号的字符串，有以下几种合法的方式：</p>
<pre><code class="language-yaml">command: [&quot;echo&quot;]
args: [&quot;this is a 'quote'&quot;]
</code></pre>
<pre><code class="language-yaml">command: ['echo']
args: ['this is a &quot;quote&quot;']
</code></pre>
<pre><code class="language-yaml">command:
  - echo
args:
  - this is a &quot;quote&quot;
</code></pre>
<pre><code class="language-yaml">command:
  - echo
args:
  - this is a 'quote'
</code></pre>
<h4 id="指定-script"><a class="header" href="#指定-script">指定 script</a></h4>
<p>SeqPod 的每个步骤可以指定 <code>script</code> 字段，即一段脚本语言（例如 Bash、Python）编写的代码，用于代替 <code>command</code> 字段。<code>script</code> 脚本会在容器开始运行时代替 <code>command</code> 被调用，而 <code>args</code> 会被当做参数传递给 <code>script</code> 脚本。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: seqpod-workflowtemplate-sample-script
spec:
  type: SeqPod
  seqPod:
    steps:
      - name: hello
        image: python
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        script: |
          #!/usr/bin/env python3
          print(&quot;Hello from Python!&quot;)
</code></pre>
<p>如果 <code>script</code> 脚本的开头不包含以 <code>#!</code> 开头的字符串（<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Shebang_(Unix)">shebang</a>），以下字符串会被自动添加到 <code>script</code> 脚本的开头：</p>
<pre><code class="language-bash">#!/bin/bash
set -e # Immediately exit if any command exited with non-zero status. 
</code></pre>
<h4 id="保留目录"><a class="header" href="#保留目录">保留目录</a></h4>
<p>为了 SeqPod WorkflowTemplate 的正常工作，最终生成的 Pod 有一些特殊的保留目录：</p>
<ul>
<li><code>/t9k/workspaces</code>：用于挂载 <a href="modules/workflows/workflowtemplate.html#%E6%8C%87%E5%AE%9A%E5%B7%A5%E4%BD%9C%E7%A9%BA%E9%97%B4">workspaces</a>，你可以通过 <code>$(workspaces.&lt;workspaceName&gt;.path)</code> 来使用该路径。</li>
<li><code>/t9k/results</code>：用于存储 <a href="modules/workflows/workflowtemplate.html#%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C">results</a>，你可以通过 <code>$(results.&lt;resultName&gt;.path)</code> 来使用该路径。</li>
<li><code>/t9k/tools</code>：用于保证 SeqPod 中 <code>steps</code> 顺序执行的辅助工具，与用户无关。</li>
<li><code>/t9k/termination</code>：用于写入 Pod 的 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/tasks/debug-application-cluster/determine-reason-pod-failure/#writing-and-reading-a-termination-message">termination message</a>，与用户无关。</li>
</ul>
<h3 id="resource-workflowtemplate"><a class="header" href="#resource-workflowtemplate">Resource WorkflowTemplate</a></h3>
<p>Resource WorkflowTemplate 用于创建另一个 Kubernetes 资源，并监测该资源的运行状态。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: resource-workflowtemplate-sample
spec:
  type: Resource
  resource:
    manifest: |
      apiVersion: batch/v1
      kind: Job
      metadata:
        generateName: pi-job-
      spec:
        template:
          metadata:
            name: pi
          spec:
            containers:
            - name: pi
              image: perl
              command: [&quot;perl&quot;,  &quot;-Mbignum=bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;]
            restartPolicy: Never
        backoffLimit: 4
    successRules:
      fieldSelector: status.succeeded &gt; 0
    failureRules:
      fieldSelector: status.failed &gt; 3
</code></pre>
<p><code>spec.resource</code> 的各个字段含义如下：</p>
<ul>
<li><code>manifest</code>：所要创建的 Kubernetes 资源的详细配置。</li>
<li><code>successRules</code>：如果所创建的资源满足该条件，本 WorkflowTemplate 视为成功。</li>
<li><code>failureRules</code>：如果所创建的资源满足该条件，本 WorkflowTemplate 视为失败。</li>
</ul>
<p><code>fieldSelector</code> 的写法与 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/">Kubernetes 标签选择器</a>的语法相同但更强大，除了标签之外还能应用到资源的任意字段，支持的运算符有 <code>&gt;</code>、<code>&lt;</code>、<code>==</code>、<code>!=</code>、<code>in</code>、<code>notin</code> 等，多个需要同时满足的条件可以用逗号连接。例如，以下都是合法的 <code>fieldSelector</code>：</p>
<ul>
<li><code>status.succeeded&gt;0</code></li>
<li><code>status.succeeded &gt; 0</code></li>
<li><code>status.succeeded &gt; 0,status.failed == 0</code></li>
<li><code>status.phase in (Succeeded, Failed),status.workflowTemplateSpec.type == DAG</code></li>
</ul>
<p>另外，<code>successRules</code> 和 <code>failureRules</code> 还支持设置 <code>conditionSelector</code>。如果所创建的资源的 <code>status.conditions</code> 字段包含一个 <code>condition</code>，其 <code>type</code> 和 <code>status</code> 都与 <code>conditionSelector</code> 相同，就认为该资源满足条件。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: resource-workflowtemplate-sample-condition
spec:
  type: Resource
  resource:
    manifest: |
      apiVersion: batch.tensorstack.dev
      kind: TensorFlowTrainingJob
      metadata:
        generateName: t9k-training-job-
      spec:
        ...
    successRules:
      conditionSelector:
        type: Succeeded
        status: &quot;True&quot;
    failureRules:
      conditionSelector:
        type: Failed
        status: &quot;True&quot;
</code></pre>
<p>如果所创建的资源类型是下列 <a href="modules/workflows/../jobs/index.html">T9k Jobs</a> 之一，系统将自动帮助填写 <code>successRules</code> 和 <code>failureRules</code>，以减轻你的负担：</p>
<ul>
<li>GenericJob</li>
<li>MPIJob</li>
<li>BeamJob</li>
<li>TensorFlowTrainingJob</li>
<li>PyTorchTrainingJob</li>
<li>XGBoostTrainingJob</li>
</ul>
<p>创建 Resource WorkflowTemplate 对应的 WorkflowRun 时需要提供一个 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/kubernetes-api/authentication-resources/service-account-v1/">Service Account</a>，使得 WorkflowRun 具有在 Kubernetes 中创建该 Resource 的权限。例如：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowRun
metadata:
  name: resource-workflowtemplate-sample-run
spec:
  workflowTemplateRef: resource-workflowtemplate-sample
  serviceAccountName: managed-project-sa
</code></pre>
<p>在网页中创建 WorkflowRun 时，系统将自动为你配置名为 <code>managed-project-sa</code> 的 Service Account，你不用关心这一项的填写。</p>
<h3 id="t9k-jobs-workflowtemplate"><a class="header" href="#t9k-jobs-workflowtemplate">T9k Jobs WorkflowTemplate</a></h3>
<p>T9k Workflow 系统对 <a href="modules/workflows/../jobs/index.html">T9k Jobs</a> 提供更进一步的原生支持，添加以下 WorkflowTemplate 类型：</p>
<ul>
<li>GenericJob</li>
<li>TensorFlowTrainingJob</li>
<li>PyTorchTrainingJob</li>
<li>XGBoostTrainingJob</li>
<li>ColossalAIJob</li>
<li>DeepSpeedJob</li>
<li>MPIJob</li>
<li>BeamJob</li>
</ul>
<p>并在 WorkflowTemplate 的 <code>spec</code> 中添加了相应字段用于填写 T9k Job 的 <code>spec</code>：</p>
<ul>
<li><code>spec.genericJob</code></li>
<li><code>spec.tensorflowTrainingJob</code></li>
<li><code>spec.pytorchTrainingJob</code></li>
<li><code>spec.xgboostTrainingJob</code></li>
<li><code>spec.colossalaiJob</code></li>
<li><code>spec.deepspeedJob</code></li>
<li><code>spec.mpiJob</code></li>
<li><code>spec.beamJob</code></li>
</ul>
<p>相比于在 Resource 类型中将资源的 <code>spec</code> 视作一个很长的字符串，添加原生类型支持的好处是在创建 WorkflowTemplate 时 T9k Job 的 <code>spec</code> 就会得到语法检查，能更早地发现错误，加深了 T9k Workflow 系统和 T9k Job 系统的集成配合。</p>
<p>例如，创建一个 MPIJob 可以使用如下格式（其中 MPIJob 示例来自 <a href="modules/workflows/../jobs/mpijob.html#%E5%88%9B%E5%BB%BA-mpijob">MPIJob 文档</a>）：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: mpijob-workflowtemplate-sample
spec:
  type: MPIJob
  mpiJob:
    spec:
      worker:
        replicas: 5
        processesPerWorker: 3
        processRecovery:
          enable: true
          limit: 100
        cmd:
          - ./random_walk
          - &quot;20&quot;
          - &quot;40&quot;
          - &quot;2&quot;
        template:
          spec:
            containers:
              - name: mpi-worker
                image: t9kpublic/mpi-tutorial:2021022-2
                resources:
                  limits:
                    cpu: 100m
                  requests:
                    cpu: 50m
                workingDir: /usr/local/code
      mca:
        btl: ^openib
      runPolicy:
        cleanUpWorkers: true
      ssh:
        sshdPath: /usr/sbin/sshd
      mpiHome: /usr/local
</code></pre>
<aside class="note">
<div class="title">注意</div>
<p>与 Resource WorkflowTemplate 相同，T9k Jobs WorkflowTemplate 对应的 WorkflowRun 也需要一个 Service Account。同样，在网页中创建 WorkflowRun 时，系统将自动为你配置名为 <code>managed-project-sa</code> 的 Service Account，你不用关心这一项的填写。</p>
</aside>
<h3 id="dag-workflowtemplate"><a class="header" href="#dag-workflowtemplate">DAG WorkflowTemplate</a></h3>
<p>DAG WorkflowTemplate 用于创建一个由其他 WorkflowTemplate 组成的有向无环图（DAG，Directed Acyclic Graph），按照有向无环图中的依赖关系按顺序执行这些 WorkflowTemplate。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: dag-workflowtemplate-sample
spec:
  type: DAG
  dag:
    templates:
      - name: a
        workflowTemplateRef: pod-workflowtemplate-sample
        dependencies: []
      - name: b1
        workflowTemplateRef: pod-workflowtemplate-sample
        dependencies: [&quot;a&quot;]
      - name: b2
        workflowTemplateRef: pod-workflowtemplate-sample
        dependencies: [&quot;a&quot;]
      - name: c
        workflowTemplateRef: pod-workflowtemplate-sample
        dependencies: [&quot;b1&quot;, &quot;b2&quot;]
</code></pre>
<p>在上面的示例中，首先运行 WorkflowTemplate a，等待 WorkflowTemplate a 运行完毕之后再同时运行 WorkflowTemplate b1 和 b2。WorkflowTemplate c 会在 b1 和 b2 都结束后运行。这些 WorkflowTemplates 组成一个从上往下顺序执行的有向无环图：</p>
<pre><code class="language-yaml">   a
 /   \
b1   b2
 \   /
   c
</code></pre>
<h2 id="指定参数"><a class="header" href="#指定参数">指定参数</a></h2>
<p>你可以为 WorkflowTemplate 指定一些参数，并在 <code>spec</code> 中用 <code>$(params.&lt;paramName&gt;)</code> 来引用参数。<a href="modules/workflows/./workflowrun.html">WorkflowRun</a> 会在运行时为这些参数提供实际值。支持 <code>params</code> 的 WorkflowTemplate 类型有 Pod、SeqPod、DAG，详见<a href="modules/workflows/../../../reference/tensorstack-resources/workflow-api/variable-substitution-rules.html#%E6%94%AF%E6%8C%81%E5%8F%98%E9%87%8F%E6%9B%BF%E6%8D%A2%E7%9A%84-workflowtemplate-%E5%AD%97%E6%AE%B5">支持变量替换的 WorkflowTemplate 字段</a>。</p>
<p>Pod WorkflowTemplate 示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: pod-workflowtemplate-sample-params
spec:
  params:
    - name: message
      default: &quot;hi&quot;
  type: Pod
  pod:
    containers:
      - name: hello
        image: ubuntu
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        command: [&quot;sh&quot;, &quot;-c&quot;]
        args: [&quot;echo $(params.message)&quot;]
</code></pre>
<p>SeqPod WorkflowTemplate 示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: seqpod-workflowtemplate-sample-params
spec:
  params:
    - name: message
      default: hi
  type: SeqPod
  seqPod:
    steps:
      - name: hello
        image: ubuntu
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        script: |
          #!/bin/sh
          echo $(params.message)
</code></pre>
<p>DAG WorkflowTemplate 在引用其他的 WorkflowTemplate 作为节点时，必须提供该节点需要的 <code>params</code>，可以是静态的字符串，也可以引用 DAG WorkflowTemplate 自身的 <code>params</code> 变量或<a href="modules/workflows/../../../reference/tensorstack-resources/workflow-api/variable-substitution-rules.html">其他变量</a>。示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: dag-workflowtemplate-sample-params
spec:
  params:
    - name: dag-param
  type: DAG
  dag:
    templates:
      - name: step0
        workflowTemplateRef: pod-workflowtemplate-sample-params
        dependencies: []
        params:
          - name: message
            value: Hello World!
      - name: step1
        workflowTemplateRef: seqpod-workflowtemplate-sample-params
        dependencies: [&quot;step0&quot;]
        params:
          - name: message
            value: &quot;$(params.dag-param)&quot;
      - name: step2
        workflowTemplateRef: seqpod-workflowtemplate-sample-params
        dependencies: [&quot;step1&quot;]
        params:
          - name: message
            value: &quot;DAG WorkflowTemplate provides param $(params.dag-param) for you&quot;
</code></pre>
<h2 id="指定工作空间"><a class="header" href="#指定工作空间">指定工作空间</a></h2>
<p>你可以为 WorkflowTemplate 指定可用的存储空间，并在 <code>spec</code> 中用 <code>$(workspaces.&lt;workspaceName&gt;.path)</code> 来引用存储空间的路径。<a href="modules/workflows/./workflowrun.html">WorkflowRun</a> 会在运行时指定具体挂载何种存储空间，例如 PVC、Secret、ConfigMap 等。支持 <code>workspaces</code> 的 WorkflowTemplate 类型有 Pod、SeqPod、DAG。</p>
<p>Pod WorkflowTemplate 示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: pod-workflowtemplate-sample-workspace
spec:
  workspaces:
    - name: pod-workspace
  type: Pod
  pod:
    containers:
      - name: hello
        image: ubuntu
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        command: [&quot;sh&quot;, &quot;-c&quot;]
        args: [&quot;echo Hello World! &gt; $(workspaces.pod-workspace.path)/output.txt&quot;]
</code></pre>
<p>SeqPod WorkflowTemplate 示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: seqpod-workflowtemplate-sample-workspaces
spec:
  workspaces:
    - name: seqpod-workspace
  type: SeqPod
  seqPod:
    steps:
      - name: hello
        image: ubuntu
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        script: |
          #!/bin/sh
          echo Hello World! &gt; $(workspaces.seqpod-workspace.path)/output.txt
</code></pre>
<p>DAG WorkflowTemplate 在引用其他的 WorkflowTemplate 作为节点时，必须提供该节点需要的 <code>workspaces</code>，一般通过 DAG WorkflowTemplate 自身的 <code>workspaces</code> 继承而来。示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: dag-workflowtemplate-sample-workspaces
spec:
  workspaces:
    - name: dag-workspace
  type: DAG
  dag:
    templates:
      - name: step0
        workflowTemplateRef: pod-workflowtemplate-sample-workspace
        dependencies: []
        workspaces:
          - name: pod-workspace
            workspace: dag-workspace
      - name: step1
        workflowTemplateRef: seqpod-workflowtemplate-sample-workspace
        dependencies: [&quot;step0&quot;]
        workspaces:
          - name: seqpod-workspace
            workspace: dag-workspace
      - name: step2
        workflowTemplateRef: seqpod-workflowtemplate-sample-workspace
        dependencies: [&quot;step1&quot;]
        workspaces:
          - name: seqpod-workspace
            workspace: dag-workspace
</code></pre>
<h2 id="输出结果"><a class="header" href="#输出结果">输出结果</a></h2>
<p>WorkflowTemplate 可以在运行过程中输出一些字符串，并最终展示在 WorkflowRun 的 <code>status</code> 中。支持 <code>results</code> 的 WorkflowTemplate 类型有 SeqPod、DAG。</p>
<p>每个 <code>result</code> 本质上是一个文件，如下例所示，你可以向 <code>$(results.&lt;resultName&gt;.path)</code> 这个路径写入想要输出的内容。注意写入内容的总和不能超过 4096 字节。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: seqpod-workflowtemplate-sample-result
spec:
  results:
    - name: my-status
      description: &quot;My status&quot;
  type: SeqPod
  seqPod:
    steps:
      - name: echo
        image: ubuntu
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        script: |
          echo I am OK &gt; $(results.my-status.path)
</code></pre>
<p><code>results</code> 更重要的用途是在 DAG WorkflowTemplate 的节点之间传递信息。DAG 的各个节点可以通过 <code>$(templates.&lt;workflowtemplateName&gt;.results.&lt;resultName&gt;)</code> 来引用这些 <code>results</code>，一般有两种用途：</p>
<ul>
<li>DAG 的下层节点可以在 <a href="modules/workflows/workflowtemplate.html#%E6%8C%87%E5%AE%9A%E5%8F%82%E6%95%B0"><code>params</code></a> 或 <a href="modules/workflows/workflowtemplate.html#%E6%9D%A1%E4%BB%B6%E5%88%86%E6%94%AF"><code>when</code></a> 字段引用上层节点的 <code>results</code>。</li>
<li>DAG WorkflowTemplate 可以组合节点的 <code>results</code> 来输出自身的 <code>results</code>。</li>
</ul>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: add-workflowtemplate
spec:
  params:
    - name: first
      description: the first operand
    - name: second
      description: the second operand
  results:
    - name: sum
      description: the sum of the first and second operand
  type: SeqPod
  seqPod:
    steps:
      - name: add
        image: ubuntu
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        env:
          - name: OP1
            value: $(params.first)
          - name: OP2
            value: $(params.second)
        command: [&quot;/bin/sh&quot;, &quot;-c&quot;]
        args:
          - echo -n $((${OP1}+${OP2})) | tee $(results.sum.path);
---
apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: sum-three-workflowtemplate
spec:
  params:
    - name: first
      description: the first operand
    - name: second
      description: the second operand
    - name: third
      description: the third operand
  type: DAG
  dag:
    templates:
      - name: first-add
        workflowTemplateRef: add-workflowtemplate
        params:
          - name: first
            value: $(params.first)
          - name: second
            value: $(params.second)
      - name: second-add
        workflowTemplateRef: add-workflowtemplate
        params:
          - name: first
            value: $(templates.first-add.results.sum)
          - name: second
            value: $(params.third)
  results:
    - name: total-sum
      description: the sum of all three operands
      value: $(templates.second-add.results.sum)
    - name: partial-sum
      description: the sum of first two operands
      value: $(templates.first-add.results.sum)
</code></pre>
<h2 id="条件分支"><a class="header" href="#条件分支">条件分支</a></h2>
<p>在 DAG WorkflowTemplate 中，如果需要在某个条件满足时才执行某个节点，可以设置 <code>when</code> 字段。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: flip-coin
spec:
  results:
    - name: coin
      description: Which side? Heads or tails?
  type: SeqPod
  seqPod:
    steps:
      - name: flip-coin
        image: python
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        script: |
          #!/usr/bin/env python3
          import random
          f = open(&quot;$(results.coin.path)&quot;, &quot;w&quot;)
          if random.random() &gt; 0.5:
            f.write(&quot;heads&quot;)
          else:
            f.write(&quot;tails&quot;)
          f.close()
---
apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: dag-workflowtemplate-sample-when
spec:
  type: DAG
  dag:
    templates:
      - name: flip-coin
        workflowTemplateRef: flip-coin
      - name: execute-only-if-heads
        workflowTemplateRef: pod-workflowtemplate-sample
        dependencies: [&quot;flip-coin&quot;]
        when:
          - input: &quot;$(templates.flip-coin.results.coin)&quot;
            operator: in
            values: [&quot;heads&quot;]
</code></pre>
<p><code>when</code> 字段包含一些表达式：</p>
<ul>
<li><code>input</code>：表达式的输入，可以是静态字符串或 <a href="modules/workflows/workflowtemplate.html#%E6%8C%87%E5%AE%9A%E5%8F%82%E6%95%B0"><code>params</code></a>、<a href="modules/workflows/workflowtemplate.html#%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C"><code>results</code></a> 等变量。如果未填写，默认为一个空的字符串。</li>
<li><code>operator</code>：表示 <code>input</code> 和 <code>values</code> 的关系，可以是 <code>in</code> 或者 <code>notin</code>。</li>
<li><code>values</code>：字符串数组，可以是静态字符串或 <a href="modules/workflows/workflowtemplate.html#%E6%8C%87%E5%AE%9A%E5%8F%82%E6%95%B0"><code>params</code></a>、<a href="modules/workflows/workflowtemplate.html#%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C"><code>results</code></a> 等变量。</li>
</ul>
<p>只有当 <code>when</code> 字段包含的所有表达式结果都为真时，该节点才会被运行，否则会跳过该节点继续运行其他节点。</p>
<p>如果一个节点的 <code>when</code> 表达式中引用了其他节点的 <code>results</code> 变量，相当于引入了前者对后者的依赖关系，前者会在后者运行结束后才开始运行。</p>
<h2 id="失败处理"><a class="header" href="#失败处理">失败处理</a></h2>
<p>对于 Pod/SeqPod/Resource WorkflowTemplate，一个 WorkflowRun 只对应一次运行，即使失败也不会重启。也就是说，一个 WorkflowRun 对应产生的 Pod 的 <code>spec</code> 中 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy"><code>restartPolicy</code></a> 永远是 <code>Never</code>。</p>
<p>对于 DAG WorkflowTemplate，DAG 的每个节点都有可能会失败，我们使用 <code>retries</code> 字段来控制节点的重启。</p>
<ul>
<li><code>retries = 0</code>（默认选项）表示不重启失败的节点。</li>
<li><code>retries &gt; 0</code> 表示会重启失败的节点，并用一个正整数来限制最多可重启的次数。</li>
</ul>
<p>如果 DAG 的某个节点失败并超过了最大可重启次数，该节点将被视为永久失败，并由 <code>spec.dag.failureStrategy</code> 决定接下来的行为：</p>
<ul>
<li><code>failureStrategy = StopAllWorkflowTemplates</code>（默认选项）表示停止创建任何新的节点。</li>
<li><code>failureStrategy = StopDependentWorkflowTemplates</code> 表示只停止创建依赖于失败节点的节点，其他分支上的节点正常创建。</li>
</ul>
<p>注意无论是哪种策略，已开始运行的节点都会等待其运行结束。</p>
<p>在下面的 DAG WorkflowTemplate 示例中，共有两个节点 <code>a</code> 和 <code>b</code>。</p>
<ul>
<li>如果 <code>a</code> 节点运行失败，它最多可以重试 5 次。</li>
<li>如果 <code>b</code> 节点运行失败，它不能进行重试，直接被认定为失败。</li>
<li>如果任意一个节点被认定为失败，整个 DAG WorkflowTemplate 也会被认定为失败，并且由于 <code>spec.dag.failureStrategy</code> 字段的值为 <code>StopAllWorkflowTemplates</code>，所有未开始运行的节点都不再运行。</li>
</ul>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: dag-workflowtemplate-sample-retries
spec:
  type: DAG
  dag:
    failureStrategy: StopAllWorkflowTemplates
    templates:
      - name: a
        workflowTemplateRef: pod-workflowtemplate-sample
        dependencies: []
        retries: 5
      - name: b
        workflowTemplateRef: pod-workflowtemplate-sample
        dependencies: [&quot;a&quot;]
        retries: 0
</code></pre>
<h2 id="下一步-32"><a class="header" href="#下一步-32">下一步</a></h2>
<ul>
<li>了解 <a href="modules/workflows/./workflowrun.html">WorkflowRun</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="workflowrun"><a class="header" href="#workflowrun">WorkflowRun</a></h1>
<p>WorkflowRun 是 WorkflowTemplate 的一次执行，为 WorkflowTemplate 提供运行时所需的一切资源，例如参数（<a href="modules/workflows/./workflowtemplate.html#%E6%8C%87%E5%AE%9A%E5%8F%82%E6%95%B0"><code>params</code></a>）、工作空间（<a href="modules/workflows/./workflowtemplate.html#%E6%8C%87%E5%AE%9A%E5%B7%A5%E4%BD%9C%E7%A9%BA%E9%97%B4"><code>workspaces</code></a>）。</p>
<h2 id="创建引用某个-workflowtemplate-的-workflowrun"><a class="header" href="#创建引用某个-workflowtemplate-的-workflowrun">创建引用某个 WorkflowTemplate 的 WorkflowRun</a></h2>
<p>下面的 WorkflowRun 示例为一个 WorkflowTemplate 创建一次运行。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowRun
metadata:
  name: workflowrun-sample
spec:
  workflowTemplateRef: workflowtemplate-sample
</code></pre>
<p>在该例中，<code>workflowTemplateRef</code> 字段标明所要运行的 WorkflowTemplate 的名称，该 WorkflowTemplate 必须是一个已经创建好的、与该 WorkflowRun 在同一个命名空间的 WorkflowTemplate。</p>
<h2 id="创建内嵌-workflowtemplate-规约的-workflowrun"><a class="header" href="#创建内嵌-workflowtemplate-规约的-workflowrun">创建内嵌 WorkflowTemplate 规约的 WorkflowRun</a></h2>
<p>下面的 WorkflowRun 示例也是为一个 WorkflowTemplate 创建一次运行，但是该 WorkflowTemplate 的规约直接在 WorkflowRun 的规约中填写。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowRun
metadata:
  name: embedded-workflowrun-sample
spec:
  workflowTemplateSpec:
    type: Pod
    pod:
      containers:
        - name: hello
          image: ubuntu:latest
          command: [&quot;echo&quot;]
          args: [&quot;Hello TensorStack!&quot;]
</code></pre>
<p>在该例中，<code>workflowTemplateSpec</code> 字段用于填写所要运行的 WorkflowTemplate 的规约，WorkflowTemplate 规约的写法详见 <a href="modules/workflows/../../../reference/tensorstack-resources/workflow-api/workflowtemplate.html#workflowTemplateSpec">WorkflowTemplateSpec</a>（坏链）。</p>
<h2 id="workflowrun-状态"><a class="header" href="#workflowrun-状态">WorkflowRun 状态</a></h2>
<p>在下面的示例中，首先创建一个类型为 DAG 的 WorkflowTemplate，然后创建一个 WorkflowRun 引用该 WorkflowTemplate。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: dag-workflowtemplate-sample
spec:
  type: DAG
  dag:
    templates:
      - name: a
        workflowTemplateRef: pod-workflowtemplate-sample
      - dependencies:
          - a
        name: b1
        workflowTemplateRef: pod-workflowtemplate-sample
      - dependencies:
          - a
        name: b2
        workflowTemplateRef: pod-workflowtemplate-sample
      - dependencies:
          - b1
          - b2
        name: c
        workflowTemplateRef: pod-workflowtemplate-sample
---
apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowRun
metadata:
  labels:
    batch.tensorstack.dev/workflowTemplate: dag-workflowtemplate-sample
  name: dag-workflowtemplate-sample-run
spec:
  serviceAccountName: ''
  workflowTemplateRef: dag-workflowtemplate-sample
status:
  completionTime: '2021-04-16T07:39:05Z'
  conditions:
    - lastTransitionTime: '2021-04-16T07:39:05Z'
      status: 'False'
      type: Running
    - lastTransitionTime: '2021-04-16T07:39:05Z'
      status: 'True'
      type: Completed
  message: All nodes in DAG have succeeded
  nodes:
    a:
      phase: Succeeded
      workflowRunName: dag-workflowtemplate-sample-run-a-pmb2m
    b1:
      phase: Succeeded
      workflowRunName: dag-workflowtemplate-sample-run-b1-mssn6
    b2:
      phase: Succeeded
      workflowRunName: dag-workflowtemplate-sample-run-b2-5db66
    c:
      phase: Succeeded
      workflowRunName: dag-workflowtemplate-sample-run-c-sjpb2
  phase: Succeeded
  startTime: '2021-04-16T07:38:10Z'
  workflowTemplateSpec:
    dag:
      templates:
        - name: a
          workflowTemplateRef: pod-workflowtemplate-sample
        - dependencies:
            - a
          name: b1
          workflowTemplateRef: pod-workflowtemplate-sample
        - dependencies:
            - a
          name: b2
          workflowTemplateRef: pod-workflowtemplate-sample
        - dependencies:
            - b1
            - b2
          name: c
          workflowTemplateRef: pod-workflowtemplate-sample
    type: DAG
</code></pre>
<p>WorkflowTemplate <code>dag-workflowtemplate-sample</code> 有四个节点，分别是：</p>
<ul>
<li><code>a</code></li>
<li><code>b1</code></li>
<li><code>b2</code></li>
<li><code>c</code></li>
</ul>
<p>WorkflowRun <code>dag-workflowtemplate-sample-run</code> 被创建后，WorkflowRun 控制器会为这四个节点创建四个 WorkflowRun，分别是</p>
<ul>
<li><code>dag-workflowtemplate-sample-run-a-pmb2m</code></li>
<li><code>dag-workflowtemplate-sample-run-b1-mssn6</code></li>
<li><code>dag-workflowtemplate-sample-run-b2-5db66</code></li>
<li><code>dag-workflowtemplate-sample-run-c-sjpb2</code></li>
</ul>
<p>如果这四个 WorkflowRun 均运行成功，WorkflowRun <code>dag-workflowtemplate-sample-run</code> 即运行成功。</p>
<p>WorkflowRun <code>dag-workflowtemplate-sample-run</code> 的 <code>status</code> 字段显示，该 WorkflowRun 处于 <code>Succeeded</code> 状态（见 <code>status.phase</code> 字段），原因是 “All nodes in DAG have succeeded”（见 <code>status.message</code> 字段）。<code>status.nodes</code> 字段记录了该 WorkflowRun 中每个 DAG 节点的名称以及对应的 WorkflowRun 名称和状态。</p>
<h2 id="下一步-33"><a class="header" href="#下一步-33">下一步</a></h2>
<ul>
<li>了解如何<a href="modules/workflows/../../tasks/build-automation-workflow.html">建立自动化工作流</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="cronworkflowrun"><a class="header" href="#cronworkflowrun">CronWorkflowRun</a></h1>
<p>CronWorkflowRun 用于方便地定时执行 <a href="modules/workflows/./workflowrun.html">WorkflowRun</a>，对于创建周期性的、反复重复的任务很有用。</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Cron">cron</a> 是一种书写定时计划的格式，用一个字符串指定何时触发任务的执行，通常由以空格分隔的 5 个部分组成：</p>
<pre><code class="language-bash"># ┌───────────── minute (0 - 59)
# │ ┌───────────── hour (0 - 23)
# │ │ ┌───────────── day of the month (1 - 31)
# │ │ │ ┌───────────── month (1 - 12)
# │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday;
# │ │ │ │ │                                   7 is also Sunday on some systems)
# │ │ │ │ │
# │ │ │ │ │
# * * * * *
</code></pre>
<p>例如：</p>
<ul>
<li><code>1 0 * * *</code> 表示在每天的 00:01 执行。</li>
<li><code>45 23 * * 6</code> 表示在每个星期六的 23:45 执行。</li>
<li><code>*/5 1,2,3 * * *</code> 表示在每天的第 1、2、3 个小时每隔 5 分钟执行一次（即 01:00，01:05，01:10，…，03:55）。</li>
</ul>
<p>注意 <code>*/n</code> 表示每隔 n 个时间单位执行一次，在某个时间单位多次执行可以用逗号连接（例如 <code>1,2,3</code>）。</p>
<p>为了更方便地创建 cron 表达式，可以使用第三方网页工具，例如 <a target="_blank" rel="noopener noreferrer" href="https://crontab.guru">crontab.guru</a>。</p>
<h2 id="创建-cronworkflowrun"><a class="header" href="#创建-cronworkflowrun">创建 CronWorkflowRun</a></h2>
<p>下面的 CronWorkflowRun 示例会每分钟创建一个 WorkflowRun。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: CronWorkflowRun
metadata:
  name: cronworkflowrun-sample
spec:
  schedule: &quot;*/1 * * * *&quot;
  workflowRun:
    spec:
      workflowTemplateRef: workflowtemplate-sample
</code></pre>
<p>在该例中：</p>
<ul>
<li><code>schedule</code> 字段是一个 cron 格式的字符串，表示每分钟触发一次 WorkflowRun 的运行。</li>
<li>所要运行的 WorkflowRun 由 <code>workflowRun</code> 字段定义，是一个引用 <code>workflowtemplate-sample</code> 的 WorkflowRun。</li>
</ul>
<h2 id="详细配置-cronworkflowrun"><a class="header" href="#详细配置-cronworkflowrun">详细配置 CronWorkflowRun</a></h2>
<p>下面是一个经过详细配置的 CronWorkflowRun 示例，与上一节类似，也会每分钟创建一个 WorkflowRun。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: CronWorkflowRun
metadata:
  name: cronworkflowrun-sample
spec:
  schedule: &quot;*/1 * * * *&quot;
  startingDeadlineSeconds: 30
  concurrencyPolicy: &quot;Allow&quot;
  suspend: true
  successfulRunsHistoryLimit: 10
  failedRunsHistoryLimit: 10
  workflowRun:
    spec:
      workflowTemplateRef: workflowtemplate-sample
</code></pre>
<p>在该例中：</p>
<ul>
<li>如果某个 WorkflowRun 由于任何原因未能准时在预设的时间点开始执行，它在 30 秒钟的期限内必须开始执行（由 <code>startingDeadlineSeconds</code> 字段指定），否则将被认为该次执行已失败。</li>
<li>如果到了某个 WorkflowRun 应该开始执行的时间点，但是上一个 WorkflowRun 仍未运行完成，允许这两个 WorkflowRun 同时运行（由 <code>concurrencyPolicy</code> 字段指定）。</li>
<li><code>suspend</code> 字段为 <code>true</code> 表示暂时停止创建新的 WorkflowRun，该字段可以随时变化。</li>
<li>由该 CronWorkflowRun 创建的所有 WorkflowRun 中，最多保留 10 个运行成功的 WorkflowRun 和 10 个运行失败的 WorkflowRun（分别由 <code>successfulRunsHistoryLimit</code> 和 <code>failedRunsHistoryLimit</code> 字段指定），多余的运行时间较早的 WorkflowRun 会被删除。</li>
</ul>
<h2 id="cronworkflowrun-状态"><a class="header" href="#cronworkflowrun-状态">CronWorkflowRun 状态</a></h2>
<p>下面是 CronWorkflowRun 的状态示例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: CronWorkflowRun
metadata:
  name: cronworkflowrun-sample
spec:
  schedule: &quot;*/1 * * * *&quot;
  startingDeadlineSeconds: 30
  concurrencyPolicy: &quot;Allow&quot;
  suspend: true
  successfulRunsHistoryLimit: 10
  failedRunsHistoryLimit: 10
  workflowRun:
    spec:
      workflowTemplateRef: workflowtemplate-sample
status:
  active:
  - apiVersion: batch.tensorstack.dev/v1beta1
    kind: WorkflowRun
    name: cronworkflowrun-sample-1631093400
    namespace: t9k-example
    resourceVersion: &quot;220623640&quot;
    uid: 39634803-d8cf-41d4-8a8e-649e0133b11b
  lastScheduleTime: &quot;2021-09-08T09:30:00Z&quot;
  conditions:
  - lastTransitionTime: &quot;2021-09-08T09:23:00Z&quot;
    message: At least one WorkflowRun has started
    status: &quot;True&quot;
    type: HasStarted
  - lastTransitionTime: &quot;2021-09-08T09:30:00Z&quot;
    message: There are running WorkflowRuns
    status: &quot;True&quot;
    type: IsRunning
  - lastTransitionTime: &quot;2021-09-08T09:23:35Z&quot;
    message: There are successful WorkflowRuns
    status: &quot;True&quot;
    type: HasSuccessfulRun
  - lastTransitionTime: &quot;2021-09-08T09:22:08Z&quot;
    message: No failed WorkflowRuns yet
    status: &quot;False&quot;
    type: HasFailedRun
</code></pre>
<p>该 CronWorkflowRun 的 <code>status</code> 字段显示：</p>
<ul>
<li>正在执行中的 WorkflowRun 有一个，其基本信息记录在 <code>status.active</code> 字段中。</li>
<li>最新的 WorkflowRun 的创建时间是 2021-09-08T09:30:00Z（由 <code>status.lastScheduleTime</code> 字段描述）。</li>
<li>在由该 CronWorkflowRun 创建的 WorkflowRun 中，已开始过至少一次 WorkflowRun（可能已结束或未结束），有正在运行中的 WorkflowRun，有已成功的 WorkflowRun，没有失败的 WorkflowRun（由 <code>status.conditions</code> 字段描述）。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="workflowtrigger"><a class="header" href="#workflowtrigger">WorkflowTrigger</a></h1>
<p>TensorStack AI 平台提供了一个灵活的工作流服务，除了支持手动执行工作流 WorkflowRun，还提供了 CronWorkflowRun 用于定时执行。</p>
<p>Workflow Trigger 模块额外提供了一种基于特定事件自动触发执行 WorkflowRun 的能力，便于用户在一些特定场景下的自动化工作流运行。</p>
<h2 id="架构-3"><a class="header" href="#架构-3">架构</a></h2>
<p>Workflow Trigger 模块提供了 EventListener 和 WorkflowTrigger 自定义扩展资源，整体架构如下图所示：</p>
<figure> 
<img alt="workflow-trigger-architecture" src="modules/workflows/../../assets/modules/workflow/workflow-trigger-architecture.drawio.svg"/>
</figure>
<p>其中：</p>
<ul>
<li>EventListener 作为事件入口接收 JSON 格式的 HTTP POST 请求，同时将请求信息转换成 <a target="_blank" rel="noopener noreferrer" href="https://github.com/cloudevents/spec">CloudEvents</a> 格式并转发至事件队列。</li>
<li>WorkflowTrigger 绑定一个或多个 EventListener 作为事件源，接收来自这些 EventListener 的 <a target="_blank" rel="noopener noreferrer" href="https://github.com/cloudevents/spec">CloudEvents</a> 格式的事件消息，并触发一个 WorkflowRun 的运行。特别地，支持对事件内容进行过滤，以及解析事件的某些字段的值填充到 WorkflowRun 的参数中。</li>
</ul>
<h2 id="快速开始"><a class="header" href="#快速开始">快速开始</a></h2>
<p>下面将通过几个简单的步骤来演示 Workflow Trigger 模块的基本使用方法。下面创建的所有资源请确保属于同一个命名空间。</p>
<h3 id="1创建-workflowtemplate"><a class="header" href="#1创建-workflowtemplate">1）创建 WorkflowTemplate</a></h3>
<p>创建文件 workflow-template-sample.yaml：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: workflow-template-sample
spec:
  description: This WorkflowTemplate creates and runs a Pod.
  params:
    - name: message
      default: &quot;TensorStack&quot;
  type: Pod
  pod:
    containers:
      - name: hello
        image: ubuntu:latest
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        command: [&quot;echo&quot;]
        args: [&quot;Hello $(params.message)!&quot;]
</code></pre>
<p>上面的示例定义了一个名为 <code>message</code> 的参数，同时将该参数值以 <code>$(params.message)</code> 的形式传递到 Pod 的容器的 <code>args</code> 参数上，执行下面的命令创建 WorkflowTemplate：</p>
<pre><code class="language-bash">kubectl apply -f workflow-template-sample.yaml
</code></pre>
<p>该 WorkflowTemplate 将作为一个静态模版用于执行一次 WorkflowRun 的运行。</p>
<h3 id="2创建-eventlistener"><a class="header" href="#2创建-eventlistener">2）创建 EventListener</a></h3>
<p>创建文件 event-listener-sample.yaml：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: EventListener
metadata:
  name: event-listener-sample
spec:
  replicas: 1
</code></pre>
<p>执行下面的命令创建一个 EventListener：</p>
<pre><code class="language-yaml">kubectl apply -f event-listener-sample.yaml
</code></pre>
<h3 id="3创建-workflowtrigger"><a class="header" href="#3创建-workflowtrigger">3）创建 WorkflowTrigger</a></h3>
<p>创建文件 workflow-trigger-sample.yaml：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: WorkflowTrigger
metadata:
  name: workflow-trigger-sample
spec:
  eventSources:
  - eventListenerName: event-listener-sample
  replicas: 1
  serviceAccountName: managed-project-sa
  workflowRunSpec:
    params:
    - name: message
      value: $(body.hello)
    workflowTemplateRef: workflow-template-sample
</code></pre>
<p>上面的示例以 <code>$(body.hello)</code> 的形式将 HTTP 请求体中的 <code>hello</code> 字段值传递到 param <code>message</code> 上，执行下面的命令创建 WorkflowTrigger：</p>
<pre><code class="language-bash">kubectl apply -f workflow-trigger-sample.yaml
</code></pre>
<h3 id="4触发事件"><a class="header" href="#4触发事件">4）触发事件</a></h3>
<p>通过执行下面的命令来查询 EventListener HTTP 服务的访问地址：</p>
<pre><code class="language-yaml">$ kubectl get eventlisteners event-listener-sample -o json | jq .status.address
{
  &quot;inClusterURL&quot;: &quot;http://event-listener-sample-eventlistener-2dbfe.default.svc.cluster.local&quot;,
  &quot;url&quot;: &quot;https://&lt;tensorstack-host&gt;/t9k/workflow/triggers/default/event-listener-sample&quot;
}
</code></pre>
<p>其中 <code>url</code> 字段为集群外部访问 EventListener HTTP 服务的地址，使用 curl 命令向此地址发送 HTTP 请求来模拟触发事件：</p>
<pre><code class="language-bash">curl -X POST https://&lt;tensorstack-host&gt;/t9k/workflow/triggers/default/event-listener-sample \
  -d '{&quot;hello&quot;: &quot;world&quot;}'
</code></pre>
<p>其中 <code>-d '{&quot;hello&quot;: &quot;world&quot;}'</code> 标识 HTTP 请求的 JSON 格式的 body 内容为 <code>{&quot;hello&quot;: &quot;world&quot;}</code>，<code>hello</code> 字段值 <code>&quot;world&quot;</code> 将作为参数传递到 WorkflowRun，HTTP 服务将返回 success 表示请求已经发送成功。</p>
<h3 id="5查看-workflowrun"><a class="header" href="#5查看-workflowrun">5）查看 WorkflowRun</a></h3>
<p>上面的步骤全部执行成功以后，WorkflowTrigger 将会触发一次 WorkflowRun 的运行，通过下面的命令进行查询：</p>
<pre><code class="language-bash">$ kubectl get workflowruns
NAME                                                  PHASE
event-listener-sample-workflow-trigger-sample-87a0d   Succeeded
</code></pre>
<p>根据返回的结果可以看出，WorkflowRun 已经创建成功。该 WorkflowRun 将根据上面 WorkflowTemplate 静态模块的内容创建一个 Pod，通过下面的命令进行查询：</p>
<pre><code class="language-bash">$ kubectl get po -l batch.tensorstack.dev/workflowRun=event-listener-sample-workflow-trigger-sample-87a0d
NAME                                                            READY   STATUS      RESTARTS   AGE
event-listener-sample-workflow-trigger-sample-87a0d-pod-6stvb   0/1     Completed   0          3m23s
</code></pre>
<p>根据返回的结果可以看出，Pod 已经创建成功，通过查询该 Pod 日志来校验参数传递：</p>
<pre><code class="language-bash">$ kubectl logs event-listener-sample-workflow-trigger-sample-87a0d-pod-6stvb
Hello world!
</code></pre>
<p>Pod 日志成功打印出 <code>“world”</code> 内容，其为手动触发事件中发送的 HTTP 请求的 body 内容，参数成功传递。</p>
<p>至此，Workflow Trigger 模块的基本使用方法已经介绍完成，阅读下面的章节来获取更详细的配置信息。</p>
<h2 id="eventlistener"><a class="header" href="#eventlistener">EventListener</a></h2>
<p>EventListener 内部运行着一个 HTTP 服务，用于接收第三方的请求，同时将请求消息转换成 <a target="_blank" rel="noopener noreferrer" href="https://github.com/cloudevents/spec">CloudEvents</a> 并将它们转发至事件队列。当前 EventListener 只支持 <strong>JSON</strong> 格式的 HTTP <strong>POST</strong> 请求。</p>
<h3 id="创建-eventlistener"><a class="header" href="#创建-eventlistener">创建 EventListener</a></h3>
<p>下面是一个基本的 EventListener 示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: EventListener
metadata:
  name: event-listener-sample
spec:
  replicas: 1
  resources:
    requests:
      memory: &quot;100Mi&quot;
      cpu: &quot;100m&quot;
    limits:
      memory: &quot;200Mi&quot;
      cpu: &quot;200m&quot;
</code></pre>
<p>在该例中：</p>
<ul>
<li><code>replicas</code> 字段定义所要创建的 Pod 副本数量，默认是 1。</li>
<li><code>resources</code> 字段定义每个 Pod 的资源限制，上述示例为缺省时的默认值。</li>
</ul>
<h3 id="eventlistener-状态"><a class="header" href="#eventlistener-状态">EventListener 状态</a></h3>
<p>通过 EventListener 的状态字段可以获取其访问地址和运行状态信息，示例如下：</p>
<pre><code class="language-yaml">status:
  address:
    inClusterURL: http://&lt;eventlistener-service-name&gt;.default.svc.cluster.local
    url: https://&lt;tensorstack-host&gt;/t9k/workflow/triggers/default/&lt;eventlistener-name&gt;
  conditions:
  - lastTransitionTime: &quot;2022-12-05T10:23:49Z&quot;
    message: The EventListener is Ready
    status: &quot;True&quot;
    type: Ready
</code></pre>
<p>其中：</p>
<ul>
<li><code>status.address</code> 表示 EventListener 所创建的 HTTP 服务的访问地址，第三方可向此地址发送请求，其中：
<ul>
<li><code>inClusterURL</code> 是只能从集群内部访问的地址。</li>
<li><code>url</code> 是可以从集群外部访问的地址。</li>
</ul>
</li>
<li><code>status.conditions</code> 表示 EventListener 的状态：
<ul>
<li><code>type: Ready</code> 表示 EventListener 是否就绪，可能的值有 <code>True</code>、<code>False</code>、<code>Unknown</code>。</li>
</ul>
</li>
</ul>
<h2 id="workflowtrigger-1"><a class="header" href="#workflowtrigger-1">WorkflowTrigger</a></h2>
<p>WorkflowTrigger 从一个或多个 EventListener 事件源获取事件消息，并触发一个 WorkflowRun 的运行。</p>
<p>WorkflowTrigger 支持对每个 EventListener 配置过滤条件，只有符合过滤条件的事件消息才会被进一步处理；WorkflowTrigger 同时支持将事件消息的某些字段解析并填充到 WorkflowRun 的参数执行。</p>
<h3 id="创建-workflowtrigger"><a class="header" href="#创建-workflowtrigger">创建 WorkflowTrigger</a></h3>
<p>下面是一个基本的 WorkflowTrigger 示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: WorkflowTrigger
metadata:
  name: workflow-trigger-sample
spec:
  eventSources:
  - eventListenerName: event-listener-sample
  replicas: 1
  resources:
    requests:
      memory: &quot;100Mi&quot;
      cpu: &quot;100m&quot;
    limits:
      memory: &quot;200Mi&quot;
      cpu: &quot;200m&quot;
  serviceAccountName: managed-project-sa
  workflowRunSpec:
    workflowTemplateRef: workflow-template-sample
</code></pre>
<p>在该例中：</p>
<ul>
<li><code>eventSources</code> 字段定义了该 WorkflowTrigger 需要订阅事件消息的事件源集合，其中：</li>
<li><code>eventListenerName</code> 表示上述 EventListener 的名称，该 EventListener 必须与该 WorkflowTrigger 同命名空间、且已成功创建。</li>
<li><code>replicas</code> 字段定义了该 WorkflowTrigger 创建的 Pod 副本数量，默认是 1。</li>
<li><code>resources</code> 字段定义每个 Pod 的资源限制，上述示例为缺省时的默认值。</li>
<li><code>serviceAccountName</code> 字段定义了该 WorkflowTrigger 创建的 Pod 的 ServiceAccount，为创建 WorkflowRun 提供权限。</li>
<li><code>workflowRunSpec</code> 字段定义了将要创建的 WorkflowRun 的配置规约，其中：
<ul>
<li><code>workflowTemplateRef</code> 表示所要运行的 WorkflowTemplate 的名称，该 WorkflowTemplate 必须与该 WorkflowTrigger 同命名空间、且已成功创建。该字段同时支持内嵌 WorkflowTemplate 规约，详见 <a href="modules/workflows/./workflowrun.html#%E5%88%9B%E5%BB%BA%E5%86%85%E5%B5%8C-workflowtemplate-%E8%A7%84%E7%BA%A6%E7%9A%84-workflowrun">WorkflowRun</a>。</li>
</ul>
</li>
</ul>
<h3 id="过滤事件"><a class="header" href="#过滤事件">过滤事件</a></h3>
<p>WorkflowTrigger 支持对来自 EventListener 的事件消息进行过滤，只有符合过滤条件的事件消息才会被进一步处理。下面是一个包含过滤条件的 WorkflowTrigger 示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: WorkflowTrigger
metadata:
  name: filter-workflow-trigger-sample
spec:
  eventSources:
  - eventListenerName: event-listener-sample
    filters:
    - path: body.object_attributes.work_in_progress
      type: bool
      values:
      - &quot;false&quot;
    - path: body.labels.0.id
      type: number
      values:
      - &quot;219&quot;
      - &quot;3&quot;
      - &quot;99&quot;
    - path: body.object_kind
      type: string
      values:
      - &quot;merge_request&quot;
  serviceAccountName: managed-project-sa
  workflowRunSpec:
    workflowTemplateRef: workflow-template-sample
</code></pre>
<p>在该例中，<code>spec.eventSources.filters</code> 定义了该 EventListener 的过滤条件集合，其中：</p>
<ul>
<li><code>path</code> 表示 HTTP 请求路径，例如 header.X-Github-Event、body.pull_request.state。</li>
<li><code>type</code> 表示该路径指向字段的值的类型，当前支持 bool、number、string。</li>
<li><code>values</code> 表示该路径指向字段的值的可允许值的集合，其为 string 类型。</li>
</ul>
<p>每个 EventListener 的 <code>filters</code> 互不影响，针对某一个 EventListener，其所有的 <code>filters</code> 必须全部通过才算符合条件。</p>
<h3 id="解析参数"><a class="header" href="#解析参数">解析参数</a></h3>
<p>WorkflowTrigger 支持对来自 EventListener 的事件消息进行解析，并将指定字段的值通过参数的形式传递到 WorkflowRun。下面是一个包含解析参数的 WorkflowTrigger 示例：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: WorkflowTrigger
metadata:
  name: param-workflow-trigger-sample
spec:
  eventSources:
  - eventListenerName: event-listener-sample
  serviceAccountName: managed-project-sa
  workflowRunSpec:
    params:
    - name: bool-name
      value: $(body.test.boolT)
    - name: number-name
      value: $(body.test.numberT)
    - name: string-name
      value: $(body.test.stringT)
    workflowTemplateRef: workflow-template-sample
</code></pre>
<p>在该例中，<code>spec.workflowRunSpec.params</code> 定义了将创建的 WorkflowRun 的参数集合，其中：</p>
<ul>
<li><code>name</code> 表示参数名称。</li>
<li><code>value</code> 表示参数的值，可通过 <code>$()</code> 形式从事件消息中获取指定字段的值。当前不支持 <code>$()</code> 嵌套。</li>
</ul>
<h3 id="workflowtrigger-状态"><a class="header" href="#workflowtrigger-状态">WorkflowTrigger 状态</a></h3>
<p>通过 WorkflowTrigger 的状态字段可以获取其运行状态信息，示例如下：</p>
<pre><code class="language-yaml">status:
  conditions:
  - lastTransitionTime: &quot;2022-12-05T10:26:46Z&quot;
    message: The WorkflowTrigger is Ready
    status: &quot;True&quot;
    type: Ready
</code></pre>
<p>其中：</p>
<ul>
<li><code>status.conditions</code> 表示 WorkflowTrigger 的状态：
<ul>
<li><code>type: Ready</code> 表示 WorkflowTrigger 是否就绪，可能的值有 <code>True</code>、<code>False</code>、<code>Unknown</code>。</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="操作指南"><a class="header" href="#操作指南">操作指南</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用模型构建控制台"><a class="header" href="#使用模型构建控制台">使用模型构建控制台</a></h1>
<p>模型构建控制台提供了大量功能，你可以在此进行<a href="tasks/../modules/building/index.html">模型构建</a>，并管理 <a href="tasks/../modules/jobs/index.html">Job</a>、<a href="tasks/../modules/storage/index.html">存储</a>和<a href="tasks/../modules/auxiliary/index.html">辅助</a>资源。本部分将演示如何在模型构建控制台中使用 Notebook 和 TensorBoard，构建和调试镜像，以及管理存储、配置和隐私信息。</p>
<p>对于如何使用 T9k Job 和 AutoTune，请分别参阅<a href="tasks/./model-training.html">运行模型训练</a>和<a href="tasks/./hyperparameter-tuning.html">进行超参数优化</a>。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="创建-notebook-3"><a class="header" href="#创建-notebook-3">创建 Notebook</a></h1>
<p>本教程演示如何创建 Notebook。</p>
<h2 id="准备工作"><a class="header" href="#准备工作">准备工作</a></h2>
<ul>
<li>了解 <a href="tasks/../modules/building/notebook.html">Notebook</a> 的基本概念。</li>
<li>成为一个<a href="tasks/../modules/security/project.html">项目</a>的管理员或<a href="tasks/./add-project-member.html">成员</a>。</li>
</ul>
<h2 id="创建-pvc-2"><a class="header" href="#创建-pvc-2">创建 PVC</a></h2>
<p>创建 Notebook 时，需要至少绑定一个 PVC 来存储代码、数据等文件。如果你的项目中已有合适的持久卷，则可以直接进入下一节。</p>
<p>在模型构建控制台的左侧导航菜单中点击<strong>存储 &gt; 持久卷</strong>进入 PVC 管理页面。然后点击右上角的<strong>创建 PVC</strong> 进入创建页面：</p>
<figure class="screenshot">
  <img alt="pvc-manage" src="tasks/../assets/tasks/develop-and-test-model/create-notebook/pvc-manage.png"/>
</figure>
<p>在 PVC 创建页面，<strong>名称</strong>填写 <code>create-notebook</code>，<strong>存储</strong>填写 <code>1Gi</code>，其他参数保持默认值，然后点击<strong>创建</strong>：</p>
<figure class="screenshot">
  <img alt="pvc-create-filled" src="tasks/../assets/tasks/develop-and-test-model/create-notebook/pvc-create-filled.png" />
</figure>
<h2 id="创建标准的-notebook"><a class="header" href="#创建标准的-notebook">创建标准的 Notebook</a></h2>
<p>在模型构建控制台的左侧导航菜单中点击<strong>构建 &gt; Notebook</strong> 进入 Notebook 管理页面，然后点击右上角的<strong>创建 Notebook</strong> 进入创建页面：</p>
<figure class="screenshot">
  <img alt="notebook-manage" src="tasks/../assets/tasks/develop-and-test-model/create-notebook/notebook-manage.png" />
</figure>
<p>在 Notebook 创建页面，如下填写各个参数：</p>
<ul>
<li><strong>名称</strong>填写 <code>create-notebook</code>。</li>
<li><strong>存储卷</strong>选择上一节创建的 <code>create-notebook</code>（或其他合适的存储卷）。存储卷会被挂载到 Notebook 的 <code>/t9k/mnt</code> 目录下。</li>
<li><strong>镜像</strong>根据你想使用的机器学习框架（如 TensorFlow、PyTorch 等）及其版本选择一个标准 Notebook 镜像。</li>
<li><strong>模版</strong>根据你的资源需求选择一个合适大小的资源模版。</li>
</ul>
<p>其他参数保持默认值，完成之后，点击<strong>创建</strong>：</p>
<figure class="screenshot">
  <img alt="notebook-create-filled" src="tasks/../assets/tasks/develop-and-test-model/create-notebook/notebook-create-filled.png" />
</figure>
<aside class="note info">
<div class="title">信息</div>
<p>标准 Notebook 镜像的默认用户是 <code>t9kuser</code>，其主目录（home directory）是 <code>/t9k/mnt</code>。</p>
</aside>
<p>回到 Notebook 管理页面查看新创建的 Notebook：</p>
<figure class="screenshot">
  <img alt="notebook-created" src="tasks/../assets/tasks/develop-and-test-model/create-notebook/notebook-created.png" />
</figure>
<aside class="note info">
<div class="title">Notebook 启动延迟</div>
<p>如果 Notebook 被分配到的节点中已经有了对应的 Notebook 镜像，那么 Notebook 通常能在几秒内启动就绪；否则，根据网络情况，可能需要几分钟甚至更长时间来拉取镜像，启动将被大大延迟。</p>
</aside>
<p>Notebook 就绪后，就可以<a href="tasks/./use-notebook.html">使用 Notebook</a>。</p>
<h2 id="其他配置"><a class="header" href="#其他配置">其他配置</a></h2>
<h3 id="使用-t9k-调度器"><a class="header" href="#使用-t9k-调度器">使用 T9k 调度器</a></h3>
<p><a href="tasks/../modules/scheduling/index.html">计算资源</a>模块还提供了选项，使用调度器 <code>t9k-scheduler</code>，以支持便捷的资源使用申请，使用 <code>t9k-scheduler</code> 调度任务时必须指定一个<a href="tasks/../modules/scheduling/queue.html">队列</a>。相比默认调度器，<code>t9k-scheduler</code> 需要额外填写如下参数：</p>
<ul>
<li><code>队列 (queue)</code>：必填，选择一个队列（如果没有队列，请联系管理员创建一个队列）。</li>
<li><code>优先级 (priority)</code>：可选，默认值是 0。代表任务在队列内部的优先级。当发生资源抢占时，优先级数字较小的工作负载会比同一个队列中的其他负载优先被驱逐。</li>
</ul>
<figure class="screenshot">
  <img alt="t9k-scheduler" src="tasks/../assets/tasks/develop-and-test-model/create-notebook/t9k-scheduler.png" />
</figure>
<h3 id="使用数据卷"><a class="header" href="#使用数据卷">使用数据卷</a></h3>
<p>可以为 Notebook 绑定额外的数据卷（存放数据的 PVC），如下图所示：</p>
<figure class="screenshot">
  <img alt="notebook-dataVolume" src="tasks/../assets/tasks/develop-and-test-model/create-notebook/notebook-dataVolume.png" />
</figure>
<p>每绑定一个数据卷需要填写如下参数：</p>
<ul>
<li><code>名称</code>：使用的 PVC 名称。</li>
<li><code>绑定路径</code>：将 PVC 绑定到 Notebook 的指定路径下。</li>
</ul>
<p>在上图的示例中，我们将 PVC <code>examples</code> 绑定到了 Notebook 的 <code>/t9k/examples</code> 路径下。你可以在 Notebook 中通过对应路径访问 PVC 中的数据。</p>
<h3 id="启用-ssh-选项"><a class="header" href="#启用-ssh-选项">启用 SSH 选项</a></h3>
<p>如果你想使用 SSH 连接到 Notebook 容器中来管理其中的文件，或者使用本地的 IDE 来编辑 Notebook 中的代码，<strong>启用 SSH</strong> 能够帮助你在 Notebook 中运行一个 SSH 服务。</p>
<p>Notebook 的 SSH 服务只允许通过密钥对进行验证，因此你需要上传公钥以使用 SSH 连接。TensorStack AI 平台使用 Secret 存储公钥信息。如果你已经创建了包含公钥的 Secret，则可以直接进入下一节。</p>
<p>在模型构建控制台的左侧导航菜单中点击<strong>辅助 &gt; Secret</strong>，然后点击右上角的<strong>创建 Secret</strong> 进入的创建页面：</p>
<figure class="screenshot">
  <img alt="secret-create" src="tasks/../assets/tasks/develop-and-test-model/create-notebook/secret-create.png" />
</figure>
<p>在 Secret 创建页面，选择类型为 <strong>SSH Public Key</strong>，填写名称和公钥内容。最后点击<strong>创建 Secret</strong> 进行创建：</p>
<aside class="note info">
<div class="title">信息</div>
<p>如果你没有生成过密钥对，或者不知道从哪里获取公钥，那么你可以参阅 <a target="_blank" rel="noopener noreferrer" href="https://www.ssh.com/academy/ssh/keygen">SSH 文档</a>或者 <a target="_blank" rel="noopener noreferrer" href="https://learn.microsoft.com/zh-cn/windows-server/administration/openssh/openssh_keymanagement#user-key-generation">Windows 文档</a>。</p>
</aside>
<figure class="screenshot">
  <img alt="secret-create-ssh" src="tasks/../assets/tasks/develop-and-test-model/create-notebook/secret-create-ssh.png" />
</figure>
<p>创建 Notebook 时，开启<strong>启用 SSH</strong> 按钮，然后选择前面创建的 Secret（此处为一个多选框，你可以同时设置多个 SSH 公钥）：</p>
<figure class="screenshot">
  <img alt="notebook-ssh" src="tasks/../assets/tasks/develop-and-test-model/create-notebook/notebook-ssh.png" />
</figure>
<aside class="note info">
<div class="title">信息</div>
<p>关于服务类型，详细的说明可以参阅 Kubernetes 官方文档<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/zh-cn/docs/concepts/services-networking/service/#publishing-services-service-types">发布服务（服务类型）</a>。</p>
</aside>
<p>点击<strong>创建</strong>，等待运行之后，你可以<a href="tasks/./ssh-notebook.html">通过 SSH 连接远程使用 Notebook</a>。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-notebook"><a class="header" href="#使用-notebook">使用 Notebook</a></h1>
<p>本教程演示如何使用 Notebook 进行模型开发相关的工作。</p>
<h2 id="打开-jupyterlab"><a class="header" href="#打开-jupyterlab">打开 JupyterLab</a></h2>
<p>在模型构建控制台的左侧导航菜单中点击<strong>构建 &gt; Notebook</strong> 进入 Notebook 管理页面，然后点击运行中的 Notebook 右侧的<strong>打开</strong>：</p>
<aside class="note info">
<div class="title">信息</div>
<p>如果 Notebook 处于暂停状态，那么你需要先点击右侧的<strong>恢复</strong>，等待 Notebook 运行后再使用。TensorStack AI 平台会自动暂停长时间闲置的 Notebook 以释放集群资源，你也可以主动暂停 Notebook。</p>
</aside>
<figure class="screenshot">
  <img alt="notebook-manage" src="tasks/../assets/tasks/develop-and-test-model/use-notebook/notebook-manage.png" />
</figure>
<p>进入到 <a target="_blank" rel="noopener noreferrer" href="https://jupyterlab.readthedocs.io/en/latest/">JupyterLab</a> 的页面：</p>
<figure class="screenshot">
  <img alt="jupyterLab" src="tasks/../assets/tasks/develop-and-test-model/use-notebook/jupyterLab.png" />
</figure>
<h2 id="使用-jupyter-notebook"><a class="header" href="#使用-jupyter-notebook">使用 Jupyter Notebook</a></h2>
<p>点击 <strong>Launcher</strong> 标签页下，<strong>Notebook</strong> 下方的 <strong>Python3</strong> 图标以创建 Jupyter Notebook：</p>
<figure class="screenshot">
  <img alt="jupyterLab-select-notebook" src="tasks/../assets/tasks/develop-and-test-model/use-notebook/jupyterLab-select-notebook.png" />
</figure>
<p>Jupyter Notebook 提供了交互式的 Python 开发环境。你可以在这里分块编辑并运行 Python 代码。比如运行 <code>keras_mnist.py</code>：</p>
<pre><code class="language-python">from tensorflow.keras import callbacks, datasets, layers, models, optimizers

model = models.Sequential([
    layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPool2D((2, 2)),
    layers.Conv2D(64, 3, activation='relu'),
    layers.MaxPool2D((2, 2)),
    layers.Conv2D(64, 3, activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax'),
])
model.compile(optimizer=optimizers.Adam(learning_rate=0.001),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy'])


(train_images, train_labels), (test_images,
                            test_labels) = datasets.mnist.load_data()

train_images = train_images.reshape((60000, 28, 28, 1))
test_images = test_images.reshape((10000, 28, 28, 1))

train_images, test_images = train_images / 255.0, test_images / 255.0

model.fit(train_images,
        train_labels,
        batch_size=32,
        epochs=5,
        validation_split=0.2)
model.evaluate(test_images, test_labels)
</code></pre>
<figure class="screenshot">
  <img alt="jupyterLab-notebook" src="tasks/../assets/tasks/develop-and-test-model/use-notebook/jupyterLab-notebook.png" />
</figure>
<h2 id="编辑文件"><a class="header" href="#编辑文件">编辑文件</a></h2>
<p>在左侧的文件系统导航菜单空白处右击，可以创建文件和目录：</p>
<figure class="screenshot">
  <img alt="jupyterLab-newfile" src="tasks/../assets/tasks/develop-and-test-model/use-notebook/jupyterLab-newfile.png" />
</figure>
<p>创建名为 <code>keras_mnist.py</code> 的文件，双击以进行编辑。复制上文中 <code>keras_mnist.py</code> 的内容，粘贴在文本编辑器中并保存：</p>
<figure class="screenshot">
  <img alt="jupyterLab-editor" src="tasks/../assets/tasks/develop-and-test-model/use-notebook/jupyterLab-editor.png" />
</figure>
<h2 id="使用-terminal"><a class="header" href="#使用-terminal">使用 Terminal</a></h2>
<p>点击左上角蓝色底色的 <strong>+</strong> 符号打开新的 <strong>Launcher</strong> 标签页，然后点击 <strong>Other</strong> 中的 <strong>Terminal</strong> 进入命令行终端。你可以在这里运行各种 bash 命令，例如运行 <code>python ./keras_mnist.py</code> 来进行模型训练：</p>
<figure class="screenshot">
  <img alt="jupyterLab-terminal" src="tasks/../assets/tasks/develop-and-test-model/use-notebook/jupyterLab-terminal.png" />
</figure>
<h2 id="查看详情"><a class="header" href="#查看详情">查看详情</a></h2>
<p>在 Notebook 管理页面，点击 Notebook 的名称进入其详情页面：</p>
<figure class="screenshot">
  <img alt="notebook-show-details" src="tasks/../assets/tasks/develop-and-test-model/use-notebook/notebook-show-details.png" />
</figure>
<p>Notebook 的详情页面展示了 Notebook 的基本信息、状况和事件。点击 <strong>Pod</strong> 右侧的链接可以查看 Pod 的日志、状况、事件、资源监测等信息：</p>
<figure class="screenshot">
  <img alt="notebook-details" src="tasks/../assets/tasks/develop-and-test-model/use-notebook/notebook-details.png" />
</figure>
<h3 id="查看日志-1"><a class="header" href="#查看日志-1">查看日志</a></h3>
<p>点击<strong>日志</strong>，查看 Notebook Pod 的运行日志：</p>
<figure class="screenshot">
  <img alt="notebook-logs" src="tasks/../assets/tasks/develop-and-test-model/use-notebook/notebook-logs.png" />
</figure>
<h3 id="查看资源监测"><a class="header" href="#查看资源监测">查看资源监测</a></h3>
<p>点击<strong>资源监测</strong>，查看 Notebook Pod 运行时实际使用的资源，包括 CPU、内存、存储 I/O 的使用量：</p>
<figure class="screenshot">
  <img alt="notebook-resource-1" src="tasks/../assets/tasks/develop-and-test-model/use-notebook/notebook-resource-1.png" />
</figure>
<figure class="screenshot">
  <img alt="notebook-resource-2" src="tasks/../assets/tasks/develop-and-test-model/use-notebook/notebook-resource-2.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="通过-ssh-远程使用-notebook"><a class="header" href="#通过-ssh-远程使用-notebook">通过 SSH 远程使用 Notebook</a></h1>
<p>本教程演示如何通过 SSH 连接远程使用 Notebook。</p>
<h2 id="准备"><a class="header" href="#准备">准备</a></h2>
<ul>
<li>创建了一个<a href="tasks/./create-notebook.html#%E5%90%AF%E7%94%A8-ssh-%E9%80%89%E9%A1%B9">启用 SSH 选项</a>的 Notebook。</li>
<li>确认该 Notebook 处于正常运行状态。</li>
</ul>
<h2 id="端口转发"><a class="header" href="#端口转发">端口转发</a></h2>
<h3 id="命令行工具-t9k-pf"><a class="header" href="#命令行工具-t9k-pf">命令行工具 t9k-pf</a></h3>
<p>命令行工具 <a href="tasks/../tools/cli-t9k-pf/index.html">t9k-pf</a> 的功能类似于 <code>kubectl port-forward</code>，可以让用户能够在本地通过端口转发的方式访问 TensorStack AI 平台的各种资源。</p>
<p>请参照<a href="tasks/../tools/cli-t9k-pf/guide.html#%E7%94%A8%E6%88%B7%E6%8C%87%E5%8D%97">用户指南</a>，下载安装 t9k-pf 并配置<a href="tasks/../tools/cli-t9k-pf/guide.html#%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81%E5%92%8C%E6%8E%88%E6%9D%83">身份认证和授权</a>。</p>
<h3 id="端口转发命令"><a class="header" href="#端口转发命令">端口转发命令</a></h3>
<p>在 Notebook 详情页面，查看并复制<strong>SSH 服务</strong>提示的命令：</p>
<figure class="screenshot">
  <img alt="copy-t9k-pf-command" src="tasks/../assets/tasks/develop-and-test-model/use-notebook-remotely-via-ssh-connection/copy-t9k-pf-command.png" />
</figure>
<p>在终端执行该命令以进行端口转发：</p>
<pre><code class="language-bash">$ t9k-pf notebook &lt;URL&gt; &lt;Port&gt;
now you can forward to your target by 127.0.0.1:&lt;Port&gt;
</code></pre>
<p>参数说明如下：</p>
<ul>
<li><code>URL</code>：Notebook 的 Web UI 地址。除上述获取方式外，你也可以在打开 Notebook 后，复制浏览器地址栏中的地址作为 <code>URL</code> 参数使用。</li>
<li><code>Port</code>：转发的本地端口。在 <a href="tasks/ssh-notebook.html#ssh-%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5">SSH 远程连接教程</a>中会使用到该端口。</li>
</ul>
<p>根据终端打印的提示信息，使用本地的端口与目标 Notebook 建立 SSH 连接，具体命令请参阅 <a href="tasks/ssh-notebook.html#ssh-%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5">SSH 远程连接</a>。</p>
<aside class="note">
<div class="title">注意</div>
<ol>
<li>端口转发成功后，需要保持执行 <code>t9k-pf</code> 命令的终端一直处于运行状态。</li>
<li>标准 Notebook 镜像的默认用户是 <code>t9kuser</code>，其主目录（home directory）是 <code>/t9k/mnt</code>。</li>
</ol>
</aside>
<h2 id="建立-ssh-连接"><a class="header" href="#建立-ssh-连接">建立 SSH 连接</a></h2>
<h3 id="使用终端"><a class="header" href="#使用终端">使用终端</a></h3>
<p>在终端中运行以下命令以连接到 Notebook：</p>
<pre><code class="language-bash">ssh t9kuser@localhost -p &lt;Port&gt; \
  -o StrictHostKeyChecking=no \
  -o GlobalKnownHostsFile=/dev/null \
  -o UserKnownHostsFile=/dev/null
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>命令行参数的说明：</p>
<ul>
<li>由于端口转发，同一个 <code>&lt;Port&gt;</code> 可以在不同时间可被映射为不同的 Notebook，导致 SSH 客户端认为 <code>host key</code> 发生变化。上面的命令设置 <code>StrictHostKeyChecking=no</code> 来跳过主机密钥的检查，并设置 <code>GlobalKnownHostsFile=/dev/null</code> 和 <code>UserKnownHostsFile=/dev/null</code> 以避免将主机密钥保存到 known_hosts 文件中；</li>
<li>运行上面的命令时会提示 <code>Warning: Permanently added '[&lt;Host&gt;]:&lt;Port&gt;' (RSA) to the list of known hosts</code>。但由于保存的路径为 <code>/dev/null</code>，并不会实际保存（期望的效果）。</li>
</ul>
</aside>
<p>然后在终端中操作 Notebook：</p>
<figure class="screenshot">
  <img alt="terminal-ssh" src="tasks/../assets/tasks/develop-and-test-model/use-notebook-remotely-via-ssh-connection/terminal-ssh.png" />
</figure>
<h3 id="使用-vscode"><a class="header" href="#使用-vscode">使用 VSCode</a></h3>
<h4 id="安装-remote-ssh-插件"><a class="header" href="#安装-remote-ssh-插件">安装 Remote SSH 插件</a></h4>
<p>在 VSCode 中搜索 <strong><a target="_blank" rel="noopener noreferrer" href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-ssh">Remote - SSH</a></strong> 插件并安装：</p>
<figure class="screenshot">
  <img alt="vscode-plugin" src="tasks/../assets/tasks/develop-and-test-model/use-notebook-remotely-via-ssh-connection/vscode-plugin.png" />
</figure>
<h4 id="添加-ssh-config"><a class="header" href="#添加-ssh-config">添加 SSH Config</a></h4>
<p>安装完成后，需要在 SSH Config 中添加主机（Notebook）的信息。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>如果你熟悉 SSH，直接编辑位于 <code>$HOME/.ssh/config</code> 的配置文件，添加以下信息：</p>
<pre><code class="language-bash">Host localhost
  HostName 127.0.0.1
  User t9kuser
  Port &lt;Port&gt;
</code></pre>
<p>确认无误后，保存文件即可。</p>
</aside>
<p>VSCode 提供了编辑 SSH Config 的方式。点击左下角的绿色 <strong>&gt;&lt;</strong> 符号，选择 <strong>Connect to Host</strong>，然后拉动滚动条到最下方，点击 <strong>Add New SSH Host</strong>：</p>
<figure class="screenshot">
  <img alt="vscode-new-host" src="tasks/../assets/tasks/develop-and-test-model/use-notebook-remotely-via-ssh-connection/vscode-new-host.png" />
</figure>
<p>根据提示，输入以下内容，然后按下回车键（Enter）：</p>
<pre><code class="language-bash">ssh t9kuser@localhost -p &lt;Port&gt;
</code></pre>
<figure class="screenshot">
  <img alt="vscode-ssh-command" src="tasks/../assets/tasks/develop-and-test-model/use-notebook-remotely-via-ssh-connection/vscode-ssh-command.png" />
</figure>
<p>VSCode 会提示 <strong>Select SSH configuration file to update</strong>，第一个选择项通常是位于 <code>$HOME/.ssh/config</code> 的配置文件，你可以选择将主机的信息存储在第一个配置文件中。</p>
<h4 id="连接到-notebook"><a class="header" href="#连接到-notebook">连接到 Notebook</a></h4>
<p>点击左下角的绿色 <strong>&gt;&lt;</strong> 符号，选择 <strong>Connect to Host</strong>：</p>
<figure class="screenshot">
  <img alt="vscode-connect" src="tasks/../assets/tasks/develop-and-test-model/use-notebook-remotely-via-ssh-connection/vscode-connect.png" />
</figure>
<p>然后选择 SSH Config 中对应的主机名（使用上述配置方式时，主机名为 <code>localhost</code>）：</p>
<figure class="screenshot">
  <img alt="vscode-connect-select" src="tasks/../assets/tasks/develop-and-test-model/use-notebook-remotely-via-ssh-connection/vscode-connect-select.png" />
</figure>
<p>VSCode 会新建一个窗口，等待连接建立之后，左下角会提示 <strong>SSH: Host</strong>。</p>
<aside class="note">
<div class="title">注意</div>
<p>第一次远程使用 Notebook 中时，需要等待 Notebook 下载 VS Code Server。根据网络情况不同，这一步骤可能耗时几分钟到十几分钟。</p>
</aside>
<p>点击 <strong>Open Folder</strong> 可以选择打开的目录或者文件。你可以和本地开发一样使用 VSCode 来操作 Notebook：</p>
<figure class="screenshot">
  <img alt="vscode-connected" src="tasks/../assets/tasks/develop-and-test-model/use-notebook-remotely-via-ssh-connection/vscode-connected.png" />
</figure>
<h3 id="使用-pycharm"><a class="header" href="#使用-pycharm">使用 PyCharm</a></h3>
<p>使用 PyCharm 远程连接到 Notebook 需要满足以下前提条件：</p>
<ol>
<li>安装了 PyCharm 专业版，且版本不低于 2022.2。PyCharm 有专业版（Professional）和社区版（Community），目前仅 PyCharm Professional 支持远程 SSH 开发。</li>
<li>Notebook 的资源配置至少为 3 个 CPU，3 GiB 内存，Notebook 绑定的持久卷至少有 2.5 GiB 的可用空间。推荐配置为至少 4 个 CPU，4 GiB 内存，5 GiB 持久卷。</li>
</ol>
<aside class="note info">
<div class="title">信息</div>
<p>使用 PyCharm 远程连接 Notebook 进行开发时，PyCharm 需要在 Notebook 容器中安装并运行一个 IDE Backend（参阅<a target="_blank" rel="noopener noreferrer" href="https://www.jetbrains.com/help/pycharm/remote-development-overview.html">官方文档</a>）。结合官方推荐的配置和实际测试，我们给出了上面的资源配置要求。</p>
</aside>
<p>打开 PyCharm，在左侧的导航菜单中点击 <strong>Remote Development &gt; SSH</strong>，然后点击右侧的 <strong>New Connection</strong>：</p>
<figure class="screenshot">
  <img alt="pycharm-ssh" src="tasks/../assets/tasks/develop-and-test-model/use-notebook-remotely-via-ssh-connection/pycharm-ssh.png" />
</figure>
<p>在弹出的对话框中填写如下参数：</p>
<ul>
<li><code>Username</code>：SSH 使用的用户名。</li>
<li><code>Host</code>：主机地址，通常为 <code>127.0.0.1</code>。</li>
<li><code>Port</code>：端口。</li>
<li><code>Specify private key</code>：建议勾选，并选择与你<a href="tasks/create-notebook.html#%E5%90%AF%E7%94%A8-ssh-%E9%80%89%E9%A1%B9">上传的公钥</a>对应的私钥。</li>
</ul>
<figure class="screenshot">
  <img alt="pycharm-connect" src="tasks/../assets/tasks/develop-and-test-model/use-notebook-remotely-via-ssh-connection/pycharm-connect.png" />
</figure>
<p>点击 <strong>Check Connection and Continue</strong>，进入下一步：</p>
<figure class="screenshot">
  <img alt="pycharm-connected" src="tasks/../assets/tasks/develop-and-test-model/use-notebook-remotely-via-ssh-connection/pycharm-connected.png" />
</figure>
<p>这里选择了在 Notebook 中安装的 IDE Backend 版本为 PyCharm 2022.2.3，远程打开的项目目录为 <code>/t9k/mnt</code>。点击 <strong>Download IDE and Connect</strong> 后，就可以通过 PyCharm 访问 Notebook 中的文件了。</p>
<aside class="note">
<div class="title">注意</div>
<p>第一次远程使用 Notebook 中时，需要等待 Notebook 下载 PyCharm IDE Backend。根据网络情况不同，这一步骤可能耗时几分钟到十几分钟。</p>
</aside>
<figure class="screenshot">
  <img alt="pycharm-edit" src="tasks/../assets/tasks/develop-and-test-model/use-notebook-remotely-via-ssh-connection/pycharm-edit.png" />
</figure>
<p>你可以和本地开发一样使用 PyCharm 来操作 Notebook：</p>
<h2 id="参考-7"><a class="header" href="#参考-7">参考</a></h2>
<ul>
<li><a href="https://code.visualstudio.com/docs/remote/ssh">https://code.visualstudio.com/docs/remote/ssh</a></li>
<li><a href="https://www.jetbrains.com/help/pycharm/remote-development-overview.html">https://www.jetbrains.com/help/pycharm/remote-development-overview.html</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="创建-tensorboard-1"><a class="header" href="#创建-tensorboard-1">创建 TensorBoard</a></h1>
<p>本教程演示如何创建 TensorBoard。</p>
<h2 id="准备工作-1"><a class="header" href="#准备工作-1">准备工作</a></h2>
<ul>
<li>了解 <a href="tasks/../modules/building/tensorboard.html">TensorBoard</a> 的基本概念。</li>
<li>成为一个<a href="tasks/../modules/security/project.html">项目</a>的管理员或<a href="tasks/./add-project-member.html">成员</a>。</li>
</ul>
<h2 id="运行示例"><a class="header" href="#运行示例">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/tensorboard">本教程对应的示例</a>，参照其 README 文档运行。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>上述操作使用 YAML 配置文件创建 TensorBoard，你也可以在模型构建控制台进行创建。</p>
</aside>
<h2 id="查看训练指标"><a class="header" href="#查看训练指标">查看训练指标</a></h2>
<p>TensorBoard 处于 <code>Running</code> 状态后，进入模型构建控制台的 TensorBoard 页面，可以看到 TensorBoard <code>tensorboard</code> 正在运行：</p>
<figure class="screenshot">
    <img alt="running" src="tasks/../assets/tasks/create-tensorboard/tensorboard-manage.png" />
</figure>
<p>点击 <strong>TensorBoard</strong> 右侧的 <strong>打开</strong> 进入 TensorBoard 页面，查看可视化展示的训练和验证指标：</p>
<figure class="screenshot">
    <img alt="tensorboard" src="tasks/../assets/tasks/create-tensorboard/tensorboard-open.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="构建镜像"><a class="header" href="#构建镜像">构建镜像</a></h1>
<p>本教程演示如何在平台上构建容器镜像（container image）并推送到指定的容器镜像仓库（container registry）。</p>
<h2 id="运行示例-1"><a class="header" href="#运行示例-1">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/build-image/build-image-on-platform">本教程对应的示例</a>，参照其 README 文档运行。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>上述操作使用 YAML 配置文件创建 Secret 和 Image Builder，你也可以在模型构建控制台进行创建。</p>
</aside>
<p>其中，创建包含身份信息的 Secret 这一步骤也可以在模型构建控制台中通过创建 <code>Docker</code> 类型的 Secret 来完成，如下图所示。详情请参阅<a href="tasks/../../guide/manage-auxiliary-resources/manage-secret.html#%E5%88%9B%E5%BB%BA-secret">创建 Secret</a>。</p>
<figure class="screenshot">
  <img alt="secret-form" src="tasks/../assets/tasks/build-image/secret-form.png" />
</figure>
<aside class="note tip">
<div class="title">提示</div>
<p><code>auth</code> 字段中填写的内容应为 <code>[username]:[password]</code> 经过 Base64 编码后的字符串。</p>
<p>在已填写 <code>auth</code> 字段的情况下，可以删除 <code>username</code> 和 <code>password</code> 这两个字段，仍然能起到身份认证的作用。</p>
</aside>
<h2 id="检查构建进度和结果"><a class="header" href="#检查构建进度和结果">检查构建进度和结果</a></h2>
<p>在模型构建控制台的左侧导航菜单中点击<strong>构建 &gt; Image Builder</strong>，然后点击刚创建的 Image Builder 右侧的<strong>详情</strong>，查看其详情和日志。拉取基础镜像、构建镜像和推送镜像都需要花费一定的时间，请耐心等待。</p>
<figure class="screenshot">
  <img alt="image-builder" src="tasks/../assets/tasks/build-image/image-builder.png" />
</figure>
<figure class="screenshot">
  <img alt="detail" src="tasks/../assets/tasks/build-image/detail.png" />
</figure>
<figure class="screenshot">
  <img alt="log" src="tasks/../assets/tasks/build-image/log.png" />
</figure>
<aside class="note">
<div class="title">注意</div>
<p>拉取和推送较大的镜像可能会花费较长的时间，取决于具体的网络情况，在这一过程中可能出现网络断线导致工作流失败。</p>
</aside>
<p>一段时间后，构建完成的镜像被推送到相应的 registry 中。</p>
<figure class="screenshot">
  <img alt="pushed-to-registry" src="tasks/../assets/tasks/build-image/pushed-to-registry.png" />
</figure>
<h2 id="faqs"><a class="header" href="#faqs">FAQs</a></h2>
<h3 id="unpacking-rootfs-失败"><a class="header" href="#unpacking-rootfs-失败"><code>Unpacking rootfs</code> 失败</a></h3>
<p>使用 ImageBuilder 制作镜像时，有时会出现类似以下的错误：</p>
<pre><code>INFO[0009] Unpacking rootfs as cmd RUN apt-get -qq update &amp;&amp;     apt-get -qq install --no-install-recommends -y curl requires it. 
error building image: error building stage: failed to get filesystem from image: stream error: stream ID 17; PROTOCOL_ERROR; received from peer
</code></pre>
<p>但是该错误信息并不准确，经分析，实际导致镜像 build 失败的可能原因是：镜像（Dockerfile 中 FROM 语句所引用的镜像）提取失败。</p>
<p>提取失败可能有以下原因：</p>
<ul>
<li>镜像来源于无法访问或下载速度过慢的仓库</li>
</ul>
<p>解决方法：</p>
<ol>
<li>切换到服务质量更好的的 Registry，例如本地网络部署的私有化 Registry，或其他 caching Regisry。</li>
<li>使用代理服务器，通过该代理下载镜像。</li>
</ol>
<aside class="note">
<div class="title">如何在 ImageBuilder 中使用代理服务器</div>
<p>可提供设置环境变量指定代理服务器。下面的 YAML 示例中，通过设置 <code>HTTPS_PROXY</code> 和 <code>HTTP_PROXY</code> 指定代理服务器地址为 <code>http://proxy.example.com:8080</code>。</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: ImageBuilder
metadata:
  name: build-image
spec:
  builder:
    kaniko: {}
  dockerConfig: {}
  tag: example.io/nanogpt:latest
  env:
  - name: HTTPS_PROXY
    value: http://proxy.example.com:8080
  - name: HTTP_PROXY
    value: http://proxy.example.com:8080
  workspace: {}
</code></pre>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="调试镜像"><a class="header" href="#调试镜像">调试镜像</a></h1>
<p>本教程演示如何方便地在模型构建控制台通过命令行进入一个镜像，以便对镜像进行探索和测试。</p>
<h2 id="准备工作-2"><a class="header" href="#准备工作-2">准备工作</a></h2>
<ul>
<li>成为一个<a href="tasks/../modules/security/project.html">项目</a>的管理员或<a href="tasks/./add-project-member.html">成员</a>。</li>
</ul>
<h2 id="示例-3"><a class="header" href="#示例-3">示例</a></h2>
<p>假设我们想知道镜像 <code>t9kpublic/tensorflow-2.11.0-notebook-cpu:1.70.0</code> 中安装了哪些 pip 包。</p>
<p>进入模型构建控制台后，点击<strong>构建 &gt; Pod</strong> 进入 Pod 管理页面。</p>
<figure class="screenshot">
  <img alt="pod-list" src="tasks/../assets/tasks/run-image/pod-list.png" />
</figure>
<p>点击右上角的<strong>创建</strong>以创建一个 Pod，执行 <code>sleep</code> 命令使镜像保持运行状态，以便我们连接镜像中的 <code>bash</code>（或 <code>sh</code>）终端。</p>
<figure class="screenshot">
  <img alt="pod-create" src="tasks/../assets/tasks/run-image/pod-create-1.png" />
</figure>
<figure class="screenshot">
  <img alt="pod-create" src="tasks/../assets/tasks/run-image/pod-create-2.png" />
</figure>
<p>分别填写项目名称、镜像名称、运行命令和资源使用量，然后点击<strong>创建</strong>。</p>
<figure class="screenshot">
  <img alt="pod-list-2" src="tasks/../assets/tasks/run-image/pod-list-2.png" />
</figure>
<p>所创建的 Pod 变为运行状态后，点击 Pod 名称进入 Pod 详情页面。</p>
<figure class="screenshot">
  <img alt="pod-detail" src="tasks/../assets/tasks/run-image/pod-detail.png" />
</figure>
<p>点击终端按钮，打开终端。</p>
<figure class="screenshot">
  <img alt="pod-terminal" src="tasks/../assets/tasks/run-image/pod-terminal.png" />
</figure>
<p>在打开的终端中，输入 <code>pip list</code> 显示该镜像中安装的所有 pip 包，或者输入其他任何命令。</p>
<p>最后，点击右上角的 <strong>X</strong> 关闭终端。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="管理-pvc"><a class="header" href="#管理-pvc">管理 PVC</a></h1>
<p>本教程演示如何在模型构建控制台中管理和使用 <a href="tasks/../modules/storage/pvc.html">PVC</a>。</p>
<h2 id="准备工作-3"><a class="header" href="#准备工作-3">准备工作</a></h2>
<ul>
<li>了解 PVC 的<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/zh/docs/concepts/storage/persistent-volumes/">概念</a>和 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/">Kubernetes API</a>。</li>
<li>成为一个<a href="tasks/../modules/security/project.html">项目</a>的管理员或<a href="tasks/./add-project-member.html">成员</a>。</li>
</ul>
<h2 id="创建-pvc-3"><a class="header" href="#创建-pvc-3">创建 PVC</a></h2>
<p>进入模型构建控制台，在左侧导航菜单（或右侧卡片）中点击<strong>存储 &gt; 持久卷</strong>进入 PVC 管理页面。</p>
<figure class="screenshot">
  <img alt="overview-pvc" src="tasks/../assets/tasks/manage-pvc/overview-pvc.png" />
</figure>
<p>点击 PVC 管理页面右上角的<strong>创建 PersistentVolumeClaim</strong> 进入 PVC 创建页面。</p>
<figure class="screenshot">
  <img alt="create-pvc" src="tasks/../assets/tasks/manage-pvc/create-pvc.png" />
</figure>
<p>在 PVC 创建页面填写名称和存储卷大小，选择存储卷访问模式和存储类，然后点击<strong>创建</strong>。</p>
<figure class="screenshot">
  <img alt="create-pvc-detail" src="tasks/../assets/tasks/manage-pvc/create-pvc-detail.png" />
</figure>
<p>你可以点击左上角的<strong>导入 PersistentVolumeClaim</strong> 以加载当前存在的 PVC 的配置。</p>
<h2 id="删除-pvc"><a class="header" href="#删除-pvc">删除 PVC</a></h2>
<p>在 PVC 管理页面，点击要删除的 PVC 右侧的<strong>更多按钮 &gt; 删除</strong>。</p>
<figure class="screenshot">
  <img alt="delete-pvc" src="tasks/../assets/tasks/manage-pvc/delete-pvc.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-explorer"><a class="header" href="#使用-explorer">使用 Explorer</a></h1>
<p>本教程演示如何使用 <a href="tasks/../modules/storage/explorer.html">Explorer</a> 查看和修改存储在 PVC 和 StorageShim 中的文件。</p>
<h2 id="启动-explorer"><a class="header" href="#启动-explorer">启动 Explorer</a></h2>
<p>在模型构建控制台的左侧导航菜单中点击<strong>存储 &gt; 持久卷</strong>进入 PVC 管理页面，点击 PVC 右侧的<strong>启动</strong>：</p>
<figure class="screenshot">
  <img alt="start-explorer" src="tasks/../assets/tasks/use-explorer/start-explorer.png" />
</figure>
<aside class="note tip">
<div class="title">提示</div>
<p>若要启动 StorageShim 的 Explorer，勾选<strong>展示 StorageShim PVC</strong>，然后点击相应 PVC 右侧的<strong>启动</strong>即可。</p>
</aside>
<p>将光标悬停在<strong>打开</strong>上，等待 File Browser 和 VS Code 就绪。随后点击 <strong>File Browser</strong> 和 <strong>VS Code</strong> 即可进入。</p>
<figure class="screenshot">
  <img alt="enter" src="tasks/../assets/tasks/use-explorer/enter.png" />
</figure>
</aside>
<h2 id="使用-file-browser"><a class="header" href="#使用-file-browser">使用 File Browser</a></h2>
</aside>
<aside class="note info">
<div class="title">File Browser</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://filebrowser.org">File Browser </a> 提供了一个在指定目录内的文件管理界面，它可以用来上传、删除、预览、重命名和编辑文件。它可以作为一个独立的应用程序使用。</p>
</aside>
<p>进入 File Browser 的前端页面，我们可以看到 PVC 中的所有文件和目录：</p>
<figure class="screenshot">
  <img alt="file-browser" src="tasks/../assets/tasks/use-explorer/file-browser.png" />
</figure>
<p>这里支持以下操作：</p>
<ul>
<li>浏览目录和文本文件</li>
<li>创建、删除、重命名、复制、移动目录和文件</li>
<li>上传、下载文件</li>
<li>修改文本文件</li>
</ul>
<h2 id="使用-vs-code"><a class="header" href="#使用-vs-code">使用 VS Code</a></h2>
</aside>
<aside class="note info">
<div class="title">VS Code for the Web</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://code.visualstudio.com/docs/editor/vscode-web">VS Code for the Web</a> 提供了一个免费的、无需安装的 VS Code 体验，完全在浏览器中运行，允许你快速安全地浏览源代码库并进行轻量级代码更改。</p>
<p>VS Code for the Web 拥有 VS Code 桌面版的许多功能，包括在浏览和编辑时的搜索和语法高亮显示，以及支持扩展以便于你处理代码库和进行简单编辑。除了可以打开来自 GitHub 等源代码控制提供商的代码库、分支和拉取请求外，你还可以处理存储在本地计算机上的代码。</p>
</aside>
<p>进入 File Browser 的前端页面，我们可以看到 PVC 中的所有文件和目录：</p>
<figure class="screenshot">
  <img alt="vs-code" src="tasks/../assets/tasks/use-explorer/vs-code.png" />
</figure>
<p>这里支持以下操作：</p>
<ul>
<li>浏览目录和文本文件</li>
<li>创建、删除、重命名、复制、移动目录和文件</li>
<li>修改文本文件，进行轻量级代码修改</li>
<li>启动终端并执行命令</li>
<li>进行源代码控制</li>
<li>安装 VS Code 插件</li>
</ul>
<h2 id="暂停和关闭-explorer"><a class="header" href="#暂停和关闭-explorer">暂停和关闭 Explorer</a></h2>
<p>使用结束后，我们可以<strong>关闭</strong> Explorer。之后重新启用即可。</p>
<figure class="screenshot">
  <img alt="pause-close-explorer" src="tasks/../assets/tasks/use-explorer/pause-close-explorer.png" />
</figure>
</aside>
<aside class="note tip">
<div class="title">暂停 Explorer</div>
<p>平台的<a href="tasks/../modules/scheduling/reclaim.html">资源回收</a>机制会自动暂停空闲时间达到规定值的 Explorer。被暂停的 Explorer 可以被手动恢复。</p>
<p>对于用户而言，手动暂停 Explorer 和关闭 Explorer 的区别不大。</p>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-storageshim-适配-s3-服务"><a class="header" href="#使用-storageshim-适配-s3-服务">使用 StorageShim 适配 S3 服务</a></h1>
<h2 id="概述-4"><a class="header" href="#概述-4">概述</a></h2>
<p>TensorStack AI 平台支持用户在多个环节使用 <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Amazon_S3">S3 协议</a>的存储服务。本教程演示如何通过 StorageShim 把 S3 存储服务转换成 PVC，以方便在一些需要使用 POSIX 文件系统接口的场景。</p>
<aside class="note info">
<div class="title"> 注意</div>
<p>通过 PVC 使用 S3 仅是为了方便而提供的一个机制。用户应当意识到这种方式的缺点：</p>
<ul>
<li>性能受影响；通过 StorageShim 提供的转换机制使用 S3 服务有性能损失；如果性能对用户的使用场景极端重要，需要考虑使用：
<ol>
<li>S3 原生的 API 直接访问 S3 存储服务；</li>
<li>直接使用集群提供的共享文件系统服务;</li>
</ol>
</li>
<li>不完整的 POSIX 文件系统语义；这种转换方式提供的 API 并不是支持所有的 POSIX 文件系统 API。</li>
</ul>
</aside>
<p>本教程涉及如下基本概念：</p>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://aws.amazon.com/cn/s3/"><strong>S3（Simple Storage Service）</strong></a>提供可扩展、安全、高可用的对象存储服务，可以存储和检索任意数量和类型的数据，包括文档、图片、视频、音频等。更多详细信息请参阅<a href="tasks/use-storageshim-s3.html#%E9%99%84%E5%BD%95">附录</a>。</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/"><strong>PVC（PersistentVolumeClaim）</strong></a>是 Kubernetes 提供的一种声明式的存储卷请求，用于向 Kubernetes 集群申请持久化存储卷。PVC 使应用程序与存储资源解耦，提高了存储资源的管理和使用效率。</li>
<li><strong>StorageShim</strong> 提供了把 S3 服务转换为 PVC 的能力，让用户能够以 Kubernetes 原生的方式使用 S3。</li>
</ul>
<h2 id="详细过程"><a class="header" href="#详细过程">详细过程</a></h2>
<p>要访问 S3 服务，需要提供使用其服务的相应配置，包括：</p>
<ul>
<li>S3 访问凭证：用于访问 S3 服务的一组密钥，包括访问密钥（access key）和秘密访问密钥（secret key）。S3 访问凭证是必需的，以在访问 S3 服务时进行身份验证和授权。</li>
<li>S3 服务的终端地址（endpoint）：HTTP 或 HTTPS 格式的地址，例如：<code>http://100.1.1.2:8000</code>。</li>
<li>S3 bucket：存储用户数据的容器；访问特定的 bucket 需要有合适权限的访问凭证。</li>
</ul>
<h3 id="准备-s3-配置"><a class="header" href="#准备-s3-配置">准备 S3 配置</a></h3>
<p>以下面的格式准备一个名为 <code>s3cfg</code> 的文件：</p>
<pre><code>[default]
# Setup access keys
access_key = &lt;you-access-key&gt;
secret_key = &lt;your-secret-key&gt;

# Setup endpoint
host_base = http[s]://&lt;host-or-ip&gt;:&lt;port&gt;
use_https = &lt;False | True&gt;
</code></pre>
<p>其中需要修改的内容包括：</p>
<ul>
<li><code>access_key</code>：你的访问密钥（access key）。</li>
<li><code>secret_key</code>：你的秘密访问密钥（secret key）。</li>
<li><code>host_base</code>：S3 服务的地址（endpoint）。</li>
<li><code>use_https</code>：是否使用 HTTPS。</li>
</ul>
<p>你可以<a href="tasks/use-storageshim-s3.html#s3-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8s3cmd">安装 s3cmd</a>，在本地运行命令来验证 s3cfg 是否正确配置：</p>
<pre><code class="language-shell">s3cmd -c s3cfg ls s3://&lt;my-bucket&gt;
</code></pre>
<h3 id="创建-secret-1"><a class="header" href="#创建-secret-1">创建 Secret</a></h3>
<h4 id="通过控制台"><a class="header" href="#通过控制台">通过控制台</a></h4>
<p>进入模型构建控制台，选择左侧导航菜单的<strong>辅助 &gt; Secret</strong>，点击<strong>创建 Secret</strong>。</p>
<p>选择类型为 <strong>S3-cfg</strong>，填写名称，然后填写 Details 的内容：</p>
<ul>
<li>服务端点：S3 服务的地址（endpoint）</li>
<li>Access Key ID：你的访问密钥（access key）。</li>
<li>密码：你的秘密访问密钥（secret key）。</li>
</ul>
<p>最后点击<strong>创建 Secret</strong>：</p>
<figure class="screenshot">
  <img alt="create-pvc-s3cfg.png" src="tasks/../assets/tasks/manage-storageshim/create-pvc-s3cfg.png" />
</figure>
<h4 id="通过命令行工具"><a class="header" href="#通过命令行工具">通过命令行工具</a></h4>
<p>用户也可以使用 <code>kubectl</code> 命令行工具创建 Secret：</p>
<pre><code class="language-shell">kubectl -n &lt;project&gt; create secret generic &lt;s3cfg-secret&gt; \
  --from-file=.s3cfg=&lt;s3cfg&gt;
</code></pre>
<p>其中需要修改的内容包括：</p>
<ul>
<li><code>&lt;project&gt;</code>：项目名称。</li>
<li><code>&lt;s3cfg-secret&gt;</code>：Secret 的名称。</li>
<li><code>&lt;s3cfg&gt;</code>：本地 <code>s3cfg</code> 文件的路径。前面的 <code>--from-file=.s3cfg=</code> 不需要修改。</li>
</ul>
<h4 id="验证"><a class="header" href="#验证">验证</a></h4>
<p>运行以下命令，查看 Secret 中保存的 <code>.s3cfg</code> 内容：</p>
<pre><code class="language-shell">kubectl -n &lt;project&gt; get secret &lt;s3cfg-secret&gt; \
    -o jsonpath={.data.&quot;\.s3cfg&quot;} | base64 -d
</code></pre>
<p>其中需要修改的内容包括：</p>
<ul>
<li><code>&lt;project&gt;</code>：项目名称。</li>
<li><code>&lt;s3cfg-secret&gt;</code>：Secret 的名称。</li>
</ul>
<p>对比输出内容与你本地的 <code>s3cfg</code>，确认内容一致，重点是 <code>access_key</code>、<code>host_base</code> 和 <code>secret_key</code> 字段。</p>
<h3 id="创建-storageshim-1"><a class="header" href="#创建-storageshim-1">创建 StorageShim</a></h3>
<h4 id="通过控制台-1"><a class="header" href="#通过控制台-1">通过控制台</a></h4>
<p>进入模型构建控制台，选择左侧导航菜单的<strong>存储 &gt; 持久卷</strong>，点击上方的 S3，然后点击右上角的<strong>创建 StorageShim</strong>：</p>
<figure class="screenshot">
  <img alt="view-storageshim.png" src="tasks/../assets/tasks/manage-storageshim/view-storageshim.png" />
</figure>
<p>输入持久卷名称、S3 URI（<code>s3://&lt;your-bucket&gt;</code>），然后选择 S3 Secret 名称，最后点击右上角的<strong>创建 StorageShim</strong> 完成创建：</p>
<figure class="screenshot">
  <img alt="create-storageshim.png" src="tasks/../assets/tasks/manage-storageshim/create-storageshim.png" />
</figure>
<p>在 S3 标签页查看新创建的 StorageShim：</p>
<figure class="screenshot">
  <img alt="new-storageshim.png" src="tasks/../assets/tasks/manage-storageshim/new-storageshim.png" />
</figure>
<h4 id="通过命令行工具-1"><a class="header" href="#通过命令行工具-1">通过命令行工具</a></h4>
<p>使用以下命令创建 StorageShim 类型的 PVC：</p>
<pre><code class="language-shell">kubectl -n &lt;project&gt; create -f - &lt;&lt;EOF
apiVersion: tensorstack.dev/v1beta1
kind: StorageShim
metadata:
  name: dataset
spec:
  readOnly: false
  s3:
    uri: 's3://42a3de90-d9e7-4769-8fc4-48a65fb561d5'
  secretRef:
    name: s3cfg-secret
EOF
</code></pre>
<p>其中需要修改的内容包括：</p>
<ul>
<li><code>&lt;project&gt;</code>：项目名称。</li>
<li><code>.spec.s3.uri</code>：S3 bucket 的路径，你也可以具体指定 bucket 中的一个文件夹。</li>
<li><code>.spec.secretRef.name</code>：保存 S3 凭证的 Secret 名称。</li>
<li><code>readOnly</code>：如果为 true，那么用户只能读取这个 StorageShim 的内容，而不能修改它。</li>
</ul>
<p>查看 PVC 状态，确认 STATUS 为 Bound：</p>
<pre><code class="language-shell">$ kubectl -n &lt;project&gt; get pvc
NAME                STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS     AGE
dataset             Bound    pvc-cc7f789a-6fcb-44a0-8f42-0e6c86e51a1a   1          RWX            csi-s3           4m5s
</code></pre>
<h2 id="附录"><a class="header" href="#附录">附录</a></h2>
<h3 id="s3-基本概念"><a class="header" href="#s3-基本概念">S3 基本概念</a></h3>
<p>S3（Simple Storage Service）提供了可扩展、安全、高可用的对象存储服务，可以存储和检索任意数量和类型的数据，包括文档、图片、视频、音频等。</p>
<p>S3 使用：</p>
<ul>
<li>Bucket：Bucket 是 S3 存储中的基本容器，类似于文件夹，用于存储和组织对象。每个 Bucket 必须具有唯一的名称，并且名称必须符合 DNS 命名规则。</li>
<li>Object：Object 是 S3 存储中的基本数据单元，可以是任意类型的数据，例如文档、图片、视频、音频等。每个 Object 由一个唯一的键（Key）和一个值（Value）组成，键是 Object 在 Bucket 中的唯一标识符，值是 Object 的实际数据。</li>
</ul>
<p>S3 管理：</p>
<ul>
<li>Region：Region 是 S3 存储的物理位置，用于指定 Bucket 存储的地理位置。每个 Region 都由多个可用区域（Availability Zone）组成，以提供高可用性和容错性。</li>
<li>ACL：ACL（Access Control List）是 S3 存储的访问控制列表，用于控制 Bucket 和 Object 的访问权限。ACL 可以指定特定用户或组的访问权限，也可以指定公共访问权限。</li>
<li>Versioning：Versioning 是 S3 存储的版本控制功能，用于保留 Object 的所有版本。启用版本控制后，每次更新 Object 时都会创建一个新版本，并可以通过指定版本号来访问特定版本的 Object。</li>
<li>Lifecycle：Lifecycle 是 S3 存储的生命周期管理功能，用于自动化管理 Bucket 和 Object 的生命周期。Lifecycle 可以指定 Object 的存储期限、转换存储类别、自动删除 Object 等操作，以优化存储成本和管理效率。</li>
</ul>
<h3 id="s3-基本使用s3cmd"><a class="header" href="#s3-基本使用s3cmd">S3 基本使用：s3cmd</a></h3>
<p>有多种工具（s3browser、WinSCP、s3cmd、s5cmd、rclone 等）可以访问 S3 存储服务，以下使用 s3cmd 演示 S3 的基本操作：</p>
<p>安装 s3cmd 工具：在 Linux 系统中使用命令行安装 s3cmd 工具，例如在 Ubuntu 系统中可以使用以下命令进行安装：</p>
<pre><code class="language-shell">sudo apt-get install s3cmd
</code></pre>
<p>配置 s3cmd 工具：在命令行中执行 <code>s3cmd --configure</code> 命令，按照提示输入 S3 访问密钥和秘密访问密钥，以及 S3 服务的访问地址和区域等参数，完成 s3cmd 工具的配置。</p>
<p>创建 S3 存储桶：使用 s3cmd mb 命令创建 S3 存储桶，例如：</p>
<pre><code class="language-shell">s3cmd mb s3://my-bucket-name
</code></pre>
<p>上传对象：使用 s3cmd put 命令上传对象到 S3 存储桶中，例如：</p>
<pre><code class="language-shell">s3cmd put /path/to/local/file s3://my-bucket-name/path/to/remote/file
</code></pre>
<p>下载对象：使用 s3cmd get 命令从 S3 存储桶中下载对象到本地，例如：</p>
<pre><code class="language-shell">s3cmd get s3://my-bucket-name/path/to/remote/file /path/to/local/file
</code></pre>
<p>删除对象：使用 s3cmd del 命令从 S3 存储桶中删除对象，例如：</p>
<pre><code class="language-shell">s3cmd del s3://my-bucket-name/path/to/remote/file
</code></pre>
<p>设置对象 ACL：使用 s3cmd setacl 命令设置对象的 ACL，例如：</p>
<pre><code class="language-shell">s3cmd setacl --acl-public s3://my-bucket-name/path/to/remote/file
</code></pre>
<h3 id="对象存储object-storage"><a class="header" href="#对象存储object-storage">对象存储（object storage）</a></h3>
<p><a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Object_storage">对象存储</a>是一种将数据存储为对象的数据存储架构，这与文件系统将数据作为文件层次结构进行管理不同。 每个对象通常包括数据本身（object）、元数据（metadata）和全局唯一标识符（object key）。</p>
<p>对象存储是存储海量非结构化数据（例如图像、视频和文档）的不错选择，例如大规模机器学习中使用的海量训练数据、特征、模型等。</p>
<p>与其他存储架构相比，对象存储具有许多优势，包括：</p>
<ul>
<li>可扩展性：对象存储可以轻松扩展以满足不断增长的应用程序的需求。</li>
<li>耐用性：对象存储被设计成高度耐用的，数据以冗余方式存储在多个位置。</li>
<li>可用性：对象存储旨在提供高可用性，可以从世界任何地方访问数据。</li>
<li>安全性：对象存储提供了许多安全功能，包括加密和访问控制。</li>
</ul>
<p>对象存储是一种强大而灵活的数据存储架构，是存储大量非结构化数据、需要从多个位置访问的数据以及需要高可用性和安全性的数据的不错选择。</p>
<h2 id="参考-8"><a class="header" href="#参考-8">参考</a></h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Amazon_S3">Wikipedia: S3 协议</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Object_storage">Wikipedia: 对象存储</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://aws.amazon.com/cn/s3/">AWS: S3 (Simple Storage Service)</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">Kubernetes: PVC(PersistentVolumeClaim)</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="管理-secret"><a class="header" href="#管理-secret">管理 Secret</a></h1>
<p>本教程演示如何在模型构建控制台中管理和使用 <a href="tasks/../modules/auxiliary/secret.html">Secret</a>。</p>
<h2 id="准备工作-4"><a class="header" href="#准备工作-4">准备工作</a></h2>
<ul>
<li>了解 Secret 的<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/zh/docs/concepts/configuration/secret/">概念</a>和 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/secret-v1/">Kubernetes API</a>。</li>
<li>成为一个<a href="tasks/../modules/security/project.html">项目</a>的管理员或<a href="tasks/./add-project-member.html">成员</a>。</li>
</ul>
<h2 id="创建-secret-2"><a class="header" href="#创建-secret-2">创建 Secret</a></h2>
<p>进入模型构建控制台，在左侧导航菜单（或右侧卡片）中点击<strong>辅助 &gt; Secret</strong> 进入 Secret 管理页面。</p>
<figure class="screenshot">
  <img alt="overview-secret" src="tasks/../assets/tasks/manage-secret/overview-secret.png" />
</figure>
<p>点击 Secret 管理页面右上角的<strong>创建 Secret</strong> 进入 Secret 创建页面。</p>
<figure class="screenshot">
  <img alt="create-secret" src="tasks/../assets/tasks/manage-secret/create-secret.png" />
</figure>
<p>在 Secret 创建页面选择模板，填写名称和要存储的数据，然后点击<strong>创建</strong>。</p>
<figure class="screenshot">
  <img alt="create-secret-detail" src="tasks/../assets/tasks/manage-secret/create-secret-detail.png" />
</figure>
<aside class="note info">
<div class="title">Secret 模板</div>
<p>这里所提供的多种 Secret 模板分别适用于存储不同类型的敏感数据，其中自定义模板支持扩展以适应各种需求。</p>
<p>Secret 存储的数据类型是通过其标签进行识别的。</p>
</aside>
<p>你可以点击左上角的<strong>导入 Secret</strong> 以加载当前存在的 Secret 的配置。</p>
<h2 id="删除-secret"><a class="header" href="#删除-secret">删除 Secret</a></h2>
<p>在 Secret 管理页面，点击要删除的 Secret 右侧的<strong>更多按钮 &gt; 删除</strong>。</p>
<figure class="screenshot">
  <img alt="delete-secret" src="tasks/../assets/tasks/manage-secret/delete-secret.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="管理-configmap"><a class="header" href="#管理-configmap">管理 ConfigMap</a></h1>
<p>本教程演示如何在模型构建控制台中管理和使用 <a href="tasks/../modules/auxiliary/configmap.html">ConfigMap</a>。</p>
<h2 id="准备工作-5"><a class="header" href="#准备工作-5">准备工作</a></h2>
<ul>
<li>了解 ConfigMap 的<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/zh/docs/concepts/configuration/configmap/">概念</a>和 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/kubernetes-api/config-and-storage-resources/config-map-v1/">Kubernetes API</a>。</li>
<li>成为一个<a href="tasks/../modules/security/project.html">项目</a>的管理员或<a href="tasks/./add-project-member.html">成员</a>。</li>
</ul>
<h2 id="创建-configmap-1"><a class="header" href="#创建-configmap-1">创建 ConfigMap</a></h2>
<p>进入模型构建控制台，在左侧导航菜单（或右侧卡片）中点击<strong>辅助 &gt; ConfigMap</strong> 进入 ConfigMap 管理页面。</p>
<figure class="screenshot">
  <img alt="overview-configmap" src="tasks/../assets/tasks/manage-configmap/overview-configmap.png" />
</figure>
<p>点击 ConfigMap 管理页面右上角的<strong>创建 ConfigMap</strong> 进入 ConfigMap 创建页面。</p>
<figure class="screenshot">
  <img alt="create-configmap" src="tasks/../assets/tasks/manage-configmap/create-configmap.png" />
</figure>
<p>在 ConfigMap 创建页面填写名称、标签和要存储的数据，然后点击<strong>创建</strong>。</p>
<figure class="screenshot">
  <img alt="create-configmap-detail" src="tasks/../assets/tasks/manage-configmap/create-configmap-detail.png" />
</figure>
<p>你可以点击左上角的<strong>导入 ConfigMap</strong> 以加载当前存在的 ConfigMap 的配置。</p>
<h2 id="删除-configmap"><a class="header" href="#删除-configmap">删除 ConfigMap</a></h2>
<p>在 ConfigMap 管理页面，点击要删除的 ConfigMap 右侧的<strong>更多按钮 &gt; 删除</strong>。</p>
<figure class="screenshot">
  <img alt="delete-configmap" src="tasks/../assets/tasks/manage-configmap/delete-configmap.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="运行模型训练"><a class="header" href="#运行模型训练">运行模型训练</a></h1>
<p>这一部分演示如何使用 <a href="tasks/../modules/jobs/index.html">T9k Job</a> 运行不同机器学习框架的模型训练任务。对于常用的机器学习框架，如 PyTorch、TensorFlow、Horovod，你都可以在这里找到相应的教程来帮助你开始训练模型。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-pytorchtrainingjob-进行数据并行训练"><a class="header" href="#使用-pytorchtrainingjob-进行数据并行训练">使用 PyTorchTrainingJob 进行数据并行训练</a></h1>
<p>本教程演示如何使用 PyTorchTrainingJob 对 PyTorch 模型进行多工作器同步训练（使用 <a target="_blank" rel="noopener noreferrer" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html"><code>torch.nn.parallel.DistributedDataParallel</code></a> 分布式数据并行模块）。</p>
<h2 id="运行示例-2"><a class="header" href="#运行示例-2">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/job/pytorchtrainingjob/ddp">本教程对应的示例</a>，参照其 README 文档运行。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>上述操作使用 YAML 配置文件创建 PyTorchTrainingJob，你也可以在模型构建控制台进行创建。</p>
</aside>
<h2 id="检查训练日志和指标"><a class="header" href="#检查训练日志和指标">检查训练日志和指标</a></h2>
<p>训练开始后，进入模型构建控制台的 Job 页面，可以看到名为 <strong>torch-mnist-trainingjob</strong> 的 PyTorchTrainingJob 正在运行：</p>
<figure class="screenshot">
    <img alt="running" src="tasks/../assets/tasks/run-distributed-training/pytorch/ddp-training/running.png" />
</figure>
<p>点击<strong>该名称</strong>进入详情页面，可以看到刚才创建的 PyTorchTrainingJob 的基本信息、状况信息和事件信息：</p>
<figure class="screenshot">
    <img alt="details" src="tasks/../assets/tasks/run-distributed-training/pytorch/ddp-training/details.png" />
</figure>
<p>点击 <strong>TensorBoard</strong> 右侧的 <strong>Running</strong> 打开 TensorBoard，可以查看可视化展示的训练和验证指标：</p>
<figure class="screenshot">
    <img alt="tensorboard" src="tasks/../assets/tasks/run-distributed-training/pytorch/ddp-training/tensorboard.png" />
</figure>
<p>点击上方标签页的<strong>副本</strong>，查看 PyTorchTrainingJob 的 Pod 信息：</p>
<figure class="screenshot">
    <img alt="replicas" src="tasks/../assets/tasks/run-distributed-training/pytorch/ddp-training/replicas.png" />
</figure>
<p>点击副本右侧的<strong>更多按钮 &gt; 日志</strong>以查看训练脚本执行过程中的日志输出：</p>
<figure class="screenshot">
    <img alt="view-log" src="tasks/../assets/tasks/run-distributed-training/pytorch/ddp-training/view-log.png" />
</figure>
<p>点击上方标签页的<strong>资源监测</strong>，查看 PyTorchTrainingJob 运行过程中使用集群计算资源、网络资源和存储资源的情况：</p>
<figure class="screenshot">
    <img alt="replicas" src="tasks/../assets/tasks/run-distributed-training/pytorch/ddp-training/metrics.png" />
</figure>
<p>一段时间之后，PyTorchTrainingJob 的状态变为 <strong>Succeeded</strong>，表示训练成功完成。</p>
<figure class="screenshot">
    <img alt="done" src="tasks/../assets/tasks/run-distributed-training/pytorch/ddp-training/done.png" />
</figure>
<p>若 PyTorchTrainingJob 在运行过程中出错，其状态会变为 <strong>Error</strong>，并在事件信息和 Pod 信息部分显示错误信息，此时需要根据给出的错误信息进行问题排查。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>除了上述方法外，你也可以在 Notebook 中直接使用 <code>kubectl</code> 命令查看 PyTorchTrainingJob 以及其下各个 Pod 的状态、基本信息、事件、日志等以检查训练的进度和结果。</p>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-pytorchtrainingjob-进行参数服务器训练"><a class="header" href="#使用-pytorchtrainingjob-进行参数服务器训练">使用 PyTorchTrainingJob 进行参数服务器训练</a></h1>
<p>本教程演示如何使用 PyTorchTrainingJob 对 PyTorch 模型进行基于 RPC 的参数服务器训练（使用<a target="_blank" rel="noopener noreferrer" href="https://pytorch.org/docs/stable/rpc.html">分布式 RPC 框架 <code>torch.distributed.rpc</code></a>）。示例修改自 PyTorch 官方教程 <a target="_blank" rel="noopener noreferrer" href="https://pytorch.org/tutorials/intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a>，关于训练脚本的更多细节信息请参考此教程。</p>
<h2 id="运行示例-3"><a class="header" href="#运行示例-3">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/job/pytorchtrainingjob/ps">本教程对应的示例</a>，参照其 README 文档运行。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>上述操作使用 YAML 配置文件创建 PyTorchTrainingJob，你也可以在模型构建控制台进行创建。</p>
</aside>
<h2 id="检查训练日志和指标-1"><a class="header" href="#检查训练日志和指标-1">检查训练日志和指标</a></h2>
<p>训练开始后，进入模型构建控制台的 Job 页面，可以看到名为 <strong>torch-mnist-trainingjob-ps</strong> 的 PyTorchTrainingJob 正在运行：</p>
<figure class="screenshot">
    <img alt="running" src="tasks/../assets/tasks/run-distributed-training/pytorch/rpc-implemented-parameter-server-training/running.png" />
</figure>
<p>点击<strong>该名称</strong>进入详情页面，可以看到刚才创建的 PyTorchTrainingJob 的基本信息、状况信息和事件信息：</p>
<figure class="screenshot">
    <img alt="details" src="tasks/../assets/tasks/run-distributed-training/pytorch/rpc-implemented-parameter-server-training/details.png" />
</figure>
<p>点击 <strong>TensorBoard</strong> 右侧的 <strong>Running</strong> 打开 TensorBoard，可以查看可视化展示的训练和验证指标：</p>
<figure class="screenshot">
    <img alt="tensorboard" src="tasks/../assets/tasks/run-distributed-training/pytorch/rpc-implemented-parameter-server-training/tensorboard.png" />
</figure>
<p>点击上方标签页的<strong>副本</strong>，查看 PyTorchTrainingJob 的 Pod 信息：</p>
<figure class="screenshot">
    <img alt="replicas" src="tasks/../assets/tasks/run-distributed-training/pytorch/rpc-implemented-parameter-server-training/replicas.png" />
</figure>
<p>点击副本右侧的<strong>更多按钮 &gt; 日志</strong>以查看训练脚本执行过程中的日志输出：</p>
<figure class="screenshot">
    <img alt="view-log" src="tasks/../assets/tasks/run-distributed-training/pytorch/rpc-implemented-parameter-server-training/view-log.png" />
</figure>
<p>点击上方标签页的<strong>资源监测</strong>，查看 PyTorchTrainingJob 运行过程中使用集群计算资源、网络资源和存储资源的情况：</p>
<figure class="screenshot">
    <img alt="replicas" src="tasks/../assets/tasks/run-distributed-training/pytorch/rpc-implemented-parameter-server-training/metrics.png" />
</figure>
<p>一段时间之后，PyTorchTrainingJob 的状态变为 <strong>Succeeded</strong>，表示训练成功完成。</p>
<figure class="screenshot">
    <img alt="done" src="tasks/../assets/tasks/run-distributed-training/pytorch/rpc-implemented-parameter-server-training/done.png" />
</figure>
<p>若 PyTorchTrainingJob 在运行过程中出错，其状态会变为 <strong>Error</strong>，并在事件信息和 Pod 信息部分显示错误信息，此时需要根据给出的错误信息进行问题排查。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>除了上述方法外，你也可以在 Notebook 中直接使用 <code>kubectl</code> 命令查看 PyTorchTrainingJob 以及其下各个 Pod 的状态、基本信息、事件、日志等以检查训练的进度和结果。</p>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-tensorflowtrainingjob-进行数据并行训练"><a class="header" href="#使用-tensorflowtrainingjob-进行数据并行训练">使用 TensorFlowTrainingJob 进行数据并行训练</a></h1>
<p>本教程演示如何使用 TensorFlowTrainingJob 对 Keras 模型进行数据并行训练（采用 <a target="_blank" rel="noopener noreferrer" href="https://www.tensorflow.org/api_docs/python/tf/distribute/MultiWorkerMirroredStrategy"><code>tf.distribute.MultiWorkerMirroredStrategy</code></a> 分布式策略）。</p>
<h2 id="运行示例-4"><a class="header" href="#运行示例-4">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/job/tensorflowtrainingjob/multiworker">本教程对应的示例</a>，参照其 README 文档运行。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>上述操作使用 YAML 配置文件创建 TensorFlowTrainingJob，你也可以在模型构建控制台进行创建。</p>
</aside>
<h2 id="检查训练日志和指标-2"><a class="header" href="#检查训练日志和指标-2">检查训练日志和指标</a></h2>
<p>训练开始后，进入模型构建控制台的 Job 页面，可以看到名为 <strong>keras-mnist-trainingjob</strong> 的 TensorFlowTrainingJob 正在运行：</p>
<figure class="screenshot">
    <img alt="running" src="tasks/../assets/tasks/run-distributed-training/tensorflow/multiworker-training/running.png" />
</figure>
<p>点击<strong>该名称</strong>进入详情页面，可以看到刚才创建的 TensorFlowTrainingJob 的基本信息、状况信息和事件信息：</p>
<figure class="screenshot">
    <img alt="details" src="tasks/../assets/tasks/run-distributed-training/tensorflow/multiworker-training/details.png" />
</figure>
<p>点击 <strong>TensorBoard</strong> 右侧的 <strong>Running</strong> 打开 TensorBoard，可以查看可视化展示的训练和验证指标：</p>
<figure class="screenshot">
    <img alt="tensorboard" src="tasks/../assets/tasks/run-distributed-training/tensorflow/multiworker-training/tensorboard.png" />
</figure>
<p>点击上方标签页的<strong>副本</strong>，查看 TensorFlowTrainingJob 的 Pod 信息：</p>
<figure class="screenshot">
    <img alt="replicas" src="tasks/../assets/tasks/run-distributed-training/tensorflow/multiworker-training/replicas.png" />
</figure>
<p>点击副本右侧的<strong>更多按钮 &gt; 日志</strong>以查看训练脚本执行过程中的日志输出：</p>
<figure class="screenshot">
    <img alt="view-log" src="tasks/../assets/tasks/run-distributed-training/tensorflow/multiworker-training/view-log.png" />
</figure>
<p>点击上方标签页的<strong>资源监测</strong>，查看 TensorFlowTrainingJob 运行过程中使用集群计算资源、网络资源和存储资源的情况：</p>
<figure class="screenshot">
    <img alt="replicas" src="tasks/../assets/tasks/run-distributed-training/tensorflow/multiworker-training/metrics.png" />
</figure>
<p>一段时间之后，TensorFlowTrainingJob 的状态变为 <strong>Succeeded</strong>，表示训练成功完成。</p>
<figure class="screenshot">
    <img alt="done" src="tasks/../assets/tasks/run-distributed-training/tensorflow/multiworker-training/done.png" />
</figure>
<p>若 TensorFlowTrainingJob 在运行过程中出错，其状态会变为 <strong>Error</strong>，并在事件信息和 Pod 信息部分显示错误信息，此时需要根据给出的错误信息进行问题排查。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>除了上述方法外，你也可以在 Notebook 中直接使用 <code>kubectl</code> 命令查看 TensorFlowTrainingJob 以及其下各个 Pod 的状态、基本信息、事件、日志等以检查训练的进度和结果。</p>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-tensorflowtrainingjob-进行参数服务器训练"><a class="header" href="#使用-tensorflowtrainingjob-进行参数服务器训练">使用 TensorFlowTrainingJob 进行参数服务器训练</a></h1>
<p>本教程演示如何使用 TensorFlowTrainingJob 对 Keras 模型进行参数服务器（parameter server）训练（采用 <a target="_blank" rel="noopener noreferrer" href="https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/ParameterServerStrategy"><code>tf.distribute.experimental.ParameterServerStrategy</code></a> 分布式策略）。</p>
<h2 id="运行示例-5"><a class="header" href="#运行示例-5">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/job/tensorflowtrainingjob/ps">本教程对应的示例</a>，参照其 README 文档运行。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>上述操作使用 YAML 配置文件创建 TensorFlowTrainingJob，你也可以在模型构建控制台进行创建。</p>
</aside>
<h2 id="检查训练日志和指标-3"><a class="header" href="#检查训练日志和指标-3">检查训练日志和指标</a></h2>
<p>训练开始后，进入模型构建控制台的 Job 页面，可以看到名为 <strong>keras-mnist-trainingjob-ps</strong> 的 TensorFlowTrainingJob 正在运行：</p>
<figure class="screenshot">
    <img alt="running" src="tasks/../assets/tasks/run-distributed-training/tensorflow/parameter-server-training/running.png" />
</figure>
<p>点击<strong>该名称</strong>进入详情页面，可以看到刚才创建的 TensorFlowTrainingJob 的基本信息、状况信息和事件信息：</p>
<figure class="screenshot">
    <img alt="details" src="tasks/../assets/tasks/run-distributed-training/tensorflow/parameter-server-training/details.png" />
</figure>
<p>点击 <strong>TensorBoard</strong> 右侧的 <strong>Running</strong> 打开 TensorBoard，可以查看可视化展示的训练和验证指标：</p>
<figure class="screenshot">
    <img alt="tensorboard" src="tasks/../assets/tasks/run-distributed-training/tensorflow/parameter-server-training/tensorboard.png" />
</figure>
<p>点击上方标签页的<strong>副本</strong>，查看 TensorFlowTrainingJob 的 Pod 信息：</p>
<figure class="screenshot">
    <img alt="replicas" src="tasks/../assets/tasks/run-distributed-training/tensorflow/parameter-server-training/replicas.png" />
</figure>
<p>点击副本右侧的<strong>更多按钮 &gt; 日志</strong>以查看训练脚本执行过程中的日志输出：</p>
<figure class="screenshot">
    <img alt="view-log" src="tasks/../assets/tasks/run-distributed-training/tensorflow/parameter-server-training/view-log.png" />
</figure>
<p>点击上方标签页的<strong>指标</strong>，查看 TensorFlowTrainingJob 运行过程中使用集群计算资源、网络资源和存储资源的情况：</p>
<figure class="screenshot">
    <img alt="replicas" src="tasks/../assets/tasks/run-distributed-training/tensorflow/parameter-server-training/metrics.png" />
</figure>
<p>一段时间之后，TensorFlowTrainingJob 的状态变为 <strong>Succeeded</strong>，表示训练成功完成。</p>
<figure class="screenshot">
    <img alt="done" src="tasks/../assets/tasks/run-distributed-training/tensorflow/parameter-server-training/done.png" />
</figure>
<p>若 TensorFlowTrainingJob 在运行过程中出错，其状态会变为 <strong>Error</strong>，并在事件信息和 Pod 信息部分显示错误信息，此时需要根据给出的错误信息进行问题排查。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>除了上述方法外，你也可以在 Notebook 中直接使用 <code>kubectl</code> 命令查看 TensorFlowTrainingJob 以及其下各个 Pod 的状态、基本信息、事件、日志等以检查训练的进度和结果。</p>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-horovod-进行-pytorch-模型的数据并行训练"><a class="header" href="#使用-horovod-进行-pytorch-模型的数据并行训练">使用 Horovod 进行 PyTorch 模型的数据并行训练</a></h1>
<p>本教程演示如何使用 MPIJob 对 PyTorch 模型进行多工作器同步训练（使用 <a target="_blank" rel="noopener noreferrer" href="https://horovod.readthedocs.io/en/stable/api.html#module-horovod.torch"><code>horovod.torch</code></a> 模块）。</p>
<h2 id="运行示例-6"><a class="header" href="#运行示例-6">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/job/mpijob/horovod-torch">本教程对应的示例</a>，参照其 README 文档运行。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>上述操作使用 YAML 配置文件创建 MPIJob，你也可以在模型构建控制台进行创建。</p>
</aside>
<h2 id="检查训练日志和指标-4"><a class="header" href="#检查训练日志和指标-4">检查训练日志和指标</a></h2>
<p>训练开始后，进入模型构建控制台的 Job 页面，可以看到名为 <strong>torch-mnist-mpijob</strong> 的 MPIJob 正在运行：</p>
<figure class="screenshot">
    <img alt="running" src="tasks/../assets/tasks/run-distributed-training/horovod/multiworker-training-of-pytorch-model/running.png" />
</figure>
<p>点击<strong>该名称</strong>进入详情页面，可以看到刚才创建的 MPIJob 的基本信息、状况信息和事件信息：</p>
<figure class="screenshot">
    <img alt="details" src="tasks/../assets/tasks/run-distributed-training/horovod/multiworker-training-of-pytorch-model/details.png" />
</figure>
<p>点击上方标签页的<strong>副本</strong>，查看 MPIJob 的 Pod 信息：</p>
<figure class="screenshot">
    <img alt="replicas" src="tasks/../assets/tasks/run-distributed-training/horovod/multiworker-training-of-pytorch-model/replicas.png" />
</figure>
<p>点击副本右侧的<strong>更多按钮 &gt; 日志</strong>以查看训练脚本执行过程中的日志输出：</p>
<figure class="screenshot">
    <img alt="view-log" src="tasks/../assets/tasks/run-distributed-training/horovod/multiworker-training-of-pytorch-model/view-log.png" />
</figure>
<p>点击上方标签页的<strong>指标</strong>，查看 MPIJob 运行过程中使用集群计算资源、网络资源和存储资源的情况：</p>
<figure class="screenshot">
    <img alt="replicas" src="tasks/../assets/tasks/run-distributed-training/tensorflow/multiworker-training/metrics.png" />
</figure>
<p>一段时间之后，MPIJob 的状态变为 <strong>Succeeded</strong>，表示训练成功完成：</p>
<figure class="screenshot">
    <img alt="done" src="tasks/../assets/tasks/run-distributed-training/horovod/multiworker-training-of-pytorch-model/done.png" />
</figure>
<p>若 MPIJob 在运行过程中出错，其状态会变为 <strong>Error</strong>，并在事件信息和 Pod 信息部分显示错误信息，此时需要根据给出的错误信息进行问题排查。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>除了上述方法外，你也可以在 Notebook 中直接使用 <code>kubectl</code> 命令查看 MPIJob 以及其下各个 Pod 的状态、基本信息、事件、日志等以检查训练的进度和结果。</p>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-horovod-进行-keras-模型的数据并行训练"><a class="header" href="#使用-horovod-进行-keras-模型的数据并行训练">使用 Horovod 进行 Keras 模型的数据并行训练</a></h1>
<p>本教程演示如何使用 MPIJob 对 Keras 模型进行多工作器同步训练（使用 <a target="_blank" rel="noopener noreferrer" href="https://horovod.readthedocs.io/en/stable/api.html#module-horovod.tensorflow.keras"><code>horovod.tensorflow.keras</code></a> 模块）。</p>
<h2 id="运行示例-7"><a class="header" href="#运行示例-7">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/job/mpijob/horovod-keras">本教程对应的示例</a>，参照其 README 文档运行。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>上述操作使用 YAML 配置文件创建 MPIJob，你也可以在模型构建控制台进行创建。</p>
</aside>
<h2 id="检查训练日志和指标-5"><a class="header" href="#检查训练日志和指标-5">检查训练日志和指标</a></h2>
<p>训练开始后，进入模型构建控制台的 Job 页面，可以看到名为 <strong>keras-mnist-mpijob</strong> 的 MPIJob 正在运行：</p>
<figure class="screenshot">
    <img alt="running" src="tasks/../assets/tasks/run-distributed-training/horovod/multiworker-training-of-keras-model/running.png" />
</figure>
<p>点击<strong>该名称</strong>进入详情页面，可以看到刚才创建的 MPIJob 的基本信息、状况信息和事件信息：</p>
<figure class="screenshot">
    <img alt="details" src="tasks/../assets/tasks/run-distributed-training/horovod/multiworker-training-of-keras-model/details.png" />
</figure>
<p>点击上方标签页的<strong>副本</strong>，查看 MPIJob 的 Pod 信息：</p>
<figure class="screenshot">
    <img alt="replicas" src="tasks/../assets/tasks/run-distributed-training/horovod/multiworker-training-of-keras-model/replicas.png" />
</figure>
<p>点击副本右侧的<strong>更多按钮 &gt; 日志</strong>以查看训练脚本执行过程中的日志输出：</p>
<figure class="screenshot">
    <img alt="view-log" src="tasks/../assets/tasks/run-distributed-training/horovod/multiworker-training-of-keras-model/view-log.png" />
</figure>
<p>点击上方标签页的<strong>指标</strong>，查看 MPIJob 运行过程中使用集群计算资源、网络资源和存储资源的情况：</p>
<figure class="screenshot">
    <img alt="replicas" src="tasks/../assets/tasks/run-distributed-training/horovod/multiworker-training-of-keras-model/metrics.png" />
</figure>
<p>一段时间之后，MPIJob 的状态变为 <strong>Succeeded</strong>，表示训练成功完成：</p>
<figure class="screenshot">
    <img alt="done" src="tasks/../assets/tasks/run-distributed-training/horovod/multiworker-training-of-keras-model/done.png" />
</figure>
<p>若 MPIJob 在运行过程中出错，其状态会变为 <strong>Error</strong>，并在事件信息和 Pod 信息部分显示错误信息，此时需要根据给出的错误信息进行问题排查。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>除了上述方法外，你也可以在 Notebook 中直接使用 <code>kubectl</code> 命令查看 MPIJob 以及其下各个 Pod 的状态、基本信息、事件、日志等以检查训练的进度和结果。</p>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-profiler-分析模型训练性能"><a class="header" href="#使用-profiler-分析模型训练性能">使用 Profiler 分析模型训练性能</a></h1>
<h2 id="概述-5"><a class="header" href="#概述-5">概述</a></h2>
<p>PyTorch 提供的 <a target="_blank" rel="noopener noreferrer" href="https://pytorch.org/docs/stable/profiler.html">profiler 工具</a>允许在训练和推理过程中收集性能指标，从而帮助用户更好地理解运算的代价和内存等资源消耗，测量 CPU 计算代价，CPU-GPU 之间数据复制成本，研究 GPU 内核程序性能并可视化执行追踪等。用户在 <a href="tasks/../modules/building/notebook.html">Notebook</a> 中可以方便地使用这一工具。</p>
<p>本教程将介绍如何在 Notebook 中对<a href="tasks/../examples/start-llm-large-scale-pretraining.html">启动 LLM 大规模预训练</a>中的训练进行性能分析。</p>
<h2 id="准备-1"><a class="header" href="#准备-1">准备</a></h2>
<p>在<a href="tasks/../examples/start-llm-large-scale-pretraining.html">启动 LLM 大规模预训练</a>给出的准备工作的基础上，还需要修改 Megatron-DeepSpeed 的训练代码，用 profiler 上下文管理器包装训练循环的代码。直接使用 Notebook 的文本编辑器修改代码即可。</p>
<pre><code class="language-python"># Megatron-DeepSpeed/megatron/training.py
...

    profile_path = os.path.join(os.path.dirname(args.tensorboard_dir), 'profiling')

    with torch.profiler.profile(
            schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),
            on_trace_ready=torch.profiler.tensorboard_trace_handler(profile_path),
            record_shapes=True,
            profile_memory=True,
            with_stack=True,
            with_flops=True,
            with_modules=True
    ) as prof:  # profiler context manager
        while iteration &lt; args.train_iters and (args.train_tokens is None or \
            args.consumed_train_tokens &lt; args.train_tokens):  # training loop

            ...

            prof.step()

...
</code></pre>
<p>其中对于 profiler 的配置为：</p>
<ul>
<li>profiler 跳过 1 个 step，热身 1 个 step，然后记录 3 个 step；总共重复 2 次。</li>
<li>生成用于 TensorBoard 展示的结果文件，与 TensorBoard 日志文件保存到同一父目录下。</li>
<li>记录算子的源信息和输入形状，记录模块（module）的调用栈，估计 FLOPS，跟踪张量内存的分配和释放。</li>
</ul>
<h2 id="启动性能分析"><a class="header" href="#启动性能分析">启动性能分析</a></h2>
<p>以 4 个 GPU 训练 125M 参数的 GPT 模型，启动训练：</p>
<pre><code class="language-bash">kubectl create -f \
  examples/deepspeed/megatron-gpt/training/gpt-125m-4xdp.yaml
</code></pre>
<p>通过以下命令查看训练过程中打印的日志：</p>
<pre><code class="language-bash">kubectl logs gpt-125m-4xdp-worker-0 -f
</code></pre>
<figure class="screenshot">
  <img alt="log" src="tasks/../assets/tasks/profile-model-training/log.png" />
</figure>
<p>性能分析完成之后，结果文件被保存在 <code>output/gpt-125m-4xdp/profiling</code> 路径下，前往该路径并启动一个 TensorBoard 实例以查看可视化结果。</p>
<figure class="screenshot">
  <img alt="create-tensorboard" src="tasks/../assets/tasks/profile-model-training/create-tensorboard.png" />
</figure>
<h2 id="查看可视化结果"><a class="header" href="#查看可视化结果">查看可视化结果</a></h2>
<p>Overview 展示了训练性能的总体情况，包含 GPU 的总体情况、不同执行类别花费的时间和占比，以及自动生成的性能优化建议：</p>
<figure class="screenshot">
  <img alt="overview" src="tasks/../assets/tasks/profile-model-training/overview.png" />
</figure>
<p>Operator View 展示了所有 PyTorch 算子被调用的次数、花费的时间以及它的调用栈：</p>
<figure class="screenshot">
  <img alt="operator-view" src="tasks/../assets/tasks/profile-model-training/operator-view.png" />
</figure>
<p>Kernel View 展示了所有 GPU 内核被调用的次数、花费的时间的统计以及它是否使用了 Tensor Core 等：</p>
<figure class="screenshot">
  <img alt="kernel-view" src="tasks/../assets/tasks/profile-model-training/kernel-view.png" />
</figure>
<p>Memory View 展示了内存使用曲线图、内存事件（分配和释放）以及内存统计数据：</p>
<figure class="screenshot">
  <img alt="memory-view" src="tasks/../assets/tasks/profile-model-training/memory-view.png" />
</figure>
<p>TensorBoard 所展示的数据和提供的功能还远不止这些，请参阅<a target="_blank" rel="noopener noreferrer" href="https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html">官方教程</a>以了解更多。这些数据应当能为用户分析和改进性能提供非常有用的帮助。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="调试-job"><a class="header" href="#调试-job">调试 Job</a></h1>
<p>本教程演示如何使用 Job 的<a href="tasks/../modules/jobs/pytorchtrainingjob.html#%E8%B0%83%E8%AF%95%E6%A8%A1%E5%BC%8F">调试模式</a>这一功能来对计算任务进行调试。</p>
<h2 id="运行示例-8"><a class="header" href="#运行示例-8">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/job/debug">本教程对应的示例</a>，参照其 README 文档运行。</p>
<h2 id="通过-ssh-远程连接"><a class="header" href="#通过-ssh-远程连接">通过 SSH 远程连接</a></h2>
<p>对于开启了 SSH 服务的容器，建立 SSH 连接的操作步骤和 Notebook 相同，请参照<a href="tasks/./ssh-notebook.html">通过 SSH 远程使用 Notebook</a>进行操作。唯一不同的是端口转发使用 <code>t9k-pf pod</code> 命令，而非 
<code>t9k-pf notebook</code> 命令：</p>
<pre><code class="language-shell">t9k-pf pod &lt;POD_NAME&gt; 5001:2222 -n &lt;PROJECT_NAME&gt;
</code></pre>
<h2 id="进行调试"><a class="header" href="#进行调试">进行调试</a></h2>
<p>不论是进入休眠的容器，还是远程连接开启了 SSH 服务的容器，调试都是通过执行一些命令来进行。例如使用 <code>nvidia-smi</code> 命令检查当前可用的 GPU，再使用 <code>ls</code> 命令检查训练脚本是否存在：</p>
<pre><code class="language-shell"># 在容器中
nvidia-smi
ls
</code></pre>
<p>然后使用 <code>torchrun</code> 命令启动训练：</p>
<pre><code class="language-shell"># 在容器中
cd ~/tutorial-examples/job/debug
torchrun --nnodes 1 --nproc_per_node 4 --rdzv_backend c10d torch_mnist_trainingjob.py --save_path model_state_dict.pt --log_dir log --backend nccl
</code></pre>
<p>随即分布式训练开始进行。如果训练脚本出错，则可以立即在终端中进行调试，不会造成 Job 的失败。调试完成后禁用 debug 模式（将 <code>spec.runMode.debug.enable</code> 设为 <code>false</code>，或直接注释第 6-12 行），再次创建 PyTorchTrainingJob 则正常启动训练。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="进行超参数优化"><a class="header" href="#进行超参数优化">进行超参数优化</a></h1>
<p>超参数优化是机器学习中的一项关键任务，其目标是选择一组最佳的超参数来改进模型性能。这一任务面临多重挑战：超参数通常不可微分，搜索空间高维且非凸，评估成本高，手动调参既繁琐又低效。为此 TensorStack AI 平台提供了自动化工具 <a href="tasks/../modules/building/autotune.html">AutoTune</a>，其支持多种超参数优化算法，能够自动搜索超参数空间、存储搜索结果并进行可视化，并且配置简单，使用方便。</p>
<p>这一部分将使用 AutoTune 进行模型的超参数优化。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-autotune-进行超参数优化"><a class="header" href="#使用-autotune-进行超参数优化">使用 AutoTune 进行超参数优化</a></h1>
<p>本教程演示如何使用 <a href="tasks/../modules/building/autotune.html">AutoTune</a> 对模型进行超参数优化（以 Keras 模型的单机训练为例）。</p>
<h2 id="准备训练脚本"><a class="header" href="#准备训练脚本">准备训练脚本</a></h2>
<p>在开始超参数优化实验之前，你需要提前准备训练脚本。你可以使用模型构建控制台中的 Notebook 编辑训练脚本。</p>
<h3 id="创建-pvc-4"><a class="header" href="#创建-pvc-4">创建 PVC</a></h3>
<p>参照<a href="tasks/./manage-pvc.html#%E5%88%9B%E5%BB%BA-pvc">创建 PVC</a> 教程创建名为 <code>autotune-mnist-keras</code>、大小为 1Gi 的 PVC。</p>
<h3 id="创建-notebook-4"><a class="header" href="#创建-notebook-4">创建 Notebook</a></h3>
<p>从模型构建控制台进入 Notebook 列表，点击右上角的<strong>创建 Notebook</strong>。</p>
<figure class="screenshot">
  <img alt="notebook-table" src="tasks/../assets/tasks/run-hyperparameter-optimization/notebook-table.png" />
</figure>
<p>创建 Notebook 时，在<strong>存储卷</strong>选择前面创建的 PVC 的名称 <code>autotune-mnist-keras</code>。</p>
<figure class="screenshot">
  <img alt="create-notebook" src="tasks/../assets/tasks/run-hyperparameter-optimization/create-notebook.png" />
</figure>
<p>创建完成之后，点击<strong>打开</strong>进入 Notebook。</p>
<figure class="screenshot">
  <img alt="after-creating-notebook" src="tasks/../assets/tasks/run-hyperparameter-optimization/after-creating-notebook.png" />
</figure>
<h3 id="在-notebook-中编辑训练脚本"><a class="header" href="#在-notebook-中编辑训练脚本">在 Notebook 中编辑训练脚本</a></h3>
<p>以下是一个 Keras 训练脚本，在此基础上做简单的修改以应用在 AutoTune 实验中。</p>
<pre><code class="language-python">import argparse
import json
import logging
import os
import time

import tensorflow as tf
from tensorflow.keras import callbacks, datasets, layers, models, optimizers

parser = argparse.ArgumentParser(
    description='Distributed training of Keras model for MNIST with '
    'MultiWorkerMirroredStrategy.')
parser.add_argument('--log_dir',
                    type=str,
                    default=None,
                    help='Path of the TensorBoard log directory.')
parser.add_argument('--no_cuda',
                    action='store_true',
                    default=False,
                    help='Disable CUDA training.')
parser.add_argument('--save_path',
                    type=str,
                    default=None,
                    help='Save path of the trained model.')
args = parser.parse_args()
logger = logging.getLogger('print')
logger.setLevel(logging.INFO)
logger.addHandler(logging.StreamHandler())
logger.propagate = False

if args.no_cuda:
    tf.config.set_visible_devices([], 'GPU')
gpus = tf.config.get_visible_devices('GPU')
if gpus:
    # Print GPU info
    logger.info('NVIDIA_VISIBLE_DEVICES: {}'.format(
        os.getenv('NVIDIA_VISIBLE_DEVICES')))
    logger.info('T9K_GPU_PERCENT: {}'.format(os.getenv('T9K_GPU_PERCENT')))
    logger.info('Visible GPUs: {}'.format(
        tf.config.get_visible_devices('GPU')))
    # Set memory growth
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)
    # # Set GPU memory limit
    # tf.config.set_logical_device_configuration(
    #     gpus[0], [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])

strategy = tf.distribute.MultiWorkerMirroredStrategy()

# Get information for current worker.
tf_config = json.loads(os.environ['TF_CONFIG'])
world_size = len(tf_config['cluster']['worker'])
task_index = tf_config['task']['index']

params = {
    # Search space:
    # 'batch_size': ...
    # 'learning_rate': ...
    # 'conv_channels1': ...
    'epochs': 10,
    'conv_channels2': 64,
    'conv_channels3': 64,
    'conv_kernel_size': 3,
    'maxpool_size': 2,
    'linear_features1': 64,
    'seed': 1,
}

with strategy.scope():
    model = models.Sequential([
        layers.Conv2D(params['conv_channels1'],
                      params['conv_kernel_size'],
                      activation='relu',
                      input_shape=(28, 28, 1)),
        layers.MaxPooling2D((params['maxpool_size'], params['maxpool_size'])),
        layers.Conv2D(params['conv_channels2'],
                      params['conv_kernel_size'],
                      activation='relu'),
        layers.MaxPooling2D((params['maxpool_size'], params['maxpool_size'])),
        layers.Conv2D(params['conv_channels3'],
                      params['conv_kernel_size'],
                      activation='relu'),
        layers.Flatten(),
        layers.Dense(params['linear_features1'], activation='relu'),
        layers.Dense(10, activation='softmax'),
    ])
    model.compile(
        optimizer=optimizers.Adam(learning_rate=params['learning_rate']),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy'])

(train_images, train_labels), (test_images,
                               test_labels) = datasets.mnist.load_data(
                                   path=os.path.join(os.getcwd(), 'mnist.npz'))
train_images = train_images.reshape((60000, 28, 28, 1)).astype(&quot;float32&quot;) / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype(&quot;float32&quot;) / 255
train_images, val_images = train_images[:48000], train_images[48000:]
train_labels, val_labels = train_labels[:48000], train_labels[48000:]
train_dataset = tf.data.Dataset.from_tensor_slices(
    (train_images, train_labels)).shuffle(
        48000, seed=params['seed']).repeat().batch(params['batch_size'])
val_dataset = tf.data.Dataset.from_tensor_slices(
    (val_images, val_labels)).batch(400)
test_dataset = tf.data.Dataset.from_tensor_slices(
    (test_images, test_labels)).batch(1000)

model.fit(train_images,
          train_labels,
          batch_size=params['batch_size'],
          epochs=params['epochs'],
          validation_split=0.2,
          verbose=2)

# TODO: Automatically save best n models.
# if args.save_path and task_index == 0:
#     t9k.autotune.utils.save_best_n_models(model, args.save_path)

model.evaluate(test_images, test_labels, callbacks=test_callbacks, verbose=2)

if task_index &gt; 0:
    # wait a while for index 0
    time.sleep(1)
</code></pre>
<p>在上述脚本中导入 <code>t9k.tuner</code> 模块，在训练模型之前调用 <code>get_next_parameter()</code> 函数获取训练超参数，替换原来的参数。</p>
<pre><code class="language-python">from t9k import tuner

def main():
    ...
    tuner_params = tuner.get_next_parameter()
    params.update(tuner_params)
    ...
</code></pre>
<p>在训练过程中，添加 <code>AutoTuneCallback</code> 上传实验指标。</p>
<pre><code class="language-python">train_callbacks = []
test_callbacks = []

if task_index == 0:
    from t9k.tuner.keras import AutoTuneFitCallback, AutoTuneEvalCallback
    train_callbacks.append(AutoTuneFitCallback(metric='accuracy'))
    test_callbacks.append(AutoTuneEvalCallback(metric='accuracy'))
    if args.log_dir:
        tensorboard_callback = callbacks.TensorBoard(log_dir=args.log_dir)
        train_callbacks.append(tensorboard_callback)

</code></pre>
<p>如下为修改后的训练脚本：</p>
<pre><code class="language-python">import argparse
import json
import logging
import os
import time

import tensorflow as tf
from tensorflow.keras import callbacks, datasets, layers, models, optimizers

from t9k import tuner

parser = argparse.ArgumentParser(
    description='Distributed training of Keras model for MNIST with '
    'MultiWorkerMirroredStrategy.')
parser.add_argument('--log_dir',
                    type=str,
                    default=None,
                    help='Path of the TensorBoard log directory.')
parser.add_argument('--no_cuda',
                    action='store_true',
                    default=False,
                    help='Disable CUDA training.')
parser.add_argument('--save_path',
                    type=str,
                    default=None,
                    help='Save path of the trained model.')
args = parser.parse_args()
logger = logging.getLogger('print')
logger.setLevel(logging.INFO)
logger.addHandler(logging.StreamHandler())
logger.propagate = False

if args.no_cuda:
    tf.config.set_visible_devices([], 'GPU')
gpus = tf.config.get_visible_devices('GPU')
if gpus:
    # Print GPU info
    logger.info('NVIDIA_VISIBLE_DEVICES: {}'.format(
        os.getenv('NVIDIA_VISIBLE_DEVICES')))
    logger.info('T9K_GPU_PERCENT: {}'.format(os.getenv('T9K_GPU_PERCENT')))
    logger.info('Visible GPUs: {}'.format(
        tf.config.get_visible_devices('GPU')))
    # Set memory growth
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)
    # # Set GPU memory limit
    # tf.config.set_logical_device_configuration(
    #     gpus[0], [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])

strategy = tf.distribute.MultiWorkerMirroredStrategy()

# Get information for current worker.
tf_config = json.loads(os.environ['TF_CONFIG'])
world_size = len(tf_config['cluster']['worker'])
task_index = tf_config['task']['index']

tuner_params = tuner.get_next_parameter()
params = {
    # Search space:
    # 'batch_size': ...
    # 'learning_rate': ...
    # 'conv_channels1': ...
    'epochs': 10,
    'conv_channels2': 64,
    'conv_channels3': 64,
    'conv_kernel_size': 3,
    'maxpool_size': 2,
    'linear_features1': 64,
    'seed': 1,
}
params.update(tuner_params)

with strategy.scope():
    model = models.Sequential([
        layers.Conv2D(params['conv_channels1'],
                      params['conv_kernel_size'],
                      activation='relu',
                      input_shape=(28, 28, 1)),
        layers.MaxPooling2D((params['maxpool_size'], params['maxpool_size'])),
        layers.Conv2D(params['conv_channels2'],
                      params['conv_kernel_size'],
                      activation='relu'),
        layers.MaxPooling2D((params['maxpool_size'], params['maxpool_size'])),
        layers.Conv2D(params['conv_channels3'],
                      params['conv_kernel_size'],
                      activation='relu'),
        layers.Flatten(),
        layers.Dense(params['linear_features1'], activation='relu'),
        layers.Dense(10, activation='softmax'),
    ])
    model.compile(
        optimizer=optimizers.Adam(learning_rate=params['learning_rate']),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy'])

(train_images, train_labels), (test_images,
                               test_labels) = datasets.mnist.load_data(
                                   path=os.path.join(os.getcwd(), 'mnist.npz'))
train_images = train_images.reshape((60000, 28, 28, 1)).astype(&quot;float32&quot;) / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype(&quot;float32&quot;) / 255
train_images, val_images = train_images[:48000], train_images[48000:]
train_labels, val_labels = train_labels[:48000], train_labels[48000:]
train_dataset = tf.data.Dataset.from_tensor_slices(
    (train_images, train_labels)).shuffle(
        48000, seed=params['seed']).repeat().batch(params['batch_size'])
val_dataset = tf.data.Dataset.from_tensor_slices(
    (val_images, val_labels)).batch(400)
test_dataset = tf.data.Dataset.from_tensor_slices(
    (test_images, test_labels)).batch(1000)

train_callbacks = []
test_callbacks = []

if task_index == 0:
    from t9k.tuner.keras import AutoTuneFitCallback, AutoTuneEvalCallback
    train_callbacks.append(AutoTuneFitCallback(metric='accuracy'))
    test_callbacks.append(AutoTuneEvalCallback(metric='accuracy'))
    if args.log_dir:
        tensorboard_callback = callbacks.TensorBoard(log_dir=args.log_dir)
        train_callbacks.append(tensorboard_callback)

model.fit(train_images,
          train_labels,
          batch_size=params['batch_size'],
          epochs=params['epochs'],
          validation_split=0.2,
          callbacks=train_callbacks,
          verbose=2)

# TODO: Automatically save best n models.
# if args.save_path and task_index == 0:
#     t9k.autotune.utils.save_best_n_models(model, args.save_path)

model.evaluate(test_images, test_labels, callbacks=test_callbacks, verbose=2)

if task_index &gt; 0:
    # wait a while for index 0
    time.sleep(1)
</code></pre>
<p>在 Notebook 中创建文件 <code>main.py</code>，写入上述脚本并保存文件。</p>
<figure class="screenshot">
  <img alt="notebook-detail" src="tasks/../assets/tasks/run-hyperparameter-optimization/notebook-detail.png" />
</figure>
<p>创建 <code>download_dataset.py</code> 文件，写入并执行以下脚本来下载实验数据。</p>
<pre><code class="language-python">import os
import tensorflow as tf

_, _ = tf.keras.datasets.mnist.load_data(os.path.join(os.getcwd(), 'mnist.npz'))
</code></pre>
<figure class="screenshot">
  <img alt="notebook-download-script" src="tasks/../assets/tasks/run-hyperparameter-optimization/notebook-download-script.png" />
</figure>
<figure class="screenshot">
  <img alt="download-data" src="tasks/../assets/tasks/run-hyperparameter-optimization/download-data.png" />
</figure>
<h2 id="准备数据库"><a class="header" href="#准备数据库">准备数据库</a></h2>
<p>你可以使用实验管理平台（以下称 EM）记录超参数调优实验中的超参数组合和训练结果。（如果你选择不使用 EM 持久记录 AutoTune 实验结果，请忽略这一步，并在开始实验时删掉 AutoTuneExperiment 的 <code>spec.aistore</code> 字段）</p>
<h3 id="在实验管理控制台中新建文件夹"><a class="header" href="#在实验管理控制台中新建文件夹">在实验管理控制台中新建文件夹</a></h3>
<p>EM 的实验数据是以文件夹形式管理的，所以你首先需要在实验管理控制台点击右上角的 <strong>+</strong> 新建一个文件夹。</p>
<figure class="screenshot">
  <img alt="create-aistore-folder" src="tasks/../assets/tasks/run-hyperparameter-optimization/create-aistore-folder.png" />
</figure>
<p>进入文件夹，点击 <strong>ID</strong> 来复制该文件夹的 ID。</p>
<figure class="screenshot">
  <img alt="folder-id" src="tasks/../assets/tasks/run-hyperparameter-optimization/folder-id.png" />
</figure>
<aside class="note info">
<div class="title">信息</div>
<p>EM 的更详细信息请参阅<a href="tasks/../modules/experiment-management.html">实验管理</a>。</p>
</aside>
<h3 id="获得访问-em-所需的-api-key"><a class="header" href="#获得访问-em-所需的-api-key">获得访问 EM 所需的 API Key</a></h3>
<p>在超参数优化实验中，如果你希望使用 EM 来存储实验数据，需要生成一个具有访问 EM 文件夹权限的 API Key，你可以通过这个 API Key 上传实验数据。</p>
<aside class="note info">
<div class="title">什么是 API Key</div>
<p>请参阅 <a href="tasks/../modules/account-and-security.html#api-key">API Key 介绍</a>。</p>
</aside>
<p>你需要按照<a href="tasks/./generate-api-key.html">生成 API Key</a> 教程中的步骤，在安全控制台中生成一个 API Key，其中必须勾选 AIStore 选项。</p>
<figure class="screenshot">
  <img alt="create-apikey" src="tasks/../assets/tasks/run-hyperparameter-optimization/create-apikey.png" />
</figure>
<p>生成 API Key 之后，点击<strong>复制按钮</strong>复制该 API Key。</p>
<figure class="screenshot">
  <img alt="after-creating-apikey" src="tasks/../assets/tasks/run-hyperparameter-optimization/after-creating-apikey.png" />
</figure>
<p>然后，你需要按照<a href="tasks/./manage-secret.html">管理 Secret</a> 教程中的步骤，在模型构建控制台中将所复制的 API Key 存入名为 <code>aistore</code> 的 Secret 中，以方便后续实验使用。</p>
<figure class="screenshot">
  <img alt="create-apikey-secret" src="tasks/../assets/tasks/run-hyperparameter-optimization/create-apikey-secret.png" />
</figure>
<h2 id="开始实验"><a class="header" href="#开始实验">开始实验</a></h2>
<p>在模型构建控制台的 AutoTune 列表页面，点击右上角的<strong>创建 AutoTuneExperiment</strong> 进入 AutoTuneExperiment 创建页面。</p>
<figure class="screenshot">
  <img alt="autotune-table" src="tasks/../assets/tasks/run-hyperparameter-optimization/autotune-table.png" />
</figure>
<p>在 AutoTuneExperiment 创建页面，点击<strong>预览 YAML</strong>，输入以下配置，点击<strong>创建</strong>：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: AutoTuneExperiment
metadata:
  name: autotune-mnist-keras
spec:
  maxExecSeconds: 3600
  maxTrialNum: 20
  trialConcurrency: 3
  storage: 100Mi
  aistore:
    secret: 'aistore'
    folder: 'b6c17378-965c-4467-9a43-eed65597f976'
  searchSpace: |-
    {
      &quot;batch_size&quot;: {&quot;_type&quot;: &quot;choice&quot;, &quot;_value&quot;: [16, 32, 64, 128]},
      &quot;learning_rate&quot;: {&quot;_type&quot;: &quot;choice&quot;, &quot;_value&quot;: [0.0001, 0.001, 0.01, 0.1]},
      &quot;conv_channels1&quot;: {&quot;_type&quot;: &quot;choice&quot;, &quot;_value&quot;: [16, 32, 64, 128]}
    }
  trainingConfig:
    type: tensorflow
    tasks:
      - type: worker
        replicas: 4
        template:
          spec:
            securityContext:
              runAsUser: 1000
            containers:
              - command:
                  - sh
                  - -c
                  - &quot;python3 main.py --log_dir /mnt/log --no_cuda&quot;
                workingDir: /mnt/
                imagePullPolicy: IfNotPresent
                image: t9kpublic/tensorflow-2.5.1:20220216
                name: tensorflow
                resources:
                  requests:
                    cpu: 2000m
                    memory: 2Gi
                  limits:
                    cpu: 4000m
                    memory: 4Gi
                volumeMounts:
                  - mountPath: /mnt
                    name: data
            volumes:
              - name: data
                persistentVolumeClaim:
                  claimName: autotune-mnist-keras
  tuner:
    builtinTunerName: TPE
    classArgs: |-
      {
        &quot;optimize_mode&quot;: &quot;maximize&quot;, 
        &quot;constant_liar_type&quot;: &quot;min&quot;
      }
</code></pre>
<p>在此例中，实验绑定了准备过程中创建的名为 <code>autotune-mnist-keras</code> 的 PVC，其中存有在 Notebook 中编辑的训练脚本；使用了名为 <code>aistore</code> 的存有 API Key 的 Secret；填入了前面创建的 EM Folder 的 ID。</p>
<figure class="screenshot">
  <img alt="create-autotune" src="tasks/../assets/tasks/run-hyperparameter-optimization/create-autotune.png" />
</figure>
<h2 id="查看实验"><a class="header" href="#查看实验">查看实验</a></h2>
<p>你可以在 AutoTune 列表页面看到已创建的 AutoTuneExperiment，点击<strong>连接</strong>进入实验详情页面。</p>
<figure class="screenshot">
  <img alt="after-creating-autotune" src="tasks/../assets/tasks/run-hyperparameter-optimization/after-creating-autotune.png" />
</figure>
<p>下图为实验详情页面，你可以在该页面查看实验基本信息、各试验的参数与结果，以及查看试验之间的对比。</p>
<figure class="screenshot">
  <img alt="autotune-detail" src="tasks/../assets/tasks/run-hyperparameter-optimization/autotune-detail.png" />
</figure>
<figure class="screenshot">
  <img alt="trial-detail" src="tasks/../assets/tasks/run-hyperparameter-optimization/trial-detail.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="部署模型推理服务"><a class="header" href="#部署模型推理服务">部署模型推理服务</a></h1>
<p>这一部分演示如何使用平台的模型部署模块部署推理服务。</p>
<ul>
<li>使用 SimpleMLService 部署 <a href="tasks/./deploy-simplemlservice.html">简单模型推理服务</a></li>
<li>使用 MLService 部署 <a href="tasks/./deploy-mlservice.html">模型推理服务</a></li>
<li>部署 <a href="tasks/./deploy-mlservice-transformer.html">包含 Transformer 的模型推理服务</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="简单推理服务"><a class="header" href="#简单推理服务">简单推理服务</a></h1>
<p>本教程演示如何使用 SimpleMLService 快速部署一个模型推理服务。</p>
<h2 id="运行示例-9"><a class="header" href="#运行示例-9">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/deployment/simplemlservice">本教程的示例</a>，参照其 README 文档运行。本示例使用 PVC 中存储的模型创建了一个 SimpleMLService 服务。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>除了上述直接提供 YAML 配置文件的方法外，你也可以选择从网页控制台创建 SimpleMLService。</p>
</aside>
<h2 id="查看推理服务状态"><a class="header" href="#查看推理服务状态">查看推理服务状态</a></h2>
<p>部署完成后，进入模型部署控制台的 SimpleMLService 页面，可以看到名为 <strong>mnist</strong> 的 SimpleMLService。</p>
<figure class="screenshot">
    <img alt="list" src="tasks/../assets/tasks/deploy-simplemlservice/list.png" />
</figure>
<p>点击 SimpleMLService 的名称 <strong>mnist</strong> 可以看见 SimpleMLService 的基本信息，其中 URL 是在集群内访问这个推理服务的地址：</p>
<figure class="screenshot">
    <img alt="detail" src="tasks/../assets/tasks/deploy-simplemlservice/details.png" />
</figure>
<h2 id="参考-9"><a class="header" href="#参考-9">参考</a></h2>
<ul>
<li><a href="tasks/../modules/deployment/simplemlservice.html">SimpleMLService 介绍</a></li>
<li>API 参考：<a href="tasks/../../references/api-reference/simplemlservice.html">SimpleMLService</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="模型推理服务"><a class="header" href="#模型推理服务">模型推理服务</a></h1>
<p>本教程演示如何使用 MLService 部署一个功能完善、自动化程度高，可用于生产环境的模型推理服务。</p>
<h2 id="运行示例-10"><a class="header" href="#运行示例-10">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/deployment/mlservice/torch-pvc">本教程的示例</a>，参照其 README 文档运行。本示例使用 PVC 中存储的模型创建了一个 MLService 服务。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>除了上述直接提供 YAML 配置文件的方法外，你也可以选择从网页控制台创建 MLService。</p>
</aside>
<h2 id="查看推理服务状态-1"><a class="header" href="#查看推理服务状态-1">查看推理服务状态</a></h2>
<p>部署完成后，进入模型部署控制台的 MLService 页面，可以看到名为 <strong>torch-mnist-pvc</strong> 的 MLService，稍等片刻，等其进入 Ready 状态：</p>
<figure class="screenshot">
    <img alt="ready" src="tasks/../assets/tasks/deploy-model-reference-serving/mlservice/running-status.png" />
</figure>
<h2 id="使用推理服务-1"><a class="header" href="#使用推理服务-1">使用推理服务</a></h2>
<p>你可以直接使用命令行工具访问 MLService 的预测服务。运行命令获取 MLService 的 URL：</p>
<pre><code class="language-shell">url=$(kubectl get mlservice torch-mnist-pvc -o jsonpath='{.status.address.url}') &amp;&amp; echo $url
</code></pre>
<p>发送推理请求：</p>
<pre><code class="language-shell">curl -T test_data/0.png ${url}/v1/models/mnist:predict # or use `1.png`, `2.png`
</code></pre>
<h2 id="监控推理服务"><a class="header" href="#监控推理服务">监控推理服务</a></h2>
<p>在模型部署控制台，点击对应的 MLService，然后切换到<strong>资源监测</strong>页面，可以查看该 MLService 的资源统计：</p>
<figure class="screenshot">
  <img alt="resource-usage" src="tasks/../assets/tasks/deploy-model-reference-serving/mlservice/resource-usage.png" />
</figure>
<h2 id="参考-10"><a class="header" href="#参考-10">参考</a></h2>
<ul>
<li><a href="tasks/../modules/deployment/mlservice.html">MLService 介绍</a></li>
<li>API 参考：<a href="tasks/../../references/api-reference/mlservice.html">MLService</a></li>
<li>API 参考：<a href="tasks/../../references/api-reference/mlservice.html#mlserviceruntime">MLServiceRuntime</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="包含-transformer-的推理服务"><a class="header" href="#包含-transformer-的推理服务">包含 Transformer 的推理服务</a></h1>
<p>本教程演示如何使用 TensorStack SDK 创建 Transformer 镜像，然后部署包含该 Transformer 的 MLService。</p>
<h2 id="准备工作-6"><a class="header" href="#准备工作-6">准备工作</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备此次部署需要用到的 PVC 和 Notebook。</p>
<h2 id="编写-transformer-逻辑"><a class="header" href="#编写-transformer-逻辑">编写 Transformer 逻辑</a></h2>
<p>接下来开始制作供 MLService 使用的 Transformer 镜像。首先进入 Notebook，启动一个终端，切换到对应目录：</p>
<pre><code class="language-bash">cd ~/tutorial-examples/deployment/mlservice/transformer
</code></pre>
<p>查看文件 <code>server.py</code> ，内容如下：</p>
<pre><code class="language-py title=&quot;server.py&quot;">import json
from t9k import mlservice

import argparse
import io
import numpy as np
from PIL import Image
from typing import Dict

# inherit parser to get command-line-args help
# feel free to add your command line args
par = argparse.ArgumentParser(parents=[mlservice.option.parser])
args, _ = par.parse_known_args()

def image_transform(instance):
    image = Image.open(io.BytesIO(instance))
    a = np.asarray(image)
    a = a / 255.0
    return a.reshape(28, 28, 1).tolist()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

def get_prediction(prediction: list)-&gt;str:
    max_value = max(prediction)
    max_index = prediction.index(max_value)
    return class_names[max_index]

class Transformer(mlservice.MLTransformer):
    def preProcess(self, path: str, requestData: bytes, headers: Dict[str, str]) -&gt; any:
        return json.dumps({'instances': [image_transform(requestData)]})

    def postProcess(self, path: str, statusCode: int, responseContent: bytes, headers: Dict[str, str]) -&gt; bytes:
        data = responseContent.decode('utf-8')
        jsonData = json.loads(data)
        jsonStr = json.dumps({'predictions': [get_prediction(predict) for predict in jsonData['predictions']]})
        return jsonStr.encode('utf-8')
    
if __name__ == &quot;__main__&quot;:
    transformer = Transformer()
    server = mlservice.MLServer()
    server.start(transformer=transformer)
</code></pre>
<p>代码中使用了 TensorStack SDK，通过重载 <code>preprocess</code> 和 <code>postprocess</code> 方法实现了一个 Transformer：</p>
<ul>
<li><code>preprocess</code>：预处理函数，Transformer 收到用户发送的数据，使用 <code>preprocess</code> 对数据进行处理，然后再发送给推理服务。在这个示例中，先转换输入图片的数据格式，需要保持与训练的模型的输入数据一致，然后再转换为推理服务的输入格式。</li>
<li><code>postprocess</code>：后处理函数，Transformer 收到推理服务返回的结果，使用 <code>postprocess</code> 对其进行处理，然后再返回给用户。在这个示例中，模型用于处理分类问题，从推理服务返回的预测概率向量中解析出该图片的分类类别，并返回给用户。</li>
</ul>
<p>用户可以参考该文件来实现自定义的 Transformer 逻辑。</p>
<h2 id="制作镜像"><a class="header" href="#制作镜像">制作镜像</a></h2>
<p>基于上述代码，我们创建对应的 Dockerfile 如下：</p>
<pre><code class="language-dockerfile">FROM python:3.8-slim

COPY t9k-sdk.tar.gz t9k-sdk.tar.gz
COPY server.py server.py

RUN pip install --upgrade pip
RUN pip install --no-cache-dir -i https://pypi.tuna.tsinghua.edu.cn/simple \
    numpy \
    pillow \
    requests
RUN pip install t9k-sdk.tar.gz  -i https://pypi.tuna.tsinghua.edu.cn/simple

ENTRYPOINT [&quot;python&quot;, &quot;server.py&quot;]
</code></pre>
<p>上述 Dockerfile 引入了相关依赖，并将上一步的 <code>server.py</code> 文件作为启动命令。用户可以参考该文件来实现自定义的镜像。</p>
<p>然后我们通过运行一个 ImageBuilder 来制作镜像，为了使用 ImageBuilder，首先我们需要参照<a href="https://github.com/t9k/tutorial-examples/blob/master/build-image/build-image-on-platform/README.md#%E5%88%9B%E5%BB%BA-secret">创建 Secret</a>准备上传镜像所需要的 DockerConfig <code>Secret</code>。</p>
<p>完成后修改 <code>imagebuilder.yaml</code> 文件，将 <code>spec.dockerConfig.secret</code> 修改为上一步中创建的 DockerConfig <code>Secret</code> 的名称，并将 <code>spec.tag</code> 修改为目标镜像，并执行以下命令：</p>
<pre><code>kubectl apply -f imagebuilder.yaml
</code></pre>
<p>查看 <code>ImageBuilder</code> 状态，等待 Phase 一栏变为 <code>Succeeded</code>：</p>
<pre><code class="language-sh">kubectl get -f imagebuilder.yaml -w
</code></pre>
<h2 id="部署-mlservice-1"><a class="header" href="#部署-mlservice-1">部署 MLService</a></h2>
<p>进入模型部署控制台，先点击左侧导航栏辅助一栏下的的 <strong>MLServiceRuntime</strong>，再点击 <strong>创建 MLServiceRuntime</strong> ，然后点击 <strong>预览 YAML</strong>， 并将下面内容复制到 YAML 编辑框中，最后点击 <strong>创建</strong> 创建 MLServiceRuntime。</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: MLServiceRuntime
metadata:
  name: t9k-tensorflow-serving
spec:
  enabled: true
  template:
    spec:
      containers:
      - name: user-container
        image: t9kpublic/tensorflow-serving:2.13.1
        command:
          - /usr/bin/tensorflow_model_server
        args:
          - --model_name={{if .MODEL_NAME}}{{.MODEL_NAME}}{{else}}model{{end}}
          - --port={{if .GRPC_PORT}}{{.GRPC_PORT}}{{else}}9000{{end}}
          - --rest_api_port=8000
          - --model_base_path=/var/lib/t9k/model
        resources:
          limits:
            cpu: &quot;200m&quot;
            memory: 200Mi
        ports:
        - containerPort: 8000
          protocol: TCP
</code></pre>
<p>进入模型部署控制台的 MLService 页面，点击右上角<strong>创建 MLService</strong>，然后点击<strong>预览 YAML</strong>。如下图所示，将下述内容复制到右侧的 YAML 编辑框，最后点击 <strong>创建</strong> 创建 MLService：</p>
<aside class="note">
<div class="title">注意</div>
<p>请将 transformer 定义中的 <code>image</code> 替换为上一步中制作好的镜像地址。</p>
</aside>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: MLService
metadata:
  name: pic-mnist
spec:
  default: origin
  transformer:
    minReplicas: 1
    template:
      spec:
        containers:
        - name: user-container
          image: &quot;&lt;your-docker-registry-address&gt;/mnist-transformer:test&quot;
  releases:
    - name: origin
      predictor:
        minReplicas: 1
        model:
          runtime: t9k-tensorflow-serving
          modelUri: pvc://tutorial/tutorial-examples/deployment/mlservice/transformer/model/
</code></pre>
<figure class="screenshot">
  <img alt="create-mlservcie-transformer" src="tasks/../assets/tasks/deploy-model-reference-serving/transformer/create-mlservice.png" class="screenshot" />
</figure>
<h1>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD
你可以直接使用命令行工具访问 MLService 的预测服务。运行命令获取 MLService 的 URL：</h1>
<h2 id="发送预测请求"><a class="header" href="#发送预测请求">发送预测请求</a></h2>
<p>使用图片 <code>shoe.png</code> 作为测试数据发送预测请求。
&gt;&gt;&gt;&gt;&gt;&gt;&gt; parent of 816714b (Update mlservice (#51))</p>
<pre><code class="language-shell">address=$(kubectl get mls pic-mnist -ojsonpath='{.status.address.url}') &amp;&amp; echo $address
curl --data-binary @./shoe.png ${address}/v1/models/model:predict
</code></pre>
<h2 id="参考-11"><a class="header" href="#参考-11">参考</a></h2>
<ul>
<li><a href="tasks/../modules/deployment/mlservice.html">MLService 介绍</a></li>
<li>API 参考：<a href="tasks/../../references/api-reference/mlservice.html">MLService</a></li>
<li>API 参考：<a href="tasks/../../references/api-reference/mlservice.html#mlserviceruntime">MLServiceRuntime</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="管理-ai-资产"><a class="header" href="#管理-ai-资产">管理 AI 资产</a></h1>
<p>这一部分演示如何使用 <a href="tasks/../modules/asset-management.html">AsestHub</a> 上传、使用和分享模型和数据集。</p>
<ul>
<li><a href="tasks/./manipulate-folder-asset.html">操作文件夹、模型和数据集</a></li>
<li><a href="tasks/./access-asset-via-s3.html">通过 S3 访问模型和数据集</a></li>
<li><a href="tasks/./modify-folder-asset.html">修改文件夹、模型和数据集的基本信息</a></li>
<li><a href="tasks/./manipulate-asset-branch-tag.html">操作模型和数据集的分支、tag 和 commit</a></li>
<li><a href="tasks/./manipulate-asset-objects.html">操作模型和数据集的对象</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="操作文件夹模型和数据集"><a class="header" href="#操作文件夹模型和数据集">操作文件夹、模型和数据集</a></h1>
<p>本教程演示如何通过多种方式操作文件夹、模型和数据集，包括创建、查看和删除。</p>
<h2 id="准备工作-7"><a class="header" href="#准备工作-7">准备工作</a></h2>
<ul>
<li><a href="tasks/../tools/python-sdk-t9k/index.html">安装</a> TensorStack SDK 并阅读<a href="tasks/../tools/python-sdk-t9k/guide.html">用户指南</a>。</li>
</ul>
<h2 id="通过命令行工具-2"><a class="header" href="#通过命令行工具-2">通过命令行工具</a></h2>
<p>切换到你的工作路径下：</p>
<pre><code class="language-shell">$ cd /your/workpath
</code></pre>
<p>假设当前用户（这里假设用户名为 <code>demo</code>）没有可以访问的文件夹，使用 <code>ah create</code> 命令创建一个模型文件夹和一个数据集文件夹：</p>
<pre><code class="language-shell">$ ah create model/llm
AH INFO: Folder /demo/t9k-assethub/model/llm created

$ ah create dataset/text
AH INFO: Folder /demo/t9k-assethub/dataset/text created
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>限于篇幅，本教程以及后续教程将仅展示各条命令的基本用法，请使用 <code>--help</code> 选项（例如 <code>ah create --help</code>）查看相应命令接受的参数格式、所有选项以及具体用例。</p>
</aside>
<p>然后使用 <code>ah create</code> 命令在模型文件夹中创建一个模型，以及在数据集文件夹中创建一个数据集：</p>
<pre><code class="language-shell">$ ah create model/llm/gpt2
AH INFO: Model gpt2 created for Folder /demo/t9k-assethub/model/llm

$ ah create dataset/text/openwebtext
AH INFO: Dataset openwebtext created for Folder /demo/t9k-assethub/dataset/text
</code></pre>
<p>创建完成之后，使用 <code>ah ls</code> 命令查看当前用户的模型文件夹和数据集文件夹：</p>
<pre><code class="language-shell">$ ah ls model
NAME    PATH                          LABELS    PERMISSION
llm     /demo/t9k-assethub/model/llm             own

$ ah ls dataset
NAME    PATH                              LABELS    PERMISSION
text    /demo/t9k-assethub/dataset/text              own
</code></pre>
<p>使用 <code>ah ls</code> 命令查看模型文件夹下的所有模型以及数据集文件夹下的所有数据集：</p>
<pre><code class="language-shell">$ ah ls model/llm
NAME    PATH                              LABELS    PERMISSION
gpt2    /demo/t9k-assethub/model/llm/gpt2            own

$ ah ls dataset/text
NAME         PATH                                        LABELS    PERMISSION
openwebtext  /demo/t9k-assethub/dataset/text/openwebtext            own
</code></pre>
<p>最后使用 <code>ah delete</code> 命令删除所有创建的模型、数据集和文件夹：</p>
<pre><code class="language-shell">$ ah delete model/llm/gpt2
AH INFO: Model /demo/t9k-assethub/model/llm/gpt2 deleted

$ ah delete dataset/text/openwebtext
AH INFO: Dataset /demo/t9k-assethub/dataset/text/openwebtext deleted

# 可以直接删除文件夹, 其中的模型或数据集都会被一并删除
$ ah delete model/llm
AH INFO: Folder /demo/t9k-assethub/model/llm deleted

$ ah delete dataset/text
AH INFO: Folder /demo/t9k-assethub/dataset/text deleted
</code></pre>
<aside class="note">
<div class="title">注意</div>
<p>删除模型、数据集和文件夹时会一并删除其中的所有内容，请慎重操作。</p>
</aside>
<h2 id="通过-python-sdk"><a class="header" href="#通过-python-sdk">通过 Python SDK</a></h2>
<p>切换到你的工作路径下，然后以任意方式执行下面的 Python 代码。</p>
<p>导入 <code>t9k.ah</code> 模块，使用 <code>ah.login()</code> 函数登录到 Asset Hub 服务器（如果配置文件中的凭据仍有效，则无需提供参数）：</p>
<pre><code class="language-python">from t9k import ah

ah.login(host='&lt;asset-hub-server-url&gt;',
         api_key='&lt;your-api-key&gt;')
</code></pre>
<pre><code>AH INFO: Logged in to Asset Hub server and AIStore server as user &lt;your-user-name&gt;
</code></pre>
<p>假设当前用户（这里假设用户名为 <code>demo</code>）没有可以访问的文件夹，使用 <code>ah.create()</code> 函数创建一个模型文件夹和一个数据集文件夹，各返回一个 <code>Folder</code> 实例：</p>
<pre><code class="language-python">model_folder = ah.create('model/llm')
dataset_folder = ah.create('dataset/text')
</code></pre>
<pre><code>AH INFO: Folder /demo/t9k-assethub/model/llm created
AH INFO: Folder /demo/t9k-assethub/dataset/text created
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>限于篇幅，本教程以及后续教程将仅展示各个函数或方法的基本用法，相应函数或方法接受的参数详情以及具体用例请参考 TensorStack SDK 的 <a href="tasks/../tools/python-sdk-t9k/api/index.html">API 文档</a>。</p>
</aside>
<p>继续使用 <code>ah.create()</code> 函数在模型文件夹中创建一个模型，以及在数据集文件夹中创建一个数据集：</p>
<pre><code class="language-python">model = ah.create('model/llm/gpt2')
dataset = ah.create('dataset/text/openwebtext')
</code></pre>
<pre><code>AH INFO: Model gpt2 created for Folder /demo/t9k-assethub/model/llm
AH INFO: Dataset openwebtext created for Folder /demo/t9k-assethub/dataset/text
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用 <code>Folder</code> 实例的 <code>create_asset()</code> 方法完成上述操作。</p>
</aside>
<p>创建完成之后，使用 <code>ah.list()</code> 函数返回当前用户的文件夹：</p>
<pre><code class="language-python">from pprint import pprint

pprint(ah.list('model'))
pprint(ah.list('dataset'))
</code></pre>
<pre><code>[{'description': '',
  'editor': 'demo',
  'extra': '{&quot;createdTimestamp&quot;: &quot;2023-08-17T08:05:24.044319Z&quot;}',
  'id': '967a5135-8b13-4283-9fad-ba53503612b3',
  'labels': [],
  'modifiedTimestamp': '2023-08-17T08:05:24.390002Z',
  'name': 'llm',
  'path': '/demo/t9k-assethub/model/llm',
  'permission': 'own',
  'storageType': 0,
  'type': 'Folder'}]
[{'description': '',
  'editor': 'demo',
  'extra': '{&quot;createdTimestamp&quot;: &quot;2023-08-17T08:05:24.196610Z&quot;}',
  'id': 'd0d9f4b2-6c15-4dbb-b2d1-0619b6774c4a',
  'labels': [],
  'modifiedTimestamp': '2023-08-17T08:05:24.519213Z',
  'name': 'text',
  'path': '/demo/t9k-assethub/dataset/text',
  'permission': 'own',
  'storageType': 0,
  'type': 'Folder'}]
</code></pre>
<p>继续使用 <code>ah.list()</code> 函数返回模型文件夹下的所有模型和数据集文件夹下的所有数据集：</p>
<pre><code class="language-python">pprint(ah.list('model/llm'))
pprint(ah.list('dataset/text'))
</code></pre>
<pre><code>[{'description': '',
  'editor': 'demo',
  'extra': '{&quot;createdTimestamp&quot;: &quot;2023-08-17T08:11:09.948554Z&quot;}',
  'id': '2157a139-e20b-4736-9e25-d4495e287af8',
  'labels': [],
  'modifiedTimestamp': '2023-08-17T08:11:10.327166Z',
  'name': 'gpt2',
  'path': '/demo/t9k-assethub/model/llm/gpt2',
  'permission': 'own',
  'storageType': 3,
  'type': 'Model'}]
[{'description': '',
  'editor': 'demo',
  'extra': '{&quot;createdTimestamp&quot;: &quot;2023-08-17T08:11:10.508407Z&quot;}',
  'id': '6826131c-2c88-483e-8a48-0f6d8fa59cfa',
  'labels': [],
  'modifiedTimestamp': '2023-08-17T08:11:10.830665Z',
  'name': 'openwebtext',
  'path': '/demo/t9k-assethub/dataset/text/openwebtext',
  'permission': 'own',
  'storageType': 3,
  'type': 'Dataset'}]
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用 <code>Folder</code> 实例的 <code>list_asset()</code> 方法完成上述操作。</p>
</aside>
<p>最后使用 <code>ah.delete()</code> 函数删除所有创建的模型、数据集和文件夹：</p>
<pre><code class="language-python">ah.delete('model/llm/gpt2')
ah.delete('dataset/text/openwebtext')
ah.delete('model/llm')    # 可以直接删除文件夹, 其中的模型或数据集都会被一并删除
ah.delete('dataset/text')
</code></pre>
<pre><code>AH INFO: Model /demo/t9k-assethub/model/llm/gpt2 deleted
AH INFO: Dataset /demo/t9k-assethub/dataset/text/openwebtext deleted
AH INFO: Folder /demo/t9k-assethub/model/llm deleted
AH INFO: Folder /demo/t9k-assethub/dataset/text deleted
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用各实例的 <code>delete()</code> 方法完成上述操作。</p>
</aside>
<h2 id="通过控制台-2"><a class="header" href="#通过控制台-2">通过控制台</a></h2>
<p>数据集文件夹、数据集的控制台操作分别和模型文件夹、模型完全一致。本教程后续仅展示模型文件夹和模型的创建、查看、删除、分享功能，你可以用同样的方式操作数据集文件夹和数据集。</p>
<p>在左侧的导航菜单中点击<strong>模型</strong>，选择查看范围为 <strong>My Own</strong>，查看当前用户的所有模型文件夹。然后点击右上角的 <strong>+</strong> 创建新的模型文件夹：</p>
<figure class="screenshot">
  <img alt="model-all" src="tasks/../assets/tasks/manage-asset/manipulate-folder-and-asset/model-owned.png" />
</figure>
<p>填写名称 <code>image-classification</code>，点击<strong>创建</strong>：</p>
<figure class="screenshot">
  <img alt="folder-create" src="tasks/../assets/tasks/manage-asset/manipulate-folder-and-asset/folder-create.png" />
</figure>
<p>接下来分享这个文件夹。点击文件夹右侧的 <strong>更多 &gt; 分享</strong>：</p>
<figure class="screenshot">
  <img alt="folder-share" src="tasks/../assets/tasks/manage-asset/manipulate-folder-and-asset/folder-share.png" />
</figure>
<p>点击<strong>添加分享目标</strong>，选择分享的对象为 <strong>Public</strong>（所有用户可见），分享的权限是 <strong>Edit</strong>，最后点击<strong>分享</strong>：</p>
<figure class="screenshot">
  <img alt="folder-share-setting" src="tasks/../assets/tasks/manage-asset/manipulate-folder-and-asset/folder-share-setting.png" />
</figure>
<p>回到 Asset Hub 控制台，点击模型文件夹 <strong>image-classification</strong> 查看其中的模型：</p>
<figure class="screenshot">
  <img alt="folder-list" src="tasks/../assets/tasks/manage-asset/manipulate-folder-and-asset/folder-list.png" />
</figure>
<p>新创建的模型文件夹中没有模型，点击右上角的 <strong>+</strong> 创建一个模型：</p>
<figure class="screenshot">
  <img alt="model-list" src="tasks/../assets/tasks/manage-asset/manipulate-folder-and-asset/model-list.png" />
</figure>
<p>填写名称 <code>mnist</code>，然后点击<strong>创建</strong>：</p>
<figure class="screenshot">
  <img alt="model-create" src="tasks/../assets/tasks/manage-asset/manipulate-folder-and-asset/model-create.png" />
</figure>
<p>创建成功后，在模型文件夹中可以看到模型信息：</p>
<figure class="screenshot">
  <img alt="model-created" src="tasks/../assets/tasks/manage-asset/manipulate-folder-and-asset/model-created.png" />
</figure>
<p>点击<strong>更多 &gt; 删除</strong>，删除创建的模型，然后点击左上角的<strong>返回</strong>，返回模型文件夹的页面：</p>
<figure class="screenshot">
  <img alt="model-delete" src="tasks/../assets/tasks/manage-asset/manipulate-folder-and-asset/model-delete.png" />
</figure>
<p>最后，返回 Asset Hub 控制台，点击<strong>更多 &gt; 删除</strong>，删除模型文件夹：</p>
<figure class="screenshot">
  <img alt="folder-delete" src="tasks/../assets/tasks/manage-asset/manipulate-folder-and-asset/folder-delete.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="通过-s3-访问模型和数据集"><a class="header" href="#通过-s3-访问模型和数据集">通过 S3 访问模型和数据集</a></h1>
<p>本教程演示如何 S3 访问模型。</p>
<p>数据集同理。</p>
<h2 id="准备工作-8"><a class="header" href="#准备工作-8">准备工作</a></h2>
<ul>
<li>完成教程<a href="tasks/./manipulate-folder-asset.html">操作文件夹、模型和数据集</a>。</li>
</ul>
<h2 id="创建-s3-凭证"><a class="header" href="#创建-s3-凭证">创建 S3 凭证</a></h2>
<p>在 AssetHub 控制台进入模型详情页面，点击 <strong>S3 凭证</strong>可以查看目前已有的所有 S3 凭证。然后点击表格右上角的 <strong>+</strong> 创建一个 S3 凭证：</p>
<figure class="screenshot">
  <img alt="s3-cred-list" src="tasks/../assets/tasks/manage-asset/access-asset-by-s3/s3-cred-list.png" />
</figure>
<p>填写名称 <code>s3-rw</code>，选择类型为<strong>可读/可写</strong>，最后点击<strong>创建</strong>：</p>
<figure class="screenshot">
  <img alt="s3-cred-create" src="tasks/../assets/tasks/manage-asset/access-asset-by-s3/s3-cred-create.png" />
</figure>
<h2 id="查看-s3-凭证"><a class="header" href="#查看-s3-凭证">查看 S3 凭证</a></h2>
<p>创建完成后，点击表格左上角的<strong>可读/可写</strong>，查看所有类型为可读/可写的 S3 凭证：</p>
<figure class="screenshot">
  <img alt="s3-cred-list-rw" src="tasks/../assets/tasks/manage-asset/access-asset-by-s3/s3-cred-list-rw.png" />
</figure>
<p>点击刚刚创建的 S3 凭证 <code>s3-rw</code>，查看其详情：</p>
<figure class="screenshot">
  <img alt="s3-cred-detail" src="tasks/../assets/tasks/manage-asset/access-asset-by-s3/s3-cred-detail.png" />
</figure>
<p>S3 凭证有三种格式：</p>
<ol>
<li><code>.s3cfg</code>：命令行工具 s3cmd 的配置文件。</li>
<li><code>S3-cfg Secret</code>：s3cfg 形式的 Secret YAML，创建后可在 Notebook、Job、Workflow 等工作负载时挂载此 Secret。</li>
<li><code>S3-env Secret</code>：s3 环境变量形式的 Secret YAML，创建后可在 Notebook、Job、Workflow 等工作负载时挂载此 Secret。</li>
</ol>
<h2 id="通过-s3cmd-访问模型"><a class="header" href="#通过-s3cmd-访问模型">通过 s3cmd 访问模型</a></h2>
<p>点击右侧的<strong>复制</strong>，复制 <code>.s3cfg</code> 格式的 S3 凭证，保存在 <code>$HOME/.s3cfg</code> 文件中，即可通过 s3cmd 命令行工具访问此模型中的文件。</p>
<aside class="note info">
<div class="title">如何安装 s3cmd 命令行工具？</div>
<p>根据操作系统的不同，分别通过以下命令安装 s3cmd 命令行工具：</p>
<pre><code class="language-bash"># macOS
brew install s3cmd

# Linux
apt install s3cmd

# Windows
pip install s3cmd
</code></pre>
</aside>
<p>例如，在上述示例中，所创建的 S3 凭证 <code>s3-rw</code> 仅可用于访问名为 <code>neox</code> 的模型。根据页面上的提示，此模型对应的 bucket 名称为 <code>adb2a768-f01a-467b-b146-e82c0693c16b</code>，用户可以通过以下命令查看此模型的 <code>main</code> 分支的 <code>README.md</code> 文件：</p>
<pre><code class="language-bash">s3cmd ls s3://baa98ded-2f93-4e9b-835a-6515a63a6eb4/main/README.md
</code></pre>
<p>通过以下命令下载此模型的某个分支下某个路径的文件：</p>
<pre><code class="language-bash">s3cmd get s3://baa98ded-2f93-4e9b-835a-6515a63a6eb4/branch-name/path/to/object
</code></pre>
<h2 id="通过-storageshim-访问模型"><a class="header" href="#通过-storageshim-访问模型">通过 StorageShim 访问模型</a></h2>
<p>除了通过命令行工具访问，用户还可以创建一个 <a href="tasks/./use-storageshim-s3.html">StorageShim</a>，将 S3 bucket 的某个子路径形式化为一个持久卷，以便在 Notebook、Job、Workflow 等工作负载中挂载，直接以文件系统的形式查看、编辑 S3 bucket 中的文件。</p>
<p>在创建 StorageShim 之前，用户首先需要创建一个 Secret 保存 S3 bucket 的相关信息。在 S3 凭证的详情页面，点击左侧的 <strong>S3-cfg Secret</strong> 标签，然后点击右上角的<strong>复制</strong>：</p>
<figure class="screenshot">
  <img alt="s3-cred-detail-s3-cfg-secret" src="tasks/../assets/tasks/manage-asset/access-asset-by-s3/s3-cred-detail-s3-cfg-secret.png" />
</figure>
<p>在模型构建控制台的左侧导航菜单中点击<strong>辅助 &gt; Secret</strong> 进入 Secret 管理页面，然后点击右上角的<strong>创建 Secret</strong>进入 Secret 创建页面：</p>
<figure class="screenshot">
  <img alt="secret-list" src="tasks/../assets/tasks/manage-asset/access-asset-by-s3/secret-list.png" />
</figure>
<p>在 Secret 创建页面，点击<strong>预览 YAML</strong>，将所复制的 <code>S3-cfg Secret</code> 粘贴到 YAML 编辑框中，最后点击<strong>创建</strong>。</p>
<figure class="screenshot">
  <img alt="secret-create" src="tasks/../assets/tasks/manage-asset/access-asset-by-s3/secret-create.png" />
</figure>
<p>在模型构建控制台的左侧导航菜单中点击<strong>存储 &gt; 持久卷</strong>进入持久卷管理页面，然后点击上方的 <strong>S3</strong> 进入 S3 类型的持久卷管理页面，最后点击右上角的<strong>创建</strong>进入 StorageShim 创建页面：</p>
<figure class="screenshot">
  <img alt="storageshim-list" src="tasks/../assets/tasks/manage-asset/access-asset-by-s3/storageshim-list.png" />
</figure>
<p>在 StorageShim 创建页面，</p>
<ol>
<li>名称填写 <code>neox</code>；</li>
<li>类型选择 <code>S3</code>；</li>
<li>S3 URI 填写 <code>s3://adb2a768-f01a-467b-b146-e82c0693c16b/main</code>，以便把上述示例模型的 main 分支挂载为持久卷；</li>
<li>S3 Secret 选择刚刚创建的 <code>s3-rw</code>。</li>
</ol>
<p>最后点击<strong>创建</strong>。</p>
<figure class="screenshot">
  <img alt="storageshim-create" src="tasks/../assets/tasks/manage-asset/access-asset-by-s3/storageshim-create.png" />
</figure>
<p>StorageShim 创建完成后，等待其阶段变为 <strong>Bound</strong>，用户即可通过以下方式使用这个名为 <code>neox</code> 的持久卷：</p>
<ol>
<li>点击<strong>启动</strong>，创建一个 Explorer 来浏览持久卷中的文件。</li>
<li>在创建 Notebook 时，添加持久卷 <code>neox</code>，以便在 Notebook 中查看和编辑此模型中的文件。</li>
<li>在创建 Job 时，添加持久卷 <code>neox</code>，以便在 Job 中使用此模型中的文件。</li>
</ol>
<figure class="screenshot">
  <img alt="storageshim-list-after-create" src="tasks/../assets/tasks/manage-asset/access-asset-by-s3/storageshim-list-after-create.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="修改文件夹模型和数据集的基本信息"><a class="header" href="#修改文件夹模型和数据集的基本信息">修改文件夹、模型和数据集的基本信息</a></h1>
<p>本教程演示如何通过多种方式修改文件夹、模型和数据集的基本信息。</p>
<h2 id="准备工作-9"><a class="header" href="#准备工作-9">准备工作</a></h2>
<ul>
<li>完成教程<a href="tasks/./manipulate-folder-asset.html">操作文件夹、模型和数据集</a>。</li>
</ul>
<h2 id="通过命令行工具-3"><a class="header" href="#通过命令行工具-3">通过命令行工具</a></h2>
<p>切换到你的工作路径下：</p>
<pre><code class="language-shell">$ cd /your/workpath
</code></pre>
<p>修信息的方式对于文件夹、模型和数据集都是相同的。下面将以模型文件夹和模型为例进行演示（这里假设用户名为 <code>demo</code>）。</p>
<p>依次创建模型文件夹和模型：</p>
<pre><code class="language-shell">$ ah create model/llm
AH INFO: Folder /demo/t9k-assethub/model/llm created

$ ah create model/llm/gpt2
AH INFO: Model gpt2 created for Folder /demo/t9k-assethub/model/llm
</code></pre>
<p>使用 <code>ah update</code> 命令修改文件夹和模型的名称：</p>
<pre><code class="language-shell">$ ah update model/llm -n chat
AH INFO: Folder /demo/t9k-assethub/model/llm updated to /demo/t9k-assethub/model/chat

$ ah update model/chat/gpt2 -n gpt3
AH INFO: Model /demo/t9k-assethub/model/chat/gpt2 updated to /demo/t9k-assethub/model/chat/gpt3
</code></pre>
<p>使用 <code>ah ls</code> 命令查看文件夹和模型的标签：</p>
<pre><code class="language-shell">$ ah ls model --detail
NAME    PATH                          ...  LABELS  ...
chat    /demo/t9k-assethub/model/chat

$ ah ls model/chat
NAME    PATH                               LABELS  ...
gpt3    /demo/t9k-assethub/model/chat/gpt3
</code></pre>
<p>两者都没有标签，再次使用 <code>ah update</code> 命令为它们添加标签：</p>
<pre><code class="language-shell">$ ah update model/chat --label &quot;NLP&quot; --label &quot;AIGC&quot;
AH INFO: Folder /demo/t9k-assethub/model/chat updated

$ ah ls model --detail
NAME    PATH                          ...  LABELS     ...
chat    /demo/t9k-assethub/model/chat       AIGC, NLP
</code></pre>
<pre><code class="language-shell">$ ah update model/chat/gpt3 --label &quot;GPT&quot;
AH INFO: Model /demo/t9k-assethub/model/chat/gpt3 updated

$ ah ls model/chat
NAME    PATH                               LABELS    PERMISSION
gpt3    /demo/t9k-assethub/model/chat/gpt3  GPT       own
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>标签的更新是全量的：每次添加标签都会移除已有的标签。</p>
</aside>
<h2 id="通过-python-sdk-1"><a class="header" href="#通过-python-sdk-1">通过 Python SDK</a></h2>
<p>切换到你的工作路径下，然后以任意方式执行下面的 Python 代码。</p>
<p>导入 <code>t9k.ah</code> 模块，使用 <code>ah.login()</code> 函数登录到 AssetHub 服务器（如果配置文件中的凭据仍有效，则无需提供参数）：</p>
<pre><code class="language-python">from t9k import ah

ah.login(host='&lt;asset-hub-server-url&gt;',
         api_key='&lt;your-api-key&gt;')
</code></pre>
<pre><code>AH INFO: Logged in to Asset Hub server and AIStore server as user &lt;your-user-name&gt;
</code></pre>
<p>修改信息的方式对于文件夹、模型和数据集都是相同的。下面将以模型文件夹和模型为例进行演示（这里假设用户名为 <code>demo</code>）。</p>
<p>依次创建模型文件夹和模型：</p>
<pre><code class="language-python">model_folder = ah.create('model/llm')
model = ah.create('model/llm/gpt2')
</code></pre>
<pre><code>AH INFO: Folder /demo/t9k-assethub/model/llm created
AH INFO: Model gpt2 created for Folder /demo/t9k-assethub/model/llm
</code></pre>
<p>使用 <code>ah.update()</code> 函数修改文件夹和模型的名称：</p>
<pre><code class="language-python">ah.update('model/llm', name='chat')
ah.update('model/chat/gpt2', name='gpt3')
</code></pre>
<pre><code>AH INFO: Folder /demo/t9k-assethub/model/llm updated to /demo/t9k-assethub/model/chat
AH INFO: Model /demo/t9k-assethub/model/chat/gpt2 updated to /demo/t9k-assethub/model/chat/gpt3
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用 <code>Folder</code> 和 <code>Model</code> 实例的 <code>update()</code> 方法完成上述操作。</p>
</aside>
<p>使用 <code>ah.list()</code> 函数查看文件夹和模型的标签：</p>
<pre><code class="language-python">from pprint import pprint

pprint(ah.list('model'))
pprint(ah.list('model/chat'))
</code></pre>
<pre><code>[{...
  'labels': [],
  'name': 'chat',
  'path': '/demo/t9k-assethub/model/chat',
  'type': 'Folder'}]
[{...
  'labels': [],
  'name': 'gpt3',
  'path': '/demo/t9k-assethub/model/chat/gpt3',
  'type': 'Model'}]
</code></pre>
<p>两者都没有标签，继续使用 <code>ah.update()</code> 函数为它们添加标签：</p>
<pre><code class="language-python">ah.update('model/chat', labels=['NLP', 'AIGC'])
ah.update('model/chat/gpt3', labels=['GPT'])
</code></pre>
<pre><code>AH INFO: Folder /demo/t9k-assethub/model/chat updated
AH INFO: Model /demo/t9k-assethub/model/chat/gpt3 updated
</code></pre>
<pre><code class="language-python">pprint(ah.list('model'))
pprint(ah.list('model/chat'))
</code></pre>
<pre><code>[{...
  'labels': ['AIGC', 'NLP'],
  'name': 'chat',
  'path': '/demo/t9k-assethub/model/chat',
  'type': 'Folder'}]
[{...
  'labels': ['GPT'],
  'name': 'gpt3',
  'path': '/demo/t9k-assethub/model/chat/gpt3',
  'type': 'Model'}]
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>标签的更新是全量的：每次添加标签都会移除已有的标签。</p>
</aside>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用 <code>Folder</code> 和 <code>Model</code> 实例的 <code>update()</code> 方法完成上述操作。</p>
</aside>
<h2 id="通过控制台-3"><a class="header" href="#通过控制台-3">通过控制台</a></h2>
<p>数据集文件夹、数据集的控制台操作分别和模型文件夹、模型完全一致。本教程后续仅展示如何修改模型文件夹和模型的基本信息，你可以用同样的方式操作数据集文件夹和数据集。</p>
<p>在进行教程之前，先按照<a href="tasks/./manipulate-folder-asset.html">操作文件夹、模型和数据集</a>一节完成模型文件夹和模型的创建（chat/gpt2）。</p>
<p>在模型文件夹列表中，选中需要修改的模型文件夹，点击<strong>更多 &gt; 编辑</strong>：</p>
<figure class="screenshot">
  <img alt="folder-list" src="tasks/../assets/tasks/manage-asset/modify-folder-asset/folder-list.png" />
</figure>
<p>填写新的名称和描述信息，添加新标签，点击<strong>更新</strong>按钮：</p>
<figure class="screenshot">
  <img alt="folder-edit" src="tasks/../assets/tasks/manage-asset/modify-folder-asset/folder-edit.png" />
</figure>
<p>回到文件夹列表，可以看到文件夹信息发生改变：</p>
<figure class="screenshot">
  <img alt="folder-list-after-edit" src="tasks/../assets/tasks/manage-asset/modify-folder-asset/folder-list-after-edit.png" />
</figure>
<p>点击文件夹名称，进入模型列表，选中需要修改的模型，点击<strong>更多 &gt; 编辑</strong>：</p>
<figure class="screenshot">
  <img alt="model-list" src="tasks/../assets/tasks/manage-asset/modify-folder-asset/model-list.png" />
</figure>
<p>填写新的名称和描述信息，添加新标签，点击<strong>更新</strong>按钮：</p>
<figure class="screenshot">
  <img alt="model-edit" src="tasks/../assets/tasks/manage-asset/modify-folder-asset/model-edit.png" />
</figure>
<p>回到模型列表，可以看到模型信息发生改变：</p>
<figure class="screenshot">
  <img alt="model-list-after-edit" src="tasks/../assets/tasks/manage-asset/modify-folder-asset/model-list-after-edit.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="操作模型和数据集的分支tag-和-commit"><a class="header" href="#操作模型和数据集的分支tag-和-commit">操作模型和数据集的分支、tag 和 commit</a></h1>
<p>本教程演示如何通过多种方式操作模型的分支、tag 和 commit，包括创建、查看和删除分支，创建、查看和删除 tag，以及查看 commit。</p>
<p>数据集同理。</p>
<h2 id="准备工作-10"><a class="header" href="#准备工作-10">准备工作</a></h2>
<ul>
<li>完成教程<a href="tasks/./manipulate-folder-asset.html">操作文件夹、模型和数据集</a>。</li>
</ul>
<h2 id="通过命令行工具-4"><a class="header" href="#通过命令行工具-4">通过命令行工具</a></h2>
<p>切换到你的工作路径下：</p>
<pre><code class="language-shell">$ cd /your/workpath
</code></pre>
<p>操作 tag 和 commit 的方式对于模型和数据集都是相同的，只有模型允许操作分支。下面将以模型为例进行演示（这里假设用户名为 <code>demo</code>）。</p>
<p>依次创建模型文件夹和模型：</p>
<pre><code class="language-shell">$ ah create model/llm
AH INFO: Folder /demo/t9k-assethub/model/llm created

$ ah create model/llm/gpt2
AH INFO: Model gpt2 created for Folder /demo/t9k-assethub/model/llm
</code></pre>
<p>继续使用 <code>ah create</code> 命令为模型创建一个分支：</p>
<pre><code class="language-shell">$ ah create model/llm/gpt2:v1
AH INFO: Branch v1 created for Model /demo/t9k-assethub/model/llm/gpt2
</code></pre>
<aside class="note">
<div class="title">注意</div>
<p>模型可以在初始的主分支（<code>main</code> 分支）之外创建新的分支，数据集则不可以。</p>
</aside>
<p>使用 <code>ah ls --branch</code> 命令查看模型的所有分支：</p>
<pre><code class="language-shell">$ ah ls model/llm/gpt2 --branch
NAME    COMMIT_ID
main    fe46da7e
v1      fe46da7e
</code></pre>
<p>继续使用 <code>ah create</code> 命令为模型创建一个 tag：</p>
<pre><code class="language-shell">$ ah create model/llm/gpt2:20230101 --tag --source v1
AH INFO: Tag 20230101 created from branch v1 for Model /demo/t9k-assethub/model/llm/gpt2
</code></pre>
<p>使用 <code>ah ls --tag</code> 命令查看模型的所有 tag：</p>
<pre><code class="language-shell">$ ah ls model/llm/gpt2 --tag
    NAME  COMMIT_ID
20230101  fe46da7e
</code></pre>
<p>使用 <code>ah ls --commit</code> 命令查看模型的一个分支下的所有 commit：</p>
<pre><code class="language-shell">$ ah ls model/llm/gpt2:v1 --commit
COMMIT_ID    MESSAGE             CREATED
fe46da7e     Repository created  3m16s ago
</code></pre>
<p>最后使用 <code>ah delete</code> 命令删除所有创建的分支和 tag：</p>
<pre><code class="language-shell">$ ah delete model/llm/gpt2:v1
AH INFO: Branch v1 deleted for Model /demo/t9k-assethub/model/llm/gpt2

$ ah delete model/llm/gpt2:20230101
AH INFO: Tag 20230101 deleted for Model /demo/t9k-assethub/model/llm/gpt2
</code></pre>
<h2 id="通过-python-sdk-2"><a class="header" href="#通过-python-sdk-2">通过 Python SDK</a></h2>
<p>切换到你的工作路径下，然后以任意方式执行下面的 Python 代码。</p>
<p>导入 <code>t9k.ah</code> 模块，使用 <code>ah.login()</code> 函数登录到 AssetHub 服务器（如果配置文件中的凭据仍有效，则无需提供参数）：</p>
<pre><code class="language-python">from t9k import ah

ah.login(host='&lt;asset-hub-server-url&gt;',
         api_key='&lt;your-api-key&gt;')
</code></pre>
<pre><code>AH INFO: Logged in to Asset Hub server and AIStore server as user &lt;your-user-name&gt;
</code></pre>
<p>操作 tag 和 commit 的方式对于模型和数据集都是相同的，只有模型允许操作分支。下面将以模型为例进行演示（这里假设用户名为 <code>demo</code>）。</p>
<p>依次创建模型文件夹和模型：</p>
<pre><code class="language-python">model_folder = ah.create('model/llm')
model = ah.create('model/llm/gpt2')
</code></pre>
<pre><code>AH INFO: Folder /demo/t9k-assethub/model/llm created
AH INFO: Model gpt2 created for Folder /demo/t9k-assethub/model/llm
</code></pre>
<p>继续使用 <code>ah.create()</code> 函数为模型创建一个分支：</p>
<pre><code class="language-python">branch = ah.create('model/llm/gpt2:v1')
</code></pre>
<pre><code>AH INFO: Branch v1 created for Model /demo/t9k-assethub/model/llm/gpt2
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用 <code>Model</code> 实例的 <code>create_branch()</code> 方法完成上述操作。</p>
</aside>
<p>使用 <code>ah.list()</code> 函数查看模型的所有分支：</p>
<pre><code class="language-python">from pprint import pprint

pprint(ah.list('model/llm/gpt2', resource='branch'))
</code></pre>
<pre><code>[{'commit_id': 'a15799f8f601d514a1a385a57b3078f8e178614a66aa920217175f6dcac2b083',
  'id': 'main'},
 {'commit_id': 'a15799f8f601d514a1a385a57b3078f8e178614a66aa920217175f6dcac2b083',
  'id': 'v1'}]
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用 <code>Model</code> 实例的 <code>list_branch()</code> 方法完成上述操作。</p>
</aside>
<p>继续使用 <code>ah.create()</code> 函数为模型创建一个 tag：</p>
<pre><code class="language-python">tag = ah.create('model/llm/gpt2:20230101', create_tag=True, source='v1')
</code></pre>
<pre><code>AH INFO: Tag 20230101 created from branch v1 for Model /demo/t9k-assethub/model/llm/gpt2
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用 <code>Branch</code> 实例的 <code>create_tag()</code> 方法完成上述操作。</p>
</aside>
<p>使用 <code>ah.list()</code> 函数查看模型的所有 tag：</p>
<pre><code class="language-python">pprint(ah.list('model/llm/gpt2', resource='tag'))
</code></pre>
<pre><code>[{'commit_id': 'a15799f8f601d514a1a385a57b3078f8e178614a66aa920217175f6dcac2b083',
  'id': '20230101'}]
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用 <code>Model</code> 实例的 <code>list_tag()</code> 方法完成上述操作。</p>
</aside>
<p>最后使用 <code>ah.delete()</code> 函数删除所有创建的分支和 tag：</p>
<pre><code class="language-python">ah.delete('model/llm/gpt2:v1')
ah.delete('model/llm/gpt2:20230101')
</code></pre>
<pre><code>AH INFO: Branch v1 deleted for Model /demo/t9k-assethub/model/llm/gpt2
AH INFO: Tag 20230101 deleted for Model /demo/t9k-assethub/model/llm/gpt2
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用各实例的 <code>delete()</code> 方法完成上述操作。</p>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="操作模型和数据集的对象"><a class="header" href="#操作模型和数据集的对象">操作模型和数据集的对象</a></h1>
<p>本教程演示如何通过多种方式操作模型的对象，包括修改、查看和下载 AssetHub 中存储的对象文件。</p>
<p>数据集同理。</p>
<h2 id="准备工作-11"><a class="header" href="#准备工作-11">准备工作</a></h2>
<ul>
<li>完成教程<a href="tasks/./manipulate-asset-branch-tag.html">操作模型/数据集的分支、tag 和 commit</a>。</li>
</ul>
<h2 id="通过命令行工具-5"><a class="header" href="#通过命令行工具-5">通过命令行工具</a></h2>
<p>切换到你的工作路径下：</p>
<pre><code class="language-shell">$ cd /your/workpath
</code></pre>
<p>操作对象的方式对于模型和数据集都是相同的，除了数据集只允许操作主分支（<code>main</code> 分支）中的对象。下面将以模型为例进行演示（这里假设用户名为 <code>demo</code>）。</p>
<p>依次创建模型文件夹、模型和分支：</p>
<pre><code class="language-shell">$ ah create model/llm
AH INFO: Folder /demo/t9k-assethub/model/llm created

$ ah create model/llm/gpt2
AH INFO: Model gpt2 created for Folder /demo/t9k-assethub/model/llm

$ ah create model/llm/gpt2:v1
AH INFO: Branch v1 created for Model /demo/t9k-assethub/model/llm/gpt2
</code></pre>
<p>使用 <code>ah commit</code> 命令向该分支上传本地文件（这里以 <code>model_state_dict.pt</code> 和 <code>README.md</code> 为例）作为对象存储：</p>
<pre><code class="language-shell">$ ah commit model/llm/gpt2:v1 --message &quot;Add model file&quot; --add model_state_dict.pt --add README.md
AH INFO: Committing changes to branch /demo/t9k-assethub/model/llm/gpt2:v1
AH INFO: Uploading object 1/2 model_state_dict.pt:
         Done        
AH INFO: Uploading object 2/2 README.md:
         Done        
AH INFO: Commit 29d6f29e created
</code></pre>
<p>使用 <code>ah ls</code> 命令查看分支的所有对象：</p>
<pre><code class="language-shell">$ ah ls model/llm/gpt2:v1
PATH                   BYTES  CHECKSUM                          MODIFIED
README.md               110B  d1f0e72bd20091c3869cefff8c72661b  1m29s ago
model_state_dict.pt  375943B  1203ee282c235c9fb4c2ea932a7b7cc8  1m29s ago
</code></pre>
<p>再次使用 <code>ah commit</code> 命令，当重复上传文件到同一路径时，原有的对象会被替换：</p>
<pre><code class="language-shell">$ ah commit model/llm/gpt2:v1 --message &quot;Update README&quot; --add README.md
AH INFO: Committing changes to branch /demo/t9k-assethub/model/llm/gpt2:v1
AH INFO: Uploading object 1/1 README.md:
         Done        
AH INFO: New commit 53097cba created

$ ah ls model/llm/gpt2:v1
PATH                   BYTES  CHECKSUM                          MODIFIED
README.md               221B  84c44f1510389ea7de91e550be8a7130  15s ago
model_state_dict.pt  375943B  1203ee282c235c9fb4c2ea932a7b7cc8  5m37s ago
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>每个对象在模型或数据集中存储时都有自己的路径，例如 <code>file1.txt</code>、<code>folder/file2.txt</code>。多级路径在控制台中会以多级目录的形式展示。</p>
<p>你可以通过 <code>-a LOCAL_PATH:PATH</code> 选项来自定义上传文件的存储路径。详细用法请参阅帮助信息 <code>ah commit --help</code>。</p>
</aside>
<p>使用 <code>-d PATH</code> 选项以删除指定路径的对象：</p>
<pre><code class="language-shell">$ ah commit model/llm/gpt2:v1 --message &quot;Remove README&quot; --delete README.md
AH INFO: Committing changes to branch /demo/t9k-assethub/model/llm/gpt2:v1
AH INFO: Deleting object README.md:
         Done
AH INFO: Commit cf8dcc26 created

$ ah ls model/llm/gpt2:v1
PATH                   BYTES  CHECKSUM                          MODIFIED
model_state_dict.pt  375943B  1203ee282c235c9fb4c2ea932a7b7cc8  6m2s ago
</code></pre>
<p>每次使用 <code>ah commit</code> 命令修改分支（添加、覆盖或删除对象）时，分支都会创建一个新的 commit。使用 <code>ah ls commit</code> 命令查看上面的操作所创建的 3 个 commit：</p>
<pre><code class="language-shell">$ ah ls model/llm/gpt2:v1 --commit
COMMIT_ID     MESSAGE               CREATED
cf8dcc26      Remove README         5m47s ago
53097cba      Update README         21m46s ago
29d6f29e      Add model file        33m8s ago
c4bebb3a      Repository created    33m18s ago   # 初始 commit
</code></pre>
<p>之后想要使用这些对象时，使用 <code>ah download</code> 命令下载对象保存为本地文件：</p>
<pre><code class="language-shell">$ ah download model/llm/gpt2:v1
AH INFO: Downloading object 1/1 model_state_dict.pt:
         ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.0% • 375.9/375.9 kB • 2.6 MB/s • 0:00:00

$ ls
model_state_dict.pt ...
</code></pre>
<h2 id="通过-python-sdk-3"><a class="header" href="#通过-python-sdk-3">通过 Python SDK</a></h2>
<p>切换到你的工作路径下，然后以任意方式执行下面的 Python 代码。</p>
<p>导入 <code>t9k.ah</code> 模块，使用 <code>ah.login()</code> 函数登录到 Asset Hub 服务器（如果配置文件中的凭据仍有效，则无需提供参数）：</p>
<pre><code class="language-python">from t9k import ah

ah.login(host='&lt;asset-hub-server-url&gt;',
         api_key='&lt;your-api-key&gt;')
</code></pre>
<pre><code>AH INFO: Logged in to Asset Hub server and AIStore server as user &lt;your-user-name&gt;
</code></pre>
<p>操作对象的方式对于模型和数据集都是相同的，除了数据集只允许操作主分支（<code>main</code> 分支）中的对象。下面将以模型为例进行演示（这里以 <code>user</code> 表示当前用户）。</p>
<p>依次创建模型文件夹、模型和分支：</p>
<pre><code class="language-python">model_folder = ah.create('model/llm')
model = ah.create('model/llm/gpt2')
branch = ah.create('model/llm/gpt2:v1')
</code></pre>
<pre><code>AH INFO: Folder /demo/t9k-assethub/model/llm created
AH INFO: Model gpt2 created for Folder /demo/t9k-assethub/model/llm
AH INFO: Branch v1 created for Model /demo/t9k-assethub/model/llm/gpt2
</code></pre>
<p>使用 <code>ah.commit()</code> 函数向该分支上传本地文件作为对象存储：</p>
<pre><code class="language-python">commit1 = ah.commit('model/llm/gpt2:v1',
                    msg='Add model file',
                    add=['model_state_dict.pt', 'README.md'])
</code></pre>
<pre><code>AH INFO: Committing changes to branch /demo/t9k-assethub/model/llm/gpt2:v1
AH INFO: Uploading object model_state_dict.pt:
         Done        
AH INFO: Uploading object README.md:
         Done        
AH INFO: Commit 6a57546b created
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用 <code>Branch</code> 实例的 <code>create_commit()</code> 方法完成上述操作。</p>
</aside>
<p>使用 <code>ah.list()</code> 函数查看分支的所有对象：</p>
<pre><code class="language-python">from pprint import pprint

pprint(ah.list('model/llm/gpt2:v1'))
</code></pre>
<pre><code>[{'checksum': 'f0db68fc4327c528b3a23fdc47c30c9e',
  'content_type': 'application/octet-stream',
  'mtime': 1683881423,
  'path': 'README.md',
  'path_type': 'object',
  'physical_address': 's3://t9k-aistore/d3a98ad0-50ca-42df-becf-8bbf4351d2c9/data/gnoggd0i2hci2stu7uhg/chevrjoi2hci2stu7un0',
  'size_bytes': 110},
 {'checksum': '1203ee282c235c9fb4c2ea932a7b7cc8',
  'content_type': 'application/octet-stream',
  'mtime': 1683881423,
  'path': 'model_state_dict.pt',
  'path_type': 'object',
  'physical_address': 's3://t9k-aistore/d3a98ad0-50ca-42df-becf-8bbf4351d2c9/data/gnoggd0i2hci2stu7uhg/chevrjgi2hci2stu7umg',
  'size_bytes': 375943}]
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用 <code>Branch</code> 实例的 <code>list_object()</code> 方法完成上述操作。</p>
</aside>
<p>再次使用 <code>ah.commit()</code> 函数，当重复上传文件到同一路径时，原有的对象会被替换：</p>
<pre><code class="language-python">commit2 = ah.commit('model/llm/gpt2:v1', msg='Update README', add=['README.md'])

pprint(ah.list('model/llm/gpt2:v1'))
</code></pre>
<pre><code>AH INFO: Committing changes to branch /demo/t9k-assethub/model/llm/gpt2:v1
AH INFO: Uploading object README.md:
         Done        
AH INFO: Commit 8183e1df created
[{'checksum': '1cbd5021ee923905bbdc29883c50a1b0',
  'content_type': 'application/octet-stream',
  'mtime': 1683881478,
  'path': 'README.md',
  'path_type': 'object',
  'physical_address': 's3://t9k-aistore/d3a98ad0-50ca-42df-becf-8bbf4351d2c9/data/gnoggd0i2hci2stu7uhg/chevs1gi2hci2stu7uog',
  'size_bytes': 221},
 {'checksum': '1203ee282c235c9fb4c2ea932a7b7cc8',
  'content_type': 'application/octet-stream',
  'mtime': 1683881423,
  'path': 'model_state_dict.pt',
  'path_type': 'object',
  'physical_address': 's3://t9k-aistore/d3a98ad0-50ca-42df-becf-8bbf4351d2c9/data/gnoggd0i2hci2stu7uhg/chevrjgi2hci2stu7umg',
  'size_bytes': 375943}]
</code></pre>
<p>使用 <code>delete</code> 选项以删除指定路径的对象：</p>
<pre><code class="language-python">commit3 = ah.commit('model/llm/gpt2:v1', msg='Remove README', delete=['README.md'])

pprint(branch.list_object())
</code></pre>
<pre><code>AH INFO: Committing changes to branch /demo/t9k-assethub/model/llm/gpt2:v1
AH INFO: Deleting object README.md:
         Done
AH INFO: Commit 00af1151 created
[{'checksum': '1203ee282c235c9fb4c2ea932a7b7cc8',
  'content_type': 'application/octet-stream',
  'mtime': 1683881423,
  'path': 'model_state_dict.pt',
  'path_type': 'object',
  'physical_address': 's3://t9k-aistore/d3a98ad0-50ca-42df-becf-8bbf4351d2c9/data/gnoggd0i2hci2stu7uhg/chevrjgi2hci2stu7umg',
  'size_bytes': 375943}]
</code></pre>
<p>每次使用 <code>ah.commit()</code> 函数修改分支（添加、覆盖或删除对象）时，分支都会创建一个新的 commit。继续使用 <code>ah.list()</code> 函数查看上面的操作所创建的 3 个 commit：</p>
<pre><code class="language-python">pprint(ah.list('model/llm/gpt2:v1', resource='commit'))
</code></pre>
<pre><code>[{'committer': 'admin',
  'creation_date': 1683881538,
  'id': '00af1151865121a79233af326b21864f2f6dbcc3b5bebb2f8768e2b13154f754',
  'message': 'Remove README',             # commit3
  'meta_range_id': 'c959b9ce4301591b82517c97ca277b034fd4a4d181b63db7571a2a8174844848',
  'metadata': {},
  'parents': ['8183e1dfb0dcded478aff1b5cb2975ae22e83ca4f37333fb904e5bcd27897923']},
 {'committer': 'admin',
  'creation_date': 1683881479,
  'id': '8183e1dfb0dcded478aff1b5cb2975ae22e83ca4f37333fb904e5bcd27897923',
  'message': 'Update README',             # commit2
  'meta_range_id': '2184d241abdc0ce3e26db44ad2c1df3e1e6a7a6b231fa1f17db7684982a55243',
  'metadata': {},
  'parents': ['6a57546b1275ba6b7f1399e0f7213552ac7bdf545de8692e494db47b93623b9d']},
 {'committer': 'admin',
  'creation_date': 1683881423,
  'id': '6a57546b1275ba6b7f1399e0f7213552ac7bdf545de8692e494db47b93623b9d',
  'message': 'Add model file',            # commit1
  'meta_range_id': '0b8943e0b3b4a3b8661f6146f47f85562aea5c7eb88bc2c66f2adf7443a08451',
  'metadata': {},
  'parents': ['610af4d2991e5c9b9d527dedf34db3cd11c8bd5bb7cc0e8ed0b97505319f8f11']},
 {'committer': '',
  'creation_date': 1683881388,
  'id': '610af4d2991e5c9b9d527dedf34db3cd11c8bd5bb7cc0e8ed0b97505319f8f11',
  'message': 'Repository created',        # 初始 commit
  'meta_range_id': '',
  'metadata': {},
  'parents': []}]
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用 <code>Branch</code> 实例的 <code>list_commit()</code> 方法完成上述操作。</p>
</aside>
<p>之后想要使用这些对象时，使用 <code>ah.download()</code> 函数下载对象保存为本地文件：</p>
<pre><code class="language-python">ah.download('model/llm/gpt2:v1')

import os
print(os.listdir())
</code></pre>
<pre><code>AH INFO: Downloading object 1/1 model_state_dict.pt:
         ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.0% • 375.9/375.9 kB • 2.6 MB/s • 0:00:00
['model_state_dict.pt', ...]
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>亦可使用 <code>Branch</code> 实例的 <code>download()</code> 方法完成上述操作。</p>
</aside>
<h2 id="通过控制台-4"><a class="header" href="#通过控制台-4">通过控制台</a></h2>
<p>数据集的控制台操作和模型完全一致。本教程后续仅展示模型对象的上传和下载，你可以用同样的方式操作数据集。</p>
<p>在进行教程之前，先按照<a href="tasks/./manipulate-folder-asset.html">操作文件夹、模型和数据集</a>一节完成模型文件夹和模型的创建（chat/gpt3）。</p>
<p>进入模型详情页后，点击<strong>所有文件 &gt; 上传图标</strong>：</p>
<figure class="screenshot">
  <img alt="model-detail" src="tasks/../assets/tasks/manage-asset/operate-asset-objects/model-detail.png" />
</figure>
<p>点击<strong>选择文件</strong>选择所要上传的文件，填写描述信息，然后点击<strong>提交</strong>：</p>
<figure class="screenshot">
  <img alt="model-upload" src="tasks/../assets/tasks/manage-asset/operate-asset-objects/model-upload.png" />
</figure>
<p>完成提交后，可以在<strong>所有文件</strong>中看到刚刚上传的文件，点击<strong>下载图标</strong>下载该文件：</p>
<figure class="screenshot">
  <img alt="model-object-list" src="tasks/../assets/tasks/manage-asset/operate-asset-objects/model-object-list.png" />
</figure>
<p>点击<strong>介绍 &gt; 添加介绍</strong>：</p>
<figure class="screenshot">
  <img alt="model-introduce" src="tasks/../assets/tasks/manage-asset/operate-asset-objects/model-introduce.png" />
</figure>
<p>在编辑框中按照 <code>markdown</code> 格式编辑模型的描述信息，填写提交信息，点击<strong>提交</strong>：</p>
<figure class="screenshot">
  <img alt="model-readme" src="tasks/../assets/tasks/manage-asset/operate-asset-objects/model-readme.png" />
</figure>
<p>添加完介绍后，在模型详情页可以看到模型介绍：</p>
<figure class="screenshot">
  <img alt="model-introduce-after-add" src="tasks/../assets/tasks/manage-asset/operate-asset-objects/model-introduce-after-add.png" />
</figure>
<p>模型介绍本质上是 <strong>README.md</strong> 文件，在<strong>所有文件</strong>中可以看到：</p>
<figure class="screenshot">
  <img alt="model-object-list-readme" src="tasks/../assets/tasks/manage-asset/operate-asset-objects/model-object-list-readme.png" />
</figure>
<aside class="note">
<div class="title">注意</div>
<p>控制台主要用来查看对象，上传、下载对象的操作实现的较为简单，一次仅能处理一个对象。如果希望大批量下载、上传或执行其他更精细的操作，请使用 Python SDK。</p>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="追踪模型训练"><a class="header" href="#追踪模型训练">追踪模型训练</a></h1>
<p>在复杂的 AI 实验中，研究人员或工程师需要处理数以百计的实验配置和结果，在缺乏有效管理工具的情况下很容易迷失在海量的数据和文件中。因此，追踪和记录实验变得十分重要，它能够帮助研究人员快速识别最佳模型，比较不同模型的差异，洞悉关键因素的作用，并且迅速迭代改进，从而大幅提升研究和开发的效率。</p>
<p>这一部分将使用<a href="tasks/../modules/experiment-management.html">实验管理模块</a>和 <a href="tasks/../tools/python-sdk-t9k/index.html">Python SDK</a> 追踪模型的训练过程和结果。Python SDK 负责自动记录超参数、指标、平台信息以及任何重要的输入输出文件，实验管理控制台则提供直观的可视化界面以及便捷的团队协作体验。我们将从介绍实验管理控制台与 Python SDK 的基本用法开始，进而到实际场景中追踪模型的训练，最后我们查看 AutoTune 进行超参数优化的结果。</p>
<p>本部分常见任务如下：</p>
<ul>
<li><a href="tasks/./use-experiment-console.html">在实验管理控制台查看和管理数据</a></li>
<li><a href="tasks/./record-using-python-sdk.html">使用 Python SDK 记录和上传数据</a></li>
<li><a href="tasks/./record-single-device-training.html">单设备训练场景</a></li>
<li><a href="tasks/./record-distributed-training.html">分布式训练场景</a></li>
<li><a href="tasks/./view-autotune-in-experiment-console.html">在实验管理控制台查看 AutoTune</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="在实验管理控制台查看和管理数据"><a class="header" href="#在实验管理控制台查看和管理数据">在实验管理控制台查看和管理数据</a></h1>
<p>本教程演示如何使用实验管理控制台来查看和管理记录的模型训练数据。</p>
<h2 id="进入实验管理控制台"><a class="header" href="#进入实验管理控制台">进入实验管理控制台</a></h2>
<p>在 TensorStack AI 平台的首页，点击<strong>实验管理</strong>进入实验管理控制台。</p>
<figure class="screenshot">
    <img alt="enter-experiment-console" src="tasks/../assets/tasks/use-experiment-console/enter-experiment-console.png" />
</figure>
<h2 id="浏览文件夹"><a class="header" href="#浏览文件夹">浏览文件夹</a></h2>
<p>当前用户的所有数据以类似于文件系统的方式组织，每个 Run（或 Artifact、AutoTune）都位于特定的路径之下。点击一个文件夹（Folder）以进入，查看其下的所有子文件夹和 Run（或 Artifact、AutoTune）。</p>
<figure class="screenshot">
    <img alt="enter-folder" src="tasks/../assets/tasks/use-experiment-console/enter-folder.png" />
</figure>
<p>使用上方的<strong>面包屑导航</strong>或左侧的<strong>导航菜单</strong>可以返回上级文件夹或跳转到其他文件夹。</p>
<figure class="screenshot">
    <img alt="jump-to-folder" src="tasks/../assets/tasks/use-experiment-console/jump-to-folder.png" />
</figure>
<h2 id="创建和删除文件夹"><a class="header" href="#创建和删除文件夹">创建和删除文件夹</a></h2>
<p>若要创建一个文件夹，点击右上角的<strong>添加</strong>，在对话框中提供文件夹名称并点击<strong>创建</strong>。</p>
<figure class="screenshot">
    <img alt="create-folder" src="tasks/../assets/tasks/use-experiment-console/create-folder.png" />
</figure>
<p>若要删除一个文件夹，点击文件夹项右侧的<strong>操作</strong>，或点击面包屑导航中的当前文件夹，然后点击<strong>删除</strong>。</p>
<figure class="screenshot">
    <img alt="delete-folder1" src="tasks/../assets/tasks/use-experiment-console/delete-folder1.png" />
</figure>
<figure class="screenshot">
    <img alt="delete-folder2" src="tasks/../assets/tasks/use-experiment-console/delete-folder2.png" />
</figure>
<h2 id="共享文件夹"><a class="header" href="#共享文件夹">共享文件夹</a></h2>
<p>点击文件夹项右侧的<strong>操作</strong>，或点击面包屑导航中的当前文件夹，点击<strong>分享</strong>，在对话框中管理文件夹的分享成员列表。空白表示文件夹当前没有被分享给任何其他用户。</p>
<figure class="screenshot">
    <img alt="share-folder" src="tasks/../assets/tasks/use-experiment-console/share-folder.png" />
</figure>
<p>分享成员列表可以任意添加（点击<strong>加号</strong>）或移除（点击用户项右侧的<strong>减号</strong>）平台的其他用户或用户组，选择用户或用户组的名称和权限，最后点击<strong>保存</strong>以确定。</p>
<figure class="screenshot">
    <img alt="share-user-list" src="tasks/../assets/tasks/use-experiment-console/share-user-list.png" />
</figure>
<p>来自其他用户分享的文件夹、Run、Artifact 或 AutoTune 将出现在导航菜单的<strong>分享给我的</strong>标签下。</p>
<figure class="screenshot">
    <img alt="shared-with-me" src="tasks/../assets/tasks/use-experiment-console/shared-with-me.png" />
</figure>
<h2 id="其他文件夹操作"><a class="header" href="#其他文件夹操作">其他文件夹操作</a></h2>
<p>同样点击文件夹项右侧的<strong>操作</strong>，或点击面包屑导航中的当前文件夹，你还可以进行<strong>创建快捷方式</strong>、<strong>移动</strong>以及<strong>重命名</strong>操作。</p>
<h2 id="查看-run-和-artifact"><a class="header" href="#查看-run-和-artifact">查看 Run 和 Artifact</a></h2>
<p>点击一个 <strong>Run 或 Artifact 的名称</strong>以进入它的详情页面。</p>
<figure class="screenshot">
    <img alt="enter-run-artifact" src="tasks/../assets/tasks/use-experiment-console/enter-run-artifact.png" />
</figure>
<p>Run 的详情页面中，多个标签页分别展示了平台信息、指标、超参数以及数据流。</p>
<figure class="screenshot">
    <img alt="run-details" src="tasks/../assets/tasks/use-experiment-console/run-details.png" />
</figure>
<p>Artifact 的详情页面中，多个标签页分别展示了文件列表以及数据流。</p>
<figure class="screenshot">
    <img alt="artifact-details" src="tasks/../assets/tasks/use-experiment-console/artifact-details.png" />
</figure>
<h2 id="创建和删除-runartifact-和-autotune"><a class="header" href="#创建和删除-runartifact-和-autotune">创建和删除 Run、Artifact 和 AutoTune</a></h2>
<p>创建 Run 和 Artifact 的方法请参阅<a href="tasks/./record-using-python-sdk.html">使用 Python SDK 记录和上传数据</a>；创建 AutoTune 的方法请参阅<a href="tasks/./autotune.html">使用 AutoTune 进行超参数优化</a>。</p>
<p>若要删除一个 Run（或 Artifact、AutoTune，下同），与删除文件夹的操作相同，点击 Run 项右侧的<strong>操作</strong>，或点击面包屑导航中的当前 Run，然后点击<strong>删除</strong>。</p>
<figure class="screenshot">
    <img alt="delete-run" src="tasks/../assets/tasks/use-experiment-console/delete-run.png" />
</figure>
<h2 id="分享-runartifact-和-autotune-以及其他操作"><a class="header" href="#分享-runartifact-和-autotune-以及其他操作">分享 Run、Artifact 和 AutoTune 以及其他操作</a></h2>
<p>分享 Run（或 Artifact、AutoTune）或者进行其他操作的方法都与文件夹相同，这里不再赘述。</p>
<h2 id="退出登录或切换用户"><a class="header" href="#退出登录或切换用户">退出登录或切换用户</a></h2>
<p>如果你想要退出当前用户的登录，点击右上角的<strong>用户头像</strong>，然后点击<strong>退出登录</strong>。</p>
<figure class="screenshot">
    <img alt="sign-out" src="tasks/../assets/tasks/use-experiment-console/sign-out.png" />
</figure>
<p>再次进入实验管理控制台时，你需要输入用户名和密码以重新登录。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-python-sdk-记录和上传数据"><a class="header" href="#使用-python-sdk-记录和上传数据">使用 Python SDK 记录和上传数据</a></h1>
<p>本教程介绍如何使用 <a href="tasks/../tools/python-sdk-t9k/guide.html">Python SDK</a> 进行创建、加载、上传 Run 和 Artifact，设定超参数，记录指标等操作。</p>
<h2 id="创建-run"><a class="header" href="#创建-run">创建 Run</a></h2>
<h3 id="基本方法"><a class="header" href="#基本方法">基本方法</a></h3>
<p>在模型的训练脚本中，你需要首先创建一个 Run，通过调用 <code>t9k.em.create_run()</code> 函数。其返回的 <code>Run</code> 实例即代表了一次训练的运行。此方法调用后，Run 将被创建，具有状态“Running”，其本地文件默认保存在相对路径 <code>.em/runs</code> 下，每个 Run 拥有一个独立的名为 <code>&lt;run_name&gt;_&lt;date&gt;_&lt;time&gt;_&lt;random_suffix&gt;</code>（称为该 Run 的备用名称）的子目录。</p>
<p>最基本的初始化方法只需要提供名称作为参数。</p>
<pre><code class="language-python">from t9k import em

run = em.create_run(name='mnist_torch')    # 返回Run实例
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>你可以通过设置环境变量 <code>EM_RUN_PARENT_DIR</code> 来修改 Run 的本地文件的保存路径。</p>
</aside>
<h3 id="自动上传"><a class="header" href="#自动上传">自动上传</a></h3>
<p>如果想要自动异步上传 Run 的更新，可以设定 <code>auto_upload=True</code>，并提供文件夹路径，以及设定是否创建不存在的各级文件夹。在这种情况下，你在创建 Run 之前需要先<a href="tasks/record-using-python-sdk.html#%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95-2">登录到 AIStore 服务器</a>。</p>
<pre><code class="language-python">run = em.create_run(name='mnist_torch',
                    auto_upload=True,      # 启用自动上传
                    folder='new-folder',   # 文件夹路径
                    make_folder=True)      # 创建不存在的各级文件夹
</code></pre>
<p>如果目标文件夹已经存在同名的 Run，则需要指定 <code>conflict_strategy</code> 参数以处理冲突，参数接受以下值：</p>
<ul>
<li><code>'skip'</code>：跳过上传。</li>
<li><code>'error'</code>：错误退出。</li>
<li><code>'new'</code>：以 Run 的备用名称上传。</li>
<li><code>'replace'</code>：替换同名的 Run。</li>
</ul>
<p>例如，运行以下代码两次，第二次创建的 Run 会以类似 <code>mnist_torch_231231_235959_61p5jc</code> 的名称被上传到 <code>new-folder</code> 文件夹下。</p>
<pre><code class="language-python">run = em.create_run(name='mnist_torch',
                    auto_upload=True,
                    folder='new-folder',
                    make_folder=True,
                    conflict_strategy='new')
</code></pre>
<h3 id="提供标签和描述"><a class="header" href="#提供标签和描述">提供标签和描述</a></h3>
<p>你可以为创建的 Run 提供用于分类或介绍的标签或描述。</p>
<pre><code class="language-python">run = em.create_run(
    name='mnist_torch',
    labels=['torch', 'CNN'],  # 标签
    description=              # 描述
    'Train a simple CNN model that classifies images of handwritten digits.')
</code></pre>
<h3 id="提供配置文件"><a class="header" href="#提供配置文件">提供配置文件</a></h3>
<p>你可以将上面的所有配置（以及下面将要提到的超参数）都写进一个 YAML 文件里，然后传入该配置文件的路径即可。</p>
<pre><code class="language-python">run = em.create_run(config_path='./run_config.yaml')  # 提供配置文件
</code></pre>
<p>其中 <code>run_config.yaml</code> 的内容如下：</p>
<pre><code class="language-yaml">name: mnist_torch
auto_upload: true
folder: new-folder
make_folder: true
conflict_strategy: new
labels:
- torch
- CNN
description: Train a simple CNN model that classifies images of handwritten digits.
</code></pre>
<h2 id="设定超参数"><a class="header" href="#设定超参数">设定超参数</a></h2>
<h3 id="基本方法-1"><a class="header" href="#基本方法-1">基本方法</a></h3>
<p>超参数是影响模型训练效果的重要因素，记录训练的超参数十分必要，尤其是当你聚焦于某几个特定的超参数时。<code>Run</code> 实例的 <code>hparams</code> 属性是一个容器对象，用于保存你想要记录的所有超参数，你可以像操作 Python 字典一样操作它。一种推荐的设定超参数的方法是调用一次该容器对象的 <code>update()</code> 方法完成所有超参数的设定。</p>
<pre><code class="language-python">run.hparams.update({
    'batch_size': 32,
    'epochs': 10,
    'learning_rate': 0.001,
    'conv_channels': 32,
    'conv_kernel_size': 3,
    'maxpool_size': 2,
    'linear_features': 64,
})

hparams = run.hparams      # 便于之后访问
</code></pre>
<p>另一种推荐的方法是在创建 Run 的时候就传入所有超参数，此时可以将超参数也写进配置文件。</p>
<pre><code class="language-python">run = em.create_run(
    name='mnist_torch',
    hparams={
    'batch_size': 32,
    'epochs': 10,
    'learning_rate': 0.001,
    'conv_channels': 32,
    'conv_kernel_size': 3,
    'maxpool_size': 2,
    'linear_features': 64,
})

# 或

run = em.create_run(config_path='./run_config.yaml')
</code></pre>
<p>其中 <code>run_config.yaml</code> 的内容如下：</p>
<pre><code class="language-yaml">name: mnist_torch
hparams:
  batch_size: 32
  epochs: 10
  learning_rate: 0.001
  conv_channels: 32
  conv_kernel_size: 3
  maxpool_size: 2
  linear_features: 64
</code></pre>
<p>当然，你也可以多次调用 <code>update()</code> 方法，或者使用类似 Python 字典的键值对赋值方法设定单个超参数。</p>
<pre><code class="language-python">run.hparams['batch_size'] = 32
</code></pre>
<p>设定完成之后，使用这些超参数配置模型，同样使用类似 Python 字典的键值对访问方法。</p>
<pre><code class="language-python">from tensorflow.keras import layers, models, optimizers

model = models.Sequential()
model.add(layers.Conv2D(hparams['conv_channels'],     # 使用超参数配置模型
                        hparams['conv_kernel_size'],
                        input_shape=(28, 28, 1)))
...
optimizer = optimizers.Adam(learning_rate=hparams['learning_rate'])
model.compile(
    optimizer=optimizer,
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy'])
...
model.fit(train_images,
          train_labels,
          batch_size=hparams['batch_size'],
          epochs=hparams['epochs'])
</code></pre>
<h3 id="设定作为标记的超参数"><a class="header" href="#设定作为标记的超参数">设定作为标记的超参数</a></h3>
<p>在上面的示例中，所有超参数都是直接传入各函数以配置模型。你也可以设定一些作为标记的超参数，例如网络类型、优化器类型、损失函数类型、激活函数类型等，以便日后快速回顾重要信息。</p>
<pre><code class="language-python">run.hparams.update({
    'network_structure': 'CNN',
    'optimizer': 'Adam',
    'loss': 'sparse categorical crossentropy',
    'linear_acti': 'relu',
})
</code></pre>
<h3 id="配合-argparse-模块使用"><a class="header" href="#配合-argparse-模块使用">配合 argparse 模块使用</a></h3>
<p>许多训练脚本的超参数都是从命令行传入，由 <code>argparse</code> 模块解析。这些超参数可以方便地转换为字典对象并传入 <code>update()</code> 方法。</p>
<pre><code class="language-python">import argparse

parser = argparse.ArgumentParser()
parser.add_argument(...)
args = parser.parse_args()

run.hparams.update(args.__dict__)
</code></pre>
<h2 id="记录指标"><a class="header" href="#记录指标">记录指标</a></h2>
<h3 id="手动记录"><a class="header" href="#手动记录">手动记录</a></h3>
<p><code>Run</code> 实例的 <code>log()</code> 方法用于记录模型在训练、验证或测试过程中产生的指标。被传入的字典对象会被作为指标记录，与此同时还需要提供指标的类型、当前的全局训练步数以及（可选的）当前的回合数。</p>
<pre><code class="language-python"># PyTorch模型
for epoch in range(1, epochs + 1):
    model.train()
    for step, (data, target) in enumerate(train_loader, 1):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

        if step % 500 == 0:
            train_loss = loss.item()
            logging.info(
                'epoch {:d}/{:d}, batch {:5d}/{:d} with loss: {:.4f}'.
                format(epoch, epochs, step, steps_per_epoch, train_loss))
            global_step = (epoch - 1) * steps_per_epoch + step

            run.log(
                type='train',                    # 指标类型
                metrics={'loss': train_loss},    # 指标名称及相应值
                step=global_step,                # 当前全局步数
                epoch=epoch)                     # 当前回合数
</code></pre>
<aside class="note">
<div class="title">注意</div>
<p>训练指标、验证指标和测试指标请分别使用指标类型 <code>'train'</code>（或 <code>'training'</code>）、<code>'val'</code>（或 <code>'validate'</code>、<code>'validation'</code>）和 <code>'test'</code>（或 <code>'testing'</code>、<code>'eval'</code>、<code>'evaluate'</code>、<code>'evaluation'</code>）。除此之外，你也可以使用其他任意字符串作为自定义指标类型。</p>
<p>指标的值可以是 Python 数字类型，或仅有一个元素的 NumPy 数组、TensorFlow 张量或 PyTorch 张量。</p>
</aside>
<h3 id="自动记录"><a class="header" href="#自动记录">自动记录</a></h3>
<p>对于建立在 Keras API 上的模型，更简单的方法是在模型的训练和测试方法中分别添加回调 <code>t9k.em.keras.EMFitCallback</code> 和 <code>t9k.em.keras.EMEvalCallback</code> 的实例。回调会相应地调用 <code>log()</code> 方法以自动记录各指标并同步到服务器。</p>
<pre><code class="language-python"># Keras模型
# 训练/验证过程和测试过程分别使用不同的回调
from t9k.em.keras import EMFitCallback, EMEvalCallback

model.fit(train_images,
          train_labels,
          epochs=10,
          validation_split=0.2,
          callbacks=EMFitCallback(run))

model.evaluate(test_images,
               test_labels,
               callbacks=EMEvalCallback(run))
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>除了记录训练指标，<code>EMFitCallback</code> 回调还会获取模型的优化器配置、损失函数类型和指标类型并更新 Run 的超参数。</p>
</aside>
<!-- 
```python
# PyTorch Lightning模型
from t9k.em.lightning import emCallback

trainer = Trainer(max_epochs=10,
                  callbacks=emCallback(trial))
``` -->
<h2 id="结束-run"><a class="header" href="#结束-run">结束 Run</a></h2>
<p>模型的训练与测试全部完成后，你需要结束 Run，通过调用 <code>Run</code> 实例的 <code>finish()</code> 方法。此方法调用后，Run 的状态将更新为“Complete”。</p>
<pre><code class="language-python">run.finish()
</code></pre>
<h2 id="创建-artifact"><a class="header" href="#创建-artifact">创建 Artifact</a></h2>
<h3 id="基本方法-2"><a class="header" href="#基本方法-2">基本方法</a></h3>
<p>如要记录和保存与训练过程有关的文件，你需要创建一个 Artifact，通过调用 <code>t9k.em.create_artifact()</code> 函数。此方法调用后，Artifact 将被创建，其本地文件默认保存在相对路径 <code>.em/artifacts</code> 下。与 Run 相同，每个 Artifact 拥有一个独立的名为 &lt;artifact_name&gt;<em><date></em><time>_&lt;random_suffix&gt;（称为该 Artifact 的备用名称）的子目录。</p>
<p>最基本的初始化方法只需要提供名称作为参数。</p>
<pre><code class="language-python">dateset_artifact = em.create_artifact(name='mnist_dataset')
</code></pre>
<h3 id="提供标签和描述-1"><a class="header" href="#提供标签和描述-1">提供标签和描述</a></h3>
<p>你可以为创建的 Artifact 提供用于分类或介绍的标签或描述。</p>
<pre><code class="language-python">dateset_artifact = em.create_artifact(
    name='mnist_dataset',
    labels=['dataset', 'MNIST'],                           # 标签
    description='Image dataset of handwritten digits.')    # 描述
</code></pre>
<h2 id="为-artifact-添加文件"><a class="header" href="#为-artifact-添加文件">为 Artifact 添加文件</a></h2>
<p>与训练过程有关的文件通过 <code>Artifact</code> 实例的 <code>add_file()</code> 和 <code>add_dir()</code> 方法添加到 Artifact 中。</p>
<pre><code class="language-python">dateset_artifact.add_file(file_path='./mnist.npz')    # 添加单个文件
dateset_artifact.add_dir(dir_path='./mnist/')         # 添加目录
</code></pre>
<p>Artifact 中的文件对象具有层次结构，你可以指定文件或目录位于 Artifact 的何路径下。</p>
<pre><code class="language-python">dateset_artifact.add_file(file_path='./mnist.npz', obj_path='dataset/')
dateset_artifact.add_dir(dir_path='./mnist/', obj_path='dataset/')
</code></pre>
<p>还可以通过 <code>add_reference()</code> 方法为 Artifact 添加一个网络文件的引用。</p>
<pre><code class="language-python">dateset_artifact.add_reference(uri='https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz', obj_path='dataset/')
</code></pre>
<h2 id="标记-artifact-为-run-的输入输出"><a class="header" href="#标记-artifact-为-run-的输入输出">标记 Artifact 为 Run 的输入输出</a></h2>
<p>为了构成 Run 与 Artifact 之间的数据流，需要调用 <code>Run</code> 实例的 <code>mark_input()</code> 和 <code>mark_output()</code> 方法以标记 <code>Artifact</code> 实例为其输入或输出。</p>
<pre><code class="language-python">run.mark_input(dateset_artifact)
run.mark_output(model_artifact)
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>Model、Dataset、Branch、Tag 和 Commit 实例也可以被标记为 Run 的输入或输出。</p>
</aside>
<h2 id="上传数据"><a class="header" href="#上传数据">上传数据</a></h2>
<h3 id="基本方法-3"><a class="header" href="#基本方法-3">基本方法</a></h3>
<p>上传数据之前，你需要先登录到 <a href="tasks/../modules/asset-management.html#%E4%BA%A7%E5%93%81%E6%9E%B6%E6%9E%84">AIStore</a> 服务器，通过调用 <code>t9k.em.login()</code> 函数。</p>
<pre><code class="language-python">em.login(ais_host='&lt;your-server-host&gt;', api_key='&lt;your-api-key&gt;')
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>生成包含 EM 权限的 API Key 的方法请参阅<a href="tasks/./generate-api-key.html">生成 API Key</a>。</p>
<p>如要了解 API Key 的更多细节和使用方法，请参阅 <a href="tasks/../modules/security/account.html#api-key">API Key</a> 和<a href="tasks/./use-api-key.html">使用 API Key</a>。</p>
</aside>
<aside class="note tip">
<div class="title">提示</div>
<p>AIStore 服务器位于平台主机域名的 <code>/t9k/aistore/server</code> 路径下。例如，如果平台首页的 URL 为 <code>https://www.tensorstack.net/t9k/landing-page/</code>，那么 AIStore 服务器的 URL 为 <code>https://www.tensorstack.net/t9k/aistore/server</code>。</p>
</aside>
<aside class="note tip">
<div class="title">提示</div>
<p>如果你在 <a href="tasks/../tools/python-sdk-t9k/guide.html#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">Python SDK 配置文件</a>中提供了 <code>contexts[*].prefixes.aistore</code> 或 <code>contexts[*].auth.api_key</code> 字段的值，则它们将作为调用 <code>login()</code> 函数时相应参数的默认值。</p>
</aside>
<p>然后调用 <code>Run</code> 或 <code>Artifact</code> 实例的 <code>upload()</code> 方法。</p>
<pre><code class="language-python">run.upload()
artifact.upload()
</code></pre>
<aside class="note">
<div class="title">注意</div>
<p>当一个 Run 被上传时，被标记为其输入输出的 Artifact 也会同时被上传。</p>
</aside>
<h3 id="上传本地保存的数据"><a class="header" href="#上传本地保存的数据">上传本地保存的数据</a></h3>
<p>你也可以在训练结束之后将本地保存的数据上传到 AIStore 服务器，以应对训练时无网络连接、最初未打算上传、误删服务器中的数据等情形。</p>
<p>首先<a href="tasks/record-using-python-sdk.html#%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95-2">登录到 AIStore 服务器</a>，然后加载保存在本地的 Run 或 Artifact，调用其 <code>upload()</code> 方法。</p>
<pre><code class="language-python">run = em.load_run(path='.em/runs/mnist_torch_231222_141932_61p5jc')
run.upload(folder='default', make_folder=True)

artifact = em.load_artifact(path='.em/runs/mnist_torch_saved_model_230908_165433_tou3ai')
artifact.upload(folder='default', make_folder=True)
</code></pre>
<h2 id="下一步-34"><a class="header" href="#下一步-34">下一步</a></h2>
<ul>
<li>进一步学习如何<a href="tasks/./record-single-device-training.html">在单设备训练场景下追踪模型训练</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="单设备训练场景"><a class="header" href="#单设备训练场景">单设备训练场景</a></h1>
<p>本教程演示如何记录并展示单设备训练场景下的训练产生的信息、指标和文件（以 PyTorch 模型在单个 CPU 或 GPU 上的训练为例）。</p>
<aside class="note info">
<div class="title">信息</div>
<p>对于 Keras 模型，<code>t9k.em</code> 提供了使用更加方便的回调，详见<a href="tasks/./record-using-python-sdk.html#%E8%87%AA%E5%8A%A8%E8%AE%B0%E5%BD%95">自动记录</a>。</p>
</aside>
<h2 id="运行示例-11"><a class="header" href="#运行示例-11">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/em/single-worker-training">本教程对应的示例</a>，参照其 README 文档运行。</p>
<p>下面介绍训练脚本进行了哪些修改以追踪训练。</p>
<h2 id="准备训练脚本-1"><a class="header" href="#准备训练脚本-1">准备训练脚本</a></h2>
<p>准备一个 PyTorch 训练脚本，其模型对 MNIST 数据集的图像进行分类，具体代码如下所示。接下来将在此脚本的基础上进行简单的修改以进行追踪。</p>
<details><summary><code class="hljs">torch_mnist.py</code></summary>
<pre><code class="language-python">import argparse
import logging
import os

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms

parser = argparse.ArgumentParser(
    description='Recording of training data of PyTorch model for MNIST with EM.'
)
parser.add_argument('--no_cuda',
                    action='store_true',
                    default=False,
                    help='Disable CUDA training.')
logging.basicConfig(format='%(message)s', level=logging.INFO)


class Net(nn.Module):

    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 64, 1)
        self.conv3 = nn.Conv2d(64, 64, 3, 1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dense1 = nn.Linear(576, 64)
        self.dense2 = nn.Linear(64, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = F.relu(self.conv3(x))
        x = torch.flatten(x, 1)
        x = F.relu(self.dense1(x))
        output = F.softmax(self.dense2(x), dim=1)
        return output


def train(scheduler):
    global global_step
    for epoch in range(1, epochs + 1):
        model.train()
        for step, (data, target) in enumerate(train_loader, 1):
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

            if step % 500 == 0:
                train_loss = loss.item()
                logging.info(
                    'epoch {:d}/{:d}, batch {:5d}/{:d} with loss: {:.4f}'.
                    format(epoch, epochs, step, steps_per_epoch, train_loss))
                global_step = (epoch - 1) * steps_per_epoch + step

        scheduler.step()
        global_step = epoch * steps_per_epoch
        test(val=True, epoch=epoch)


def test(val=False, epoch=None):
    label = 'val' if val else 'test'
    model.eval()
    running_loss = 0.0
    correct = 0

    with torch.no_grad():
        loader = val_loader if val else test_loader
        for data, target in loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            loss = criterion(output, target)
            running_loss += loss.item()
            prediction = output.max(1)[1]
            correct += (prediction == target).sum().item()

    test_loss = running_loss / len(loader)
    test_accuracy = correct / len(loader.dataset)
    msg = '{:s} loss: {:.4f}, {:s} accuracy: {:.4f}'.format(
        label, test_loss, label, test_accuracy)
    if val:
        msg = 'epoch {:d}/{:d} with '.format(epoch, epochs) + msg
    logging.info(msg)


if __name__ == '__main__':
    args = parser.parse_args()

    use_cuda = not args.no_cuda and torch.cuda.is_available()
    if use_cuda:
        logging.info('Using CUDA')
    device = torch.device('cuda' if use_cuda else 'cpu')
    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}

    torch.manual_seed(1)

    model = Net().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)

    dataset_path = os.path.join(os.path.dirname(os.path.realpath(__file__)),
                                'data')
    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5), (0.5))])
    train_dataset = datasets.MNIST(root=dataset_path,
                                   train=True,
                                   download=True,
                                   transform=transform)
    train_dataset, val_dataset = torch.utils.data.random_split(
        train_dataset, [48000, 12000])
    test_dataset = datasets.MNIST(root=dataset_path,
                                  train=False,
                                  download=True,
                                  transform=transform)
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=32,
        shuffle=True,
        **kwargs)
    val_loader = torch.utils.data.DataLoader(val_dataset,
                                             batch_size=400,
                                             shuffle=False,
                                             **kwargs)
    test_loader = torch.utils.data.DataLoader(test_dataset,
                                              batch_size=1000,
                                              shuffle=False,
                                              **kwargs)

    global_step = 0
    epochs = 10
    steps_per_epoch = len(train_loader)
    train(scheduler)
    test()

    torch.save(model.state_dict(), 'model_state_dict.pt')
</code></pre>
</details>
<h2 id="创建-run-1"><a class="header" href="#创建-run-1">创建 Run</a></h2>
<p>在建立模型之前，创建并初始化一个 <code>Run</code> 实例。</p>
<pre><code class="language-python">from t9k import em

if __name__ == '__main__':
    ...
    run = em.create_run(name='mnist_torch')  # Run 的名称
    ...
</code></pre>
<p><code>Run</code> 实例的 <code>hparams</code> 属性用于保存超参数，使用类似 Python 字典的方法更新它以设定超参数。</p>
<pre><code class="language-python">if __name__ == '__main__':
    ...
    run.hparams.update({
        'batch_size': 32,
        'epochs': 10,
        'learning_rate': 0.001,
        'learning_rate_decay_period': 1,
        'learning_rate_decay_factor': 0.7,
        'conv_channels1': 32,
        'conv_channels2': 64,
        'conv_channels3': 64,
        'conv_kernel_size': 3,
        'maxpool_size': 2,
        'linear_features1': 64,
        'seed': 1,
    })
    hparams = run.hparams
    ...
</code></pre>
<h2 id="使用设定的超参数配置模型"><a class="header" href="#使用设定的超参数配置模型">使用设定的超参数配置模型</a></h2>
<p>使用上面设定的试验的超参数替换直接提供的超参数值，以配置模型各层、数据集、优化器、训练流程等。</p>
<pre><code class="language-python">class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, hparams['conv_channels1'],
                               hparams['conv_kernel_size'], 1)
        self.conv2 = nn.Conv2d(hparams['conv_channels1'],
                               hparams['conv_channels2'],
                               hparams['conv_kernel_size'], 1)
        self.conv3 = nn.Conv2d(hparams['conv_channels2'],
                               hparams['conv_channels3'],
                               hparams['conv_kernel_size'], 1)
        self.pool = nn.MaxPool2d(hparams['maxpool_size'],
                                 hparams['maxpool_size'])
        self.dense1 = nn.Linear(576, hparams['linear_features1'])
        self.dense2 = nn.Linear(hparams['linear_features1'], 10)
    ...

if __name__ == '__main__':
    ...
    torch.manual_seed(hparams['seed'])
    ...
    optimizer = optim.Adam(model.parameters(), lr=hparams['learning_rate'])
    scheduler = optim.lr_scheduler.StepLR(
        optimizer,
        step_size=hparams['learning_rate_decay_period'],
        gamma=hparams['learning_rate_decay_factor'])
    ...
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=hparams['batch_size'],
        shuffle=True,
        **kwargs)
    ...
    epochs = hparams['epochs']
    ...
</code></pre>
<h2 id="记录指标-1"><a class="header" href="#记录指标-1">记录指标</a></h2>
<p>在模型的训练和测试过程中调用 <code>Run</code> 实例的 <code>log()</code> 方法，以记录模型在此期间产生的指标。</p>
<pre><code class="language-python">def train(scheduler):
    ...
            if step % 500 == 0:
                train_loss = loss.item()
                logging.info(
                    'epoch {:d}/{:d}, batch {:5d}/{:d} with loss: {:.4f}'.
                    format(epoch, epochs, step, steps_per_epoch, train_loss))
                global_step = (epoch - 1) * steps_per_epoch + step

                run.log(type='train',                    # 记录训练指标
                        metrics={'loss': train_loss},    # 指标名称及相应值
                        step=global_step,                # 当前全局步数
                        epoch=epoch)                     # 当前回合数
    ...

def test(val=False, epoch=None):
    ...
    test_loss = running_loss / len(loader)
    test_accuracy = correct / len(loader.dataset)
    msg = '{:s} loss: {:.4f}, {:s} accuracy: {:.4f}'.format(
        label, test_loss, label, test_accuracy)
    if val:
        msg = 'epoch {:d}/{:d} with '.format(epoch, epochs) + msg
    logging.info(msg)

    run.log(type=label,    # 记录验证/测试指标
            metrics={
                'loss': test_loss,
                'accuracy': test_accuracy,
            },
            step=global_step,
            epoch=epoch)

</code></pre>
<h2 id="创建-artifact-并添加模型检查点文件"><a class="header" href="#创建-artifact-并添加模型检查点文件">创建 Artifact 并添加模型检查点文件</a></h2>
<p>在保存模型检查点文件之后，创建并初始化一个新的 <code>Artifact</code> 实例，为其添加该检查点文件，并标记为 Run 的输出。</p>
<pre><code class="language-python">if __name__ == '__main__':
    ...
    torch.save(model.state_dict(), 'model_state_dict.pt')
    model_artifact = em.create_artifact(name='mnist_torch_saved_model')
    model_artifact.add_file('model_state_dict.pt')
    run.mark_output(model_artifact)
    ...
</code></pre>
<h2 id="结束和上传-run"><a class="header" href="#结束和上传-run">结束和上传 Run</a></h2>
<p>模型的训练和测试结束后，调用 <code>Run</code> 实例的 <code>finish()</code> 和 <code>upload()</code> 方法以结束和上传 Run（Artifact 也会被一并上传）。在上传之前需要调用 <code>em.login()</code> 函数以登录到 AIStore 服务器。</p>
<pre><code class="language-python">if __name__ == '__main__':
    ...
    run.finish()
    em.login()
    run.upload(folder='em-examples', make_folder=True)

</code></pre>
<h2 id="检查-run-和-artifact"><a class="header" href="#检查-run-和-artifact">检查 Run 和 Artifact</a></h2>
<p>训练结束后，进入实验管理控制台，可以看到名为 mnist_torch 的 Run 及其输出的 Artifact 被上传：</p>
<figure class="screenshot">
    <img alt="uploaded" src="tasks/../assets/tasks/record-single-device-training/uploaded.png" />
</figure>
<p>点击 Run 或 Artifact 的名称进入其详情页面，可以看到 Run 的平台信息、指标、超参数和数据流，以及 Artifact 的文件和数据流。并且它们的数据流是连通的。</p>
<figure class="screenshot">
    <img alt="run" src="tasks/../assets/tasks/record-single-device-training/run.png" />
</figure>
<figure class="screenshot">
    <img alt="artifact" src="tasks/../assets/tasks/record-single-device-training/artifact.png" />
</figure>
<figure class="screenshot">
    <img alt="dataflow" src="tasks/../assets/tasks/record-single-device-training/dataflow.png" />
</figure>
<h2 id="下一步-35"><a class="header" href="#下一步-35">下一步</a></h2>
<ul>
<li>进一步学习如何<a href="tasks/./record-distributed-training.html">在分布式训练场景下追踪模型训练</a></li>
<li>进一步学习如何<a href="tasks/./view-autotune-in-experiment-console.html">在实验管理控制台查看 AutoTune</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="分布式训练场景"><a class="header" href="#分布式训练场景">分布式训练场景</a></h1>
<p>本教程演示如何记录并展示 PyTorchTrainingJob 分布式训练场景下的训练产生的信息、指标和文件（以 PyTorch 模型的数据并行训练为例）。</p>
<aside class="note info">
<div class="title">信息</div>
<p>对于 Keras 模型，<code>t9k.em</code> 提供了使用更加方便的回调，详见<a href="tasks/./record-using-python-sdk.html#%E8%87%AA%E5%8A%A8%E8%AE%B0%E5%BD%95">自动记录</a>。</p>
</aside>
<h2 id="运行示例-12"><a class="header" href="#运行示例-12">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/em/data-parallel-training">本教程对应的示例</a>，参照其 README 文档运行。</p>
<p>下面介绍训练脚本进行了哪些修改以追踪训练。该方法是通用的，可以推广到任意类型的 TrainingJob、DeepSpeedJob、ColossalAIJob、MPIJob 或 GenericJob。</p>
<h2 id="准备训练脚本-2"><a class="header" href="#准备训练脚本-2">准备训练脚本</a></h2>
<p>准备一个 PyTorch 训练脚本，其模型对 MNIST 数据集的图像进行分类，使用 <code>DistributedDataParallel</code>（DDP）模块进行分布式训练，具体代码如下所示（这里使用与<a href="tasks/./pytorch-training-parallel.html">使用 PyTorchTrainingJob 进行数据并行训练</a>相同的脚本）。接下来将在此脚本的基础上进行简单的修改以进行追踪。</p>
<details><summary><code class="hljs">torch_mnist_trainingjob_em.py</code></summary>
<pre><code class="language-python">import argparse
import logging
import os
import shutil

import torch
import torch.distributed as dist
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.parallel import DistributedDataParallel as DDP
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
from torchvision import datasets, transforms

parser = argparse.ArgumentParser(
    description='Distributed training of Keras model for MNIST with DDP.')
parser.add_argument(
    '--backend',
    type=str,
    help='Distributed backend',
    choices=[dist.Backend.GLOO, dist.Backend.NCCL, dist.Backend.MPI],
    default=dist.Backend.GLOO)
parser.add_argument('--log_dir',
                    type=str,
                    default='/mnt/log',
                    help='Path of the TensorBoard log directory.')
parser.add_argument('--no_cuda',
                    action='store_true',
                    default=False,
                    help='Disable CUDA training.')
logging.basicConfig(format='%(message)s', level=logging.INFO)


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.conv3 = nn.Conv2d(64, 64, 3, 1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dense1 = nn.Linear(576, 64)
        self.dense2 = nn.Linear(64, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = F.relu(self.conv3(x))
        x = torch.flatten(x, 1)
        x = F.relu(self.dense1(x))
        output = F.softmax(self.dense2(x), dim=1)
        return output


def train(scheduler):
    global global_step
    for epoch in range(1, epochs + 1):
        model.train()
        for step, (data, target) in enumerate(train_loader, 1):
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

            if step % (500 // world_size) == 0:
                train_loss = loss.item()
                logging.info(
                    'epoch {:d}/{:d}, batch {:5d}/{:d} with loss: {:.4f}'.
                    format(epoch, epochs, step, steps_per_epoch, train_loss))
                global_step = (epoch - 1) * steps_per_epoch + step

                if args.log_dir and rank == 0:
                    writer.add_scalar('train/loss', train_loss, global_step)

        scheduler.step()
        global_step = epoch * steps_per_epoch
        test(val=True, epoch=epoch)


def test(val=False, epoch=None):
    label = 'val' if val else 'test'
    model.eval()
    running_loss = 0.0
    correct = 0

    with torch.no_grad():
        loader = val_loader if val else test_loader
        for data, target in loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            loss = criterion(output, target)
            running_loss += loss.item()
            prediction = output.max(1)[1]
            correct += (prediction == target).sum().item()

    test_loss = running_loss / len(loader)
    test_accuracy = correct / len(loader.dataset)
    msg = '{:s} loss: {:.4f}, {:s} accuracy: {:.4f}'.format(
        label, test_loss, label, test_accuracy)
    if val:
        msg = 'epoch {:d}/{:d} with '.format(epoch, epochs) + msg
    logging.info(msg)

    if args.log_dir and rank == 0:
        writer.add_scalar('{:s}/loss'.format(label), test_loss, global_step)
        writer.add_scalar('{:s}/accuracy'.format(label), test_accuracy,
                          global_step)


if __name__ == '__main__':
    args = parser.parse_args()

    use_cuda = not args.no_cuda and torch.cuda.is_available()
    if use_cuda:
        logging.info('Using CUDA')
    device = torch.device(&quot;cuda&quot; if use_cuda else &quot;cpu&quot;)
    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}

    logging.info('Using distributed PyTorch with {} backend'.format(
        args.backend))
    dist.init_process_group(backend=args.backend)
    rank = dist.get_rank()
    world_size = dist.get_world_size()

    torch.manual_seed(1)

    model = Net().to(device)
    model = DDP(model)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001 * world_size)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)

    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5), (0.5))])
    train_dataset = datasets.MNIST(root='./data',
                                   train=True,
                                   download=False,
                                   transform=transform)
    train_dataset, val_dataset = torch.utils.data.random_split(
        train_dataset, [48000, 12000])
    test_dataset = datasets.MNIST(root='./data',
                                  train=False,
                                  download=False,
                                  transform=transform)
    train_loader = torch.utils.data.DataLoader(train_dataset,
                                               batch_size=32 * world_size,
                                               shuffle=True,
                                               **kwargs)
    val_loader = torch.utils.data.DataLoader(val_dataset,
                                             batch_size=400,
                                             shuffle=False,
                                             **kwargs)
    test_loader = torch.utils.data.DataLoader(test_dataset,
                                              batch_size=1000,
                                              shuffle=False,
                                              **kwargs)

    if args.log_dir and rank == 0:
        log_dir = args.log_dir
        if os.path.exists(log_dir):
            shutil.rmtree(log_dir, ignore_errors=True)
        writer = SummaryWriter(log_dir)

    global_step = 0
    epochs = 10
    steps_per_epoch = len(train_loader)
    train(scheduler)
    test()
</code></pre>
</details>
<h2 id="创建-run-2"><a class="header" href="#创建-run-2">创建 Run</a></h2>
<p>创建一个包含所有（想要记录的）超参数的 Python 字典。</p>
<pre><code class="language-python">from t9k import em

if __name__ == '__main__':
    ...
    hparams = {
        'batch_size': 32 * world_size,
        'epochs': 10,
        'learning_rate': 0.001 * world_size,
        'learning_rate_decay_period': 1,
        'learning_rate_decay_factor': 0.7,
        'conv_channels1': 32,
        'conv_channels2': 64,
        'conv_channels3': 64,
        'conv_kernel_size': 3,
        'maxpool_size': 2,
        'linear_features1': 64,
        'seed': 1,
    }
    ...
</code></pre>
<p><strong>指定一个工作器</strong>负责在建立模型之前创建并初始化一个 <code>Run</code> 实例，传入名称和上面的超参数字典。</p>
<pre><code class="language-python">if __name__ == '__main__':
    ...
    if rank == 0:
        run = em.create_run(name='mnist_torch_distributed', hparams=hparams)
    ...
</code></pre>
<h2 id="使用设定的超参数配置模型-1"><a class="header" href="#使用设定的超参数配置模型-1">使用设定的超参数配置模型</a></h2>
<p>使用上面的超参数字典的值替换直接提供的超参数值，以配置模型各层、数据集、优化器、训练流程等。</p>
<pre><code class="language-python">class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, hparams['conv_channels1'],
                               hparams['conv_kernel_size'], 1)
        self.conv2 = nn.Conv2d(hparams['conv_channels1'],
                               hparams['conv_channels2'],
                               hparams['conv_kernel_size'], 1)
        self.conv3 = nn.Conv2d(hparams['conv_channels2'],
                               hparams['conv_channels3'],
                               hparams['conv_kernel_size'], 1)
        self.pool = nn.MaxPool2d(hparams['maxpool_size'],
                                 hparams['maxpool_size'])
        self.dense1 = nn.Linear(576, hparams['linear_features1'])
        self.dense2 = nn.Linear(hparams['linear_features1'], 10)
    ...

if __name__ == '__main__':
    ...
    torch.manual_seed(hparams['seed'])
    ...
    optimizer = optim.Adam(model.parameters(), lr=hparams['learning_rate'])
    scheduler = optim.lr_scheduler.StepLR(
        optimizer,
        step_size=hparams['learning_rate_decay_period'],
        gamma=hparams['learning_rate_decay_factor'])
    ...
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=hparams['batch_size'],
        shuffle=True,
        **kwargs)
    ...
    epochs = hparams['epochs']
    ...
</code></pre>
<h2 id="记录指标-2"><a class="header" href="#记录指标-2">记录指标</a></h2>
<p>在模型的训练和测试过程中，<strong>被指定的工作器</strong>调用 <code>Run</code> 实例的 <code>log()</code> 方法以记录模型在此期间产生的指标。</p>
<pre><code class="language-python">def train(scheduler):
    ...
            if step % (500 // world_size) == 0:
                train_loss = loss.item()
                logging.info(
                    'epoch {:d}/{:d}, batch {:5d}/{:d} with loss: {:.4f}'.
                    format(epoch, epochs, step, steps_per_epoch, train_loss))
                global_step = (epoch - 1) * steps_per_epoch + step

                if rank == 0:
                    run.log(type='train',                  # 记录训练指标
                            metrics={'loss': train_loss},  # 指标名称及相应值
                            step=global_step,              # 当前全局步数
                            epoch=epoch)                   # 当前回合数
    ...

def test(val=False, epoch=None):
    ...
    test_loss = running_loss / len(loader)
    test_accuracy = correct / len(loader.dataset)
    msg = '{:s} loss: {:.4f}, {:s} accuracy: {:.4f}'.format(
        label, test_loss, label, test_accuracy)
    if val:
        msg = 'epoch {:d}/{:d} with '.format(epoch, epochs) + msg
    logging.info(msg)

    if rank == 0:
        run.log(type=label,    # 记录验证/测试指标
                metrics={
                    'loss': test_loss,
                    'accuracy': test_accuracy,
                },
                step=global_step,
                epoch=epoch)

</code></pre>
<h2 id="创建-artifact-并添加模型检查点文件-1"><a class="header" href="#创建-artifact-并添加模型检查点文件-1">创建 Artifact 并添加模型检查点文件</a></h2>
<p>在保存模型检查点文件之后，<strong>被指定的工作器</strong>创建并初始化一个新的 <code>Artifact</code> 实例，为其添加该检查点文件，并标记为 Run 的输出。</p>
<pre><code class="language-python">if __name__ == '__main__':
    ...
    if rank == 0:
        torch.save(model.state_dict(), 'model_state_dict.pt')
        model_artifact = em.create_artifact(name='mnist_torch_saved_model')
        model_artifact.add_file('model_state_dict.pt')
        run.mark_output(model_artifact)
    ...
</code></pre>
<h2 id="结束和上传试验"><a class="header" href="#结束和上传试验">结束和上传试验</a></h2>
<p>模型的训练和测试结束后，<strong>被指定的工作器</strong>调用 <code>Run</code> 实例的 <code>finish()</code> 和 <code>upload()</code> 方法以结束和上传 Run（Artifact 也会被一并上传）。在上传之前需要调用 <code>em.login()</code> 函数以登录到服务器。</p>
<pre><code class="language-python">if __name__ == '__main__':
    ...
    if rank == 0:
        run.finish()
        em.login()
        run.upload(folder='em-examples', make_folder=True)

</code></pre>
<h2 id="检查-run-和-artifact-1"><a class="header" href="#检查-run-和-artifact-1">检查 Run 和 Artifact</a></h2>
<p>训练结束后，进入实验管理控制台，可以看到名为 mnist_torch_distributed 的 Run 及其输出的 Artifact 被上传：</p>
<figure class="screenshot">
    <img alt="uploaded" src="tasks/../assets/tasks/record-distributed-training/uploaded.png" />
</figure>
<p>点击 Run 或 Artifact 的名称进入其详情页面，可以看到 Run 的平台信息、指标、超参数和数据流，以及 Artifact 的文件和数据流。并且它们的数据流是连通的。</p>
<figure class="screenshot">
    <img alt="run" src="tasks/../assets/tasks/record-distributed-training/run.png" />
</figure>
<figure class="screenshot">
    <img alt="artifact" src="tasks/../assets/tasks/record-distributed-training/artifact.png" />
</figure>
<figure class="screenshot">
    <img alt="dataflow" src="tasks/../assets/tasks/record-distributed-training/dataflow.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="在实验管理控制台查看-autotune"><a class="header" href="#在实验管理控制台查看-autotune">在实验管理控制台查看 AutoTune</a></h1>
<p>如果 <a href="tasks/../modules/building/autotuneexperiment.html#%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8">AutoTune 使用 AIStore 作为数据库</a>，那么 AutoTune 会自动记录实验以及其中所有试验的数据到 AIStore 中。</p>
<p>参照<a href="tasks/./autotune.html">使用 AutoTune 进行超参数优化</a>创建一个 AutoTuneExperiment。唯一需要修改的部分是，将 AutoTuneExperiment 配置文件的 <code>spec.em.folder</code> 字段修改为文件夹 <code>em-examples</code> 的 ID。</p>
<p>创建完成之后，进入实验管理控制台，可以看到 <code>em-examples/</code> 路径下出现了一个名为 keras-mnist-autotune 的 AutoTune：</p>
<figure class="screenshot">
    <img alt="created" src="tasks/../assets/tasks/view-autotune-in-experiment-console/created.png" />
</figure>
<p>点击<strong>其名称</strong>进入详情页面，可以看到 AutoTuneExperiment 的信息、当前进度、各试验的信息以及可视化图表：</p>
<figure class="screenshot">
    <img alt="details" src="tasks/../assets/tasks/view-autotune-in-experiment-console/details.png" />
</figure>
<p>点击任意一个试验的右侧的<strong>详情</strong>可以看到试验使用的超参数以及指标：</p>
<figure class="screenshot">
    <img alt="trial-hparams" src="tasks/../assets/tasks/view-autotune-in-experiment-console/trial-hparams.png" />
</figure>
<figure class="screenshot">
    <img alt="trial-metrics" src="tasks/../assets/tasks/view-autotune-in-experiment-console/trial-metrics.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="构建自动化工作流"><a class="header" href="#构建自动化工作流">构建自动化工作流</a></h1>
<p>这一部分演示如何使用<a href="tasks/../modules/workflows/index.html">工作流</a>系统进行 AI 开发和实验，帮助管理 AI 项目中数据清洗、特征工程、模型训练、评估等多个步骤之间的依赖关系，确保它们以正确的顺序执行，并提高可复用性。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="创建工作流的基本单元"><a class="header" href="#创建工作流的基本单元">创建工作流的基本单元</a></h1>
<p>本教程演示如何创建工作流的基本单元。</p>
<h2 id="准备工作-12"><a class="header" href="#准备工作-12">准备工作</a></h2>
<ul>
<li>了解 <a href="tasks/../modules/workflows/workflowtemplate.html">WorkflowTemplate</a> 和 <a href="tasks/../modules/workflows/workflowrun.html">WorkflowRun</a> 的基本概念。</li>
<li>成为一个<a href="tasks/../modules/security/project.html">项目</a>的管理员或<a href="tasks/./add-project-member.html">成员</a>。</li>
</ul>
<h2 id="创建-workflowtemplate-1"><a class="header" href="#创建-workflowtemplate-1">创建 WorkflowTemplate</a></h2>
<p>在浏览器中进入工作流控制台之后，点击左侧导航菜单的 <strong>WorkflowTemplate</strong> 进入 WorkflowTemplate 列表页面，然后点击右上角的 <strong>Project</strong> 框选择一个 Project，然后点击列表右上角的 <strong>+</strong> 在该 Project 中创建一个 WorkflowTemplate。</p>
<figure class="screenshot">
  <img alt="workflowtemplate-list" src="tasks/../assets/tasks/build-automatic-workflow/create-basic-unit-of-workflow/workflowtemplate-list.png" />
</figure>
<p>进入创建 WorkflowTemplate 页面之后，左侧的表格和右侧的 YAML 都可以进行编辑，并且两侧始终是同步变化的。你可以在此填写所要创建的 WorkflowTemplate。</p>
<figure class="screenshot">
  <img alt="create-workflowtemplate" src="tasks/../assets/tasks/build-automatic-workflow/create-basic-unit-of-workflow/create-workflowtemplate.png" />
</figure>
<p>首先，你需要在名为 <strong>WorkflowTemplate Name</strong> 的文本框中填写 WorkflowTemplate 的名称，然后在名为 <strong>Type</strong> 的下拉框中选择 WorkflowTemplate 的类型（可以是 <code>Pod</code>、<code>SeqPod</code>、<code>Resource</code> 等），最后根据 WorkflowTemplate 类型的不同，继续填写余下配置。</p>
<aside class="note info">
<div class="title">信息</div>
<p>WorkflowTemplate 的每个字段的含义详见<a href="tasks/../references/workflow.html">参考</a>。</p>
</aside>
<p>编辑好 WorkflowTemplate 之后，点击表格右上角的 <strong>Create WorkflowTemplate</strong> 创建该 WorkflowTemplate，右下角会有悬浮框提示是否创建成功。</p>
<h2 id="创建-workflowrun"><a class="header" href="#创建-workflowrun">创建 WorkflowRun</a></h2>
<p>再次点击左侧导航菜单的 <strong>WorkflowTemplate</strong> 进入 WorkflowTemplate 列表页面，找到你刚才创建的 WorkflowTemplate <strong>hello</strong>，点击 WorkflowTemplate 的名称进入 WorkflowTemplate 的详情页面。</p>
<figure class="screenshot">
  <img alt="workflowtemplate-detail" src="tasks/../assets/tasks/build-automatic-workflow/create-basic-unit-of-workflow/workflowtemplate-detail.png" />
</figure>
<p>在 WorkflowTemplate 的详情页面，你可以点击 <strong>SPECS</strong> 或 <strong>YAML</strong> 标签查看 WorkflowTemplate 的详细情况，检查是否有错误。如果没有错误，点击右上角的 <strong>Create WorkflowRun</strong> 为该 WorkflowTemplate 创建一个 WorkflowRun。</p>
<figure class="screenshot">
  <img alt="create-workflowrun" src="tasks/../assets/tasks/build-automatic-workflow/create-basic-unit-of-workflow/create-workflowrun-step1.png" />
</figure>
<p>在弹出的创建 WorkflowRun 对话框中，按步骤依次填写 WorkflowRun 所需要的参数，最后点击 <strong>Create</strong> 创建 WorkflowRun，右下角会有悬浮框提示是否创建成功。</p>
<figure class="screenshot">
  <img alt="create-workflowrun" src="tasks/../assets/tasks/build-automatic-workflow/create-basic-unit-of-workflow/create-workflowrun-step3.png" />
</figure>
<h2 id="查看-workflowrun-运行情况"><a class="header" href="#查看-workflowrun-运行情况">查看 WorkflowRun 运行情况</a></h2>
<p>点击左侧导航菜单的 <strong>WorkflowRun</strong> 进入 WorkflowRun 列表页面，找到你刚刚创建的 WorkflowRun <strong>hello-run-3xrlm</strong>，点击 WorkflowRun 的名称进入 WorkflowRun 的详情页面。</p>
<figure class="screenshot">
  <img alt="workflowrun-detail" src="tasks/../assets/tasks/build-automatic-workflow/create-basic-unit-of-workflow/workflowrun-detail.png" />
</figure>
<p>在 WorkflowRun 的详情页面，你可以点击 <strong>LOGS</strong>、<strong>STATUS</strong>、<strong>SPECS</strong> 和 <strong>YAML</strong> 等标签，分别查看 WorkflowRun 的日志、状态、规约和 YAML。如果 WorkflowRun 正在运行而且其类型是 Pod 或 SeqPod，你可以点击 <strong>TERMINAL</strong> 标签，连接到 WorkflowRun 创建的 Pod 的某个容器的终端（shell），利用命令行工具进行调试。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="创建执行各类任务的工作流单元"><a class="header" href="#创建执行各类任务的工作流单元">创建执行各类任务的工作流单元</a></h1>
<p>本教程演示如何创建执行各类任务的工作流单元。</p>
<h2 id="准备工作-13"><a class="header" href="#准备工作-13">准备工作</a></h2>
<ul>
<li>完成教程<a href="tasks/./create-workflow-unit.html">创建工作流的基本单元</a>。</li>
<li>成为一个<a href="tasks/../modules/security/project.html">项目</a>的管理员或<a href="tasks/./add-project-member.html">成员</a>。</li>
</ul>
<h2 id="创建类型为-pod-和-seqpod-的-workflowtemplate"><a class="header" href="#创建类型为-pod-和-seqpod-的-workflowtemplate">创建类型为 <code>Pod</code> 和 <code>SeqPod</code> 的 WorkflowTemplate</a></h2>
<p>如 <a href="tasks/../modules/workflows/workflowtemplate.html">WorkflowTemplate 介绍</a>中所述，<code>Pod</code> 和 <code>SeqPod</code> 类型的区别在于，<code>Pod</code> 中的所有容器是一起（近乎同时）开始运行的，而 <code>SeqPod</code> 中的每个步骤是按照定义的顺序依次执行的。如无特殊情况，我们一般使用 <code>SeqPod</code> 类型即可。以下均以 <code>SeqPod</code> 类型为基础进行讲解。</p>
<h3 id="选择镜像"><a class="header" href="#选择镜像">选择镜像</a></h3>
<p>在教程<a href="tasks/./create-workflow-unit.html">创建工作流的基本单元</a>中，我们已经完成了 <code>SeqPod</code> 类型的 WorkflowTemplate 的创建和运行。如教程中所述，在 <code>SeqPod</code> 的每个步骤（step）中，都要填写所使用的镜像。一般来说，镜像的来源可能有以下几种：</p>
<ul>
<li>TensorStack AI 平台预先提供的镜像：例如 <a href="tasks/../modules/building/notebook.html#%E9%A2%84%E5%85%88%E7%BC%96%E8%AF%91%E5%A5%BD%E7%9A%84%E9%95%9C%E5%83%8F">Notebook 镜像</a>，或者 <a target="_blank" rel="noopener noreferrer" href="https://registry.tensorstack.cn/">TensorStack 镜像站</a>中的任何镜像。</li>
<li>第三方镜像：例如来自 Docker 官方镜像站 <a target="_blank" rel="noopener noreferrer" href="https://hub.docker.com/">Docker Hub</a> 的镜像。</li>
<li>自制镜像：你可以利用 <a href="tasks/../tools/cli-t9k/index.html">TensorStack 命令行工具</a>、<a target="_blank" rel="noopener noreferrer" href="https://docs.docker.com/engine/reference/commandline/cli/">Docker 命令行工具</a>自行编译镜像。</li>
</ul>
<p>准备好镜像之后，在 <strong>Image</strong> 框中填入镜像的地址。</p>
<figure class="screenshot">
  <img alt="select-image" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/select-image.png" />
</figure>
<h3 id="执行-pvc-中的脚本"><a class="header" href="#执行-pvc-中的脚本">执行 PVC 中的脚本</a></h3>
<p>当你在 <a href="tasks/../modules/building/notebook.html">Notebook</a> 中编写了一些 Python 脚本或 Shell 脚本后，你可以创建 WorkflowTemplate 以及对应的 WorkflowRun 来运行该脚本。只要 WorkflowRun 和 Notebook 绑定的是同一个 PVC，WorkflowRun 就能访问到你在 Notebook 中编写的脚本。</p>
<p>首先，在 Notebook 中编写想要运行的脚本，并 <strong>Ctrl+S</strong> 保存。</p>
<figure class="screenshot">
  <img alt="script-1" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/script-1.png" />
</figure>
<p>查看 Notebook 所绑定的 PVC 名称，以便创建 WorkflowRun 时使用。</p>
<figure class="screenshot">
  <img alt="script-2" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/script-2.png" />
</figure>
<p>按照下图所示填写表格，创建一个 <code>SeqPod</code> 类型的 WorkflowTemplate。</p>
<figure class="screenshot">
  <img alt="script-3" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/script-3.png" />
</figure>
<p>或者，你也可以复制粘贴下面的 YAML 配置文件来创建 WorkflowTemplate：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: WorkflowTemplate
metadata:
  name: run-script
  labels: {}
spec:
  params: []
  results: []
  seqPod:
    steps:
      - args:
          - $(workspaces.notebook-pvc.path)/run.py
        command:
          - python
        image: 'registry.tensorstack.cn/t9k/tensorflow-2.8.0-notebook-cpu:1.50.0'
        name: step1
        resources:
          limits:
            cpu: 100m
            memory: 200Mi
  type: SeqPod
  workspaces:
    - description: the pvc used by notebook
      name: notebook-pvc
</code></pre>
<p>然后，创建 WorkflowRun 来运行该 WorkflowTemplate。</p>
<figure class="screenshot">
  <img alt="script-4" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/script-4.png" />
</figure>
<aside class="note">
<div class="title">注意</div>
<p>WorkflowRun 和 Notebook 必须绑定同一个 PVC。</p>
</aside>
<p>WorkflowRun 运行完成后，可以看到打印结果与所编写的脚本运行预期结果一致。</p>
<figure class="screenshot">
  <img alt="script-5" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/script-5.png" />
</figure>
<h3 id="执行自定义脚本"><a class="header" href="#执行自定义脚本">执行自定义脚本</a></h3>
<p>除了在 Notebook 中编写脚本，你还可以在创建 WorkflowTemplate 的过程中现场编写 Python 或 Shell 脚本。</p>
<p>如下图所示，创建 WorkflowTemplate 时选择类型为 <code>SeqPod</code>，然后点击 <strong>Add Step</strong>，在 Step 中选择 <strong>Script</strong> 即可嵌入自定义脚本。</p>
<figure class="screenshot">
  <img alt="embedded-1" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/embedded-1.png" />
</figure>
<p>目前支持 Python 和 Shell 两种语言，可通过下拉框进行选择。</p>
<figure class="screenshot">
  <img alt="embedded-2" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/embedded-2.png" />
</figure>
<p>创建 WorkflowTemplate 和对应的 WorkflowRun 来运行，可以看到打印结果与脚本运行与其结果一致。</p>
<figure class="screenshot">
  <img alt="embedded-3" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/embedded-3.png" />
</figure>
<h2 id="创建类型为-resource-的-workflowtemplate"><a class="header" href="#创建类型为-resource-的-workflowtemplate">创建类型为 <code>Resource</code> 的 WorkflowTemplate</a></h2>
<p>如 <a href="tasks/../modules/workflows/workflowtemplate.html#resource-workflowtemplate">WorkflowTemplate 介绍</a>中所述，<code>Resource</code> 类型的 WorkflowTemplate 用于创建一个 Kubernetes 资源。下面展示两个常用示例。</p>
<h3 id="创建分布式训练"><a class="header" href="#创建分布式训练">创建分布式训练</a></h3>
<p>假设你已经有一个可以运行的 TrainingJob YAML 配置文件：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: TensorFlowTrainingJob
metadata:
  name: mnist
spec:
  tensorboardSpec:               # TensorBoard服务器规约
    trainingLogFilesets:
      - t9k://pvc/mnist/log      # 日志文件路径
    image: tensorflow/tensorflow:2.8.0
                                # TensorBoard服务器使用的镜像
  replicaSpecs:
    - type: worker               # 工作器
      replicas: 4                # 工作器数量
      restartPolicy: ExitCode
      template:
        spec:
          securityContext:
            runAsUser: 1000
          containers:
            - image: tensorflow/tensorflow:2.8.0
                                  # 容器的镜像
              workingDir: /mnt
              name: tensorflow
              command:           # 执行`python`命令以执行训练脚本
                - sh
                - '-c'
                - &gt;-
                  python /mnt/keras_mnist_trainingjob.py --log_dir /mnt/log --save_path /mnt/saved_model
                  --no_cuda
              env: []
              resources:
                limits:          # 限制量
                  cpu: '4'       # CPU
                  memory: 2Gi    # 内存
                requests:        # 请求量
                  cpu: '2'
                  memory: 1Gi
              volumeMounts:
                - name: data
                  mountPath: /mnt
          volumes:
            - name: data
              persistentVolumeClaim:
                claimName: mnist
</code></pre>
<p>如果你想将创建 TrainingJob 插入工作流中成为其中一个步骤，可以使用 <code>Resource</code> 类型的 WorkflowTemplate。如下图所示，在 WorkflowTemplate 创建页面，选择类型为 <code>Resource</code>，然后将上面的 YAML 配置文件复制粘贴到 <strong>Resource Manifest</strong> 文本框中，即可创建一个 WorkflowTemplate 来运行这个 TrainingJob。</p>
<figure class="screenshot">
  <img alt="trainingjob-1" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/trainingjob-1.png" />
</figure>
<p>但是，由于在同一个项目中不能创建两个同名的 TrainingJob，上述方式创建的 WorkflowTemplate 只能运行一次，不具备可复用性。因此我们可以对 TrainingJob 配置文件做一些修改，利用 WorkflowTemplate 的<a href="tasks/../modules/workflows/workflowtemplate.html#%E6%8C%87%E5%AE%9A%E5%8F%82%E6%95%B0">指定参数</a>功能，使其能被重复使用。</p>
<p>经过修改的 TrainingJob 配置文件如下：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: TensorFlowTrainingJob
metadata:
  name: $(params.trainingjob_name)
spec:
  tensorboardSpec:               # TensorBoard服务器规约
    trainingLogFilesets:
      - t9k://pvc/mnist/log      # 日志文件路径
    image: tensorflow/tensorflow:2.8.0
                                # TensorBoard服务器使用的镜像
  replicaSpecs:
    - type: worker               # 工作器
      replicas: 4                # 工作器数量
      restartPolicy: ExitCode
      template:
        spec:
          securityContext:
            runAsUser: 1000
          containers:
            - image: tensorflow/tensorflow:2.8.0
                                # 容器的镜像
              workingDir: /mnt
              name: tensorflow
              command:          # 执行`python`命令以执行训练脚本
                - sh
                - '-c'
                - &gt;-
                  python /mnt/keras_mnist_trainingjob.py --log_dir /mnt/log --save_path /mnt/saved_model
                  --no_cuda
              env: []
              resources:
                limits:
                  cpu: '4'
                  memory: 4Gi
                requests:
                  cpu: '2'
                  memory: 2Gi
              volumeMounts:
                - name: data
                  mountPath: /mnt
          volumes:
            - name: data
              persistentVolumeClaim:
                claimName: $(params.pvc_name)
</code></pre>
<p>改动有两处：</p>
<ul>
<li><code>metadata.name</code> 从固定的 <code>mnist</code> 改为 <code>$(params.trainingjob_name)</code>。</li>
<li><code>spec.replicaSpecs.template.volumes.persistentVolumeClaim.claimName</code> 从固定的 <code>mnist</code> 改为 <code>$(params.pvc_name)</code>。</li>
</ul>
<p>这两个改动使得 TrainingJob 的名称和所使用的 PVC 的名称在运行时才被传入，这样创建的 WorkflowTemplate 就能够多次重复使用了。</p>
<p>在 WorkflowTemplate 创建页面，将上述改动过的 Trainingjob 配置文件复制粘贴到 <strong>Resource Manifest</strong> 文本框中，并为 WorkflowTemplate 添加两个参数，分别名为 <code>trainingjob_name</code> 和 <code>pvc_name</code>，然后点击 <strong>Create WorkflowTemplate</strong> 进行创建。</p>
<figure class="screenshot">
  <img alt="trainingjob-2" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/trainingjob-2.png" />
</figure>
<p>在创建 WorkflowRun 时，为 <code>trainingjob_name</code> 和 <code>pvc_name</code> 这两个参数提供实际值。</p>
<figure class="screenshot">
  <img alt="trainingjob-3" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/trainingjob-3.png" />
</figure>
<p>等待 WorkflowRun 完成运行。</p>
<figure class="screenshot">
  <img alt="trainingjob-4" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/trainingjob-4.png" />
</figure>
<h3 id="创建推理服务"><a class="header" href="#创建推理服务">创建推理服务</a></h3>
<p>与<a href="tasks/create-task-workflow-unit.html#%E5%88%9B%E5%BB%BA%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83">创建分布式训练</a>类似，我们可以在<a href="tasks/./deploy-simplemlservice.html">简单推理服务</a>的 YAML 配置文件基础上，加入可变的参数：</p>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: SimpleMLService
metadata:
  name: $(params.simplemlservice_name)
spec:
  replicas: 1
  storage:
    pvc:
      containerPath: /var/lib/t9k/models/mnist
      name: tutorial
      subPath: tutorial-examples/deployment/model/tensorflow/mnist
  tensorflow:
    image: t9kpublic/tensorflow-serving:2.6.0
</code></pre>
<p>在 WorkflowTemplate 创建页面，将上述 YAML 配置文件复制粘贴到 <strong>Resource Manifest</strong> 文本框中，并为 WorkflowTemplate 添加一些参数。</p>
<figure class="screenshot">
  <img alt="simplemlservice-1" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/simplemlservice-1.png" class="screenshot"/>
</figure>
<p>创建 WorkflowTemplate，然后创建对应的 WorkflowRun 并提供参数的实际值。</p>
<p>与分布式训练不同，推理服务是一个长时间运行的服务，没有结束时间。因此所创建的 WorkflowRun 也不会结束运行，而是一直处于 Running 状态。</p>
<figure class="screenshot">
  <img alt="simplemlservice-2" src="tasks/../assets/tasks/build-automatic-workflow/create-various-unit-of-workflow/simplemlservice-2.png" class="screenshot"/>
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="创建存在依赖关系的工作流"><a class="header" href="#创建存在依赖关系的工作流">创建存在依赖关系的工作流</a></h1>
<p>本教程演示如何创建存在依赖关系的工作流。</p>
<h2 id="准备工作-14"><a class="header" href="#准备工作-14">准备工作</a></h2>
<ul>
<li>完成教程<a href="tasks/./create-workflow-unit.html">创建工作流的基本单元</a>。</li>
<li>了解 <a href="tasks/../modules/workflows/workflowtemplate.html#dag-workflowtemplate">DAG WorkflowTemplate</a> 的基本概念。</li>
<li>成为一个<a href="tasks/../modules/security/project.html">项目</a>的管理员或<a href="tasks/./add-project-member.html">成员</a>。</li>
</ul>
<h2 id="创建一些简单的-workflowtemplate"><a class="header" href="#创建一些简单的-workflowtemplate">创建一些简单的 WorkflowTemplate</a></h2>
<p>在浏览器中进入工作流控制台之后，点击左侧导航菜单的 <strong>WorkflowTemplate</strong> 进入 WorkflowTemplate 列表页面，然后点击右上角的 <strong>Project 选择框</strong>选择一个 Project。</p>
<p>本教程使用<a href="tasks/./create-workflow-unit.html#%E5%88%9B%E5%BB%BA-workflowtemplate">创建工作流的基本单元</a>教程中创建好的 WorkflowTemplate <strong>hello</strong> 即可。如果有需要，你可以点击列表右上角的加号，按照<a href="tasks/./create-workflow-unit.html#%E5%88%9B%E5%BB%BA-workflowtemplate">创建工作流的基本单元</a>教程中的步骤，创建一些简单的 WorkflowTemplate。</p>
<h2 id="创建-dag-workflowtemplate"><a class="header" href="#创建-dag-workflowtemplate">创建 DAG WorkflowTemplate</a></h2>
<p>点击左侧导航菜单的 <strong>WorkflowTemplate</strong> 进入 WorkflowTemplate 列表页面，然后点击列表右上角的<strong>树状图标</strong>来创建一个 DAG WorkflowTemplate。</p>
<figure class="screenshot">
  <img alt="workflowtemplate-list" src="tasks/../assets/tasks/build-automatic-workflow/create-workflow-including-dependencies/workflowtemplate-list.png" />
</figure>
<p>进入创建 DAG WorkflowTemplate 页面之后，除了最左侧的导航菜单之外整个页面分为三个部分，左边是 WorkflowTemplate 列表，中间是用于组建 DAG 的画布，右边是 DAG WorkflowTemplate 的详情。你可以从左边的 WorkflowTemplate 列表中用鼠标选取一个 WorkflowTemplate 拖拽到中间的画布上，然后通过绿色锚点连接多个 WorkflowTemplate，表示它们的执行顺序。画布中所有的 WorkflowTemplate 由依赖关系组成一个有向无环图（DAG）。</p>
<figure class="screenshot">
  <img alt="create-workflowtemplate" src="tasks/../assets/tasks/build-automatic-workflow/create-workflow-including-dependencies/create-workflowtemplate.png" />
</figure>
<p>建立好有向无环图之后，你可以在右边的表格编辑 DAG WorkflowTemplate 的详情，例如 WorkflowTemplate 的名称、工作空间、参数等。点击画布中的方块即可编辑该节点的详情，点击画布的空白处可以编辑整个 DAG WorkflowTemplate 的详情。</p>
<p>最后，点击表格上方的 <strong>Create DAG WorkflowTemplate</strong> 创建该 DAG WorkflowTemplate，右下角会有悬浮框提示是否创建成功。</p>
<h2 id="创建-workflowrun-1"><a class="header" href="#创建-workflowrun-1">创建 WorkflowRun</a></h2>
<p>再次点击左侧导航菜单的 <strong>WorkflowTemplate</strong> 进入 WorkflowTemplate 列表页面，找到你刚刚创建的 WorkflowTemplate <strong>hello-again</strong>，点击 WorkflowTemplate 的名称进入 WorkflowTemplate 的详情页面。</p>
<figure class="screenshot">
  <img alt="workflowtemplate-detail" src="tasks/../assets/tasks/build-automatic-workflow/create-workflow-including-dependencies/workflowtemplate-detail.png" />
</figure>
<p>在 WorkflowTemplate 的详情页面，点击右上角的 <strong>Create WorkflowRun</strong> 为该 WorkflowTemplate 创建一个 WorkflowRun。</p>
<figure class="screenshot">
  <img alt="create-workflowrun" src="tasks/../assets/tasks/build-automatic-workflow/create-workflow-including-dependencies/create-workflowrun.png" />
</figure>
<p>在弹出的创建 WorkflowRun 对话框中。按步骤依次填写 WorkflowRun 所需要的参数，最后点击 <strong>Create</strong> 创建 WorkflowRun，右下角会有悬浮框提示是否创建成功。</p>
<h2 id="查看-workflowrun-运行情况-1"><a class="header" href="#查看-workflowrun-运行情况-1">查看 WorkflowRun 运行情况</a></h2>
<p>点击左侧导航菜单的 <strong>WorkflowRun</strong> 进入 WorkflowRun 列表页面，找到你刚刚创建的 WorkflowRun <strong>hello-again-run-9214x</strong>，点击 WorkflowRun 的名称进入 WorkflowRun 的详情页面。</p>
<figure class="screenshot">
  <img alt="workflowrun-detail" src="tasks/../assets/tasks/build-automatic-workflow/create-workflow-including-dependencies/workflowrun-detail.png" />
</figure>
<p>在 WorkflowRun 的详情页面，你可以点击 <strong>GRAPH</strong> 标签，查看 DAG 的详细情况，点击 DAG 的节点可以在弹框中查看节点的详细情况。</p>
<figure class="screenshot">
  <img alt="workflowrun-detail-node" src="tasks/../assets/tasks/build-automatic-workflow/create-workflow-including-dependencies/workflowrun-detail-node.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="建立从数据采样到模型导出的自动化工作流"><a class="header" href="#建立从数据采样到模型导出的自动化工作流">建立从数据采样到模型导出的自动化工作流</a></h1>
<p>本教程演示如何建立一个端到端的机器学习工作流，包括数据预处理、模型训练、模型分析等步骤。本教程使用的机器学习应用样例是一个二分类问题，根据乘客搭乘出租车的位置、路程、用时等特征数据预测乘客是否会付小费。</p>
<h2 id="准备工作-15"><a class="header" href="#准备工作-15">准备工作</a></h2>
<ul>
<li>完成教程<a href="tasks/./create-dependent-workflow.html">创建存在依赖关系的工作流</a>。</li>
<li>成为一个<a href="tasks/../modules/security/project.html">项目</a>的管理员或<a href="tasks/./add-project-member.html">成员</a>。</li>
</ul>
<h2 id="运行示例-13"><a class="header" href="#运行示例-13">运行示例</a></h2>
<p>请按照<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/blob/master/docs/README-zh.md#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">使用方法</a>准备环境，然后前往<a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/tutorial-examples/tree/master/workflow/e2e-workflow">本教程对应的示例</a>，参照其 README 文档运行。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>上述操作使用 YAML 配置文件创建 WorkflowTemplate 及 WorkflowRun，你也可以在工作流控制台进行创建。</p>
</aside>
<h2 id="查看运行结果"><a class="header" href="#查看运行结果">查看运行结果</a></h2>
<p>成功创建 WorkflowRun 之后，进入工作流控制台的 WorkflowRun 列表页面，可以看到名为 <strong>taxi-tips-prediction-run-75v60</strong> 的 WorkflowRun 正在运行：</p>
<figure class="screenshot">
  <img alt="workflowrun-list-success" src="tasks/../assets/tasks/build-automatic-workflow/build-automatic-workflow-from-data-sampling-to-model-exporting/workflowrun-list-success.png" />
</figure>
<p>点击<strong>该名称</strong> 进入详情页面，可以看到刚才创建的 WorkflowRun 的详细运行状态：</p>
<figure class="screenshot">
  <img alt="workflowrun-detail" src="tasks/../assets/tasks/build-automatic-workflow/build-automatic-workflow-from-data-sampling-to-model-exporting/workflowrun-detail.png" />
</figure>
<p>本页面会自动刷新以获取 WorkflowRun 的最新状态，你也可以点击右上角的<strong>刷新图标</strong>手动刷新。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="调度工作负载"><a class="header" href="#调度工作负载">调度工作负载</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用队列"><a class="header" href="#使用队列">使用队列</a></h1>
<h2 id="概述-6"><a class="header" href="#概述-6">概述</a></h2>
<p>队列是 T9k 平台中资源管理的机制，用于补充 K8s 原生平台在 scheduling 方面的不足。管理员可以为队列设定使用权限，资源来源的集群节点，资源配额，最大运行时长等属性，以精细化管理集群。</p>
<p>用户在创建使用调度器 T9k Scheduler 的工作负载时，需为工作负载指定一个队列。</p>
<h2 id="为工作负载指定队列"><a class="header" href="#为工作负载指定队列">为工作负载指定队列</a></h2>
<p>根据工作负载的种类，指定队列的方式如下。</p>
<h3 id="v1pod"><a class="header" href="#v1pod">v1/Pod</a></h3>
<p>创建 Pod 时，有两种指定所属队列的方式：</p>
<ul>
<li>直接指定队列：此类 Pod 不属于任何 PodGroup。</li>
<li>通过 PodGroup 间接指定队列：此类 Pod 属于所指定的 PodGroup。</li>
</ul>
<h4 id="直接指定队列"><a class="header" href="#直接指定队列">直接指定队列</a></h4>
<p>Pod 通过标签来表明他属于哪一个队列，标签的 key 是 <code>scheduler.tensorstack.dev/queue</code>。</p>
<aside class="note">
<div class="title">注意</div>
<p>Pod 一旦指定了所属的队列，就无法修改其所属的队列，如果想要修改 Pod 所属的队列，需要删除 Pod 再重新创建并指定新的队列。</p>
</aside>
<p>在下面的示例中，Pod 指定了队列 demo：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: test1
  labels:
    scheduler.tensorstack.dev/queue: demo
spec:
  schedulerName: t9k-scheduler
  containers:
  - image: nginx:latest
    name: test
    resources:
      requests:
        cpu: 1
        memory: 200Mi
</code></pre>
<h4 id="通过-podgroup-指定队列"><a class="header" href="#通过-podgroup-指定队列">通过 PodGroup 指定队列</a></h4>
<p>如果 Pod 属于某个 PodGroup，那么 PodGroup 指定的队列就是这个 Pod 所属的队列。</p>
<p>Pod 如何指定 PodGroup 请参考 <a href="tasks/./use-podgroup.html">使用 PodGroup</a></p>
<h3 id="t9k-jobs"><a class="header" href="#t9k-jobs">T9k Jobs</a></h3>
<p>T9k Job 包括 TensorFlowTrainingJob、PyTorchTrainingJob、XGBoostTrainingJob、GenericJob、MPIJob、ColossalAIJob、DeepSpeedJob 和 BeamJob，这些 Job 中都有相同的 <code>spec.scheduler</code> 字段。</p>
<p>创建 T9k Job 时，用户可以通过设置 <code>spec.scheduler</code> 字段来表明使用 T9k scheduler，并指定 Job 使用哪个队列。</p>
<p>在下面的示例中：<code>spec.scheduler.t9kScheduler.queue</code> 字段表明 Job 使用的队列是 demo，GenericJob 控制器会自动创建使用队列 demo 的 PodGroup 和 Pod。</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: GenericJob
metadata:
 name: job-sample
spec:
 scheduler:
   t9kScheduler:
     queue: demo
     priority: 10
 replicaSpecs:
   - type: worker
     replicas: 4
     ...
   - type: ps
     replicas: 1
     ...
</code></pre>
<h3 id="t9k-podgroup"><a class="header" href="#t9k-podgroup">T9k PodGroup</a></h3>
<p>创建 PodGroup 时，通过 <code>spec.queue</code> 字段来表明 PodGroup 所使用的队列。</p>
<p>在下面的示例中，PodGroup 表明自己使用的队列是 demo：</p>
<pre><code class="language-yaml">apiVersion: scheduler.tensorstack.dev/v1beta1
kind: PodGroup
metadata:
 name: test
spec:
 minMember: 2
 queue: demo
 priority: 50
</code></pre>
<h3 id="batchv1job"><a class="header" href="#batchv1job">batch/v1/Job</a></h3>
<p>与 <a href="tasks/use-queue.html#v1pod">v1/Pod</a> 类似，创建 batch/v1 Job 使用队列时，需要通过设置 Pod 的标签来表明 Pod 所使用的队列。有两种设置 Pod 标签的方法：</p>
<ul>
<li>直接指定队列：为 Pod 设置标签 <code>scheduler.tensorstack.dev/queue:&lt;queue-name&gt; </code> 表明 Pod 所使用的队列。</li>
<li>通过 PodGroup 间接指定队列：为 Pod 设置标签 <code>scheduler.tensorstack.dev/group-name:&lt;group-name&gt;</code> 表明 Pod 所属的 PodGroup，PodGroup 使用的队列就是 Pod 使用的队列。</li>
</ul>
<p>在下面的示例中，Job 通过为 Pod 设置标签 <code>scheduler.tensorstack.dev/queue:demo</code> 来表明使用队列 demo。</p>
<pre><code class="language-yaml">apiVersion: batch/v1
kind: Job
metadata:
 name: test
spec:
 parallelism: 2
 template:
   metadata:
     labels:
       scheduler.tensorstack.dev/queue: demo
   spec:
     schedulerName: t9k-scheduler
     containers:
       - name: create
         image: nginx:latest
         command:
         - sleep
         - 10s
         resources:
           requests:
             cpu: 1
             memory: 100Mi
     restartPolicy: Never
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-podgroup"><a class="header" href="#使用-podgroup">使用 PodGroup</a></h1>
<h2 id="概念"><a class="header" href="#概念">概念</a></h2>
<p>PodGroup 是 namespaced-scoped 资源对象，代表一组协同工作的 Pod。PodGroup spec 中定义了 coscheduling 和其他相关的配置信息，调度器 T9k Scheduler 会根据这些信息为 Pod 分配资源。</p>
<h2 id="使用-podgroup-1"><a class="header" href="#使用-podgroup-1">使用 PodGroup</a></h2>
<p>根据工作负载的种类，创建并使用 PodGroup 的方式如下。</p>
<h3 id="pod-1"><a class="header" href="#pod-1">Pod</a></h3>
<p>一般仅需要通过 Job 控制器自动化地实现对 PodGroup 的使用。工作负载控制器的编程者，或者需手工设定 pod 的 PodGroup，可参考本节内容。</p>
<p>用户创建一组使用调度器 T9k Scheduler 进行协同工作的 Pod 时，需要：</p>
<ol>
<li>先在相同的 namespace 中创建一个 PodGroup</li>
<li>为 Pod 添加标签 <code>scheduler.tensorstack.dev/group-name: &lt;PodGroup-name&gt;</code> 来表明 Pod 属于步骤一创建的 PodGroup</li>
</ol>
<aside class="note">
<div class="title">注意</div>
<p>Pod 一旦指定了所属的 PodGroup，就无法修改其所属的 PodGroup，如果想要修改 Pod 所属的 PodGroup，需要删除 Pod 再重新创建并指定新的 PodGroup。</p>
</aside>
<h4 id="示例1---基本场景"><a class="header" href="#示例1---基本场景">示例1 - 基本场景</a></h4>
<p>首先需要创建一个 PodGroup：</p>
<pre><code class="language-yaml">apiVersion: scheduler.tensorstack.dev/v1beta1
kind: PodGroup
metadata:
  name: dance
spec:
  minMember: 2
  queue: default
  priority: 50
</code></pre>
<p>然后创建 2 个 Pod 并指定 PodGroup，Pod 通过标签 <code>scheduler.tensorstack.dev/group-name: dance</code> 表明他们属于 PodGroup dance。</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: test1
  labels:
    scheduler.tensorstack.dev/group-name: dance
spec:
  schedulerName: t9k-scheduler
  containers:
  - image: nginx:latest
    name: test
    resources:
      requests:
        cpu: 1
        memory: 200Mi
--
apiVersion: v1
kind: Pod
metadata:
  name: test2
  labels:
    scheduler.tensorstack.dev/group-name: dance
spec:
  schedulerName: t9k-scheduler
  containers:
  - image: nginx:latest
    name: test
    resources:
      requests:
        cpu: 1
        memory: 200Mi
</code></pre>
<h4 id="示例2---使用-role"><a class="header" href="#示例2---使用-role">示例2 - 使用 role</a></h4>
<p>本示例展示有 2 个 role 并设置了 role minMember 的 PodGroup 使用场景。</p>
<p>创建 PodGroup</p>
<pre><code class="language-yaml">apiVersion: scheduler.tensorstack.dev/v1beta1
kind: PodGroup
metadata:
  name: role-test
spec:
  roles:
  - name: master
    minMember: 1
  - name: worker
    minMember: 1
  minMember: 3
  queue: default
  priority: 50
</code></pre>
<p>说明：上面这个 PodGroup 的最小运行需求如下，这些需求都被满足了，调度器才会为 PodGroup 中的 Pod 分配资源：</p>
<ul>
<li>PodGroup 的 Pod 数量需要达到 3</li>
<li>角色名称是 master 的 Pod 数量需要达到 1</li>
<li>角色名称是 worker 的 Pod 数量需要达到 1</li>
</ul>
<p>创建 Pod：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: master
  labels:
    scheduler.tensorstack.dev/group-name: role-test
    scheduler.tensorstack.dev/role: master
spec:
  schedulerName: t9k-scheduler
  containers:
  - image: nginx:latest
    name: test
    resources:
      requests:
        cpu: 100m
        memory: 200Mi
--
apiVersion: v1
kind: Pod
metadata:
  name: worker
  labels:
    scheduler.tensorstack.dev/group-name: role-test
    scheduler.tensorstack.dev/role: worker
spec:
  schedulerName: t9k-scheduler
  containers:
  - image: nginx:latest
    name: test
    resources:
      requests:
        cpu: 100m
        memory: 200Mi
--
apiVersion: v1
kind: Pod
metadata:
  name: worker1
  labels:
    scheduler.tensorstack.dev/group-name: role-test
    scheduler.tensorstack.dev/role: worker
spec:
  schedulerName: t9k-scheduler
  containers:
  - image: nginx:latest
    name: test
    resources:
      requests:
        cpu: 100m
        memory: 200Mi
</code></pre>
<p>Pod 通过标签 <code>scheduler.tensorstack.dev/role: &lt;role-name&gt;</code> 来表明自己的角色名称。 </p>
<h3 id="t9k-jobs-1"><a class="header" href="#t9k-jobs-1">T9k Jobs</a></h3>
<p>T9k Job 包括 TensorFlowTrainingJob、PyTorchTrainingJob、XGBoostTrainingJob、GenericJob、MPIJob、ColossalAIJob、DeepSpeedJob 和 BeamJob，这些 Job 中都有相同的 <code>spec.scheduler</code> 字段。</p>
<p>创建 T9k Job 时，用户可以通过设置 <code>spec.scheduler</code> 字段来表明使用 T9k scheduler，并指定 Job 使用哪个队列，然后控制器会自动地创建 PodGroup、并创建 Pod 使用这个 PodGroup。</p>
<h4 id="基本示例"><a class="header" href="#基本示例">基本示例</a></h4>
<p>本示例适用于未启用弹性训练的 Job。</p>
<p>以下面这个 GenericJob 为例：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: GenericJob
metadata:
 name: job-sample
spec:
 scheduler:
   t9kScheduler:
     queue: default
     priority: 10
 replicaSpecs:
   - type: worker
     replicas: 4
     ...
   - type: ps
     replicas: 1
     ...
</code></pre>
<p>控制器在监测到上述 CRD 后，会创建一个 PodGroup:</p>
<pre><code class="language-yaml">apiVersion: scheduler.tensorstack.dev/v1beta1
kind: PodGroup
metadata:
  name: job-sample
  ownerReferences: [...]
spec:
  minMember: 5
  priority: 10
  queue: default
</code></pre>
<p>其中，priority 和 queue 字段参考 job 的 <code>spec.scheduler.t9kScheduler</code> 中的信息设置，minMember 即为 job 所有副本的总数。</p>
<p>随后，控制器会在创建副本的 Pod 时，为 Pod 设置标签 <code>scheduler.tensorstack.dev/group-name: job-sample</code> 来使用上述 PodGroup。</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  labels:
    genericjob: job-sample
    genericjob-replica: job-sample-worker-2
    scheduler.tensorstack.dev/group-name: job-sample
    scheduler.tensorstack.dev/queue: default
    tensorstack.dev/component: genericjob
    tensorstack.dev/component-type: user
  name: job-sample-worker-0
  namespace: dev-wangdi
  ownerReferences: [...]
</code></pre>
<h4 id="弹性训练-1"><a class="header" href="#弹性训练-1">弹性训练</a></h4>
<p>弹性训练要求训练规模可以动态调整，所以对 PodGroup 的设置也有所不同。</p>
<p>T9k Job 中，PyTorchTrainingJob 和 DeepSpeedJob 支持弹性训练，他们具有相同的 <code>spec.elastic</code> 字段，以此启动弹性训练。</p>
<p>以下面的 PyTorchTrainingJob 为例：</p>
<ul>
<li><code>spec.elastic.enabled</code> 是 true 表明启用弹性训练</li>
<li>PyTorchTrainingJob 支持最少 3 个副本、最多 10 个副本的训练规模</li>
</ul>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: PyTorchTrainingJob
metadata:
 name: torch-mnist-trainingjob
spec:
 scheduler:
   t9kScheduler:
     queue: default
     priority: 10
 elastic:
   enabled: true
   minReplicas: 3
   maxReplicas: 10
   expectedReplicas: 7
 ...
</code></pre>
<p>控制器在监测到上述 CRD 后，会创建下列 PodGroup，使用 <code>spec.elastic.minReplicas</code> 作为 PodGroup 的 <code>spec.minMember</code>：</p>
<pre><code class="language-yaml">apiVersion: scheduler.tensorstack.dev/v1beta1
kind: PodGroup
metadata:
  name: torch-mnist-trainingjob
  ownerReferences: [...]
spec:
  minMember: 3
  priority: 10
  queue: default
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用平台存储"><a class="header" href="#使用平台存储">使用平台存储</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="上传和下载文件"><a class="header" href="#上传和下载文件">上传和下载文件</a></h1>
<p>通过 <a href="tasks/../modules/storage/pvc.html">PVC</a> 使用集群存储非常方便，它可作为存储卷被挂载到 Notebook、Job、MLService 等各种工作负载的 Pod 中。例如在进行模型训练时，你可以把训练脚本以及训练数据存放到 PVC，然后挂载在 Job 的 Pod 中。</p>
<p>本教程将分场景介绍如何从集群外部上传文件到 PVC，以及如何从 PVC 下载文件到集群外部。</p>
<p>由于下面的部分方法需要使用到命令行工具，而 Notebook 提供了终端并且 Notebook 的镜像中预装了这些命令行工具，因此我们推荐把 PVC 挂载到一个 Notebook 上，然后在 Notebook 中进行操作。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>PVC 可以扩容，即增加存储卷大小。因此你在创建 PVC 时可以先指定一个较为保守的存储卷大小的值，之后如有需要则继续增加。</p>
</aside>
<h2 id="本地文件系统"><a class="header" href="#本地文件系统">本地文件系统</a></h2>
<h3 id="notebook-1"><a class="header" href="#notebook-1">Notebook</a></h3>
<p>把 PVC 挂载到 Notebook 上，本地文件系统和 PVC 之间的文件传输，可直接在 Notebook 的前端页面上操作：</p>
<figure class="screenshot">
  <img alt="notebook-upload-download" src="tasks/../assets/tasks/pvc-importing-and-exporting-files/notebook-upload-download.png" />
</figure>
<h3 id="file-browser"><a class="header" href="#file-browser">File Browser</a></h3>
<p>在 PVC 上启动 <a href="tasks/./use-explorer.html">Explorer</a> 之后，则可通过 <a href="tasks/./use-explorer.html#%E4%BD%BF%E7%94%A8-file-browser">File Browser</a> ：</p>
<figure class="screenshot">
  <img alt="file-browser-upload-download" src="tasks/../assets/tasks/pvc-importing-and-exporting-files/file-browser-upload-download.png" />
</figure>
<aside class="note">
<div class="title">注意</div>
<ul>
<li>Notebook 不限制上传或下载的单个文件的大小（根据管理员配置，File Browser 有可能限制上传的单个文件的大小）；但上传过程容易因为网络波动而出错，建议 &gt; ~5GB（也取决于具体网络环境）的单个文件使用其他方法上传。</li>
<li>可以一次上传或下载多个文件；但在文件数量较多（&gt; ~50）的情况下容易出错，推荐打包成压缩文件再上传或下载。</li>
</ul>
</aside>
<h3 id="云存储中转"><a class="header" href="#云存储中转">云存储中转</a></h3>
<p>也可通过其他云存储服务进行中转，即 <code>本地 -&gt; 云存储 -&gt; 集群 PVC</code>：</p>
<ol>
<li>本地与云存储之间的文件传输方法请参阅相应云存储的文档；</li>
<li>云存储与 PVC 之间的文件传输方法请参阅<a href="tasks/pvc-importing-and-exporting-files.html#%E4%BA%91%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1">云存储服务</a>。</li>
</ol>
<h2 id="云存储服务"><a class="header" href="#云存储服务">云存储服务</a></h2>
<p>要在云存储与 PVC 之间复制或同步文件，可以在 Notebook 的终端中使用命令行工具 <a target="_blank" rel="noopener noreferrer" href="https://rclone.org">rclone</a>。这里以 Amazon S3 为例，首先参照 <a target="_blank" rel="noopener noreferrer" href="https://rclone.org/s3/">Amazon S3 Config</a> 进行配置，完成后执行以下命令：</p>
<pre><code class="language-bash">rclone copy &lt;REMOTE&gt;:&lt;BUCKET&gt;/path/to/the/file .   # 从 S3 存储下载
rclone copy ./file &lt;REMOTE&gt;:&lt;BUCKET&gt;/path/to/the/  # 上传到 S3 存储

rclone sync &lt;REMOTE&gt;:&lt;BUCKET&gt;/path/to/the/dir .    # 从 S3 存储同步
rclone sync . &lt;REMOTE&gt;:&lt;BUCKET&gt;/path/to/the/dir    # 同步到 S3 存储
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>rclone 支持的云存储提供商请参阅 <a target="_blank" rel="noopener noreferrer" href="https://rclone.org/#providers">Supported Providers</a>。</p>
</aside>
<p>rclone 之外，还有其他方便的工具可供使用，例如 <a target="_blank" rel="noopener noreferrer" href="https://github.com/s3tools/s3cmd">s3cmd</a>、<a target="_blank" rel="noopener noreferrer" href="https://github.com/peak/s5cmd">s5cmd</a> 等。</p>
<h2 id="httpftp-服务"><a class="header" href="#httpftp-服务">HTTP/FTP 服务</a></h2>
<p>要通过 HTTP(S)、(S)FTP 等协议从网络下载文件到 PVC，可以在 Notebook 的终端中使用 <code>wget</code> 或 <code>curl</code> 命令进行下载：</p>
<pre><code class="language-bash">wget &lt;URL&gt;
curl -O &lt;URL&gt;
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>你也可以在终端中使用命令行工具 rclone 来访问和下载存储在 HTTP(S) 和 FTP(S) 服务器上的文件（对于 FTP(S) 服务器还可以上传文件）。rclone 将这些服务器视为一种类型的云存储，请参阅 <a target="_blank" rel="noopener noreferrer" href="https://rclone.org/http/">HTTP Config</a> 和 <a target="_blank" rel="noopener noreferrer" href="https://rclone.org/ftp/">FTP Config</a>。</p>
</aside>
<h2 id="git-仓库"><a class="header" href="#git-仓库">Git 仓库</a></h2>
<p>可以在 Notebook 的终端中使用 <code>git</code> 命令，从 GitHub 等代码托管平台克隆或拉取项目，并在提交修改后推送回去：</p>
<pre><code class="language-bash">git clone &lt;repository&gt;
git pull
git fetch
git push
</code></pre>
<h2 id="hugging-face-hub"><a class="header" href="#hugging-face-hub">Hugging Face Hub</a></h2>
<p><a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/models">Hugging Face Hub</a> 是一个拥有超过 35 万个模型和 7.5 万个数据集的平台，所有这些模型和数据集都是开源并且公开可用的。从 Hugging Face Hub 下载一个模型或数据集有多种方法，下面以模型 <code>mistralai/Mistral-7B-v0.1</code> 为例进行演示，首先来到该模型的 <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/mistralai/Mistral-7B-v0.1/tree/main">Files and versions 标签页</a>：</p>
<figure class="screenshot">
  <img alt="files-and-versions" src="tasks/../assets/tasks/pvc-importing-and-exporting-files/files-and-versions.png" />
</figure>
<h3 id="使用脚本"><a class="header" href="#使用脚本">使用脚本</a></h3>
<p>点击 <strong>Use in Transformers</strong>，按照提示进行操作，即在 Python 程序中调用 <code>transformers</code> 库加载模型。首次加载时，模型文件会被下载到缓存目录下，即 PVC 的 <code>.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.1/</code> 路径下。</p>
<figure class="screenshot">
  <img alt="use-in-transformers" src="tasks/../assets/tasks/pvc-importing-and-exporting-files/use-in-transformers.png" />
</figure>
<figure class="screenshot">
  <img alt="use-in-transformers-detail" src="tasks/../assets/tasks/pvc-importing-and-exporting-files/use-in-transformers-detail.png" />
</figure>
<pre><code class="language-python">from transformers import pipeline

pipe = pipeline(&quot;text-generation&quot;, model=&quot;mistralai/Mistral-7B-v0.1&quot;)

# 或

from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(&quot;mistralai/Mistral-7B-v0.1&quot;)
model = AutoModelForCausalLM.from_pretrained(&quot;mistralai/Mistral-7B-v0.1&quot;)
</code></pre>
<aside class="note">
<div class="title">注意</div>
<p>部分模型和数据集（例如模型 <code>meta-llama/Llama-2-7b</code>）在使用前需要先登录到 Hugging Face 并获取访问权限。</p>
</aside>
<h3 id="使用-git"><a class="header" href="#使用-git">使用 git</a></h3>
<p>点击 <strong>Clone repository</strong>，按照提示进行操作，即使用 <code>git</code> 命令将模型的 Git 仓库直接克隆到 PVC 中：</p>
<figure class="screenshot">
  <img alt="clone-repository" src="tasks/../assets/tasks/pvc-importing-and-exporting-files/clone-repository.png" />
</figure>
<figure class="screenshot">
  <img alt="clone-repository-detail" src="tasks/../assets/tasks/pvc-importing-and-exporting-files/clone-repository-detail.png" />
</figure>
<pre><code class="language-bash"># git lfs install    # Notebook 的镜像中已经预装了 git-lfs，因此不必再执行
git clone https://huggingface.co/mistralai/Mistral-7B-v0.1
</code></pre>
<aside class="note tip">
<div class="title">信息</div>
<p>模型和数据集都是作为 Git 仓库托管在 Hugging Face Hub 上。</p>
</aside>
<h3 id="单个文件"><a class="header" href="#单个文件">单个文件</a></h3>
<p>如果只需要下载个别文件，例如只下载模型的 safetensors 文件，那么可以复制相应文件的下载链接，然后在终端中使用 <code>wget</code> 命令下载：</p>
<pre><code class="language-bash">wget https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/model-00001-of-00002.safetensors?download=true
wget https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/model-00002-of-00002.safetensors?download=true
</code></pre>
<h2 id="大规模数据"><a class="header" href="#大规模数据">大规模数据</a></h2>
<p>在处理大规模数据（如 100TB 级别）的导入和导出时，根据数据源的不同，我们采用不同的策略以确保数据传输的效率和安全性。以下是针对不同数据源的一些方法：</p>
<p>数据源为云存储时：</p>
<ul>
<li>参照<a href="tasks/pvc-importing-and-exporting-files.html#%E4%BA%91%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1">云存储服务</a>操作。</li>
</ul>
<p>数据源为 HDD/SDD 外置驱动器或类似设备时：</p>
<ol>
<li>将驱动器连接到集群外的与集群网络连接速度较快的计算机上，然后参照<a href="tasks/pvc-importing-and-exporting-files.html#%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F">本地文件系统</a>继续操作。</li>
<li>或者，请求管理员操作，将驱动器连接到存储集群的节点上，直接使用存储系统的工具进行数据传输。这种方法的数据传输速度一般较快，但需要能够访问存储集群的工具和接口。</li>
</ol>
<h2 id="参考-12"><a class="header" href="#参考-12">参考</a></h2>
<p><a href="https://rclone.org/">https://rclone.org/</a></p>
<p><a href="https://huggingface.co/models">https://huggingface.co/models</a></p>
<p><a href="https://github.com/peak/s5cmd">https://github.com/peak/s5cmd</a></p>
<p><a href="https://github.com/s3tools/s3cmd">https://github.com/s3tools/s3cmd</a></p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="管理个人账户"><a class="header" href="#管理个人账户">管理个人账户</a></h1>
<p>这一部分演示如何使用生成并使用 API Key 来进行身份验证，以及如何管理自己负责的项目（如果你是项目管理员）。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="生成-api-key"><a class="header" href="#生成-api-key">生成 API Key</a></h1>
<p>本教程演示如何生成一个 API Key。</p>
<h2 id="准备工作-16"><a class="header" href="#准备工作-16">准备工作</a></h2>
<ul>
<li>了解 <a href="tasks/../modules/security/account.html#api-key">API Key</a> 的基本概念。</li>
</ul>
<h2 id="开启-api-key-服务"><a class="header" href="#开启-api-key-服务">开启 API Key 服务</a></h2>
<p>进入安全管理控制台之后，在左侧的导航菜单中点击<strong>账号 &gt; API Key</strong> 进入 API Key 管理页面。如果你是第一次使用 API Key 服务，需要进行一次额外的登录认证。点击<strong>启用</strong>开始登录认证。</p>
<figure class="screenshot">
  <img alt="enable-apikey" src="tasks/../assets/tasks/account/generate-api-key/enable-apikey.png" />
</figure>
<p>在弹出的对话框中，输入你的用户名和密码，并点击<strong>启用</strong>以开启 API Key 服务，右下角会有悬浮框提示是否成功。</p>
<figure class="screenshot">
  <img alt="login" src="tasks/../assets/tasks/account/generate-api-key/login.png" />
</figure>
<h2 id="生成一个-api-key"><a class="header" href="#生成一个-api-key">生成一个 API Key</a></h2>
<p>开启 API Key 服务之后，再次进入 API Key 管理页面，此时会列出你拥有的所有 API Key。点击右上角的<strong>创建新的 API Key</strong> 以生成一个新的 API Key。</p>
<figure class="screenshot">
  <img alt="apikey-list" src="tasks/../assets/tasks/account/generate-api-key/apikey-list.png" />
</figure>
<p>在 API Key 生成页面，填写名称并勾选你想要包含在 API Key 中的权限，然后点击<strong>创建新的 API Key</strong>，右下角会有悬浮框提示是否成功。</p>
<figure class="screenshot">
  <img alt="gen-apikey" src="tasks/../assets/tasks/account/generate-api-key/gen-apikey.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-api-key"><a class="header" href="#使用-api-key">使用 API Key</a></h1>
<p>本教程演示几种 API Key 的使用实例。</p>
<h2 id="在-tensorstack-cli-中使用-api-key"><a class="header" href="#在-tensorstack-cli-中使用-api-key">在 TensorStack CLI 中使用 API Key</a></h2>
<p>你可以使用以下命令并按照提示信息完成 API Key 的录入，随后命令行工具将使用该 API Key 作为用户身份凭证向平台服务器发送请求。</p>
<pre><code class="language-bash">t9k config auth &lt;server-address&gt; -u &lt;user-name&gt; -k
</code></pre>
<p>登录操作实质上就是将身份信息记录在 <a href="tasks/../tools/cli-t9k/guide.html#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">T9k Config 文件</a>中作为一个上下文（context），该配置文件中可以同时记录多个上下文，使用以下命令查看、切换和删除：</p>
<pre><code class="language-bash"># 查看所有上下文
% t9k config get-contexts
CURRENT   NAME            SERVER                     AUTH_TYPE
*         &lt;config-name&gt;   &lt;server-address&gt;           apikey

# 切换所要使用的上下文，即当前上下文
% t9k config use-context &lt;config-name&gt;

# 删除上下文
% t9k config delete-context &lt;config-name&gt;
</code></pre>
<p>关于 TensorStack CLI 的详细使用说明，请参阅<a href="tasks/../tools/cli-t9k/guide.html">CLI 用户指南</a>。</p>
<h2 id="使用-api-key-作为凭证向-aistore-上传数据"><a class="header" href="#使用-api-key-作为凭证向-aistore-上传数据">使用 API Key 作为凭证向 AIStore 上传数据</a></h2>
<p>你可以在模型训练中使用 API Key 作为凭证向 AIStore 上传数据。</p>
<h3 id="通常的模型训练"><a class="header" href="#通常的模型训练">通常的模型训练</a></h3>
<!-- 在通常的模型训练中（不论是单个设备训练还是分布式训练）使用 AIStore 记录训练数据时，你需要在调用 `t9k.em` 模块的 `login()` 函数时提供 API Key，如下所示： -->
<p>在使用 <a href="tasks/../tools/python-sdk-t9k/index.html">Python SDK</a> 将数据上传到 AIStore 中时，你需要调用 <code>t9k.em</code> 模块的 <code>login()</code> 函数进行身份验证，在不设置 <code>login()</code> 函数参数的情况下，SDK 会自动使用 <a href="tasks/../tools/cli-t9k/guide.html#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">T9k Config 文件</a>中当前上下文中的身份信息，如果你想在训练时使用其他身份信息，则可以设置 <code>ais_host</code> 和 <code>api_key</code> 参数。</p>
<pre><code class="language-python">from t9k import em

# 使用 T9k Config 中当前上下文中的身份信息
em.login()

# 使用其他身份信息
em.login(ais_host='url-of-em-server', api_key='api-key-of-user')
</code></pre>
<h3 id="autotuneexperiment-1"><a class="header" href="#autotuneexperiment-1">AutoTuneExperiment</a></h3>
<p>为了让 AutoTuneExperiment 能够使用 API Key，你需要创建一个 Secret 来存储 API Key，Secret 的格式如下：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: aistore-secret
  namespace: t9k-example
data:
  apikey: ZDQyMjJjZjUtMmI0Ni00Mjk2LWFiMzYtYWI4NmVhZGUwZjQx  # API Key 的 Base64 编码
type: Opaque
</code></pre>
<p>在上述 Secret 中，在 <code>data.apikey</code> 字段中记录 API Key 的 Base64 编码。然后在 AutoTuneExperiment 的配置中引用这个 Secret，具体方式请参阅 <a href="tasks/../modules/building/autotuneexperiment.html#aistore-%E7%9A%84%E4%BD%BF%E7%94%A8">AutoTuneExperiment 文档</a>。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="添加项目成员"><a class="header" href="#添加项目成员">添加项目成员</a></h1>
<p>本教程演示如何为一个项目添加成员。</p>
<h2 id="准备工作-17"><a class="header" href="#准备工作-17">准备工作</a></h2>
<ul>
<li>了解<a href="tasks/../modules/security/project.html">项目</a>的基本概念。</li>
<li>成为一个项目的管理员。如果你不是任何一个项目的管理员，请联系平台管理员为你创建一个项目。</li>
</ul>
<h2 id="查看自己的项目"><a class="header" href="#查看自己的项目">查看自己的项目</a></h2>
<p>在浏览器中进入安全管理控制台之后，在左侧的导航菜单中点击<strong>资源 &gt; 项目</strong>进入项目列表页面。其中，<strong>我的项目</strong>部分列出了所有你作为管理员的项目，<strong>分享给我的项目</strong>部分列出了所有你作为成员的项目。</p>
<figure class="screenshot">
  <img alt="project-list" src="tasks/../assets/tasks/account/add-project-member/project-list.png" />
</figure>
<h2 id="为项目添加用户"><a class="header" href="#为项目添加用户">为项目添加用户</a></h2>
<p>在<strong>我的项目</strong>部分，点击其中一个项目的名称进入该项目的详情页面，这里展示了项目的所有成员（你是项目的管理员）。</p>
<figure class="screenshot">
  <img alt="project-detail" src="tasks/../assets/tasks/account/add-project-member/project-detail.png" />
</figure>
<p>点击成员右侧的<strong>修改按钮</strong>，再点击 <strong>⊕</strong> 为该项目添加成员。在弹出的对话框中，你需要选择所要添加的成员名以及该成员可使用的范围（scope），填写完成之后点击<strong>保存</strong>提交更改，右下角会有悬浮框提示是否添加成功。</p>
<figure class="screenshot">
  <img alt="add-member" src="tasks/../assets/tasks/account/add-project-member/add-member.png" />
</figure>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="小技巧"><a class="header" href="#小技巧">小技巧</a></h1>
<p>本教程汇总了一些实用的小技巧，可以帮助用户更好地使用平台。</p>
<h2 id="让-notebook-不被资源回收"><a class="header" href="#让-notebook-不被资源回收">让 Notebook 不被资源回收</a></h2>
<p>如果想要让 Notebook 不被<a href="tasks/../modules/scheduling/reclaim.html">资源回收</a>，可以在该 Notebook 中<a href="tasks/./use-notebook.html#%E4%BD%BF%E7%94%A8-jupyter-notebook">创建一个 Jupyter Notebook</a>，并运行以下代码：</p>
<pre><code class="language-python"># To keep the kernel active
import time

while True:
    time.sleep(60)
</code></pre>
<p>上述代码使 Notebook 保持活跃状态，而又不占用额外的计算资源。如要恢复对该 Notebook 的资源回收，只需停止上述代码的运行即可。</p>
<h2 id="在终端中了解-kubernetes-api-资源及其字段"><a class="header" href="#在终端中了解-kubernetes-api-资源及其字段">在终端中了解 Kubernetes API 资源及其字段</a></h2>
<p>在创建、查看或调试 Kubernetes API 资源（包括 Kubernetes 原生资源和平台提供的 CRD）时，我们需要了解资源有哪些字段以及它们的含义。要获取这些信息，一种方法是查阅相应的参考文档，但更便捷的方式是在终端使用 <code>kubectl explain</code> 命令：</p>
<pre><code class="language-bash"># 获取资源及其字段的描述
kubectl explain pod

# 获取资源的指定字段及其子字段的描述
kubectl explain pod.spec.containers

# 获取资源的所有子字段
kubectl explain pod --recursive
</code></pre>
<p>例如现在我们想要启用 DeepSpeedJob 的调试模式，但不知道该如何编写 YAML 配置文件，那么可以在 Notebook 的终端中执行以下命令：</p>
<pre><code class="language-bash">kubectl explain dj --recursive    # `dj` 是 DeepSpeedJob 的简称
</code></pre>
<p>输出应类似于：</p>
<pre><code>KIND:     DeepSpeedJob
VERSION:  batch.tensorstack.dev/v1beta1

DESCRIPTION:
     DeepSpeedJob defines the schema for the DeepSpeedJob API.

FIELDS:
   ...
   spec &lt;Object&gt;
      ...
      runMode   &lt;Object&gt;
         debug  &lt;Object&gt;
            enabled     &lt;boolean&gt;
            replicaSpecs        &lt;[]Object&gt;
               command  &lt;[]string&gt;
               skipInitContainer        &lt;boolean&gt;
               type     &lt;string&gt;
         pause  &lt;Object&gt;
            enabled     &lt;boolean&gt;
            resumeSpecs &lt;[]Object&gt;
               args     &lt;[]string&gt;
               command  &lt;[]string&gt;
               skipInitContainer        &lt;boolean&gt;
               type     &lt;string&gt;
      ...
   ...
</code></pre>
<p>由此我们得以写出正确的配置：</p>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: DeepspeedJob
metadata:
  name: deepspeed-example
spec:
  runMode:
    debug:
      enabled: true
  ...
</code></pre>
<h2 id="查看容器的日志"><a class="header" href="#查看容器的日志">查看容器的日志</a></h2>
<p>查看 Pod 中的容器的日志有两种方法。第一种方法是在终端使用 <code>kubectl logs</code> 命令：</p>
<pre><code class="language-bash"># 首先列举所有 Pod
kubectl get pod

# 返回指定 Pod 的（唯一容器的）日志快照
kubectl logs nginx

# 持续输出日志
kubectl logs -f nginx

# 返回日志的最后 20 行
kubectl logs --tail=20 nginx

# 返回最近 1 个小时的日志
kubectl logs --since=1h nginx
</code></pre>
<p>第二种方法是在控制台中查看。进入模型构建控制台，在左侧的导航菜单中点击<strong>构建 &gt; Pod</strong> 进入 Pod 管理页面，然后点击 Pod 的名称进入详情页面：</p>
<figure class="screenshot">
    <img alt="list" src="tasks/../assets/tasks/tricks/list.png" />
</figure>
<p>点击<strong>日志右侧的按钮</strong>即可查看日志：</p>
<figure class="screenshot">
    <img alt="details" src="tasks/../assets/tasks/tricks/details.png" />
</figure>
<figure class="screenshot">
    <img alt="log" src="tasks/../assets/tasks/tricks/log.png" />
</figure>
<p>此外，部分 CRD 所创建的 Pod 的容器日志也可以从相应 CRD 的详情页面查看，请参阅：</p>
<ul>
<li><a href="tasks/./pytorch-training-parallel.html#%E6%A3%80%E6%9F%A5%E8%AE%AD%E7%BB%83%E6%97%A5%E5%BF%97%E5%92%8C%E6%8C%87%E6%A0%87">查看 Job 的容器日志</a></li>
<li><a href="tasks/./build-image.html#%E6%A3%80%E6%9F%A5%E6%9E%84%E5%BB%BA%E8%BF%9B%E5%BA%A6%E5%92%8C%E7%BB%93%E6%9E%9C">查看 Image Builder 的容器日志</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="命令行工具和-sdk"><a class="header" href="#命令行工具和-sdk">命令行工具和 SDK</a></h1>
<p>除了在网页控制台进行操作外，你还可以使用命令行工具和 Python SDK 来与 TensorStack AI 平台进行交互。</p>
<p>此外，命令行工具和 Python SDK 也为平台的部分功能提供支持。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="命令行工具t9k"><a class="header" href="#命令行工具t9k">命令行工具：t9k</a></h1>
<p>TensorStack CLI（简称 T9k CLI）是 TensorStack AI 平台的命令行工具，用于对 TensorStack AI 平台的各种资源对象进行增、删、改、查操作。</p>
<aside class="note info">
<div class="title">信息</div>
<p>如果你使用过 kubectl，那么你可以将 T9k CLI 看作面向 T9k 资源的 kubectl（但是 T9k CLI 采用了资源对象在前、操作在后的语法格式，例如 <code>t9k notebook get -A</code>）。这样的类比能帮助你非常快速地理解 T9k CLI 的用法。但是不了解 kubectl 也不会影响你阅读本文档，你可以从本文档中学会 T9k CLI 的使用方式。</p>
</aside>
<h2 id="功能"><a class="header" href="#功能">功能</a></h2>
<p>TensorStack CLI 目前包含了两大功能：其一是管理 T9k 集群计算资源分配，主要的使用者是 TensorStack AI 平台管理员；其二是管理 TensorStack AI 平台中被创建的作业、服务等资源，主要的使用者是使用平台进行机器学习模型开发、训练、部署等工作的数据科学家。</p>
<p>TensorStack CLI 的目标是：提供对于 T9k 自定义资源的有效支持。对于平台管理员来说，这些功能可以作为 kubectl 的补充来管理 TensorStack AI 平台。对于数据科学家来说，这些功能和控制台一起，帮助他们在 TensorStack AI 平台上开展机器学习相关的工作，而不需要过多的 Kubernetes 基础知识。</p>
<figure>
  <img alt="architecture" src="tools/cli-t9k/../../assets/tools/tensorstack-cli/architecture.drawio.svg"/>
</figure>
<center>图 1：T9k CLI 示意图</center>
<h2 id="资源类型"><a class="header" href="#资源类型">资源类型</a></h2>
<p>T9k CLI 支持的资源类型有：</p>
<ul>
<li>基于 Kubernetes 定义的，用来解决机器学习相关问题的 TensorStack AI 平台资源：
<ul>
<li>AutoTune</li>
<li>BeamJob</li>
<li>ColossalAIJob</li>
<li>DeepSpeedJob</li>
<li>GenericJob</li>
<li>MLService</li>
<li>MPIJob</li>
<li>Notebook</li>
<li>PyTorchTrainingJob</li>
<li>SimpleMLService</li>
<li>TensorFlowTrainingJob</li>
<li>WorkflowTemplate</li>
<li>WorkflowRun</li>
<li>XGBoostTrainingJob</li>
</ul>
</li>
<li>基于 Kubernetes 定义的，用来管理集群资源及权限的 TensorStack AI 平台资源：
<ul>
<li>PodGroup</li>
<li>Project</li>
<li>Queue</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="用户指南"><a class="header" href="#用户指南">用户指南</a></h1>
<h2 id="下载安装"><a class="header" href="#下载安装">下载安装</a></h2>
<h3 id="下载"><a class="header" href="#下载">下载</a></h3>
<p>TensorStack CLI（以下简称 T9k CLI）可以从平台首页下载。请根据操作系统和架构（可以在命令行运行 <code>uname -om</code> 获取）选择适当的版本。</p>
<h3 id="安装"><a class="header" href="#安装">安装</a></h3>
<p>你需要根据下载的版本，设置 T9k CLI 的版本和系统架构等变量：</p>
<pre><code class="language-bash">version=1.78.6
os=darwin
arch=amd64
</code></pre>
<p>然后解压下载好的 T9k CLI，并把得到的二进制文件移动到 <code>/usr/local/bin</code> 路径下：</p>
<pre><code class="language-bash">tar -zxvf &quot;$HOME/Downloads/t9k-$version-$os-$arch.tar.gz&quot;
mv t9k-$os-$arch /usr/local/bin/t9k
rm -f &quot;$HOME/Downloads/t9k-$version-$os-$arch.tar.gz&quot;
</code></pre>
<p>你可以运行以下命令来验证 T9k CLI 安装完成：</p>
<pre><code class="language-bash">t9k version
</code></pre>
<h3 id="卸载"><a class="header" href="#卸载">卸载</a></h3>
<p>删除二进制文件以卸载 T9k CLI。</p>
<pre><code class="language-bash">rm -f /usr/local/bin/t9k
</code></pre>
<h2 id="配置文件"><a class="header" href="#配置文件">配置文件</a></h2>
<p>TensorStack CLI 使用 T9k Config 作为配置文件。T9k Config 文件的路径通过命令行参数 <code>-c, --config</code> 进行指定，在未被指定时，使用默认路径 <code>$HOME/.t9k/t9k-config.yaml</code>。第一次使用时，可以通过 <code>t9k config auth</code> 命令来生成配置文件，详情请参阅 <a href="tools/cli-t9k/./command.html#auth">t9k config auth</a>。</p>
<p>T9k Config 示例如下：</p>
<pre><code class="language-yaml">current-context: default-context
contexts:
- name: default-context
  server: https://&lt;example.com&gt;
  image-registry: https://&lt;example.io&gt;
  prefixes:
    aistore: /t9k/aistore/server
    asset-hub: /t9k/asset-hub/server
    build-console: /t9k/build-console/server
    cluster-admin: /t9k/cluster-admin/server
    deploy-console: /t9k/deploy-console/server
    security-console: /t9k/security/server
    workflow-manager: /t9k/workflow/server
  auth:
    apikey: &lt;your-apikey&gt;
    token: &lt;your-token&gt;
  extension:
    codepack:
      data-copy-image: &lt;your-image&gt;
</code></pre>
<p>T9k Config 包括以下两个部分：</p>
<ul>
<li><code>current-context</code>：字符串，记录默认使用的 Context 名称。你可以通过设置命令行参数 <code>-x, --context</code> 访问其他的 Context。</li>
<li><code>contexts</code>：数组，包含集群相关信息。
<ul>
<li><code>name</code>：字符串，Context 的名称。</li>
<li><code>server</code>：字符串，记录访问这个集群服务的域名。</li>
<li><code>image-registry</code>：字符串，记录这个集群使用镜像仓库的地址。</li>
<li><code>prefixes</code>：数组，记录这个集群中的 T9k Servers 路径前缀。</li>
<li><code>auth</code>：，记录认证信息，支持 <code>apikey</code> 和 <code>token</code> 两种认证方式，需要填写其中一种。</li>
<li><code>extension</code>：记录其他工具需要用到的拓展配置。</li>
</ul>
</li>
</ul>
<h2 id="全局选项"><a class="header" href="#全局选项">全局选项</a></h2>
<p>TensorStack CLI 定义了以下的全局命令行参数：</p>
<pre><code class="language-bash">  -c, --config string      t9k config file (default: $HOME/.t9k/t9k-config.yaml)
  -x, --context string     name of the context to use (default: current-context in t9k config)
  -h, --help               t9k help
  -n, --namespace string   alias of -p and --project, invalid if --project is set by user.
  -p, --project string     project to use (default: from t9k config file)
  -v, --verbose int        Set level-based filter in logging (default -1)
</code></pre>
<p>具体说明如下：</p>
<ul>
<li><code>-c, --config</code>：字符串，指定 T9k Config 文件的路径。对于子命令 <code>config</code>，设置的 T9k Config 文件会被创建或修改。默认路径是 <code>$HOME/.t9k/t9k-config.yaml</code>。</li>
<li><code>-x, --context</code>：字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 <code>current-context</code> 字段指定的 Context。</li>
<li><code>-h, --help </code>：查看当前指令的帮助信息和示例。</li>
<li><code>-p, --project</code>：字符串，指定使用的项目（本文档中的项目和命名空间同义）。</li>
<li><code>-n, --namespace</code>：字符串，和 <code>-p, --project</code> 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。</li>
<li><code>-v, --verbose</code>：指定输出 log 信息的详细程度。</li>
</ul>
<p>项目（命名空间）的使用优先级是（排在前面的优先级更高）：</p>
<ol>
<li>你通过命令行参数 <code>-p, --project</code> 设置的项目。</li>
<li>你通过命令行参数 <code>-n, --namespace</code> 设置的项目。</li>
<li>使用项目 <code>default</code>。</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="命令"><a class="header" href="#命令">命令</a></h1>
<h2 id="autotune-1"><a class="header" href="#autotune-1">autotune</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/building/autotune.html">AutoTune</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>at</code> 代替 <code>autotune</code>。</p>
</aside>
<h3 id="delete"><a class="header" href="#delete">delete</a></h3>
<p>删除指定的 AutoTune。</p>
<h4 id="使用-3"><a class="header" href="#使用-3">使用</a></h4>
<pre><code>t9k autotune delete [names...] [--all] [-f]
</code></pre>
<p><code>t9k autotune delete</code> 也可以用 <code>t9k autotune rm</code> 代替。</p>
<h4 id="选项"><a class="header" href="#选项">选项</a></h4>
<pre><code>--all                   删除当前 Project 中的所有 AutoTunes。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-1"><a class="header" href="#全局选项-1">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-4"><a class="header" href="#示例-4">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 AutoTune：</p>
<pre><code>t9k autotune delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 AutoTune：</p>
<pre><code>t9k autotune delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 AutoTune：</p>
<pre><code>t9k autotune delete foo -p demo --all
</code></pre>
<h3 id="describe"><a class="header" href="#describe">describe</a></h3>
<p>查看某个 AutoTune 的详细信息。</p>
<h4 id="使用-4"><a class="header" href="#使用-4">使用</a></h4>
<pre><code>t9k at describe &lt;name&gt; [--color]
</code></pre>
<p><code>t9k at describe</code> 也可以用 <code>t9k at desc</code> 代替。</p>
<h4 id="选项-1"><a class="header" href="#选项-1">选项</a></h4>
<pre><code>--color                 使用彩色的输出信息（默认全是黑色）。
</code></pre>
<h4 id="全局选项-2"><a class="header" href="#全局选项-2">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-5"><a class="header" href="#示例-5">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 AutoTune 的详细描述：</p>
<pre><code>t9k at describe foo -p demo
</code></pre>
<h3 id="get"><a class="header" href="#get">get</a></h3>
<p>查看 AutoTune 相关信息。</p>
<h4 id="使用-5"><a class="header" href="#使用-5">使用</a></h4>
<pre><code>t9k at get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-2"><a class="header" href="#选项-2">选项</a></h4>
<pre><code>-A, --all-namespaces    获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string     指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`。
</code></pre>
<h4 id="全局选项-3"><a class="header" href="#全局选项-3">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-6"><a class="header" href="#示例-6">示例</a></h4>
<p>以默认格式查看 Project example 下所有 AutoTune：</p>
<pre><code>t9k at get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 AutoTune：</p>
<pre><code>t9k at get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 AutoTune：</p>
<pre><code>t9k at get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 AutoTune：</p>
<pre><code>t9k at get foo -p example -o yaml
</code></pre>
<h3 id="wait"><a class="header" href="#wait">wait</a></h3>
<p>等待 AutoTune 完成。</p>
<h4 id="使用-6"><a class="header" href="#使用-6">使用</a></h4>
<pre><code>t9k at wait &lt;name&gt; [--timeout=&lt;timeoutTime&gt;] [--period=&lt;periodTime&gt;] [--print-log]
</code></pre>
<h4 id="选项-3"><a class="header" href="#选项-3">选项</a></h4>
<pre><code>--timeout string        字符串，最长等待时间。默认值：&quot;1h&quot;，1 小时。
--period  string        字符串，检查任务是否完成的周期。默认值：&quot;1s&quot;，每秒检查一次。
--print-log             是否在等待时流式查看日志。
</code></pre>
<h4 id="全局选项-4"><a class="header" href="#全局选项-4">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-7"><a class="header" href="#示例-7">示例</a></h4>
<p>等待 Project example 下的 AutoTune foo 完成：</p>
<pre><code>t9k at wait foo -p example
</code></pre>
<p>等待 Project example 下的 AutoTune foo 完成，只等待 10 分钟：</p>
<pre><code>t9k at wait foo -p example --timeout 10m
</code></pre>
<p>等待 Project example 下的 AutoTune foo 完成，同时打印 server 的日志：</p>
<pre><code>t9k at wait foo -p example --print-log
</code></pre>
<h2 id="beamjob-1"><a class="header" href="#beamjob-1">beamjob</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/jobs/beamjob.html">BeamJob</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>bj</code> 代替 <code>beamjob</code>。</p>
</aside>
<h3 id="delete-1"><a class="header" href="#delete-1">delete</a></h3>
<p>删除指定的 BeamJob。</p>
<h4 id="使用-7"><a class="header" href="#使用-7">使用</a></h4>
<pre><code>t9k beamjob delete [names...] [--all] [-f]
</code></pre>
<p><code>t9k beamjob delete</code> 也可以用 <code>t9k bj rm</code> 代替。</p>
<h4 id="选项-4"><a class="header" href="#选项-4">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 BeamJob。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-5"><a class="header" href="#全局选项-5">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-8"><a class="header" href="#示例-8">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 BeamJob：</p>
<pre><code>t9k beamjob delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 BeamJob：</p>
<pre><code>t9k beamjob delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 BeamJob：</p>
<pre><code>t9k beamjob delete foo -p demo --all
</code></pre>
<h3 id="describe-1"><a class="header" href="#describe-1">describe</a></h3>
<p>查看某个 BeamJob 的详细信息。</p>
<h4 id="使用-8"><a class="header" href="#使用-8">使用</a></h4>
<pre><code>t9k bj describe &lt;name&gt;
</code></pre>
<p><code>t9k bj describe</code> 也可以用 <code>t9k bj desc</code> 代替。</p>
<h4 id="全局选项-6"><a class="header" href="#全局选项-6">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-9"><a class="header" href="#示例-9">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 BeamJob 的详细描述：</p>
<pre><code>t9k bj describe foo -p demo
</code></pre>
<h3 id="get-1"><a class="header" href="#get-1">get</a></h3>
<p>查看 BeamJob 相关信息。</p>
<h4 id="使用-9"><a class="header" href="#使用-9">使用</a></h4>
<pre><code>t9k bj get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-5"><a class="header" href="#选项-5">选项</a></h4>
<pre><code>-A, --all-namespaces    获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string     指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`。
</code></pre>
<h4 id="全局选项-7"><a class="header" href="#全局选项-7">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-10"><a class="header" href="#示例-10">示例</a></h4>
<p>以默认格式查看 Project example 下所有 BeamJob：</p>
<pre><code>t9k bj get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 BeamJob：</p>
<pre><code>t9k bj get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 BeamJob：</p>
<pre><code>t9k bj get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 BeamJob：</p>
<pre><code>t9k bj get foo -p example -o yaml
</code></pre>
<h3 id="logs"><a class="header" href="#logs">logs</a></h3>
<p>查看 BeamJob 某个计算节点的日志。</p>
<h4 id="使用-10"><a class="header" href="#使用-10">使用</a></h4>
<pre><code>t9k bj logs [--type=jobmanager|taskmanager|batchjob] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [-f] [--tail] [--timestamps]
</code></pre>
<h4 id="选项-6"><a class="header" href="#选项-6">选项</a></h4>
<pre><code>--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
-f, --follow            流式查看日志。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--tail int              整数，要查看的日志的行数（从后往前）。默认值：-1，查看全部日志。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `taskmanager`，`batchjob` 以及默认值 `jobmanager`。
</code></pre>
<h4 id="全局选项-8"><a class="header" href="#全局选项-8">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-11"><a class="header" href="#示例-11">示例</a></h4>
<p>查看 Project example 下 BeamJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的日志：</p>
<pre><code>t9k bj logs foo --type=replicaType --index=replicaIndex -p example
</code></pre>
<p>流式查看 Project example 下 BeamJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的容器 <code>mnist</code> 的日志：</p>
<pre><code>t9k bj logs foo --type=replicaType --index=replicaIndex --container=mnist --follow
</code></pre>
<p>查看 BeamJob foo 第 0 个 jobmanager 节点的最后 20 行日志：</p>
<pre><code>t9k bj logs foo --tail 20
</code></pre>
<h3 id="wait-1"><a class="header" href="#wait-1">wait</a></h3>
<p>等待 BeamJob 完成。</p>
<h4 id="使用-11"><a class="header" href="#使用-11">使用</a></h4>
<pre><code>t9k bj wait &lt;name&gt; [--timeout=&lt;timeoutTime&gt;] [--period=&lt;periodTime&gt;] [--print-log [--type=jobmanager|taskmanager|batchjob] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [--timestamps]]
</code></pre>
<h4 id="选项-7"><a class="header" href="#选项-7">选项</a></h4>
<pre><code>--timeout string        字符串，最长等待时间。默认值：&quot;1h&quot;，1 小时。
--period  string        字符串，检查任务是否完成的周期。默认值：&quot;1s&quot;，每秒检查一次。
--print-log             是否在等待时流式查看日志。

以下参数只有在开启了 `--print-log` 后才生效。

--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `taskmanager`，`batchjob` 以及默认值 `jobmanager`。
</code></pre>
<h4 id="全局选项-9"><a class="header" href="#全局选项-9">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-12"><a class="header" href="#示例-12">示例</a></h4>
<p>等待 Project example 下的 BeamJob foo 完成：</p>
<pre><code>t9k bj wait foo -p example
</code></pre>
<p>等待 Project example 下的 BeamJob foo 完成，只等待 10 分钟：</p>
<pre><code>t9k bj wait foo -p example --timeout 10m
</code></pre>
<p>等待 Project example 下的 BeamJob foo 完成，同时打印节点 flinkcluster-taskmanager-0 的日志：</p>
<pre><code>t9k bj wait foo -p example --print-log --type taskmanager --index 0
</code></pre>
<h2 id="colossalaijob-1"><a class="header" href="#colossalaijob-1">colossalaijob</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/jobs/colossalaijob.html">ColossalAIJob</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>caij</code> 代替 <code>colossalaijob</code>。</p>
</aside>
<h3 id="delete-2"><a class="header" href="#delete-2">delete</a></h3>
<p>删除指定的 ColossalAIJob。</p>
<h4 id="使用-12"><a class="header" href="#使用-12">使用</a></h4>
<pre><code>t9k colossalaijob delete [names...] [--all] [-f]
</code></pre>
<p><code>t9k colossalaijob delete</code> 也可以用 <code>t9k caij rm</code> 代替。</p>
<h4 id="选项-8"><a class="header" href="#选项-8">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 ColossalAIJob。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-10"><a class="header" href="#全局选项-10">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-13"><a class="header" href="#示例-13">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 ColossalAIJob：</p>
<pre><code>t9k colossalaijob delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 ColossalAIJob：</p>
<pre><code>t9k colossalaijob delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 ColossalAIJob：</p>
<pre><code>t9k colossalaijob delete foo -p demo --all
</code></pre>
<h3 id="describe-2"><a class="header" href="#describe-2">describe</a></h3>
<p>查看某个 ColossalAIJob 的详细信息。</p>
<h4 id="使用-13"><a class="header" href="#使用-13">使用</a></h4>
<pre><code>t9k caij describe &lt;name&gt;
</code></pre>
<p><code>t9k caij describe</code> 也可以用 <code>t9k caij desc</code> 代替。</p>
<h4 id="全局选项-11"><a class="header" href="#全局选项-11">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-14"><a class="header" href="#示例-14">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 ColossalAIJob 的详细描述：</p>
<pre><code>t9k caij describe foo -p demo
</code></pre>
<h3 id="get-2"><a class="header" href="#get-2">get</a></h3>
<p>查看 ColossalAIJob 相关信息。</p>
<h4 id="使用-14"><a class="header" href="#使用-14">使用</a></h4>
<pre><code>t9k caij get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-9"><a class="header" href="#选项-9">选项</a></h4>
<pre><code>-A, --all-namespaces    获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string     指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`。
</code></pre>
<h4 id="全局选项-12"><a class="header" href="#全局选项-12">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-15"><a class="header" href="#示例-15">示例</a></h4>
<p>以默认格式查看 Project example 下所有 ColossalAIJob：</p>
<pre><code>t9k caij get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 ColossalAIJob：</p>
<pre><code>t9k caij get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 ColossalAIJob：</p>
<pre><code>t9k caij get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 ColossalAIJob：</p>
<pre><code>t9k caij get foo -p example -o yaml
</code></pre>
<h3 id="logs-1"><a class="header" href="#logs-1">logs</a></h3>
<p>查看 ColossalAIJob 某个计算节点的日志。</p>
<h4 id="使用-15"><a class="header" href="#使用-15">使用</a></h4>
<pre><code>t9k caij logs [--type=master|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [-f] [--tail] [--timestamps]
</code></pre>
<h4 id="选项-10"><a class="header" href="#选项-10">选项</a></h4>
<pre><code>--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
-f, --follow            流式查看日志。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--tail int              整数，要查看的日志的行数（从后往前）。默认值：-1，查看全部日志。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `master` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-13"><a class="header" href="#全局选项-13">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-16"><a class="header" href="#示例-16">示例</a></h4>
<p>查看 Project example 下 ColossalAIJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的日志：</p>
<pre><code>t9k caij logs foo --type=replicaType --index=replicaIndex -p example
</code></pre>
<p>流式查看 Project example 下 ColossalAIJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的容器 <code>mnist</code> 的日志：</p>
<pre><code>t9k caij logs foo --type=replicaType --index=replicaIndex --container=mnist --follow
</code></pre>
<p>查看 ColossalAIJob foo 第 0 个 worker 节点的最后 20 行日志：</p>
<pre><code>t9k caij logs foo --tail 20
</code></pre>
<h3 id="wait-2"><a class="header" href="#wait-2">wait</a></h3>
<p>等待 ColossalAIJob 完成。</p>
<h4 id="使用-16"><a class="header" href="#使用-16">使用</a></h4>
<pre><code>t9k caij wait &lt;name&gt; [--timeout=&lt;timeoutTime&gt;] [--period=&lt;periodTime&gt;] [--print-log [--type=master|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [--timestamps]]
</code></pre>
<h4 id="选项-11"><a class="header" href="#选项-11">选项</a></h4>
<pre><code>--timeout string        字符串，最长等待时间。默认值：&quot;1h&quot;，1 小时。
--period  string        字符串，检查任务是否完成的周期。默认值：&quot;1s&quot;，每秒检查一次。
--print-log             是否在等待时流式查看日志。

以下参数只有在开启了 `--print-log` 后才生效。

--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `master` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-14"><a class="header" href="#全局选项-14">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-17"><a class="header" href="#示例-17">示例</a></h4>
<p>等待 Project example 下的 ColossalAIJob foo 完成：</p>
<pre><code>t9k caij wait foo -p example
</code></pre>
<p>等待 Project example 下的 ColossalAIJob foo 完成，只等待 10 分钟：</p>
<pre><code>t9k caij wait foo -p example --timeout 10m
</code></pre>
<p>等待 Project example 下的 ColossalAIJob foo 完成，同时打印节点 master-0 的日志：</p>
<pre><code>t9k caij wait foo -p example --print-log --type master --index 0
</code></pre>
<h2 id="config"><a class="header" href="#config">config</a></h2>
<p>对指定的 <a href="tools/cli-t9k/./guide.html#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">T9k Config</a> 进行生成、管理、查看。T9k Config 默认使用文件 <code>${HOME}/.t9k/t9k-config.yaml</code>，可通过全局选项 <code>-c, --config</code> 指定该文件路径。</p>
<h3 id="auth"><a class="header" href="#auth">auth</a></h3>
<p>完成用户身份认证，生成 T9k Config。用户第一次使用 T9k 命令行工具时，需要使用此命令来进行身份认证。认证成功后，此命令会修改（如果是首次认证会新建）T9k Config。之后用户便可以通过该认证信息去使用 T9k 其他命令。</p>
<h4 id="使用-17"><a class="header" href="#使用-17">使用</a></h4>
<pre><code>t9k config auth &lt;server&gt; [--apikey] [--user=&lt;username&gt;]
</code></pre>
<h4 id="选项-12"><a class="header" href="#选项-12">选项</a></h4>
<pre><code>-k, --apikey            启用交互式输入 API Key。
-u, --user string       字符串，指定用户密码登录的用户名称。
</code></pre>
<h4 id="全局选项-15"><a class="header" href="#全局选项-15">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定要查看、修改的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定新增 Context 的名称。
-h, --help              查看当前指令的帮助信息和示例。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-18"><a class="header" href="#示例-18">示例</a></h4>
<h5 id="通过用户密码完成认证"><a class="header" href="#通过用户密码完成认证">通过用户密码完成认证</a></h5>
<p>用户指定要登录的域名，然后输入用户名和密码完成认证。认证完成后，当前的 T9k Config 中便会新增一个 <code>&lt;用户名&gt;-&lt;域名&gt;</code> 的 Context，用户也可以自己指定 Context 的名称。</p>
<pre><code>$ t9k config auth &lt;http://example.com&gt;
Authenticating using username and password by default, add --apikey to use apikey.
Please enter your username: demo
Please enter your password:
Please enter Context name [default: demo-example.com]: demo
Login succeeded!
</code></pre>
<p>!!! note “注意” 
Context 的名称需要满足 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-subdomain-names">DNS Subdomain Names</a> 的要求，如果 Context 名字重复，可以选择覆盖原内容或者重新输入。</p>
<h5 id="通过-api-key-完成认证"><a class="header" href="#通过-api-key-完成认证">通过 API Key 完成认证</a></h5>
<p>用户指定要登录的域名，然后输入 API Key。认证完成后，当前的 T9k Config 中便会新增一个 <code>apikey-&lt;hash&gt;-&lt;域名&gt;</code> 的 Context，用户也可以自己指定 Context 的名称。</p>
<pre><code>$ t9k config auth &lt;http://example.com&gt; --apikey
Authenticating using API Key...
Please enter your API Key:
Please enter Context name [default: apikey-&lt;hash&gt;-example.com]: demo-apikey
Login succeeded!
</code></pre>
<h3 id="delete-context"><a class="header" href="#delete-context">delete-context</a></h3>
<p>删除指定的 Context。</p>
<p>!!! note “注意” 
即使指定的 Context 是 current-context，此命令也会直接删除掉。所以务必确认之后再删除。</p>
<h4 id="使用-18"><a class="header" href="#使用-18">使用</a></h4>
<pre><code>t9k config delete-context &lt;name&gt;
</code></pre>
<h4 id="全局选项-16"><a class="header" href="#全局选项-16">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定要查看、修改的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-h, --help              查看当前指令的帮助信息和示例。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-19"><a class="header" href="#示例-19">示例</a></h4>
<p>删除 Context demo：</p>
<pre><code>t9k config delete-context demo
</code></pre>
<h3 id="get-contexts"><a class="header" href="#get-contexts">get-contexts</a></h3>
<p>用于获取当前使用的 T9k Config 中 Context 的相关信息。具体包括：</p>
<ul>
<li><code>CURRENT</code>：是否是当前正在使用的 Context</li>
<li><code>NAME</code>：Context 的名称</li>
<li><code>SERVER</code>：T9k 平台的地址</li>
<li><code>AUTH_TYPE</code>：认证信息的类型（token 或者 apikey）</li>
</ul>
<h4 id="使用-19"><a class="header" href="#使用-19">使用</a></h4>
<pre><code>t9k config get-contexts [name] 
</code></pre>
<h4 id="全局选项-17"><a class="header" href="#全局选项-17">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定要查看、修改的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-h, --help              查看当前指令的帮助信息和示例。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-20"><a class="header" href="#示例-20">示例</a></h4>
<p>获取当前 T9k Config 中所有 Context 的信息：</p>
<pre><code>t9k config get-contexts
</code></pre>
<p>获取指定 Context 的信息：</p>
<pre><code>t9k config get-contexts my-context
</code></pre>
<h3 id="use-context"><a class="header" href="#use-context">use-context</a></h3>
<p>切换当前使用的 Context，此命令会修改当前 T9k Config 中 current-context 的值。</p>
<h4 id="使用-20"><a class="header" href="#使用-20">使用</a></h4>
<pre><code>t9k config use-context &lt;name&gt;
</code></pre>
<h4 id="全局选项-18"><a class="header" href="#全局选项-18">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定要查看、修改的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-h, --help              查看当前指令的帮助信息和示例。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-21"><a class="header" href="#示例-21">示例</a></h4>
<p>切换到 Context foo：</p>
<pre><code>t9k config use-context foo
</code></pre>
<p>将文件 <code>$HOME/t9kConfig.yaml</code> 下的 Context 切换到 foo：</p>
<pre><code>t9k config use-context foo -c $HOME/t9kConfig.yaml
</code></pre>
<h2 id="create"><a class="header" href="#create">create</a></h2>
<p>通过文件创建 TensorStack AI 平台的资源或者其他支持的资源 （PVC 和 secret）。</p>
<h4 id="使用-21"><a class="header" href="#使用-21">使用</a></h4>
<pre><code>t9k create --filename=&lt;file&gt;
</code></pre>
<h4 id="选项-13"><a class="header" href="#选项-13">选项</a></h4>
<pre><code>-f, --filename          文件路径
</code></pre>
<h4 id="全局选项-19"><a class="header" href="#全局选项-19">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-22"><a class="header" href="#示例-22">示例</a></h4>
<p>通过文件在 Project demo 下创建一个 Notebook 资源。</p>
<pre><code>t9k create -f notebook.yaml -p demo
</code></pre>
<h2 id="delete-3"><a class="header" href="#delete-3">delete</a></h2>
<p>根据文件删除资源。</p>
<h4 id="使用-22"><a class="header" href="#使用-22">使用</a></h4>
<pre><code>t9k delete --filename=&lt;file&gt;
</code></pre>
<h4 id="选项-14"><a class="header" href="#选项-14">选项</a></h4>
<pre><code>-f, --filename          文件路径
</code></pre>
<h4 id="全局选项-20"><a class="header" href="#全局选项-20">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-23"><a class="header" href="#示例-23">示例</a></h4>
<p>根据文件内容删除 Project demo 下相应的 Notebook 资源。</p>
<pre><code>t9k delete -f notebook.yaml -p demo
</code></pre>
<h2 id="deepspeedjob-1"><a class="header" href="#deepspeedjob-1">deepspeedjob</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/jobs/deepspeedjob.html">DeepSpeedJob</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>dj</code> 代替 <code>deepspeedjob</code>。</p>
</aside>
<h3 id="delete-4"><a class="header" href="#delete-4">delete</a></h3>
<p>删除指定的 DeepSpeedJob。</p>
<h4 id="使用-23"><a class="header" href="#使用-23">使用</a></h4>
<pre><code>t9k deepspeedjob delete [names...] [--all] [-f]
</code></pre>
<p><code>t9k deepspeedjob delete</code> 也可以用 <code>t9k dj rm</code> 代替。</p>
<h4 id="选项-15"><a class="header" href="#选项-15">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 DeepSpeedJob。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-21"><a class="header" href="#全局选项-21">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-24"><a class="header" href="#示例-24">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 DeepSpeedJob：</p>
<pre><code>t9k deepspeedjob delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 DeepSpeedJob：</p>
<pre><code>t9k deepspeedjob delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 DeepSpeedJob：</p>
<pre><code>t9k deepspeedjob delete foo -p demo --all
</code></pre>
<h3 id="describe-3"><a class="header" href="#describe-3">describe</a></h3>
<p>查看某个 DeepSpeedJob 的详细信息。</p>
<h4 id="使用-24"><a class="header" href="#使用-24">使用</a></h4>
<pre><code>t9k dj describe &lt;name&gt;
</code></pre>
<p><code>t9k dj describe</code> 也可以用 <code>t9k dj desc</code> 代替。</p>
<h4 id="全局选项-22"><a class="header" href="#全局选项-22">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-25"><a class="header" href="#示例-25">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 DeepSpeedJob 的详细描述：</p>
<pre><code>t9k dj describe foo -p demo
</code></pre>
<h3 id="get-3"><a class="header" href="#get-3">get</a></h3>
<p>查看 DeepSpeedJob 相关信息。</p>
<h4 id="使用-25"><a class="header" href="#使用-25">使用</a></h4>
<pre><code>t9k dj get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-16"><a class="header" href="#选项-16">选项</a></h4>
<pre><code>-A, --all-namespaces    获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string     指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`。
</code></pre>
<h4 id="全局选项-23"><a class="header" href="#全局选项-23">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-26"><a class="header" href="#示例-26">示例</a></h4>
<p>以默认格式查看 Project example 下所有 DeepSpeedJob：</p>
<pre><code>t9k dj get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 DeepSpeedJob：</p>
<pre><code>t9k dj get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 DeepSpeedJob：</p>
<pre><code>t9k dj get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 DeepSpeedJob：</p>
<pre><code>t9k dj get foo -p example -o yaml
</code></pre>
<h3 id="logs-2"><a class="header" href="#logs-2">logs</a></h3>
<p>查看 DeepSpeedJob 某个计算节点的日志。</p>
<h4 id="使用-26"><a class="header" href="#使用-26">使用</a></h4>
<pre><code>t9k dj logs [--type=master|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [-f] [--tail] [--timestamps]
</code></pre>
<h4 id="选项-17"><a class="header" href="#选项-17">选项</a></h4>
<pre><code>--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
-f, --follow            流式查看日志。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--tail int              整数，要查看的日志的行数（从后往前）。默认值：-1，查看全部日志。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `master` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-24"><a class="header" href="#全局选项-24">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-27"><a class="header" href="#示例-27">示例</a></h4>
<p>查看 Project example 下 DeepSpeedJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的日志：</p>
<pre><code>t9k dj logs foo --type=replicaType --index=replicaIndex -p example
</code></pre>
<p>流式查看 Project example 下 DeepSpeedJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的容器 <code>mnist</code> 的日志：</p>
<pre><code>t9k dj logs foo --type=replicaType --index=replicaIndex --container=mnist --follow
</code></pre>
<p>查看 DeepSpeedJob foo 第 0 个 worker 节点的最后 20 行日志：</p>
<pre><code>t9k dj logs foo --tail 20
</code></pre>
<h3 id="wait-3"><a class="header" href="#wait-3">wait</a></h3>
<p>等待 DeepSpeedJob 完成。</p>
<h4 id="使用-27"><a class="header" href="#使用-27">使用</a></h4>
<pre><code>t9k dj wait &lt;name&gt; [--timeout=&lt;timeoutTime&gt;] [--period=&lt;periodTime&gt;] [--print-log [--type=master|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [--timestamps]]
</code></pre>
<h4 id="选项-18"><a class="header" href="#选项-18">选项</a></h4>
<pre><code>--timeout string        字符串，最长等待时间。默认值：&quot;1h&quot;，1 小时。
--period  string        字符串，检查任务是否完成的周期。默认值：&quot;1s&quot;，每秒检查一次。
--print-log             是否在等待时流式查看日志。

以下参数只有在开启了 `--print-log` 后才生效。

--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `master` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-25"><a class="header" href="#全局选项-25">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-28"><a class="header" href="#示例-28">示例</a></h4>
<p>等待 Project example 下的 DeepSpeedJob foo 完成：</p>
<pre><code>t9k dj wait foo -p example
</code></pre>
<p>等待 Project example 下的 DeepSpeedJob foo 完成，只等待 10 分钟：</p>
<pre><code>t9k dj wait foo -p example --timeout 10m
</code></pre>
<p>等待 Project example 下的 DeepSpeedJob foo 完成，同时打印节点 master-0 的日志：</p>
<pre><code>t9k dj wait foo -p example --print-log --type master --index 0
</code></pre>
<h2 id="genericjob-1"><a class="header" href="#genericjob-1">genericjob</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/jobs/genericjob.html">GenericJob</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>gj</code> 代替 <code>genericjob</code>。</p>
</aside>
<h3 id="delete-5"><a class="header" href="#delete-5">delete</a></h3>
<p>删除指定的 GenericJob。</p>
<h4 id="使用-28"><a class="header" href="#使用-28">使用</a></h4>
<pre><code>t9k genericjob delete [names...] [--all] [-f]
</code></pre>
<p><code>t9k genericjob delete</code> 也可以用 <code>t9k gj rm</code> 代替。</p>
<h4 id="选项-19"><a class="header" href="#选项-19">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 GenericJob。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-26"><a class="header" href="#全局选项-26">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-29"><a class="header" href="#示例-29">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 GenericJob：</p>
<pre><code>t9k genericjob delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 GenericJob：</p>
<pre><code>t9k genericjob delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 GenericJob：</p>
<pre><code>t9k genericjob delete foo -p demo --all
</code></pre>
<h3 id="describe-4"><a class="header" href="#describe-4">describe</a></h3>
<p>查看某个 GenericJob 的详细信息。</p>
<h4 id="使用-29"><a class="header" href="#使用-29">使用</a></h4>
<pre><code>t9k gj describe &lt;name&gt;
</code></pre>
<p><code>t9k gj describe</code> 也可以用 <code>t9k gj desc</code> 代替。</p>
<h4 id="全局选项-27"><a class="header" href="#全局选项-27">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-30"><a class="header" href="#示例-30">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 GenericJob 的详细描述：</p>
<pre><code>t9k gj describe foo -p demo
</code></pre>
<h3 id="get-4"><a class="header" href="#get-4">get</a></h3>
<p>查看 GenericJob 相关信息。</p>
<h4 id="使用-30"><a class="header" href="#使用-30">使用</a></h4>
<pre><code>t9k gj get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-20"><a class="header" href="#选项-20">选项</a></h4>
<pre><code>-A, --all-namespaces    获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string     指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`。
</code></pre>
<h4 id="全局选项-28"><a class="header" href="#全局选项-28">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-31"><a class="header" href="#示例-31">示例</a></h4>
<p>以默认格式查看 Project example 下所有 GenericJob：</p>
<pre><code>t9k gj get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 GenericJob：</p>
<pre><code>t9k gj get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 GenericJob：</p>
<pre><code>t9k gj get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 GenericJob：</p>
<pre><code>t9k gj get foo -p example -o yaml
</code></pre>
<h3 id="logs-3"><a class="header" href="#logs-3">logs</a></h3>
<p>查看 GenericJob 某个计算节点的日志。</p>
<h4 id="使用-31"><a class="header" href="#使用-31">使用</a></h4>
<pre><code>t9k gj logs [--type=master|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [-f] [--tail] [--timestamps]
</code></pre>
<h4 id="选项-21"><a class="header" href="#选项-21">选项</a></h4>
<pre><code>--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
-f, --follow            流式查看日志。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--tail int              整数，要查看的日志的行数（从后往前）。默认值：-1，查看全部日志。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `master` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-29"><a class="header" href="#全局选项-29">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-32"><a class="header" href="#示例-32">示例</a></h4>
<p>查看 Project example 下 GenericJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的日志：</p>
<pre><code>t9k gj logs foo --type=replicaType --index=replicaIndex -p example
</code></pre>
<p>流式查看 Project example 下 GenericJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的容器 <code>mnist</code> 的日志：</p>
<pre><code>t9k gj logs foo --type=replicaType --index=replicaIndex --container=mnist --follow
</code></pre>
<p>查看 GenericJob foo 第 0 个 worker 节点的最后 20 行日志：</p>
<pre><code>t9k gj logs foo --tail 20
</code></pre>
<h3 id="wait-4"><a class="header" href="#wait-4">wait</a></h3>
<p>等待 GenericJob 完成。</p>
<h4 id="使用-32"><a class="header" href="#使用-32">使用</a></h4>
<pre><code>t9k gj wait &lt;name&gt; [--timeout=&lt;timeoutTime&gt;] [--period=&lt;periodTime&gt;] [--print-log [--type=master|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [--timestamps]]
</code></pre>
<h4 id="选项-22"><a class="header" href="#选项-22">选项</a></h4>
<pre><code>--timeout string        字符串，最长等待时间。默认值：&quot;1h&quot;，1 小时。
--period  string        字符串，检查任务是否完成的周期。默认值：&quot;1s&quot;，每秒检查一次。
--print-log             是否在等待时流式查看日志。

以下参数只有在开启了 `--print-log` 后才生效。

--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `master` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-30"><a class="header" href="#全局选项-30">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-33"><a class="header" href="#示例-33">示例</a></h4>
<p>等待 Project example 下的 GenericJob foo 完成：</p>
<pre><code>t9k gj wait foo -p example
</code></pre>
<p>等待 Project example 下的 GenericJob foo 完成，只等待 10 分钟：</p>
<pre><code>t9k gj wait foo -p example --timeout 10m
</code></pre>
<p>等待 Project example 下的 GenericJob foo 完成，同时打印节点 master-0 的日志：</p>
<pre><code>t9k gj wait foo -p example --print-log --type master --index 0
</code></pre>
<h2 id="mlservice-1"><a class="header" href="#mlservice-1">mlservice</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/deployment/mlservice.html">MLService</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>mls</code> 代替 <code>mlservice</code>。</p>
</aside>
<h3 id="canary"><a class="header" href="#canary">canary</a></h3>
<p>设置<a href="tools/cli-t9k/../../modules/deployment/mlservice.html#%E9%87%91%E4%B8%9D%E9%9B%80%E5%8F%91%E5%B8%83">金丝雀发布</a>。</p>
<h4 id="使用-33"><a class="header" href="#使用-33">使用</a></h4>
<pre><code>t9k mlservice set-canary [--default=default-release] [--canary=canary-release] [--traffic=canary-percentage] [--dry-run] [-o yaml|json]
</code></pre>
<h4 id="选项-23"><a class="header" href="#选项-23">选项</a></h4>
<pre><code>--canary string         字符串，指定金丝雀发布的版本名称
--default string        字符串，指定默认发布的版本名称
--dry-run               只打印更新后的 yaml 文件，但是不执行 apply 操作。
-o, --output string     字符串，指定 --dry-run 打印的格式。可选值有 `json`，`yaml`。
--traffic int           整数，指定金丝雀发布的路由权重
</code></pre>
<h4 id="全局选项-31"><a class="header" href="#全局选项-31">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-34"><a class="header" href="#示例-34">示例</a></h4>
<p>将 Project demo 下 MLService maskdetection 的默认发布版本设为 <code>foo</code>，金丝雀发布版本设为 <code>bar</code> 且权重为 20%：</p>
<pre><code>t9k mlservice set-canary maskdetection --default=foo --canary=bar --traffic=20 -n demo
</code></pre>
<p>将 Project demo 下 MLService maskdetection 的金丝雀发布版本权重设为 30%：</p>
<pre><code>t9k mlservice set-canary maskdetection --traffic=30 -n demo
</code></pre>
<p>将 Project demo 下 MLService maskdetection 的默认发布版本设为 <code>foo</code>：</p>
<pre><code>t9k mlservice set-canary maskdetection --default=foo
</code></pre>
<p>将 Project demo 下 MLService maskdetection 的金丝雀发布版本设为 <code>bar</code>：</p>
<pre><code>t9k mlservice set-canary maskdetection --canary=bar -n demo
</code></pre>
<h3 id="delete-6"><a class="header" href="#delete-6">delete</a></h3>
<p>删除指定的 MLService。</p>
<h4 id="使用-34"><a class="header" href="#使用-34">使用</a></h4>
<pre><code>t9k mls delete [names...] [-f] [--all]
</code></pre>
<p><code>t9k mls delete</code> 也可以用 <code>t9k mls rm</code> 代替。</p>
<h4 id="选项-24"><a class="header" href="#选项-24">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 XGBoostTrainingJob。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-32"><a class="header" href="#全局选项-32">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-35"><a class="header" href="#示例-35">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 MLService：</p>
<pre><code>t9k mls delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 MLService：</p>
<pre><code>t9k mls delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 MLService：</p>
<pre><code>t9k mls delete foo -p demo --all
</code></pre>
<h3 id="describe-5"><a class="header" href="#describe-5">describe</a></h3>
<p>查看 MLService 详细信息。</p>
<h4 id="使用-35"><a class="header" href="#使用-35">使用</a></h4>
<pre><code>t9k mls describe &lt;name&gt; [--color]
</code></pre>
<h4 id="选项-25"><a class="header" href="#选项-25">选项</a></h4>
<pre><code>--color                 使用彩色的输出信息（默认全是黑色）。
</code></pre>
<h4 id="全局选项-33"><a class="header" href="#全局选项-33">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-36"><a class="header" href="#示例-36">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 MLService 的详细描述：</p>
<pre><code>t9k mls describe foo -p demo
</code></pre>
<h3 id="get-5"><a class="header" href="#get-5">get</a></h3>
<p>查看 MLService 相关信息。</p>
<h4 id="使用-36"><a class="header" href="#使用-36">使用</a></h4>
<pre><code>t9k mls get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-26"><a class="header" href="#选项-26">选项</a></h4>
<pre><code>-A, --all-namespaces       获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string        指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`
</code></pre>
<h4 id="全局选项-34"><a class="header" href="#全局选项-34">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-37"><a class="header" href="#示例-37">示例</a></h4>
<p>以默认格式查看 Project example 下所有 MLService：</p>
<pre><code>t9k mls get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 MLService：</p>
<pre><code>t9k mls get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 MLService：</p>
<pre><code>t9k mls get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 MLService：</p>
<pre><code>t9k mls get foo -p example -o yaml
</code></pre>
<h3 id="delete-release"><a class="header" href="#delete-release">delete-release</a></h3>
<p>删除 MLService 中发布的版本。</p>
<h4 id="使用-37"><a class="header" href="#使用-37">使用</a></h4>
<pre><code>t9k delete-release &lt;name&gt; [--release=release-names...]
</code></pre>
<h4 id="选项-27"><a class="header" href="#选项-27">选项</a></h4>
<pre><code>--release string        字符串，删除的版本名称，如要删除多个版本，用 `,` 进行分割。
--dry-run               只打印更新后的 yaml 文件，但是不执行 apply 操作。
-o, --output string     字符串，指定 --dry-run 打印的格式。可选值有 `json`，`yaml`。
</code></pre>
<h4 id="全局选项-35"><a class="header" href="#全局选项-35">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-38"><a class="header" href="#示例-38">示例</a></h4>
<p>删除 Project demo 下的推理服务 maskdetection 的 foo 和 bar 两个已发布的版本：</p>
<pre><code>t9k delete-release maskdetection --release foo,bar -p demo
</code></pre>
<h2 id="mpijob-1"><a class="header" href="#mpijob-1">mpijob</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/jobs/mpijob.html">MPIJob</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>mj</code> 代替 <code>mpijob</code>。</p>
</aside>
<h3 id="delete-7"><a class="header" href="#delete-7">delete</a></h3>
<p>删除指定的 MPIJob。</p>
<h4 id="使用-38"><a class="header" href="#使用-38">使用</a></h4>
<pre><code>t9k mpijob delete [names...] [--all] [-f]
</code></pre>
<p><code>t9k mpijob delete</code> 也可以用 <code>t9k mj rm</code> 代替。</p>
<h4 id="选项-28"><a class="header" href="#选项-28">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 MPIJob。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-36"><a class="header" href="#全局选项-36">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-39"><a class="header" href="#示例-39">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 MPIJob：</p>
<pre><code>t9k mpijob delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 MPIJob：</p>
<pre><code>t9k mpijob delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 MPIJob：</p>
<pre><code>t9k mpijob delete foo -p demo --all
</code></pre>
<h3 id="describe-6"><a class="header" href="#describe-6">describe</a></h3>
<p>查看某个 MPIJob 的详细信息。</p>
<h4 id="使用-39"><a class="header" href="#使用-39">使用</a></h4>
<pre><code>t9k mj describe &lt;name&gt;
</code></pre>
<p><code>t9k mj describe</code> 也可以用 <code>t9k mj desc</code> 代替。</p>
<h4 id="全局选项-37"><a class="header" href="#全局选项-37">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-40"><a class="header" href="#示例-40">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 MPIJob 的详细描述：</p>
<pre><code>t9k mj describe foo -p demo
</code></pre>
<h3 id="get-6"><a class="header" href="#get-6">get</a></h3>
<p>查看 MPIJob 相关信息。</p>
<h4 id="使用-40"><a class="header" href="#使用-40">使用</a></h4>
<pre><code>t9k mj get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-29"><a class="header" href="#选项-29">选项</a></h4>
<pre><code>-A, --all-namespaces    获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string     指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`。
</code></pre>
<h4 id="全局选项-38"><a class="header" href="#全局选项-38">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-41"><a class="header" href="#示例-41">示例</a></h4>
<p>以默认格式查看 Project example 下所有 MPIJob：</p>
<pre><code>t9k mj get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 MPIJob：</p>
<pre><code>t9k mj get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 MPIJob：</p>
<pre><code>t9k mj get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 MPIJob：</p>
<pre><code>t9k mj get foo -p example -o yaml
</code></pre>
<h3 id="logs-4"><a class="header" href="#logs-4">logs</a></h3>
<p>查看 MPIJob 某个计算节点的日志。</p>
<h4 id="使用-41"><a class="header" href="#使用-41">使用</a></h4>
<pre><code>t9k mj logs [--type=launcher|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [-f] [--tail] [--timestamps]
</code></pre>
<h4 id="选项-30"><a class="header" href="#选项-30">选项</a></h4>
<pre><code>--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
-f, --follow            流式查看日志。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--tail int              整数，要查看的日志的行数（从后往前）。默认值：-1，查看全部日志。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `launcher` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-39"><a class="header" href="#全局选项-39">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-42"><a class="header" href="#示例-42">示例</a></h4>
<p>查看 Project example 下 MPIJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的日志：</p>
<pre><code>t9k mj logs foo --type=replicaType --index=replicaIndex -p example
</code></pre>
<p>流式查看 Project example 下 MPIJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的容器 <code>mnist</code> 的日志：</p>
<pre><code>t9k mj logs foo --type=replicaType --index=replicaIndex --container=mnist --follow
</code></pre>
<p>查看 MPIJob foo 第 0 个 worker 节点的最后 20 行日志：</p>
<pre><code>t9k mj logs foo --tail 20
</code></pre>
<h3 id="wait-5"><a class="header" href="#wait-5">wait</a></h3>
<p>等待 MPIJob 完成。</p>
<h4 id="使用-42"><a class="header" href="#使用-42">使用</a></h4>
<pre><code>t9k mj wait &lt;name&gt; [--timeout=&lt;timeoutTime&gt;] [--period=&lt;periodTime&gt;] [--print-log [--type=launcher|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [--timestamps]]
</code></pre>
<h4 id="选项-31"><a class="header" href="#选项-31">选项</a></h4>
<pre><code>--timeout string        字符串，最长等待时间。默认值：&quot;1h&quot;，1 小时。
--period  string        字符串，检查任务是否完成的周期。默认值：&quot;1s&quot;，每秒检查一次。
--print-log             是否在等待时流式查看日志。

以下参数只有在开启了 `--print-log` 后才生效。

--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `launcher` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-40"><a class="header" href="#全局选项-40">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-43"><a class="header" href="#示例-43">示例</a></h4>
<p>等待 Project example 下的 MPIJob foo 完成：</p>
<pre><code>t9k mj wait foo -p example
</code></pre>
<p>等待 Project example 下的 MPIJob foo 完成，只等待 10 分钟：</p>
<pre><code>t9k mj wait foo -p example --timeout 10m
</code></pre>
<p>等待 Project example 下的 MPIJob foo 完成，同时打印节点 launcher 的日志：</p>
<pre><code>t9k mj wait foo -p example --print-log --type launcher
</code></pre>
<h2 id="notebook-2"><a class="header" href="#notebook-2">notebook</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/building/notebook.html">Notebook</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>nb</code> 代替 <code>notebook</code>。</p>
</aside>
<h3 id="delete-8"><a class="header" href="#delete-8">delete</a></h3>
<p>删除指定的 Notebook。</p>
<h4 id="使用-43"><a class="header" href="#使用-43">使用</a></h4>
<pre><code>t9k notebook delete [names...] [--all] [-f]
</code></pre>
<p><code>t9k notebook delete</code> 也可以用 <code>t9k nb rm</code> 代替。</p>
<h4 id="选项-32"><a class="header" href="#选项-32">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 Notebook。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-41"><a class="header" href="#全局选项-41">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-44"><a class="header" href="#示例-44">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 Notebook：</p>
<pre><code>t9k notebook delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 Notebook：</p>
<pre><code>t9k notebook delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 Notebook：</p>
<pre><code>t9k notebook delete foo -p demo --all
</code></pre>
<h3 id="describe-7"><a class="header" href="#describe-7">describe</a></h3>
<p>查看某个 Notebook 的详细信息。</p>
<h4 id="使用-44"><a class="header" href="#使用-44">使用</a></h4>
<pre><code>t9k nb describe &lt;name&gt;
</code></pre>
<p><code>t9k nb describe</code> 也可以用 <code>t9k nb desc</code> 代替。</p>
<h4 id="选项-33"><a class="header" href="#选项-33">选项</a></h4>
<pre><code>--color                 使用彩色的输出信息（默认全是黑色）。
</code></pre>
<h4 id="全局选项-42"><a class="header" href="#全局选项-42">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-45"><a class="header" href="#示例-45">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 Notebook 的详细描述：</p>
<pre><code>t9k nb describe foo -p demo
</code></pre>
<h3 id="get-7"><a class="header" href="#get-7">get</a></h3>
<p>查看 Notebook 相关信息。</p>
<h4 id="使用-45"><a class="header" href="#使用-45">使用</a></h4>
<pre><code>t9k nb get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-34"><a class="header" href="#选项-34">选项</a></h4>
<pre><code>-A, --all-namespaces    获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string     字符串，指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`。
</code></pre>
<h4 id="全局选项-43"><a class="header" href="#全局选项-43">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-46"><a class="header" href="#示例-46">示例</a></h4>
<p>以默认格式查看 Project example 下所有 Notebook：</p>
<pre><code>t9k nb get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 Notebook：</p>
<pre><code>t9k nb get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 Notebook：</p>
<pre><code>t9k nb get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 Notebook：</p>
<pre><code>t9k nb get foo -p example -o yaml
</code></pre>
<h2 id="podgroup-1"><a class="header" href="#podgroup-1">podgroup</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/scheduling/podgroup.html">PodGroup</a>，只有集群管理员才有相关权限。</p>
<h3 id="get-8"><a class="header" href="#get-8">get</a></h3>
<p>查看 PodGroup 相关信息。</p>
<h4 id="使用-46"><a class="header" href="#使用-46">使用</a></h4>
<pre><code>t9k podgroup get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-35"><a class="header" href="#选项-35">选项</a></h4>
<pre><code>-A, --all-namespaces       获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string        指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`
</code></pre>
<h4 id="全局选项-44"><a class="header" href="#全局选项-44">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-47"><a class="header" href="#示例-47">示例</a></h4>
<p>以默认格式查看 Project example 下所有 PodGroup：</p>
<pre><code>t9k podgroup get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 PodGroup：</p>
<pre><code>t9k podgroup get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 PodGroup：</p>
<pre><code>t9k podgroup get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 PodGroup：</p>
<pre><code>t9k podgroup get foo -p example -o yaml
</code></pre>
<h2 id="project"><a class="header" href="#project">project</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/account-and-security.html#project">Project</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>proj</code> 代替 <code>project</code>。</p>
</aside>
<h3 id="create-1"><a class="header" href="#create-1">create</a></h3>
<p>创建新项目，只有集群管理员才有权限创建新项目。</p>
<h4 id="使用-47"><a class="header" href="#使用-47">使用</a></h4>
<pre><code>t9k project create &lt;name&gt; &lt;owner&gt; [--build] [--deploy]
</code></pre>
<h4 id="选项-36"><a class="header" href="#选项-36">选项</a></h4>
<pre><code>--build                 项目拥有者是否拥有模型构建权限
--deploy                项目拥有者是否拥有模型部署权限
</code></pre>
<h4 id="全局选项-45"><a class="header" href="#全局选项-45">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-48"><a class="header" href="#示例-48">示例</a></h4>
<p>创建一个名为 sample 的项目，管理员为 admin，且 admin 只有模型构建的权限，没有模型部署的权限：</p>
<pre><code>t9k project create sample admin --build
</code></pre>
<h3 id="describe-8"><a class="header" href="#describe-8">describe</a></h3>
<p>查看项目详细描述，只能查看当前用户所拥有的项目。</p>
<h4 id="使用-48"><a class="header" href="#使用-48">使用</a></h4>
<pre><code>t9k proj describe &lt;name&gt;
</code></pre>
<p><code>t9k proj describe</code> 也可以用 <code>t9k proj desc</code> 代替。</p>
<h4 id="全局选项-46"><a class="header" href="#全局选项-46">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-49"><a class="header" href="#示例-49">示例</a></h4>
<p>详细描述项目 demo：</p>
<pre><code>t9k proj describe demo
</code></pre>
<h3 id="get-9"><a class="header" href="#get-9">get</a></h3>
<p>查看项目的相关信息，只能查看用户拥有权限的项目。</p>
<h4 id="使用-49"><a class="header" href="#使用-49">使用</a></h4>
<pre><code>t9k project get [name...]
</code></pre>
<p>可以通过指定 name 获取一个或多个 project，不指定的话默认获取所有当前用户有权限的项目。</p>
<h4 id="全局选项-47"><a class="header" href="#全局选项-47">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-50"><a class="header" href="#示例-50">示例</a></h4>
<p>查看当前用户有权限的所有项目：</p>
<pre><code>t9k project get
</code></pre>
<p>查看当前用户有权限的项目中名为 foo 的项目：</p>
<pre><code>t9k project get foo
</code></pre>
<h2 id="pytorchtrainingjob-1"><a class="header" href="#pytorchtrainingjob-1">pytorchtrainingjob</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/jobs/pytorchtrainingjob.html">PyTorchTrainingJob</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>pj</code> 代替 <code>pytorchtrainingjob</code>。</p>
</aside>
<h3 id="delete-9"><a class="header" href="#delete-9">delete</a></h3>
<p>删除指定的 PyTorchTrainingJob。</p>
<h4 id="使用-50"><a class="header" href="#使用-50">使用</a></h4>
<pre><code>t9k pytorchtrainingjob delete [names...] [--all] [-f]
</code></pre>
<p><code>t9k pytorchtrainingjob delete</code> 也可以用 <code>t9k pj rm</code> 代替。</p>
<h4 id="选项-37"><a class="header" href="#选项-37">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 PyTorchTrainingJob。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-48"><a class="header" href="#全局选项-48">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-51"><a class="header" href="#示例-51">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 PyTorchTrainingJob：</p>
<pre><code>t9k pytorchtrainingjob delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 PyTorchTrainingJob：</p>
<pre><code>t9k pytorchtrainingjob delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 PyTorchTrainingJob：</p>
<pre><code>t9k pytorchtrainingjob delete foo -p demo --all
</code></pre>
<h3 id="describe-9"><a class="header" href="#describe-9">describe</a></h3>
<p>查看某个 PyTorchTrainingJob 的详细信息。</p>
<h4 id="使用-51"><a class="header" href="#使用-51">使用</a></h4>
<pre><code>t9k pj describe &lt;name&gt;
</code></pre>
<p><code>t9k pj describe</code> 也可以用 <code>t9k pj desc</code> 代替。</p>
<h4 id="全局选项-49"><a class="header" href="#全局选项-49">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-52"><a class="header" href="#示例-52">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 PyTorchTrainingJob 的详细描述：</p>
<pre><code>t9k pj describe foo -p demo
</code></pre>
<h3 id="get-10"><a class="header" href="#get-10">get</a></h3>
<p>查看 PyTorchTrainingJob 相关信息。</p>
<h4 id="使用-52"><a class="header" href="#使用-52">使用</a></h4>
<pre><code>t9k pj get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-38"><a class="header" href="#选项-38">选项</a></h4>
<pre><code>-A, --all-namespaces    获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string     指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`。
</code></pre>
<h4 id="全局选项-50"><a class="header" href="#全局选项-50">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-53"><a class="header" href="#示例-53">示例</a></h4>
<p>以默认格式查看 Project example 下所有 PyTorchTrainingJob：</p>
<pre><code>t9k pj get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 PyTorchTrainingJob：</p>
<pre><code>t9k pj get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 PyTorchTrainingJob：</p>
<pre><code>t9k pj get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 PyTorchTrainingJob：</p>
<pre><code>t9k pj get foo -p example -o yaml
</code></pre>
<h3 id="logs-5"><a class="header" href="#logs-5">logs</a></h3>
<p>查看 PyTorchTrainingJob 某个计算节点的日志。</p>
<h4 id="使用-53"><a class="header" href="#使用-53">使用</a></h4>
<pre><code>t9k pj logs [--type=master|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [-f] [--tail] [--timestamps]
</code></pre>
<h4 id="选项-39"><a class="header" href="#选项-39">选项</a></h4>
<pre><code>--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
-f, --follow            流式查看日志。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--tail int              整数，要查看的日志的行数（从后往前）。默认值：-1，查看全部日志。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `master` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-51"><a class="header" href="#全局选项-51">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-54"><a class="header" href="#示例-54">示例</a></h4>
<p>查看 Project example 下 PyTorchTrainingJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的日志：</p>
<pre><code>t9k pj logs foo --type=replicaType --index=replicaIndex -p example
</code></pre>
<p>流式查看 Project example 下 PyTorchTrainingJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的容器 <code>mnist</code> 的日志：</p>
<pre><code>t9k pj logs foo --type=replicaType --index=replicaIndex --container=mnist --follow
</code></pre>
<p>查看 PyTorchTrainingJob foo 第 0 个 worker 节点的最后 20 行日志：</p>
<pre><code>t9k pj logs foo --tail 20
</code></pre>
<h3 id="wait-6"><a class="header" href="#wait-6">wait</a></h3>
<p>等待 PyTorchTrainingJob 完成。</p>
<h4 id="使用-54"><a class="header" href="#使用-54">使用</a></h4>
<pre><code>t9k pj wait &lt;name&gt; [--timeout=&lt;timeoutTime&gt;] [--period=&lt;periodTime&gt;] [--print-log [--type=master|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [--timestamps]]
</code></pre>
<h4 id="选项-40"><a class="header" href="#选项-40">选项</a></h4>
<pre><code>--timeout string        字符串，最长等待时间。默认值：&quot;1h&quot;，1 小时。
--period  string        字符串，检查任务是否完成的周期。默认值：&quot;1s&quot;，每秒检查一次。
--print-log             是否在等待时流式查看日志。

以下参数只有在开启了 `--print-log` 后才生效。

--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `master` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-52"><a class="header" href="#全局选项-52">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-55"><a class="header" href="#示例-55">示例</a></h4>
<p>等待 Project example 下的 PyTorchTrainingJob foo 完成：</p>
<pre><code>t9k pj wait foo -p example
</code></pre>
<p>等待 Project example 下的 PyTorchTrainingJob foo 完成，只等待 10 分钟：</p>
<pre><code>t9k pj wait foo -p example --timeout 10m
</code></pre>
<p>等待 Project example 下的 PyTorchTrainingJob foo 完成，同时打印节点 master-0 的日志：</p>
<pre><code>t9k pj wait foo -p example --print-log --type master --index 0
</code></pre>
<h2 id="queue"><a class="header" href="#queue">queue</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/scheduling/queue.html">Queue</a>，只有集群管理员才有相关权限。</p>
<h3 id="close"><a class="header" href="#close">close</a></h3>
<p>关闭 Queue。</p>
<h4 id="使用-55"><a class="header" href="#使用-55">使用</a></h4>
<pre><code>t9k queue close &lt;name&gt;
</code></pre>
<h4 id="全局选项-53"><a class="header" href="#全局选项-53">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-56"><a class="header" href="#示例-56">示例</a></h4>
<p>关闭 Queue foo：</p>
<pre><code>t9k queue close foo
</code></pre>
<h3 id="get-11"><a class="header" href="#get-11">get</a></h3>
<p>查看 Queue 相关信息。</p>
<h4 id="使用-56"><a class="header" href="#使用-56">使用</a></h4>
<pre><code>t9k queue get [names...] [-o json|yaml|template]
</code></pre>
<h4 id="选项-41"><a class="header" href="#选项-41">选项</a></h4>
<pre><code>-o, --output string        指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`
</code></pre>
<h4 id="全局选项-54"><a class="header" href="#全局选项-54">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-57"><a class="header" href="#示例-57">示例</a></h4>
<p>以默认格式查看所有 Queue：</p>
<pre><code>t9k queue get
</code></pre>
<p>以默认格式查看名为 foo 和 bar 的两个 Queue：</p>
<pre><code>t9k queue get foo bar
</code></pre>
<p>以 yaml 格式查看名为 foo 的 Queue：</p>
<pre><code>t9k queue get foo -o yaml
</code></pre>
<h3 id="open"><a class="header" href="#open">open</a></h3>
<p>打开 Queue。</p>
<h4 id="使用-57"><a class="header" href="#使用-57">使用</a></h4>
<pre><code>t9k queue open &lt;name&gt;
</code></pre>
<h4 id="全局选项-55"><a class="header" href="#全局选项-55">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-58"><a class="header" href="#示例-58">示例</a></h4>
<p>打开 Queue foo：</p>
<pre><code>t9k queue open foo
</code></pre>
<h2 id="simplemlservice-1"><a class="header" href="#simplemlservice-1">simplemlservice</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/deployment/simplemlservice.html">SimpleMLService</a></p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>smls</code> 代替 <code>simplemlservice</code>。</p>
</aside>
<h3 id="create-2"><a class="header" href="#create-2">create</a></h3>
<p>创建一个新的 SimpleMLService。</p>
<h4 id="使用-58"><a class="header" href="#使用-58">使用</a></h4>
<pre><code>t9k simplemlservice create &lt;name&gt; --model=&lt;model-url&gt;  -image=&lt;serving-image&gt; [--secret=&lt;serect-name&gt;] [--tech tensorflow|pytorch|xgboost] [--dry-run] [-o yaml|json]
</code></pre>
<h4 id="选项-42"><a class="header" href="#选项-42">选项</a></h4>
<pre><code>--model string          字符串，推理服务使用的模型地址
--image string          字符串，推理服务使用的镜像
--dry-run               只打印更新后的 yaml 文件，但是不执行 apply 操作。
-o, --output string     字符串，指定 --dry-run 打印的格式。可选值有 `json`，`yaml`。
--tech string           字符串，推理服务使用的机器学习框架，如果 image 中已经含有关键字，可不填此参数。可选值有 `tensorflow`，`pytorch`，`xgboost`。
--secret string         字符串，加载模型所使用的密钥名称
</code></pre>
<h4 id="全局选项-56"><a class="header" href="#全局选项-56">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-59"><a class="header" href="#示例-59">示例</a></h4>
<p>在 Project demo 下创建一个名为 mnist 的推理服务。其使用的镜像为<code>registry.tensorstack.dev/t9kmirror/tensorflow-serving:1.15.0</code>，模型地址为 <code>mms://aihub.tensorstack.dev/t9kpublic/mnist:v1</code>：</p>
<pre><code>t9k simplemlservice create mnist \
  --model=&quot;mms://aihub.tensorstack.dev/t9kpublic/mnist:v1&quot; \
  --image=&quot;registry.tensorstack.dev/t9kmirror/tensorflow-serving:1.15.0&quot; \
  -n demo
</code></pre>
<p>在 Project t9k-sample 下创建一个名为 mnist-cnn 的推理服务。其使用的镜像为<code>registry.tensorstack.dev/t9kmirror/tensorflow-serving:1.15.0</code>，模型地址为 <code>mms://aihub.tensorstack.dev/private/mnist:v2</code>，模型下载使用的密钥为同一个 Project demo 下的 secret <code>mms-access</code>：</p>
<pre><code>t9k mls create mnist-cnn \
  --project=t9k-sample \
  --model=&quot;mms://aihub.tensorstack.dev/private/mnist:v2&quot; \
  --image=&quot;registry.tensorstack.dev/t9kmirror/tensorflow-serving:1.15.0&quot; \
  --tech=&quot;tensorflow&quot; \
  --secret=&quot;mms-access&quot; 
</code></pre>
<h3 id="delete-10"><a class="header" href="#delete-10">delete</a></h3>
<p>删除指定的 SimpleMLService。</p>
<h4 id="使用-59"><a class="header" href="#使用-59">使用</a></h4>
<pre><code>t9k smls delete [names...] [-f] [--all]
</code></pre>
<p><code>t9k smls delete</code> 也可以用 <code>t9k smls rm</code> 代替。</p>
<h4 id="选项-43"><a class="header" href="#选项-43">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 XGBoostTrainingJob。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-57"><a class="header" href="#全局选项-57">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-60"><a class="header" href="#示例-60">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 SimpleMLService：</p>
<pre><code>t9k smls delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 SimpleMLService：</p>
<pre><code>t9k smls delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 SimpleMLService：</p>
<pre><code>t9k smls delete foo -p demo --all
</code></pre>
<h3 id="describe-10"><a class="header" href="#describe-10">describe</a></h3>
<p>查看 SimpleMLService 详细信息。</p>
<h4 id="使用-60"><a class="header" href="#使用-60">使用</a></h4>
<pre><code>t9k mls describe &lt;name&gt;
</code></pre>
<h4 id="全局选项-58"><a class="header" href="#全局选项-58">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-61"><a class="header" href="#示例-61">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 SimpleMLService 的详细描述：</p>
<pre><code>t9k mls describe foo -p demo
</code></pre>
<h3 id="get-12"><a class="header" href="#get-12">get</a></h3>
<p>查看 SimpleMLService 相关信息。</p>
<h4 id="使用-61"><a class="header" href="#使用-61">使用</a></h4>
<pre><code>t9k smls get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-44"><a class="header" href="#选项-44">选项</a></h4>
<pre><code>-A, --all-namespaces       获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string        指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`
</code></pre>
<h4 id="全局选项-59"><a class="header" href="#全局选项-59">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-62"><a class="header" href="#示例-62">示例</a></h4>
<p>以默认格式查看 Project example 下所有 SimpleMLService：</p>
<pre><code>t9k smls get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 SimpleMLService：</p>
<pre><code>t9k smls get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 SimpleMLService：</p>
<pre><code>t9k smls get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 SimpleMLService：</p>
<pre><code>t9k smls get foo -p example -o yaml
</code></pre>
<h2 id="tensorflowtrainingjob-1"><a class="header" href="#tensorflowtrainingjob-1">tensorflowtrainingjob</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/jobs/tensorflowtrainingjob.html">TensorFlowTrainingJob</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>tj</code> 代替 <code>tensorflowtrainingjob</code>。</p>
</aside>
<h3 id="delete-11"><a class="header" href="#delete-11">delete</a></h3>
<p>删除指定的 TensorFlowTrainingJob。</p>
<h4 id="使用-62"><a class="header" href="#使用-62">使用</a></h4>
<pre><code>t9k tensorflowtrainingjob delete [names...] [--all] [-f]
</code></pre>
<p><code>t9k tensorflowtrainingjob delete</code> 也可以用 <code>t9k tj rm</code> 代替。</p>
<h4 id="选项-45"><a class="header" href="#选项-45">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 TensorFlowTrainingJob。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-60"><a class="header" href="#全局选项-60">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-63"><a class="header" href="#示例-63">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 TensorFlowTrainingJob：</p>
<pre><code>t9k tensorflowtrainingjob delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 TensorFlowTrainingJob：</p>
<pre><code>t9k tensorflowtrainingjob delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 TensorFlowTrainingJob：</p>
<pre><code>t9k tensorflowtrainingjob delete foo -p demo --all
</code></pre>
<h3 id="describe-11"><a class="header" href="#describe-11">describe</a></h3>
<p>查看某个 TensorFlowTrainingJob 的详细信息。</p>
<h4 id="使用-63"><a class="header" href="#使用-63">使用</a></h4>
<pre><code>t9k tj describe &lt;name&gt;
</code></pre>
<p><code>t9k tj describe</code> 也可以用 <code>t9k tj desc</code> 代替。</p>
<h4 id="全局选项-61"><a class="header" href="#全局选项-61">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-64"><a class="header" href="#示例-64">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 TensorFlowTrainingJob 的详细描述：</p>
<pre><code>t9k tj describe foo -p demo
</code></pre>
<h3 id="get-13"><a class="header" href="#get-13">get</a></h3>
<p>查看 TensorFlowTrainingJob 相关信息。</p>
<h4 id="使用-64"><a class="header" href="#使用-64">使用</a></h4>
<pre><code>t9k tj get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-46"><a class="header" href="#选项-46">选项</a></h4>
<pre><code>-A, --all-namespaces    获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string     字符串，指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`。
</code></pre>
<h4 id="全局选项-62"><a class="header" href="#全局选项-62">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-65"><a class="header" href="#示例-65">示例</a></h4>
<p>以默认格式查看 Project example 下所有 TensorFlowTrainingJob：</p>
<pre><code>t9k tj get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 TensorFlowTrainingJob：</p>
<pre><code>t9k tj get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 TensorFlowTrainingJob：</p>
<pre><code>t9k tj get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 TensorFlowTrainingJob：</p>
<pre><code>t9k tj get foo -p example -o yaml
</code></pre>
<h3 id="logs-6"><a class="header" href="#logs-6">logs</a></h3>
<p>查看 TensorFlowTrainingJob 某个计算节点的日志。</p>
<h4 id="使用-65"><a class="header" href="#使用-65">使用</a></h4>
<pre><code>t9k tj logs &lt;name&gt; [--type=chief|ps|evaluator|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [-f] [--tail] [--timestamps]
</code></pre>
<h4 id="选项-47"><a class="header" href="#选项-47">选项</a></h4>
<pre><code>--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
-f, --follow            流式查看日志。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--tail int              整数，要查看的日志的行数（从后往前）。默认值：-1，查看全部日志。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `chief`，`ps`，`evaluator` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-63"><a class="header" href="#全局选项-63">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-66"><a class="header" href="#示例-66">示例</a></h4>
<p>查看 Project example 下 TensorFlowTrainingJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的日志：</p>
<pre><code>t9k tj logs foo --type=replicaType --index=replicaIndex -p example
</code></pre>
<p>流式查看 Project example 下 TensorFlowTrainingJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的容器 <code>mnist</code> 的日志：</p>
<pre><code>t9k tj logs foo --type=replicaType --index=replicaIndex --container=mnist --follow
</code></pre>
<p>查看 TensorFlowTrainingJob foo 第 0 个 worker 节点的最后 20 行日志：</p>
<pre><code>t9k tj logs foo --tail 20
</code></pre>
<h3 id="wait-7"><a class="header" href="#wait-7">wait</a></h3>
<p>等待 TensorFlowTrainingJob 完成。</p>
<h4 id="使用-66"><a class="header" href="#使用-66">使用</a></h4>
<pre><code>t9k tj wait &lt;name&gt; [--timeout=&lt;timeoutTime&gt;] [--period=&lt;periodTime&gt;] [--print-log [--type=chief|ps|evaluator|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [--timestamps]]
</code></pre>
<h4 id="选项-48"><a class="header" href="#选项-48">选项</a></h4>
<pre><code>--timeout string        字符串，最长等待时间。默认值：&quot;1h&quot;，1 小时。
--period  string        字符串，检查任务是否完成的周期。默认值：&quot;1s&quot;，每秒检查一次。
--print-log             是否在等待时流式查看日志。

以下参数只有在开启了 `--print-log` 后才生效。

--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `chief`，`ps`，`evaluator` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-64"><a class="header" href="#全局选项-64">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-67"><a class="header" href="#示例-67">示例</a></h4>
<p>等待 Project example 下的 TensorFlowTrainingJob foo 完成：</p>
<pre><code>t9k tj wait foo -p example
</code></pre>
<p>等待 Project example 下的 TensorFlowTrainingJob foo 完成，只等待 10 分钟：</p>
<pre><code>t9k tj wait foo -p example --timeout 10m
</code></pre>
<p>等待 Project example 下的 TensorFlowTrainingJob foo 完成，同时打印节点 chief-0 的日志：</p>
<pre><code>t9k tj wait foo -p example --print-log --type chief --index 0
</code></pre>
<h2 id="version"><a class="header" href="#version">version</a></h2>
<p>查看当前 T9k CLI 版本信息。</p>
<h4 id="使用-67"><a class="header" href="#使用-67">使用</a></h4>
<pre><code>t9k version
</code></pre>
<h4 id="示例-68"><a class="header" href="#示例-68">示例</a></h4>
<p>查看当前 t9k 二进制文件的版本信息。</p>
<pre><code>t9k version
</code></pre>
<h2 id="workflowrun-1"><a class="header" href="#workflowrun-1">workflowrun</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/workflows/workflowrun.html">WorkflowRun</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>wr</code> 代替 <code>workflowrun</code>。</p>
</aside>
<h3 id="delete-12"><a class="header" href="#delete-12">delete</a></h3>
<p>删除指定的 WorkflowRun。</p>
<h4 id="使用-68"><a class="header" href="#使用-68">使用</a></h4>
<pre><code>t9k workflowrun delete [names...] [--all] [-f]
</code></pre>
<p><code>t9k workflowrun delete</code> 也可以用 <code>t9k wr rm</code> 代替。</p>
<h4 id="选项-49"><a class="header" href="#选项-49">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 WorkflowRun。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-65"><a class="header" href="#全局选项-65">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-69"><a class="header" href="#示例-69">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 WorkflowRun：</p>
<pre><code>t9k workflowrun delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 WorkflowRun：</p>
<pre><code>t9k workflowrun delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 WorkflowRun：</p>
<pre><code>t9k workflowrun delete foo -p demo --all
</code></pre>
<h3 id="describe-12"><a class="header" href="#describe-12">describe</a></h3>
<p>查看某个 WorkflowRun 的详细信息。</p>
<h4 id="使用-69"><a class="header" href="#使用-69">使用</a></h4>
<pre><code>t9k wr describe &lt;name&gt;
</code></pre>
<p><code>t9k wr describe</code> 也可以用 <code>t9k wr desc</code> 代替。</p>
<h4 id="选项-50"><a class="header" href="#选项-50">选项</a></h4>
<pre><code>--color                 使用彩色的输出信息（默认全是黑色）。
</code></pre>
<h4 id="全局选项-66"><a class="header" href="#全局选项-66">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-70"><a class="header" href="#示例-70">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 WorkflowRun 的详细描述：</p>
<pre><code>t9k wr describe foo -p demo
</code></pre>
<h3 id="get-14"><a class="header" href="#get-14">get</a></h3>
<p>查看 WorkflowRun 相关信息。</p>
<h4 id="使用-70"><a class="header" href="#使用-70">使用</a></h4>
<pre><code>t9k wr get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-51"><a class="header" href="#选项-51">选项</a></h4>
<pre><code>-A, --all-namespaces    获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string     字符串，指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`。
</code></pre>
<h4 id="全局选项-67"><a class="header" href="#全局选项-67">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-71"><a class="header" href="#示例-71">示例</a></h4>
<p>以默认格式查看 Project example 下所有 WorkflowRun：</p>
<pre><code>t9k wr get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 WorkflowRun：</p>
<pre><code>t9k wr get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 WorkflowRun：</p>
<pre><code>t9k wr get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 WorkflowRun：</p>
<pre><code>t9k wr get foo -p example -o yaml
</code></pre>
<h3 id="logs-7"><a class="header" href="#logs-7">logs</a></h3>
<p>查看 WorkflowRun 某个容器的日志，不支持直接查看 DAG 类型的 WorkflowRun 的日志。</p>
<h4 id="使用-71"><a class="header" href="#使用-71">使用</a></h4>
<pre><code>t9k wr logs [--container=&lt;containerName&gt;] [-f] [--tail] [--timestamps]
</code></pre>
<h4 id="选项-52"><a class="header" href="#选项-52">选项</a></h4>
<pre><code>--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
-f, --follow            流式查看日志。
--tail int              整数，要查看的日志的行数（从后往前）。默认值：-1，查看全部日志。
--timestamps            是否展示时间戳。
</code></pre>
<h4 id="全局选项-68"><a class="header" href="#全局选项-68">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-72"><a class="header" href="#示例-72">示例</a></h4>
<p>查看 Project demo 下 WorkflowRun foo 唯一容器的日志：</p>
<pre><code>t9k wr logs foo -p demo
</code></pre>
<p>流式查看 Project demo 下 WorkflowRun foo 容器 mnist 的日志：</p>
<pre><code>t9k wr logs foo --container=mnist -p demo -f
</code></pre>
<p>查看 Project demo 下 WorkflowRun foo 唯一容器的最后 20 行日志：</p>
<pre><code>t9k wr logs foo -p demo --tail=20
</code></pre>
<h3 id="wait-8"><a class="header" href="#wait-8">wait</a></h3>
<p>等待 WorkflowRun 完成，该命令不支持 DAG 类型的 WorkflowRun。</p>
<h4 id="使用-72"><a class="header" href="#使用-72">使用</a></h4>
<pre><code>t9k wr wait &lt;name&gt; [--timeout=&lt;timeoutTime&gt;] [--period=&lt;periodTime&gt;] [--print-log [--container=&lt;containerName&gt;] [--timestamps]]
</code></pre>
<h4 id="选项-53"><a class="header" href="#选项-53">选项</a></h4>
<pre><code>--timeout string        字符串，最长等待时间。默认值：&quot;1h&quot;，1 小时。
--period  string        字符串，检查任务是否完成的周期。默认值：&quot;1s&quot;，每秒检查一次。
--print-log             是否在等待时流式查看日志。

以下参数只有在开启了 `--print-log` 后才生效。

--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
--timestamps            是否展示时间戳。
</code></pre>
<h4 id="全局选项-69"><a class="header" href="#全局选项-69">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-73"><a class="header" href="#示例-73">示例</a></h4>
<p>等待 Project example 下的 WorkflowRun foo 完成：</p>
<pre><code>t9k wr wait foo -p example
</code></pre>
<p>等待 Project example 下的 WorkflowRun foo 完成，只等待 10 分钟：</p>
<pre><code>t9k wr wait foo -p example --timeout 10m
</code></pre>
<p>等待 Project example 下的 WorkflowRun foo 完成，同时打印其容器 mnist 的日志：</p>
<pre><code>t9k wr wait foo -p example --print-log --container mnist
</code></pre>
<h2 id="workflowtemplate-1"><a class="header" href="#workflowtemplate-1">workflowtemplate</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/workflows/workflowtemplate.html">WorkflowTemplate</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>wt</code> 代替 <code>workflowtemplate</code>。</p>
</aside>
<h3 id="delete-13"><a class="header" href="#delete-13">delete</a></h3>
<p>删除指定的 WorkflowTemplate。</p>
<h4 id="使用-73"><a class="header" href="#使用-73">使用</a></h4>
<pre><code>t9k workflowtemplate delete [names...] [--all] [-f]
</code></pre>
<p><code>t9k workflowtemplate delete</code> 也可以用 <code>t9k wr rm</code> 代替。</p>
<h4 id="选项-54"><a class="header" href="#选项-54">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 WorkflowTemplate。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-70"><a class="header" href="#全局选项-70">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-74"><a class="header" href="#示例-74">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 WorkflowTemplate：</p>
<pre><code>t9k workflowtemplate delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 WorkflowTemplate：</p>
<pre><code>t9k workflowtemplate delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 WorkflowTemplate：</p>
<pre><code>t9k workflowtemplate delete foo -p demo --all
</code></pre>
<h3 id="describe-13"><a class="header" href="#describe-13">describe</a></h3>
<p>查看某个 WorkflowTemplate 的详细信息。</p>
<h4 id="使用-74"><a class="header" href="#使用-74">使用</a></h4>
<pre><code>t9k wt describe &lt;name&gt;
</code></pre>
<p><code>t9k wt describe</code> 也可以用 <code>t9k wt desc</code> 代替。</p>
<h4 id="选项-55"><a class="header" href="#选项-55">选项</a></h4>
<pre><code>--color                 使用彩色的输出信息（默认全是黑色）。
</code></pre>
<h4 id="全局选项-71"><a class="header" href="#全局选项-71">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-75"><a class="header" href="#示例-75">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 WorkflowTemplate 的详细描述：</p>
<pre><code>t9k wt describe foo -p demo
</code></pre>
<h3 id="get-15"><a class="header" href="#get-15">get</a></h3>
<p>查看 WorkflowTemplate 相关信息。</p>
<h4 id="使用-75"><a class="header" href="#使用-75">使用</a></h4>
<pre><code>t9k wt get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-56"><a class="header" href="#选项-56">选项</a></h4>
<pre><code>-A, --all-namespaces    获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string     字符串，指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`。
</code></pre>
<h4 id="全局选项-72"><a class="header" href="#全局选项-72">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-76"><a class="header" href="#示例-76">示例</a></h4>
<p>以默认格式查看 Project example 下所有 WorkflowTemplate：</p>
<pre><code>t9k wt get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 WorkflowTemplate：</p>
<pre><code>t9k wt get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 WorkflowTemplate：</p>
<pre><code>t9k wt get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 WorkflowTemplate：</p>
<pre><code>t9k wt get foo -p example -o yaml
</code></pre>
<h3 id="start"><a class="header" href="#start">start</a></h3>
<p>执行 WorkflowTemplate。</p>
<h4 id="使用-76"><a class="header" href="#使用-76">使用</a></h4>
<pre><code>t9k wt start &lt;name&gt; [-l &lt;labelStrings&gt;] [-r &lt;paramStrings&gt;] [-s &lt;serviceAccount&gt;] [--timeout=&lt;timeoutTime&gt;] [-w &lt;workplaceStrings&gt;] [--use-param-defaults] [--dry-run] [-o yaml|json]
</code></pre>
<h4 id="选项-57"><a class="header" href="#选项-57">选项</a></h4>
<pre><code>-l, --label strings          以键值对的方式指定 workflowRun 的 label。例如 -l &quot;LABEL_1=VAL_1,LABEL_2=VAL_2&quot;。
-r, --param strings          以键值对的方式指定 workflowRun 的参数。例如 -l &quot;KEY_1=VAL_1,KEY_2=VAL_2&quot;。
-w, --workspace strings      以键值对的方式指定 workspace 相关信息。例如 -w &quot;name=$workspace_name,type=$workspace_type,$key$value&quot;。
--use-param-defaults         是否采用默认参数
--timeout string             字符串，指定 workflowRun 的超时时间。
--dry-run                    只打印更新后的 yaml 文件，但是不执行 apply 操作。
-o, --output string          指定 --dry-run 打印的格式。可选值有 `json`，`yaml`。
-s, --serviceaccount string  指定 workflowRun 的 serviceAccount。
</code></pre>
<h4 id="全局选项-73"><a class="header" href="#全局选项-73">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-77"><a class="header" href="#示例-77">示例</a></h4>
<p>执行 Project demo 下的 WorkflowTemplate foo：</p>
<pre><code>t9k wt start foo -p demo
</code></pre>
<p>根据指定的 workspace 信息执行 Project demo 下的 WorkflowTemplate foo：</p>
<pre><code>t9k wt start foo --workspace=name=bar,type=pvc,claimName=bar-pvc,subPath=/user/local/Document -p demo
</code></pre>
<p>执行 Project demo 下的 WorkflowTemplate foo，并设置参数 bar 值为 hello：</p>
<pre><code>t9k wt start foo --param=bar=hello
</code></pre>
<h2 id="xgboosttrainingjob-1"><a class="header" href="#xgboosttrainingjob-1">xgboosttrainingjob</a></h2>
<p>用于管理 <a href="tools/cli-t9k/../../modules/jobs/xgboosttrainingjob.html">XGBoostTrainingJob</a>。</p>
<aside class="note info">
<div class="title">信息</div>
<p>支持使用缩写 <code>xj</code> 代替 <code>xgboosttrainingjob</code>。</p>
</aside>
<h3 id="delete-14"><a class="header" href="#delete-14">delete</a></h3>
<p>删除指定的 XGBoostTrainingJob。</p>
<h4 id="使用-77"><a class="header" href="#使用-77">使用</a></h4>
<pre><code>t9k xgboosttrainingjob delete [names...] [--all] [-f]
</code></pre>
<p><code>t9k xgboosttrainingjob delete</code> 也可以用 <code>t9k xj rm</code> 代替。</p>
<h4 id="选项-58"><a class="header" href="#选项-58">选项</a></h4>
<pre><code>--all                   删除当前 Project 中所有的 XGBoostTrainingJob。
-f, --force             跳过确认，直接执行删除操作。
</code></pre>
<h4 id="全局选项-74"><a class="header" href="#全局选项-74">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-78"><a class="header" href="#示例-78">示例</a></h4>
<p>删除 Project demo 下名为 foo 和 bar 的两个 XGBoostTrainingJob：</p>
<pre><code>t9k xgboosttrainingjob delete foo bar -p demo
</code></pre>
<p>跳过确认，直接删除 Project demo 下名为 foo 的 XGBoostTrainingJob：</p>
<pre><code>t9k xgboosttrainingjob delete foo -p demo -f
</code></pre>
<p>删除 Project demo 下所有的 XGBoostTrainingJob：</p>
<pre><code>t9k xgboosttrainingjob delete foo -p demo --all
</code></pre>
<h3 id="describe-14"><a class="header" href="#describe-14">describe</a></h3>
<p>查看某个 XGBoostTrainingJob 的详细信息。</p>
<h4 id="使用-78"><a class="header" href="#使用-78">使用</a></h4>
<pre><code>t9k xj describe &lt;name&gt;
</code></pre>
<p><code>t9k xj describe</code> 也可以用 <code>t9k xj desc</code> 代替。</p>
<h4 id="全局选项-75"><a class="header" href="#全局选项-75">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-79"><a class="header" href="#示例-79">示例</a></h4>
<p>查看 Project demo 下名为 foo 的 XGBoostTrainingJob 的详细描述：</p>
<pre><code>t9k xj describe foo -p demo
</code></pre>
<h3 id="get-16"><a class="header" href="#get-16">get</a></h3>
<p>查看 XGBoostTrainingJob 相关信息。</p>
<h4 id="使用-79"><a class="header" href="#使用-79">使用</a></h4>
<pre><code>t9k xj get [names...] [-A] [-o json|yaml|template]
</code></pre>
<h4 id="选项-59"><a class="header" href="#选项-59">选项</a></h4>
<pre><code>-A, --all-namespaces    获取用户具有权限的所有 Namespace（Project）中的资源。
-o, --output string     字符串，指定输出信息的形式。可选值有 `json`，`yaml` 和默认的 `template`。
</code></pre>
<h4 id="全局选项-76"><a class="header" href="#全局选项-76">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-80"><a class="header" href="#示例-80">示例</a></h4>
<p>以默认格式查看 Project example 下所有 XGBoostTrainingJob：</p>
<pre><code>t9k xj get -p example
</code></pre>
<p>以默认格式查看所有 Project 下的所有 XGBoostTrainingJob：</p>
<pre><code>t9k xj get -A
</code></pre>
<p>以默认格式查看 Project example 下名为 foo 和 bar 的两个 XGBoostTrainingJob：</p>
<pre><code>t9k xj get foo bar -p example
</code></pre>
<p>以 yaml 格式查看 Project example 下名为 foo 的 XGBoostTrainingJob：</p>
<pre><code>t9k xj get foo -p example -o yaml
</code></pre>
<h3 id="logs-8"><a class="header" href="#logs-8">logs</a></h3>
<p>查看 XGBoostTrainingJob 某个计算节点的日志。</p>
<h4 id="使用-80"><a class="header" href="#使用-80">使用</a></h4>
<pre><code>t9k xj logs [--type=master|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [-f] [--tail] [--timestamps]
</code></pre>
<h4 id="选项-60"><a class="header" href="#选项-60">选项</a></h4>
<pre><code>--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
-f, --follow            流式查看日志。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--tail int              整数，要查看的日志的行数（从后往前）。默认值：-1，查看全部日志。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `master` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-77"><a class="header" href="#全局选项-77">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-81"><a class="header" href="#示例-81">示例</a></h4>
<p>查看 Project example 下 XGBoostTrainingJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的日志：</p>
<pre><code>t9k xj logs foo --type=replicaType --index=replicaIndex -p example
</code></pre>
<p>流式查看 Project example 下 XGBoostTrainingJob foo 第 <code>replicaIndex</code> 个 <code>replicaType</code> 节点的容器 <code>mnist</code> 的日志：</p>
<pre><code>t9k xj logs foo --type=replicaType --index=replicaIndex --container=mnist --follow
</code></pre>
<p>查看 XGBoostTrainingJob foo 第 0 个 worker 节点的最后 20 行日志：</p>
<pre><code>t9k xj logs foo --tail 20
</code></pre>
<h3 id="wait-9"><a class="header" href="#wait-9">wait</a></h3>
<p>等待 XGBoostTrainingJob 完成。</p>
<h4 id="使用-81"><a class="header" href="#使用-81">使用</a></h4>
<pre><code>t9k xj wait &lt;name&gt; [--timeout=&lt;timeoutTime&gt;] [--period=&lt;periodTime&gt;] [--print-log [--type=master|worker] [--index=&lt;replicaIndex&gt;] [--container=&lt;containerName&gt;] [--timestamps]]
</code></pre>
<h4 id="选项-61"><a class="header" href="#选项-61">选项</a></h4>
<pre><code>--timeout string        字符串，最长等待时间。默认值：&quot;1h&quot;，1 小时。
--period  string        字符串，检查任务是否完成的周期。默认值：&quot;1s&quot;，每秒检查一次。
--print-log             是否在等待时流式查看日志。

以下参数只有在开启了 `--print-log` 后才生效。

--container string      字符串，指定要查看的 container 名称，如果计算节点的 container 不止 1 个，必须指定此项。
--index string          字符串，要查看的计算节点的序号。默认值：0。
--timestamps            是否展示时间戳。
--type string           字符串，要查看的计算节点的角色。可选值有 `master` 以及默认值 `worker`。
</code></pre>
<h4 id="全局选项-78"><a class="header" href="#全局选项-78">全局选项</a></h4>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-x, --context           字符串，指定使用 T9k Config 中的哪一个 Context，在未设置这个参数时，会使用 T9k Config 中 `current-context` 字段指定的 Context。
-h, --help              查看当前指令的帮助信息和示例。
-p, --project           字符串，指定使用的项目（本文档中的项目和命名空间同义）。
-n, --namespace         字符串，和 `-p, --project` 作用一致，指定使用的项目。这个设计是为了符合 kubectl 用户的习惯。
-v, --verbose           指定输出 log 信息的详细程度。
</code></pre>
<h4 id="示例-82"><a class="header" href="#示例-82">示例</a></h4>
<p>等待 Project example 下的 XGBoostTrainingJob foo 完成：</p>
<pre><code>t9k xj wait foo -p example
</code></pre>
<p>等待 Project example 下的 XGBoostTrainingJob foo 完成，只等待 10 分钟：</p>
<pre><code>t9k xj wait foo -p example --timeout 10m
</code></pre>
<p>等待 Project example 下的 XGBoostTrainingJob foo 完成，同时打印节点 master-0 的日志：</p>
<pre><code>t9k xj wait foo -p example --print-log --type master --index 0
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="命令行工具t9k-pf"><a class="header" href="#命令行工具t9k-pf">命令行工具：t9k-pf</a></h1>
<p>TensorStack AI 平台提供了命令行工具 t9k-pf，其功能类似于 <code>kubectl port-forward</code>，使用户能够在本地通过端口转发的方式访问 TensorStack AI 平台的各种资源。目前支持的资源类型有 Notebook、Pod、Service。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="用户指南-1"><a class="header" href="#用户指南-1">用户指南</a></h1>
<h2 id="下载安装-1"><a class="header" href="#下载安装-1">下载安装</a></h2>
<h3 id="下载-1"><a class="header" href="#下载-1">下载</a></h3>
<p>t9k-pf 可以从平台首页下载。请根据操作系统和架构（可以在命令行运行 <code>uname -om</code> 获取）选择适当的版本。</p>
<h3 id="安装-1"><a class="header" href="#安装-1">安装</a></h3>
<p>根据下载的版本，设置 t9k-pf 的版本和系统架构等变量：</p>
<pre><code class="language-bash">version=0.2.6
os=darwin
arch=amd64
</code></pre>
<p>然后解压下载好的 t9k-pf，并把得到的二进制文件移动到 <code>/usr/local/bin</code> 路径下：</p>
<pre><code class="language-bash">tar -zxvf &quot;$HOME/Downloads/t9k-pf-$version-$os-$arch.tar.gz&quot;
mv t9k-pf-$os-$arch /usr/local/bin/t9k-pf
rm -f &quot;$HOME/Downloads/t9k-pf-$version-$os-$arch.tar.gz&quot;
</code></pre>
<p>安装完成后，运行以下命令来验证安装是否成功：</p>
<pre><code class="language-bash">t9k-pf version
</code></pre>
<h3 id="卸载-1"><a class="header" href="#卸载-1">卸载</a></h3>
<p>删除二进制文件即可卸载 t9k-pf。</p>
<pre><code class="language-bash">rm -f /usr/local/bin/t9k-pf
</code></pre>
<h2 id="身份认证和授权"><a class="header" href="#身份认证和授权">身份认证和授权</a></h2>
<h3 id="通过-t9k-config-进行身份认证和授权"><a class="header" href="#通过-t9k-config-进行身份认证和授权">通过 T9k Config 进行身份认证和授权</a></h3>
<p>t9k-pf 默认使用 <a href="tools/cli-t9k-pf/../tensorstack-cli/user-guide.html#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">T9k Config</a> 来进行身份认证和授权。你可以通过命令行参数 <code>-c, --config</code> 来指定 t9k-pf 使用的 T9k Config 文件的路径，未指定时，默认使用 <code>$HOME/.t9k/t9k-config.yaml</code> 路径下 T9k Config 中 current-context 的认证信息。</p>
<p>下面是一个 T9k Config 的示例，其中 current-context 为 <code>demo1</code>，该 Context 的 token 字段不为空，因此最终 t9k-pf 使用该值 <code>demo1-token</code> 来完成身份验证（如果 apikey 和 token 均不为空，t9k-pf 优先使用 apikey）。</p>
<pre><code class="language-yaml">current-context: demo1
contexts:
- name: demo1
  server: https://&lt;example.com&gt;
  image-registry: https://&lt;example.io&gt;
  prefixes:
    aistore: /t9k/aistore/server
    asset-hub: /t9k/asset-hub/server
    build-console: /t9k/build-console/server
    cluster-admin: /t9k/cluster-admin/server
    deploy-console: /t9k/deploy-console/server
    security-console: /t9k/security/server
    workflow-manager: /t9k/workflow/server
  auth:
    apikey: &quot;&quot;
    token: demo1-token
  extension:
    codepack:
      data-copy-image: &lt;your-image&gt;
- name: demo2
  server: https://&lt;example.com&gt;
  ...
</code></pre>
<h3 id="通过-api-key-进行临时身份认证和授权"><a class="header" href="#通过-api-key-进行临时身份认证和授权">通过 API Key 进行临时身份认证和授权</a></h3>
<p>t9k-pf 支持通过命令行参数 <code>-k,--apikey</code> 直接指定 API Key，完成单次端口转发的身份认证和授权。</p>
<p>例如输入以下指令（其中 <code>notebook &lt;URL&gt;</code> 会在<a href="tools/cli-t9k-pf/./commands.html">命令</a>中介绍，此处只用关注 <code>--apikey</code> 的使用）：</p>
<pre><code class="language-bash">t9k-pf notebook &lt;url&gt; --apikey
</code></pre>
<p>命令行会进入交互式输入界面，粘贴你的 API Key 再按下回车即可。</p>
<aside class="note">
<div class="title">注意</div>
<p>此方式指定的 API Key 不会被保存，认证信息只在这次端口转发中生效。</p>
</aside>
<h2 id="全局选项-79"><a class="header" href="#全局选项-79">全局选项</a></h2>
<ul>
<li>
<p><strong>-c, –config</strong></p>
<p>使用的 T9k Config 文件的路径。默认路径是 <code>$HOME/.t9k/t9k-config.yaml</code>。</p>
</li>
<li>
<p><strong>-k, –apikey</strong></p>
<p>开启交互式输入 API Key。</p>
</li>
<li>
<p><strong>-n, –namespace</strong> </p>
<p>使用的项目（命名空间）名称。</p>
</li>
<li>
<p><strong>-h, –help</strong> </p>
<p>查看当前指令的帮助信息和示例。</p>
</li>
<li>
<p><strong>–address</strong> </p>
<p>本地监听地址。默认为 <code>localhost</code>。</p>
</li>
<li>
<p><strong>–retryMaxTimes</strong> </p>
<p>整数，最大重试次数。默认为 <code>10</code>。</p>
</li>
<li>
<p><strong>–retryPeriod</strong> </p>
<p>整数，重试间隔时间（单位：秒）。默认为 <code>10</code>。</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="命令-1"><a class="header" href="#命令-1">命令</a></h1>
<h2 id="notebook-3"><a class="header" href="#notebook-3">notebook</a></h2>
<p>针对 TensorStack AI 平台的 Notebook 资源，我们提供了直接通过其 URL 地址获取 SSH 连接方式的功能。使用该命令，你不需要指定名称、命名空间等信息。关于 SSH 连接的详细内容请参阅<a href="tools/cli-t9k-pf/../../tasks/ssh-notebook.html">通过 SSH 连接远程使用 Notebook</a>。</p>
<h3 id="使用-82"><a class="header" href="#使用-82">使用</a></h3>
<pre><code class="language-bash">t9k-pf notebook &lt;url&gt; &lt;localPort&gt;
</code></pre>
<p>其中 <code>&lt;url&gt;</code> 代表地址栏中的地址，<code>&lt;localPort&gt;</code> 代表你指定的本地端口号（小于 1024 的本地端口需要管理员权限才可以绑定），如果不指定，会随机使用一个本地端口。</p>
<p><code>t9k-pf notebook</code> 也可以用 <code>t9k-pf nb</code> 代替。</p>
<aside class="note">
<div class="title">注意</div>
<p>为了方便用户快速连接 SSH，t9k-pf 命令行不支持指定 Notebook 资源的目标端口。如果你有相关需求，可以先获取 Notebook 对应的 Pod 资源，然后参照<a href="tools/cli-t9k-pf/commands.html#pod">访问 Pod</a> 来访问特定的目标端口。</p>
</aside>
<h3 id="全局选项-80"><a class="header" href="#全局选项-80">全局选项</a></h3>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-h, --help              查看当前指令的帮助信息和示例。
-n, --namespace         字符串，指定使用的项目（命名空间）名称。
-k, --apikey            开启交互式输入 API Key。
--address               本地监听地址。默认为 `localhost`。
--retryMaxTimes         整数，最大重试次数。默认为 `10`。
--retryPeriod           整数，重试间隔时间（单位：秒）。默认为 `10`。
</code></pre>
<h3 id="示例-83"><a class="header" href="#示例-83">示例</a></h3>
<p>通过本地 127.0.0.1 的随机端口访问 Project demo 下 Notebook ml-labs 的 SSH 端口。</p>
<pre><code class="language-bash">t9k-pf notebook &lt;tensorstack-host&gt;/t9k/build-console/projects/demo/notebooks/ml-labs/lab
</code></pre>
<p>通过本地 127.0.0.1:8888 访问 Project demo 下 Notebook ml-labs 的 SSH 端口。</p>
<pre><code class="language-bash">t9k-pf nb &lt;tensorstack-host&gt;/t9k/build-console/projects/demo/notebooks/ml-labs/lab 8888
</code></pre>
<p>通过本地 0.0.0.0:8888 访问 Project demo 下 Notebook ml-labs 的 SSH 端口。</p>
<pre><code class="language-bash">t9k-pf nb &lt;tensorstack-host&gt;/t9k/build-console/projects/demo/notebooks/ml-labs/lab 8888 --address 0.0.0.0
</code></pre>
<aside class="note">
<div class="title">注意</div>
<p>在 port-forward 成功后，你仍然需要保持你的 t9k-pf 命令行窗口一直保持运行状态。</p>
</aside>
<h2 id="pod-2"><a class="header" href="#pod-2">pod</a></h2>
<p>访问指定 Pod 的指定端口。</p>
<h3 id="使用-83"><a class="header" href="#使用-83">使用</a></h3>
<pre><code class="language-bash">t9k-pf pod &lt;name&gt; [&lt;localPort&gt;:]&lt;targetPort&gt;
</code></pre>
<p>其中 <code>&lt;localPort&gt;</code> 代表本地监听的端口（小于 1024 的本地端口需要管理员权限才可以绑定），<code>&lt;targetPort&gt;</code> 代表目标 Pod 的端口。</p>
<h3 id="全局选项-81"><a class="header" href="#全局选项-81">全局选项</a></h3>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-h, --help              查看当前指令的帮助信息和示例。
-n, --namespace         字符串，指定使用的项目（命名空间）名称。
-k, --apikey            开启交互式输入 API Key。
--address               本地监听地址。默认为 `localhost`。
--retryMaxTimes         整数，最大重试次数。默认为 `10`。
--retryPeriod           整数，重试间隔时间（单位：秒）。默认为 `10`。
</code></pre>
<h3 id="示例-84"><a class="header" href="#示例-84">示例</a></h3>
<p>通过本地 127.0.0.1:3333 访问命名空间 dev 下的 Pod example 的 2222 端口。</p>
<pre><code class="language-bash">t9k-pf pod example 3333:2222 -n dev
</code></pre>
<p>通过本地 0.0.0.0:3333 访问命名空间 dev 下的 Pod example 的 2222 端口。</p>
<pre><code class="language-bash">t9k-pf pod example 3333:2222 -n dev --address 0.0.0.0
</code></pre>
<p>通过本地 127.0.0.1 的随机端口访问命名空间 dev 下的 Pod example 的 2222 端口。</p>
<pre><code class="language-bash">t9k-pf pod example 2222 -n dev
</code></pre>
<aside class="note">
<div class="title">注意</div>
<p>在 port-forward 成功后，你仍然需要保持你的 t9k-pf 命令行窗口一直保持运行状态。</p>
</aside>
<h2 id="service"><a class="header" href="#service">service</a></h2>
<p>访问指定 Service 的指定端口。</p>
<h3 id="使用-84"><a class="header" href="#使用-84">使用</a></h3>
<pre><code class="language-bash">t9k-pf service &lt;name&gt; [&lt;localPort&gt;:]&lt;targetPort&gt;
</code></pre>
<p>其中 <code>&lt;localPort&gt;</code> 代表本地监听的端口（小于 1024 的本地端口需要管理员权限才可以绑定），<code>&lt;targetPort&gt;</code> 代表目标 Service 的端口。</p>
<p><code>t9k-pf service</code> 也可以用 <code>t9k-pf svc</code> 代替。</p>
<h3 id="全局选项-82"><a class="header" href="#全局选项-82">全局选项</a></h3>
<pre><code>-c, --config            字符串，指定使用的 T9k Config 文件的路径。默认路径是 `$HOME/.t9k/t9k-config.yaml`。
-h, --help              查看当前指令的帮助信息和示例。
-n, --namespace         字符串，指定使用的项目（命名空间）名称。默认是 `default`。
-k, --apikey            开启交互式输入 API Key。
--address               本地监听地址。默认为 `localhost`。
--retryMaxTimes         整数，最大重试次数。默认为 `10`。
--retryPeriod           整数，重试间隔时间（单位：秒）。默认为 `10`。
</code></pre>
<h3 id="示例-85"><a class="header" href="#示例-85">示例</a></h3>
<p>通过本地 127.0.0.1:8888 访问默认命名空间 default 下的 Service myservice 的 80 端口。</p>
<pre><code class="language-bash">t9k-pf service myservice 8888:80
</code></pre>
<p>通过本地 0.0.0.0:8888 访问默认命名空间 default 下的 Service myservice 的 80 端口。</p>
<pre><code class="language-bash">t9k-pf service myservice 8888:80 --address 0.0.0.0
</code></pre>
<p>通过本地 127.0.0.1 的随机端口访问命名空间 dev 下的 Service myservice 的 80 端口。</p>
<pre><code class="language-bash">t9k-pf service myservice 80 -n dev
</code></pre>
<aside class="note">
<div class="title">注意</div>
<p>在 port-forward 成功后，你仍然需要保持你的 t9k-pf 命令行窗口一直保持运行状态。</p>
</aside>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="python-sdkt9k"><a class="header" href="#python-sdkt9k">Python SDK：t9k</a></h1>
<p>TensorStack AI 平台提供了 Python SDK t9k，其为平台中的多种功能提供支持。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="用户指南-2"><a class="header" href="#用户指南-2">用户指南</a></h1>
<h2 id="安装-2"><a class="header" href="#安装-2">安装</a></h2>
<p>目前 TensorStack SDK 仅提供用于本地安装的 Python 包，你可以从平台首页下载。</p>
<p>然后使用以下命令进行安装：</p>
<pre><code class="language-shell">pip install t9k-sdk-&lt;version&gt;.tar.gz [-i &lt;pypi-mirror-url&gt;]
</code></pre>
<h2 id="配置"><a class="header" href="#配置">配置</a></h2>
<h3 id="配置文件-1"><a class="header" href="#配置文件-1">配置文件</a></h3>
<p>TensorStack SDK 没有单独的配置文件，而是使用 <a href="tools/python-sdk-t9k/../cli-t9k/guide.html#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">TensorStack CLI 的配置文件</a>。在导入 <code>t9k</code> 模块时，会自动读取位于路径 <code>~/.t9k/t9k-config.yaml</code> 的配置文件（如果设置了环境变量 <code>T9K_CONFIG</code>，则读取其值给出的路径）。如果配置文件不存在或缺少部分配置项，则缺少的这些配置项会被设置为 <code>None</code>，这可能导致 TensorStack SDK 的部分功能不能正常工作。</p>
<h3 id="使用和修改配置"><a class="header" href="#使用和修改配置">使用和修改配置</a></h3>
<p>在 Python 脚本中导入 <code>t9k</code> 模块之后，<code>t9k.CONFIG</code> 对象就代表了 TensorStack SDK 的配置，你可以像操作 Python 字典一样操作它，例如获取、设置、更新值。</p>
<pre><code class="language-python">import t9k

print(t9k.CONFIG['api_key'])
t9k.CONFIG['api_key'] = 'e4ccd2a3-3425-44b0-8b44-148bd303a0f9'
t9k.CONFIG.update({'api_key': 'e4ccd2a3-3425-44b0-8b44-148bd303a0f9'})
</code></pre>
<aside class="note">
<div class="title">注意</div>
<p>你对于配置的任何修改都只是临时的，这些修改不会被保存到配置文件中。</p>
</aside>
<h2 id="命令行工具-1"><a class="header" href="#命令行工具-1">命令行工具</a></h2>
<p>TensorStack SDK 提供了两个命令行工具：</p>
<ul>
<li><code>em</code>：对应于 <code>t9k.em</code> 模块，用于用户登录和登出 AIStore 服务器（会修改配置文件），查看和上传本地保存的 Run 和 Artifact 数据。执行 <code>em --help</code> 和 <code>em COMMAND --help</code> 以查看相应命令的详细使用方法。</li>
<li><code>ah</code>：对应于 <code>t9k.ah</code> 模块，用于用户登录和登出 Asset Hub 服务器（会修改配置文件），查看、创建、修改和删除资产和资产目录，以及上传、修改和下载资产文件。执行 <code>ah --help</code> 和 <code>ah COMMAND --help</code> 命令以查看相应命令的详细使用方法。</li>
</ul>
<!-- 
详细教程
 -->
<h2 id="各主题教程"><a class="header" href="#各主题教程">各主题教程</a></h2>
<ul>
<li>AI 资产管理相关：请参阅<a href="tools/python-sdk-t9k/../../tasks/manage-ai-assets.html">管理 AI 资产</a>。</li>
<li>实验管理相关：请参阅<a href="tools/python-sdk-t9k/../../tasks/track-model-training.html">追踪模型训练</a>。</li>
<li>模型构建相关：请参阅<a href="tools/python-sdk-t9k/../../tasks/hyperparameter-tuning.html">进行超参数优化</a>。</li>
<li>模型部署相关：请参阅<a href="tools/python-sdk-t9k/../../tasks/deploy-mlservice-transformer.html">制作 Transformer</a>。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api"><a class="header" href="#api">API</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="t9kah"><a class="header" href="#t9kah">t9k.ah</a></h1>
<h2 id="t9kahcommit"><a class="header" href="#t9kahcommit">t9k.ah.commit</a></h2>
<pre><code class="language-python">commit(path: str, msg: str, delete: Optional[Sequence[str]] = None, add: Union[Sequence[str], Mapping[str, str], None] = None, force: bool = False) ‑&gt; Optional[t9k.ah.core.Commit]
</code></pre>
<p>Commits changes to a branch of an Asset.</p>
<p>First delete, then add.</p>
<p>If no branch is provided, <code>:main</code> will be used.</p>
<p>For Windows platform, if you provide absolute paths for parameter <code>add</code>, change its format from ‘C:\local\path’ to ‘\C\local\path’.</p>
<h3 id="examples"><a class="header" href="#examples">Examples</a></h3>
<p>Add a file as object to specified branch of Model:</p>
<pre><code class="language-python">ah.commit('model/llm/gpt2:v1', msg='add ...', add=['model.pt'])
</code></pre>
<p>Specify a path in Asset for a file to add:</p>
<pre><code class="language-python">ah.commit('model/llm/gpt2:v1', msg='add ...', add={'model.pt': 'saved_model/'})
</code></pre>
<p>Add all files under a directory as objects (with the directory):</p>
<pre><code class="language-python">ah.commit('model/llm/gpt2:v1', msg='add ...', add=['./saved_model'])
</code></pre>
<p>Add all files under a directory as objects (without the directory):</p>
<pre><code class="language-python">ah.commit('model/llm/gpt2:v1', msg='add ...', add=['./saved_model/*'])
</code></pre>
<p>Specify a path in Asset for a directory to add:</p>
<pre><code class="language-python">ah.commit('model/llm/gpt2:v1', msg='add ...', add={'./saved_model': 'path/to/[saved_model]'})
## or
ah.commit('model/llm/gpt2:v1', msg='add ...', add={'./saved_model': 'path/to/renamed_dir'})
</code></pre>
<p>Delete an object from a Dataset:</p>
<pre><code class="language-python">ah.commit('dataset/images/cifar10', msg='delete ...', delete=['0.png'])
</code></pre>
<p>Delete all objects under the specified path:</p>
<pre><code class="language-python">ah.commit('dataset/images/cifar10', msg='delete ...', delete=['data/'])
</code></pre>
<h3 id="args"><a class="header" href="#args">Args</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the branch.</p>
</li>
<li>
<p><strong>msg</strong> (<em>str</em>)</p>
<p>Commit message.</p>
</li>
<li>
<p><strong>delete</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Files or directories to delete from the branch, can be a sequence of paths in branch or <code>None</code>. If empty sequence or <code>None</code>, delete nothing. If the files or directories to delete do not exist, do nothing (rather than raise an error). Here format <code>a/.../b</code> signifies a file, while <code>a/.../b/</code> signifies a directory.</p>
</li>
<li>
<p><strong>add</strong> (<em>Union[Sequence[str], Mapping[str, str], None]</em>)</p>
<p>Files or directories to add to the branch, can be a sequence of local paths, a mapping from local paths to their paths in Asset, or <code>None</code>. If empty sequence, empty mapping or <code>None</code>, add nothing.</p>
</li>
<li>
<p><strong>force</strong> (<em>bool</em>)</p>
<p>Whether to create a new commit if unknown changes or unimplemented changes are found.</p>
</li>
</ul>
<h3 id="returns"><a class="header" href="#returns">Returns</a></h3>
<p>A <code>Commit</code> instance representing created commit if changes are
commited, <code>None</code> if not.</p>
<h2 id="t9kahcreate"><a class="header" href="#t9kahcreate">t9k.ah.create</a></h2>
<pre><code class="language-python">create(path: str, labels: Optional[Sequence[str]] = None, description: str = '', exist_ok: bool = False, create_tag: bool = False, source: str = 'main') ‑&gt; Union[t9k.ah.core.Folder, t9k.ah.core.Model, t9k.ah.core.Dataset, t9k.ah.core.Branch, t9k.ah.core.Tag]
</code></pre>
<p>Creates a resource.</p>
<p>Note that you cannot create a Folder for another user.</p>
<h3 id="examples-1"><a class="header" href="#examples-1">Examples</a></h3>
<p>Create a Folder:</p>
<pre><code class="language-python">folder = ah.create('model/llm')
</code></pre>
<p>Create a Model with labels:</p>
<pre><code class="language-python">model = ah.create('model/llm/gpt2', labels=['PyTorch'])
</code></pre>
<p>Create a Dataset with a description:</p>
<pre><code class="language-python">description = 'CIFAR-10 is a widely used benchmark dataset ...'
dataset = ah.create('dataset/images/cifar10', description=description)
</code></pre>
<p>Create a non-main branch of specified Model:</p>
<pre><code class="language-python">branch = ah.create('model/llm/gpt2:v1')
</code></pre>
<p>Create a tag:</p>
<pre><code class="language-python">tag = ah.create('model/llm/gpt2:20220101', create_tag=True, source='v1')
## or
tag = ah.create('model/llm/gpt2:20220101', create_tag=True, source='model/llm/gpt2:v1')
</code></pre>
<p>Create a Model for another user:</p>
<pre><code class="language-python">model = ah.create('/user/t9k-assethub/model/llm/gpt2')
</code></pre>
<h3 id="args-1"><a class="header" href="#args-1">Args</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the resource.</p>
</li>
<li>
<p><strong>labels</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Labels of the resource. Only applicable for creating a Folder, Model or Dataset.</p>
</li>
<li>
<p><strong>description</strong> (<em>str</em>)</p>
<p>Description of the resource. Only applicable for creating a Folder, Model or Dataset.</p>
</li>
<li>
<p><strong>exist_ok</strong> (<em>bool</em>)</p>
<p>If True and the resource already exists, return a corresponding instance representing the resource; if False and resource exists, raise a <code>RuntimeError</code>. Only applicable for creating a Folder, Model or Dataset.</p>
</li>
<li>
<p><strong>create_tag</strong> (<em>bool</em>)</p>
<p>Whether to create a tag instead of a branch. Only applicable for creating a branch or tag.</p>
</li>
<li>
<p><strong>source</strong> (<em>str</em>)</p>
<p>Name/ID or path of the source reference (branch, tag or commit) from which a tag is created. Only applicable for creating a tag.</p>
</li>
</ul>
<h3 id="returns-1"><a class="header" href="#returns-1">Returns</a></h3>
<p>A corresponding instance representing retrieved resource.</p>
<h2 id="t9kahdelete"><a class="header" href="#t9kahdelete">t9k.ah.delete</a></h2>
<pre><code class="language-python">delete(path: str, force: bool = False) ‑&gt; None
</code></pre>
<p>Deletes a resource.</p>
<h3 id="examples-2"><a class="header" href="#examples-2">Examples</a></h3>
<p>Delete a Folder:</p>
<pre><code class="language-python">ah.delete('model/llm')
</code></pre>
<p>Delete a Model:</p>
<pre><code class="language-python">ah.delete('model/llm/gpt2')
</code></pre>
<p>Delete a Dataset:</p>
<pre><code class="language-python">ah.delete('dataset/images/cifar10')
</code></pre>
<p>Delete a non-main branch of specified Model:</p>
<pre><code class="language-python">ah.delete('model/llm/gpt2:v1')
</code></pre>
<p>Delete a tag:</p>
<pre><code class="language-python">ah.delete('model/llm/gpt2:20220101')
</code></pre>
<p>Delete another user’s Folder:</p>
<pre><code class="language-python">ah.delete('/user/t9k-assethub/model/llm')
</code></pre>
<p>If the Folder does not exist, do nothing:</p>
<pre><code class="language-python">ah.delete('model/llm', force=True)
</code></pre>
<h3 id="args-2"><a class="header" href="#args-2">Args</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the resource.</p>
</li>
<li>
<p><strong>force</strong> (<em>bool</em>)</p>
<p>If True, ignore non-existent resources.</p>
</li>
</ul>
<h2 id="t9kahdownload"><a class="header" href="#t9kahdownload">t9k.ah.download</a></h2>
<pre><code class="language-python">download(path: str, objects: Optional[Sequence[str]] = None, save_dir: str = '.')
</code></pre>
<p>Download objects of a reference of an Asset.</p>
<p>If no reference is provided, <code>:main</code> will be used.</p>
<h3 id="examples-3"><a class="header" href="#examples-3">Examples</a></h3>
<p>Download all objects of specified branch of Model to current working directory:</p>
<pre><code class="language-python">ah.download('model/llm/gpt2:v1')
</code></pre>
<p>Download an object to specified directory:</p>
<pre><code class="language-python">ah.download('model/llm/gpt2:v1', objects=['model.pt'], save_dir='./saved_model')
</code></pre>
<p>Download all objects under the same path:</p>
<pre><code class="language-python">ah.download('model/llm/gpt2:v1', objects=['saved_model/'])
</code></pre>
<p>Specify the reference by tag:</p>
<pre><code class="language-python">ah.download('dataset/images/cifar10:20220101')
</code></pre>
<p>Specify the reference by commit:</p>
<pre><code class="language-python">ah.download('dataset/images/cifar10:a41ac4ec')
</code></pre>
<h3 id="args-3"><a class="header" href="#args-3">Args</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the reference from which objects are downloaded.</p>
</li>
<li>
<p><strong>objects</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Objects to download.</p>
</li>
<li>
<p><strong>save_dir</strong> (<em>str</em>)</p>
<p>Local directory which objects are downloaded to.</p>
</li>
</ul>
<h2 id="t9kahget"><a class="header" href="#t9kahget">t9k.ah.get</a></h2>
<pre><code class="language-python">get(path: str) ‑&gt; Union[t9k.ah.core.Folder, t9k.ah.core.Model, t9k.ah.core.Dataset, t9k.ah.core.Branch, t9k.ah.core.Tag, t9k.ah.core.Commit]
</code></pre>
<p>Gets a resource.</p>
<p>To get a commit, please provide a commit ID with a length of at least 4 to avoid potential conflicts with branches or tags.</p>
<h3 id="examples-4"><a class="header" href="#examples-4">Examples</a></h3>
<p>Get a Folder:</p>
<pre><code class="language-python">folder = ah.get('model/llm')
</code></pre>
<p>Get a Model:</p>
<pre><code class="language-python">model = ah.get('model/llm/gpt2')
</code></pre>
<p>Get a Dataset:</p>
<pre><code class="language-python">dataset = ah.get('dataset/images/cifar10')
</code></pre>
<p>Get a non-main branch of specified Model:</p>
<pre><code class="language-python">branch = ah.get('model/llm/gpt2:v1')
</code></pre>
<p>Get a tag:</p>
<pre><code class="language-python">tag = ah.get('model/llm/gpt2:20220101')
</code></pre>
<p>Get another user’s Folder:</p>
<pre><code class="language-python">folder = ah.get('/user/t9k-assethub/model/llm')
</code></pre>
<h3 id="args-4"><a class="header" href="#args-4">Args</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the resource.</p>
</li>
</ul>
<h3 id="returns-2"><a class="header" href="#returns-2">Returns</a></h3>
<p>A instance representing retrieved resource.</p>
<h2 id="t9kahlist"><a class="header" href="#t9kahlist">t9k.ah.list</a></h2>
<pre><code class="language-python">list(path: str, resource: str = 'default') ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists resources.</p>
<p>Based on the provided <code>path</code>, list Folders with the specified Asset kind, Assets within the specified Folder, or all objects of the specified reference (branch, tag or commit) of Asset.</p>
<p>To list Folders that are shared with you, set <code>path='shared/model'</code> (or <code>path='shared/dataset'</code>); to list Folders that are public, set <code>path='/public/t9k-assethub/model'</code> (or <code>path='/public/t9k-assethub/dataset'</code>).</p>
<p>To list branches, provide a <code>path</code> that points to an Asset and set <code>resource='branch'</code>; to list tags, provide a <code>path</code> that points to an Asset and set <code>resource='tag'</code>; to list commits, provide a <code>path</code> that points to a branch of an Asset and set <code>resource='commit'</code>.</p>
<p>If a reference is expected but omitted, <code>:main</code> will be used.</p>
<h3 id="examples-5"><a class="header" href="#examples-5">Examples</a></h3>
<p>List Model Folders that you own:</p>
<pre><code class="language-python">folders = ah.list('model')
</code></pre>
<p>List Model Folders that are shared with you:</p>
<pre><code class="language-python">folders = ah.list('shared/model')
</code></pre>
<p>List Model Folders that are public:</p>
<pre><code class="language-python">folders = ah.list('/public/t9k-assethub/model')
</code></pre>
<p>List Models in your own Folder:</p>
<pre><code class="language-python">models = ah.list('model/llm')
</code></pre>
<p>List Models in another user’s Folder:</p>
<pre><code class="language-python">models = ah.list('/user1/t9k-assethub/model/llm')
</code></pre>
<p>List objects of specified branch of Model:</p>
<pre><code class="language-python">objects = ah.list('model/llm/gpt2:v1')
</code></pre>
<p>List objects of specified tag of Dataset:</p>
<pre><code class="language-python">objects = ah.list('dataset/images/cifar10:20220101')
</code></pre>
<p>List branches of specified Model:</p>
<pre><code class="language-python">branches = ah.list('model/llm/gpt2', resource='branch')
</code></pre>
<p>List tags of specified Model:</p>
<pre><code class="language-python">tags = ah.list('model/llm/gpt2', resource='tag')
</code></pre>
<p>List commits of specified branch of Model:</p>
<pre><code class="language-python">commits = ah.list('model/llm/gpt2:v1', resource='commit')
</code></pre>
<p>List commits of specified Dataset:</p>
<pre><code class="language-python">commits = ah.list('dataset/images/cifar10', resource='commit')
</code></pre>
<h3 id="args-5"><a class="header" href="#args-5">Args</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path to be listed.</p>
</li>
<li>
<p><strong>resource</strong> (<em>str</em>)</p>
<p>Kind of the resources, must be <code>'default'</code>, <code>'branch'</code>, ‘<code>tag</code>’ or <code>'commit'</code>. This parameter is used to list branches, tags or commits: to list branches, provide a <code>path</code> that points to an Asset and set <code>resource='branch'</code>; to list tags, provide a <code>path</code> that points to an Asset and set <code>resource='tag'</code>; to list commits, provide a <code>path</code> that points to a branch of an Asset and set <code>resource='commit'</code>.</p>
</li>
</ul>
<h3 id="returns-3"><a class="header" href="#returns-3">Returns</a></h3>
<p>A list of resources.</p>
<h2 id="t9kahlogin"><a class="header" href="#t9kahlogin">t9k.ah.login</a></h2>
<pre><code class="language-python">login(ah_host: Optional[str] = None, ais_host: Optional[str] = None, api_key: Optional[str] = None, timeout: Optional[int] = None) ‑&gt; None
</code></pre>
<p>Logs in to AIStore server and Asset Hub server.</p>
<p>Sets up the client that corresponds with AIStore server and Asset Hub server.</p>
<h3 id="args-6"><a class="header" href="#args-6">Args</a></h3>
<ul>
<li>
<p><strong>ah_host</strong> (<em>Optional[str]</em>)</p>
<p>URL of Asset Hub server. Defaults to <code>t9k.CONFIG['asset_hub_host']</code>.</p>
</li>
<li>
<p><strong>ais_host</strong> (<em>Optional[str]</em>)</p>
<p>URL of AIStore server. Defaults to <code>t9k.CONFIG['aistore_host']</code>.</p>
</li>
<li>
<p><strong>api_key</strong> (<em>Optional[str]</em>)</p>
<p>API Key for requesting server. Defaults to <code>t9k.CONFIG['api_key']</code>.</p>
</li>
<li>
<p><strong>timeout</strong> (<em>Optional[int]</em>)</p>
<p>How many seconds to wait for server to send data before giving up.</p>
</li>
</ul>
<h3 id="raises"><a class="header" href="#raises">Raises</a></h3>
<ul>
<li>
<p><strong>requests.HTTPError</strong></p>
<p>Unable to connect to the server.</p>
</li>
</ul>
<h2 id="t9kahlogout"><a class="header" href="#t9kahlogout">t9k.ah.logout</a></h2>
<pre><code class="language-python">logout() ‑&gt; None
</code></pre>
<p>Logs out from the current AIStore server and Asset Hub server.</p>
<p>The client is unset, it can no longer correspond with AIStore server and Asset Hub server until it is set up again.</p>
<h2 id="t9kahmerge"><a class="header" href="#t9kahmerge">t9k.ah.merge</a></h2>
<pre><code class="language-python">merge(path: str) ‑&gt; None
</code></pre>
<p>Merges a branch of a Model to the main branch.</p>
<p>Here, the specific operation of “merge” involves deleting all objects from the main branch and then copying all objects from the specified branch to the main branch.</p>
<p>Note that the specified branch itself cannot be the main branch.</p>
<h3 id="examples-6"><a class="header" href="#examples-6">Examples</a></h3>
<pre><code class="language-python">ah.merge('model/llm/gpt2:v1')
</code></pre>
<h3 id="args-7"><a class="header" href="#args-7">Args</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the branch.</p>
</li>
</ul>
<h2 id="t9kahreset"><a class="header" href="#t9kahreset">t9k.ah.reset</a></h2>
<pre><code class="language-python">reset(path: str) ‑&gt; None
</code></pre>
<p>Resets a branch to clear all uncommitted changes.</p>
<h3 id="examples-7"><a class="header" href="#examples-7">Examples</a></h3>
<pre><code class="language-python">ah.reset('model/llm/gpt2:main')
</code></pre>
<h3 id="args-8"><a class="header" href="#args-8">Args</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the branch.</p>
</li>
</ul>
<h2 id="t9kahupdate"><a class="header" href="#t9kahupdate">t9k.ah.update</a></h2>
<pre><code class="language-python">update(path: str, name: Optional[str] = None, labels: Optional[Sequence[str]] = None, description: Optional[str] = None) ‑&gt; None
</code></pre>
<p>Updates a resource.</p>
<p>Only Folders and Assets can be updated.</p>
<p>If none of the args is provided, do nothing.</p>
<h3 id="examples-8"><a class="header" href="#examples-8">Examples</a></h3>
<p>Rename a Folder:</p>
<pre><code class="language-python">ah.update('model/llm', name='generative-language-model')
</code></pre>
<p>Relabel a Model:</p>
<pre><code class="language-python">ah.update('model/llm/gpt2', labels=['JAX'])
</code></pre>
<h3 id="args-9"><a class="header" href="#args-9">Args</a></h3>
<ul>
<li>
<p><strong>name</strong> (<em>Optional[str]</em>)</p>
<p>New name of the resource.</p>
</li>
<li>
<p><strong>labels</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>New labels of the resource.</p>
</li>
<li>
<p><strong>description</strong> (<em>Optional[str]</em>)</p>
<p>New description of the resource.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="t9kahcore"><a class="header" href="#t9kahcore">t9k.ah.core</a></h1>
<h2 id="t9kahcorebranch"><a class="header" href="#t9kahcorebranch">t9k.ah.core.Branch</a></h2>
<pre><code class="language-python">Branch(asset: Union[t9k.ah.core.Model, t9k.ah.core.Dataset], name: str, commit_id: str)
</code></pre>
<p>Represents a branch of Asset.</p>
<h3 id="attributes"><a class="header" href="#attributes">Attributes</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the branch.</p>
</li>
<li>
<p><strong>asset</strong> (<em>Union[t9k.ah.core.Model, t9k.ah.core.Dataset]</em>)</p>
<p>A <code>Model</code> or <code>Dataset</code> instance corresponding to the Asset that the branch belongs to.</p>
</li>
<li>
<p><strong>kind</strong> (<em>str</em>)</p>
<p>A string <code>'branch'</code>.</p>
</li>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the branch.</p>
</li>
<li>
<p><strong>commit_id</strong> (<em>str</em>)</p>
<p>ID of the commit that the branch points to.</p>
</li>
<li>
<p><strong>alive</strong> (<em>bool</em>)</p>
<p>Whether the branch is alive.</p>
</li>
</ul>
<h3 id="ancestors"><a class="header" href="#ancestors">Ancestors</a></h3>
<ul>
<li><code>t9k.ah.core._Ref</code></li>
</ul>
<h3 id="methods"><a class="header" href="#methods">Methods</a></h3>
<h4 id="create_commit"><a class="header" href="#create_commit">create_commit</a></h4>
<pre><code class="language-python">create_commit(self, msg: str, delete: Optional[Sequence[str]] = None, add: Union[Sequence[str], Mapping[str, str], None] = None, force: bool = False) ‑&gt; Optional[t9k.ah.core.Commit]
</code></pre>
<p>Commits changes to this branch.</p>
<p>First delete, then add.</p>
<h5 id="examples-9"><a class="header" href="#examples-9">Examples</a></h5>
<p>Add a file as object to this branch:</p>
<pre><code class="language-python">branch.create_commit(msg='add ...', add=['model.pt'])
</code></pre>
<p>Specify a path in Asset for a file to add:</p>
<pre><code class="language-python">branch.create_commit(msg='add ...', add={'model.pt': 'saved_model/'})
</code></pre>
<p>Add all files under a directory as objects (with the directory):</p>
<pre><code class="language-python">branch.create_commit(msg='add ...', add=['./saved_model'])
</code></pre>
<p>Add all files under a directory as objects (without the directory):</p>
<pre><code class="language-python">branch.create_commit(msg='add ...', add=['./saved_model/*'])
</code></pre>
<p>Specify a path in Asset for a directory to add:</p>
<pre><code class="language-python">branch.create_commit(msg='add ...', add={'./saved_model': 'path/to/[saved_model]'})
## or
branch.create_commit(msg='add ...', add={'./saved_model': 'path/to/renamed_dir'})
</code></pre>
<p>Delete an object from this branch:</p>
<pre><code class="language-python">branch.create_commit(msg='delete ...', delete=['model.pt'])
</code></pre>
<p>Delete all objects under the specified path:</p>
<pre><code class="language-python">branch.create_commit(msg='delete ...', delete=['saved_model/'])
</code></pre>
<h5 id="args-10"><a class="header" href="#args-10">Args</a></h5>
<ul>
<li>
<p><strong>msg</strong> (<em>str</em>)</p>
<p>Commit message.</p>
</li>
<li>
<p><strong>delete</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Files or directories to delete from the branch, can be a sequence of paths in branch or <code>None</code>. If empty sequence or <code>None</code>, delete nothing. If the files or directories to delete do not exist, do nothing (rather than raise an error). Here format <code>a/.../b</code> signifies a file, while <code>a/.../b/</code> signifies a directory.</p>
</li>
<li>
<p><strong>add</strong> (<em>Union[Sequence[str], Mapping[str, str], None]</em>)</p>
<p>Files or directories to add to the branch, can be a sequence of local paths, a mapping from local paths to their paths in Asset, or <code>None</code>. If empty sequence, empty mapping or <code>None</code>, add nothing.</p>
</li>
<li>
<p><strong>force</strong> (<em>bool</em>)</p>
<p>Whether to create a new commit if unknown changes or unimplemented changes are found.</p>
</li>
</ul>
<h5 id="returns-4"><a class="header" href="#returns-4">Returns</a></h5>
<p>A <code>Commit</code> instance representing created commit if changes are
commited, <code>None</code> if not.</p>
<h4 id="create_tag"><a class="header" href="#create_tag">create_tag</a></h4>
<pre><code class="language-python">create_tag(self, name: str) ‑&gt; t9k.ah.core.Tag
</code></pre>
<p>Creates a tag that points to this branch.</p>
<h5 id="args-11"><a class="header" href="#args-11">Args</a></h5>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the tag.</p>
</li>
</ul>
<h5 id="returns-5"><a class="header" href="#returns-5">Returns</a></h5>
<p>A <code>Tag</code> instance representing created tag.</p>
<h4 id="delete-15"><a class="header" href="#delete-15">delete</a></h4>
<pre><code class="language-python">delete(self) ‑&gt; None
</code></pre>
<p>Deletes this branch.</p>
<h4 id="download"><a class="header" href="#download">download</a></h4>
<pre><code class="language-python">download(self, paths: Optional[Sequence[str]] = None, save_dir: str = '.') ‑&gt; None
</code></pre>
<p>Downloads objects of this branch.</p>
<h5 id="args-12"><a class="header" href="#args-12">Args</a></h5>
<ul>
<li>
<p><strong>paths</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Files or directories to download from this branch, is a sequence of paths in branch. Here format <code>a/.../b</code> signifies a file while <code>a/.../b/</code> signifies a directory. Defaults to all objects.</p>
</li>
<li>
<p><strong>save_dir</strong> (<em>str</em>)</p>
<p>Local directory which objects are downloaded to. If the directory does not exist, create it. Defaults to current working directory.</p>
</li>
</ul>
<h4 id="get_commit"><a class="header" href="#get_commit">get_commit</a></h4>
<pre><code class="language-python">get_commit(self, index: Optional[int] = None, id: Optional[str] = None) ‑&gt; t9k.ah.core.Commit
</code></pre>
<p>Gets a commit of this branch.</p>
<p>If neither <code>index</code> or <code>id</code> is provided, return the last commit. If both
<code>index</code> and <code>id</code> are provided, <code>id</code> will not be used.</p>
<h5 id="args-13"><a class="header" href="#args-13">Args</a></h5>
<ul>
<li>
<p><strong>index</strong> (<em>Optional[int]</em>)</p>
<p>Index of the commit in this branch, <code>0</code> for the last commit, <code>-1</code> for the first commit.</p>
</li>
<li>
<p><strong>id</strong> (<em>Optional[str]</em>)</p>
<p>A prefix of ID of the commit.</p>
</li>
</ul>
<h5 id="returns-6"><a class="header" href="#returns-6">Returns</a></h5>
<p>A <code>Commit</code> instance representing retrieved commit.</p>
<h4 id="list_commit"><a class="header" href="#list_commit">list_commit</a></h4>
<pre><code class="language-python">list_commit(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists commits of this branch.</p>
<h4 id="list_object"><a class="header" href="#list_object">list_object</a></h4>
<pre><code class="language-python">list_object(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists objects of this branch.</p>
<h4 id="merge"><a class="header" href="#merge">merge</a></h4>
<pre><code class="language-python">merge(self) ‑&gt; None
</code></pre>
<p>Merges this branch to the main branch.</p>
<p>Here, the specific operation of “merge” involves deleting all objects
from the main branch and then copying all objects from this branch to
the main branch.</p>
<p>Note that this branch itself cannot be the main branch.</p>
<h4 id="reset"><a class="header" href="#reset">reset</a></h4>
<pre><code class="language-python">reset(self) ‑&gt; None
</code></pre>
<p>Resets this branch to clear all uncommitted changes.</p>
<h2 id="t9kahcorecommit"><a class="header" href="#t9kahcorecommit">t9k.ah.core.Commit</a></h2>
<pre><code class="language-python">Commit(asset: Union[t9k.ah.core.Model, t9k.ah.core.Dataset], id_: str)
</code></pre>
<p>Represents a commit of Asset.</p>
<h3 id="attributes-1"><a class="header" href="#attributes-1">Attributes</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the commit.</p>
</li>
<li>
<p><strong>asset</strong> (<em>Union[t9k.ah.core.Model, t9k.ah.core.Dataset]</em>)</p>
<p>A <code>Model</code> or <code>Dataset</code> instance corresponding to the Asset that the commit belongs to.</p>
</li>
<li>
<p><strong>kind</strong> (<em>str</em>)</p>
<p>A string <code>'commit'</code>.</p>
</li>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>First 8 characters of ID of the commit.</p>
</li>
<li>
<p><strong>id</strong> (<em>str</em>)</p>
<p>ID of the commit.</p>
</li>
<li>
<p><strong>alive</strong> (<em>bool</em>)</p>
<p>Whether the commit is alive.</p>
</li>
</ul>
<h3 id="ancestors-1"><a class="header" href="#ancestors-1">Ancestors</a></h3>
<ul>
<li><code>t9k.ah.core._Ref</code></li>
</ul>
<h3 id="methods-1"><a class="header" href="#methods-1">Methods</a></h3>
<h4 id="create_tag-1"><a class="header" href="#create_tag-1">create_tag</a></h4>
<pre><code class="language-python">create_tag(self, name: str) ‑&gt; t9k.ah.core.Tag
</code></pre>
<p>Creates a tag that points to this commit.</p>
<h5 id="args-14"><a class="header" href="#args-14">Args</a></h5>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the tag.</p>
</li>
</ul>
<h5 id="returns-7"><a class="header" href="#returns-7">Returns</a></h5>
<p>A <code>Tag</code> instance representing created tag.</p>
<h4 id="download-1"><a class="header" href="#download-1">download</a></h4>
<pre><code class="language-python">download(self, paths: Optional[Sequence[str]] = None, save_dir: str = '.') ‑&gt; None
</code></pre>
<p>Downloads objects of this commit.</p>
<h5 id="args-15"><a class="header" href="#args-15">Args</a></h5>
<ul>
<li>
<p><strong>paths</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Files or directories to download from this commit, is a sequence of paths in commit. Here format <code>a/.../b</code> signifies a file while <code>a/.../b/</code> signifies a directory. Defaults to all objects.</p>
</li>
<li>
<p><strong>save_dir</strong> (<em>str</em>)</p>
<p>Local directory which objects are downloaded to. If the directory does not exist, create it. Defaults to current working directory.</p>
</li>
</ul>
<h4 id="list_commit-1"><a class="header" href="#list_commit-1">list_commit</a></h4>
<pre><code class="language-python">list_commit(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists commits of this commit.</p>
<h4 id="list_object-1"><a class="header" href="#list_object-1">list_object</a></h4>
<pre><code class="language-python">list_object(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists objects of this commit.</p>
<h2 id="t9kahcoredataset"><a class="header" href="#t9kahcoredataset">t9k.ah.core.Dataset</a></h2>
<pre><code class="language-python">Dataset(id_: str, folder: t9k.ah.core.Folder, name: str, labels: List[str], description: str, extra: str)
</code></pre>
<p>Represents a Dataset in server.</p>
<h3 id="attributes-2"><a class="header" href="#attributes-2">Attributes</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the Dataset in server.</p>
</li>
<li>
<p><strong>id</strong> (<em>str</em>)</p>
<p>ID of the Dataset in server.</p>
</li>
<li>
<p><strong>folder</strong> (<em>t9k.ah.core.Folder</em>)</p>
<p>A <code>Folder</code> instance corresponding to the Folder that the Dataset belongs to.</p>
</li>
<li>
<p><strong>kind</strong> (<em>str</em>)</p>
<p>A string <code>'Dataset'</code>.</p>
</li>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the Dataset.</p>
</li>
<li>
<p><strong>labels</strong> (<em>List[str]</em>)</p>
<p>Labels of the Dataset.</p>
</li>
<li>
<p><strong>description</strong> (<em>str</em>)</p>
<p>Description of the Dataset.</p>
</li>
<li>
<p><strong>commit_id</strong> (<em>str</em>)</p>
<p>ID of the commit that the main branch points to.</p>
</li>
<li>
<p><strong>extra</strong> (<em>str</em>)</p>
<p>Extra information about the Dataset.</p>
</li>
<li>
<p><strong>alive</strong> (<em>bool</em>)</p>
<p>Whether the Dataset is alive.</p>
</li>
</ul>
<h3 id="ancestors-2"><a class="header" href="#ancestors-2">Ancestors</a></h3>
<ul>
<li><code>t9k.ah.core._Dataset</code></li>
</ul>
<h3 id="methods-2"><a class="header" href="#methods-2">Methods</a></h3>
<h4 id="create_commit-1"><a class="header" href="#create_commit-1">create_commit</a></h4>
<pre><code class="language-python">create_commit(self, msg: str, delete: Optional[Sequence[str]] = None, add: Union[Sequence[str], Mapping[str, str], None] = None) ‑&gt; Optional[t9k.ah.core.Commit]
</code></pre>
<p>Commits changes to this Dataset.</p>
<p>First delete, then add.</p>
<h5 id="examples-10"><a class="header" href="#examples-10">Examples</a></h5>
<p>Add a file as object to this Dataset:</p>
<pre><code class="language-python">dataset.create_commit(msg='add ...', add=['0.png'])
</code></pre>
<p>Specify a path in Dataset for an object to add:</p>
<pre><code class="language-python">dataset.create_commit(msg='add ...', add={'0.png': 'data/'})
</code></pre>
<p>Add all files under a directory as objects:</p>
<pre><code class="language-python">dataset.create_commit(msg='add ...', add=['./data'])
</code></pre>
<p>Delete an object from this Dataset:</p>
<pre><code class="language-python">dataset.create_commit(msg='delete ...', delete=['0.png'])
</code></pre>
<p>Delete all objects under the specified path:</p>
<pre><code class="language-python">dataset.create_commit(msg='delete ...', delete=['data/'])
</code></pre>
<h5 id="args-16"><a class="header" href="#args-16">Args</a></h5>
<ul>
<li>
<p><strong>msg</strong> (<em>str</em>)</p>
<p>Commit message.</p>
</li>
<li>
<p><strong>delete</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Files or directories to delete from the Dataset, can be a sequence of paths in Dataset or <code>None</code>. If empty sequence or <code>None</code>, delete nothing. If the files or directories to delete do not exist, do nothing (rather than raise an error). Here format <code>a/.../b</code> signifies a file, while <code>a/.../b/</code> signifies a directory.</p>
</li>
<li>
<p><strong>add</strong> (<em>Union[Sequence[str], Mapping[str, str], None]</em>)</p>
<p>Files or directories to add to the Dataset, can be a sequence of local paths, a mapping from local paths to their paths in Dataset, or <code>None</code>. If empty sequence, empty mapping or <code>None</code>, add nothing.</p>
</li>
</ul>
<h5 id="returns-8"><a class="header" href="#returns-8">Returns</a></h5>
<p>A <code>Commit</code> instance representing created commit if changes are
commited, <code>None</code> if not.</p>
<h4 id="delete-16"><a class="header" href="#delete-16">delete</a></h4>
<pre><code class="language-python">delete(self) ‑&gt; None
</code></pre>
<p>Deletes this Dataset.</p>
<h4 id="download-2"><a class="header" href="#download-2">download</a></h4>
<pre><code class="language-python">download(self, paths: Optional[Sequence[str]] = None, save_dir: str = '.') ‑&gt; None
</code></pre>
<p>Downloads objects of this Dataset.</p>
<h5 id="args-17"><a class="header" href="#args-17">Args</a></h5>
<ul>
<li>
<p><strong>paths</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Files or directories to download from this Dataset, is a sequence of paths in Dataset. Here format <code>a/.../b</code> signifies a file while <code>a/.../b/</code> signifies a directory. Defaults to all objects.</p>
</li>
<li>
<p><strong>save_dir</strong> (<em>str</em>)</p>
<p>Local directory which objects are downloaded to. If the directory does not exist, create it. Defaults to current working directory.</p>
</li>
</ul>
<h4 id="get_commit-1"><a class="header" href="#get_commit-1">get_commit</a></h4>
<pre><code class="language-python">get_commit(self, index: Optional[int] = None, id: Optional[str] = None) ‑&gt; t9k.ah.core.Commit
</code></pre>
<p>Gets a commit of this Dataset.</p>
<p>If neither <code>index</code> or <code>id</code> is provided, return the last commit. If both
<code>index</code> and <code>id</code> are provided, <code>id</code> will not be used.</p>
<h5 id="args-18"><a class="header" href="#args-18">Args</a></h5>
<ul>
<li>
<p><strong>index</strong> (<em>Optional[int]</em>)</p>
<p>Index of the commit in this branch, <code>0</code> for the last commit, <code>-1</code> for the first commit.</p>
</li>
<li>
<p><strong>id</strong> (<em>Optional[str]</em>)</p>
<p>A prefix of ID of the commit.</p>
</li>
</ul>
<h5 id="returns-9"><a class="header" href="#returns-9">Returns</a></h5>
<p>A <code>Commit</code> instance representing retrieved commit.</p>
<h4 id="get_tag"><a class="header" href="#get_tag">get_tag</a></h4>
<pre><code class="language-python">get_tag(self, name: str, verbose: bool = True) ‑&gt; t9k.ah.core.Tag
</code></pre>
<p>Gets a tag of this Dataset.</p>
<h5 id="args-19"><a class="header" href="#args-19">Args</a></h5>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the tag.</p>
</li>
<li>
<p><strong>verbose</strong> (<em>bool</em>)</p>
<p>Whether to log error.</p>
</li>
</ul>
<h5 id="returns-10"><a class="header" href="#returns-10">Returns</a></h5>
<p>A <code>Tag</code> instance representing retrieved tag.</p>
<h4 id="list_branch"><a class="header" href="#list_branch">list_branch</a></h4>
<pre><code class="language-python">list_branch(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists branches in this Dataset.</p>
<h4 id="list_commit-2"><a class="header" href="#list_commit-2">list_commit</a></h4>
<pre><code class="language-python">list_commit(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists commits of this Dataset.</p>
<h4 id="list_object-2"><a class="header" href="#list_object-2">list_object</a></h4>
<pre><code class="language-python">list_object(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists objects of this Dataset.</p>
<h4 id="list_tag"><a class="header" href="#list_tag">list_tag</a></h4>
<pre><code class="language-python">list_tag(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists tags of this Dataset.</p>
<h4 id="update"><a class="header" href="#update">update</a></h4>
<pre><code class="language-python">update(self, name: Optional[str] = None, labels: Optional[Sequence[str]] = None, description: Optional[str] = None) ‑&gt; None
</code></pre>
<p>Updates the metadata of this Dataset.</p>
<p>If none of the args is provided, do nothing.</p>
<h5 id="args-20"><a class="header" href="#args-20">Args</a></h5>
<ul>
<li>
<p><strong>name</strong> (<em>Optional[str]</em>)</p>
<p>New name of this Dataset.</p>
</li>
<li>
<p><strong>labels</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>New labels of this Dataset.</p>
</li>
<li>
<p><strong>description</strong> (<em>Optional[str]</em>)</p>
<p>New description of this Dataset.</p>
</li>
</ul>
<h2 id="t9kahcorefolder"><a class="header" href="#t9kahcorefolder">t9k.ah.core.Folder</a></h2>
<pre><code class="language-python">Folder(path: str, id_: str, owner: str, asset_kind: str, name: str, labels: List[str], description: str, extra: str)
</code></pre>
<p>Represents a Asset Hub Folder in server.</p>
<h3 id="attributes-3"><a class="header" href="#attributes-3">Attributes</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the Folder.</p>
</li>
<li>
<p><strong>id</strong> (<em>str</em>)</p>
<p>ID of the Folder in server.</p>
</li>
<li>
<p><strong>owner</strong> (<em>str</em>)</p>
<p>Owner of the Folder.</p>
</li>
<li>
<p><strong>kind</strong> (<em>str</em>)</p>
<p>Kind of the Folder, is a string <code>'Model'</code> or <code>'Dataset'</code>.</p>
</li>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the Folder.</p>
</li>
<li>
<p><strong>labels</strong> (<em>List[str]</em>)</p>
<p>Labels of the Folder.</p>
</li>
<li>
<p><strong>description</strong> (<em>str</em>)</p>
<p>Description of the Folder.</p>
</li>
<li>
<p><strong>extra</strong> (<em>str</em>)</p>
<p>Extra information about the Folder.</p>
</li>
<li>
<p><strong>alive</strong> (<em>bool</em>)</p>
<p>Whether the Folder is alive.</p>
</li>
</ul>
<h3 id="methods-3"><a class="header" href="#methods-3">Methods</a></h3>
<h4 id="create_asset"><a class="header" href="#create_asset">create_asset</a></h4>
<pre><code class="language-python">create_asset(self, name: str, labels: Optional[Sequence[str]] = None, description: str = '', exist_ok: bool = False) ‑&gt; Union[t9k.ah.core.Model, t9k.ah.core.Dataset]
</code></pre>
<p>Creates an Asset in this Folder.</p>
<h5 id="args-21"><a class="header" href="#args-21">Args</a></h5>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the Asset.</p>
</li>
<li>
<p><strong>labels</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Labels of the Asset.</p>
</li>
<li>
<p><strong>description</strong> (<em>str</em>)</p>
<p>Description of the Asset.</p>
</li>
<li>
<p><strong>exist_ok</strong> (<em>bool</em>)</p>
<p>If True and Asset with <code>name</code> already exists, return a <code>Model</code> or <code>Dataset</code> instance representing this Asset; if False and Asset exists, raise a <code>RuntimeError</code>.</p>
</li>
</ul>
<h5 id="returns-11"><a class="header" href="#returns-11">Returns</a></h5>
<p>A <code>Model</code> or <code>Dataset</code> instance representing created Model or
Dataset, depending on Asset kind of this Folder.</p>
<h4 id="delete-17"><a class="header" href="#delete-17">delete</a></h4>
<pre><code class="language-python">delete(self) ‑&gt; None
</code></pre>
<p>Deletes this Folder.</p>
<h4 id="get_asset"><a class="header" href="#get_asset">get_asset</a></h4>
<pre><code class="language-python">get_asset(self, name: str) ‑&gt; Union[t9k.ah.core.Model, t9k.ah.core.Dataset]
</code></pre>
<p>Gets an Asset in this Folder.</p>
<p>If you want to get Asset directly by its path, use <code>ah.get_asset()</code>.</p>
<h5 id="args-22"><a class="header" href="#args-22">Args</a></h5>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the Asset.</p>
</li>
</ul>
<h5 id="returns-12"><a class="header" href="#returns-12">Returns</a></h5>
<p>A <code>Model</code> or <code>Dataset</code> instance representing retrieved Model or
Dataset, depending on Asset kind of this Folder.</p>
<h4 id="list_asset"><a class="header" href="#list_asset">list_asset</a></h4>
<pre><code class="language-python">list_asset(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists Assets in this Folder.</p>
<h4 id="update-1"><a class="header" href="#update-1">update</a></h4>
<pre><code class="language-python">update(self, name: Optional[str] = None, labels: Optional[Sequence[str]] = None, description: Optional[str] = None) ‑&gt; None
</code></pre>
<p>Updates the metadata of this Folder.</p>
<p>If none of the args is provided, do nothing.</p>
<h5 id="args-23"><a class="header" href="#args-23">Args</a></h5>
<ul>
<li>
<p><strong>name</strong> (<em>Optional[str]</em>)</p>
<p>New name of this Folder.</p>
</li>
<li>
<p><strong>labels</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>New labels of this Folder.</p>
</li>
<li>
<p><strong>description</strong> (<em>Optional[str]</em>)</p>
<p>New description of this Folder.</p>
</li>
</ul>
<h2 id="t9kahcoremodel"><a class="header" href="#t9kahcoremodel">t9k.ah.core.Model</a></h2>
<pre><code class="language-python">Model(id_: str, folder: t9k.ah.core.Folder, name: str, labels: List[str], description: str, extra: str)
</code></pre>
<p>Represents a Model in server.</p>
<h3 id="attributes-4"><a class="header" href="#attributes-4">Attributes</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the Model in server.</p>
</li>
<li>
<p><strong>id</strong> (<em>str</em>)</p>
<p>ID of the Model in server.</p>
</li>
<li>
<p><strong>folder</strong> (<em>t9k.ah.core.Folder</em>)</p>
<p>A <code>Folder</code> instance corresponding to the Folder that the Model belongs to.</p>
</li>
<li>
<p><strong>kind</strong> (<em>str</em>)</p>
<p>A string <code>'Model'</code>.</p>
</li>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the Model.</p>
</li>
<li>
<p><strong>labels</strong> (<em>List[str]</em>)</p>
<p>Labels of the Model.</p>
</li>
<li>
<p><strong>description</strong> (<em>str</em>)</p>
<p>Description of the Model.</p>
</li>
<li>
<p><strong>extra</strong> (<em>str</em>)</p>
<p>Extra information about the Model.</p>
</li>
<li>
<p><strong>alive</strong> (<em>bool</em>)</p>
<p>Whether the Model is alive.</p>
</li>
</ul>
<h3 id="ancestors-3"><a class="header" href="#ancestors-3">Ancestors</a></h3>
<ul>
<li><code>t9k.ah.core._Model</code></li>
</ul>
<h3 id="methods-4"><a class="header" href="#methods-4">Methods</a></h3>
<h4 id="create_branch"><a class="header" href="#create_branch">create_branch</a></h4>
<pre><code class="language-python">create_branch(self, name: str) ‑&gt; t9k.ah.core.Branch
</code></pre>
<p>Creates an empty branch of this Model.</p>
<h5 id="args-24"><a class="header" href="#args-24">Args</a></h5>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the branch.</p>
</li>
</ul>
<h5 id="returns-13"><a class="header" href="#returns-13">Returns</a></h5>
<p>A <code>Branch</code> instance representing created branch.</p>
<h4 id="delete-18"><a class="header" href="#delete-18">delete</a></h4>
<pre><code class="language-python">delete(self) ‑&gt; None
</code></pre>
<p>Deletes this Model.</p>
<h4 id="download-3"><a class="header" href="#download-3">download</a></h4>
<pre><code class="language-python">download(self, paths: Optional[Sequence[str]] = None, save_dir: str = '.') ‑&gt; None
</code></pre>
<p>Downloads objects of this Model.</p>
<h5 id="args-25"><a class="header" href="#args-25">Args</a></h5>
<ul>
<li>
<p><strong>paths</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Files or directories to download from this Dataset, is a sequence of paths in Dataset. Here format <code>a/.../b</code> signifies a file while <code>a/.../b/</code> signifies a directory. Defaults to all objects.</p>
</li>
<li>
<p><strong>save_dir</strong> (<em>str</em>)</p>
<p>Local directory which objects are downloaded to. If the directory does not exist, create it. Defaults to current working directory.</p>
</li>
</ul>
<h4 id="get_branch"><a class="header" href="#get_branch">get_branch</a></h4>
<pre><code class="language-python">get_branch(self, name: str, verbose: bool = True) ‑&gt; t9k.ah.core.Branch
</code></pre>
<p>Gets a branch of this Model.</p>
<h5 id="args-26"><a class="header" href="#args-26">Args</a></h5>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the branch.</p>
</li>
<li>
<p><strong>verbose</strong> (<em>bool</em>)</p>
<p>Whether to log error.</p>
</li>
</ul>
<h5 id="returns-14"><a class="header" href="#returns-14">Returns</a></h5>
<p>A <code>Branch</code> instance representing retrieved branch.</p>
<h4 id="get_commit-2"><a class="header" href="#get_commit-2">get_commit</a></h4>
<pre><code class="language-python">get_commit(self, id: str) ‑&gt; t9k.ah.core.Commit
</code></pre>
<p>Gets a commit of this Model.</p>
<p>If no commit matches <code>id</code>, or two or more commits matche <code>id</code>,
raise a <code>RuntimeError</code>.</p>
<h5 id="args-27"><a class="header" href="#args-27">Args</a></h5>
<ul>
<li>
<p><strong>id</strong> (<em>str</em>)</p>
<p>A prefix of ID of the commit.</p>
</li>
</ul>
<h5 id="returns-15"><a class="header" href="#returns-15">Returns</a></h5>
<p>A <code>Commit</code> instance representing retrieved commit.</p>
<h4 id="get_tag-1"><a class="header" href="#get_tag-1">get_tag</a></h4>
<pre><code class="language-python">get_tag(self, name: str, verbose: bool = True) ‑&gt; t9k.ah.core.Tag
</code></pre>
<p>Gets a tag of this Model.</p>
<h5 id="args-28"><a class="header" href="#args-28">Args</a></h5>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the tag.</p>
</li>
<li>
<p><strong>verbose</strong> (<em>bool</em>)</p>
<p>Whether to log error.</p>
</li>
</ul>
<h5 id="returns-16"><a class="header" href="#returns-16">Returns</a></h5>
<p>A <code>Tag</code> instance representing retrieved tag.</p>
<h4 id="list_branch-1"><a class="header" href="#list_branch-1">list_branch</a></h4>
<pre><code class="language-python">list_branch(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists branches in this Model.</p>
<h4 id="list_object-3"><a class="header" href="#list_object-3">list_object</a></h4>
<pre><code class="language-python">list_object(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists objects of this Model.</p>
<h4 id="list_tag-1"><a class="header" href="#list_tag-1">list_tag</a></h4>
<pre><code class="language-python">list_tag(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists tags of this Model.</p>
<h4 id="update-2"><a class="header" href="#update-2">update</a></h4>
<pre><code class="language-python">update(self, name: Optional[str] = None, labels: Optional[Sequence[str]] = None, description: Optional[str] = None) ‑&gt; None
</code></pre>
<p>Updates the metadata of this Model.</p>
<p>If none of the args is provided, do nothing.</p>
<h5 id="args-29"><a class="header" href="#args-29">Args</a></h5>
<ul>
<li>
<p><strong>name</strong> (<em>Optional[str]</em>)</p>
<p>New name of this Model.</p>
</li>
<li>
<p><strong>labels</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>New labels of this Model.</p>
</li>
<li>
<p><strong>description</strong> (<em>Optional[str]</em>)</p>
<p>New description of this Model.</p>
</li>
</ul>
<h2 id="t9kahcoretag"><a class="header" href="#t9kahcoretag">t9k.ah.core.Tag</a></h2>
<pre><code class="language-python">Tag(asset: Union[t9k.ah.core.Model, t9k.ah.core.Dataset], name: str, commit_id: str)
</code></pre>
<p>Represents a tag of Asset.</p>
<h3 id="attributes-5"><a class="header" href="#attributes-5">Attributes</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Path of the tag.</p>
</li>
<li>
<p><strong>asset</strong> (<em>Union[t9k.ah.core.Model, t9k.ah.core.Dataset]</em>)</p>
<p>A <code>Model</code> or <code>Dataset</code> instance corresponding to the Asset that the tag belongs to.</p>
</li>
<li>
<p><strong>kind</strong> (<em>str</em>)</p>
<p>A string <code>'tag'</code>.</p>
</li>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the tag.</p>
</li>
<li>
<p><strong>commit_id</strong> (<em>str</em>)</p>
<p>ID of the commit that the tag points to.</p>
</li>
<li>
<p><strong>alive</strong> (<em>bool</em>)</p>
<p>Whether the tag is alive.</p>
</li>
</ul>
<h3 id="ancestors-4"><a class="header" href="#ancestors-4">Ancestors</a></h3>
<ul>
<li><code>t9k.ah.core._Ref</code></li>
</ul>
<h3 id="methods-5"><a class="header" href="#methods-5">Methods</a></h3>
<h4 id="create_tag-2"><a class="header" href="#create_tag-2">create_tag</a></h4>
<pre><code class="language-python">create_tag(self, name: str) ‑&gt; t9k.ah.core.Tag
</code></pre>
<p>Creates another tag that points to this tag.</p>
<h5 id="args-30"><a class="header" href="#args-30">Args</a></h5>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the tag.</p>
</li>
</ul>
<h5 id="returns-17"><a class="header" href="#returns-17">Returns</a></h5>
<p>A <code>Tag</code> instance representing created tag.</p>
<h4 id="delete-19"><a class="header" href="#delete-19">delete</a></h4>
<pre><code class="language-python">delete(self) ‑&gt; None
</code></pre>
<p>Deletes this tag.</p>
<h4 id="download-4"><a class="header" href="#download-4">download</a></h4>
<pre><code class="language-python">download(self, paths: Optional[Sequence[str]] = None, save_dir: str = '.') ‑&gt; None
</code></pre>
<p>Downloads objects of this tag.</p>
<h5 id="args-31"><a class="header" href="#args-31">Args</a></h5>
<ul>
<li>
<p><strong>paths</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Files or directories to download from this tag, is a sequence of paths in tag. Here format <code>a/.../b</code> signifies a file while <code>a/.../b/</code> signifies a directory. Defaults to all objects.</p>
</li>
<li>
<p><strong>save_dir</strong> (<em>str</em>)</p>
<p>Local directory which objects are downloaded to. If the directory does not exist, create it. Defaults to current working directory.</p>
</li>
</ul>
<h4 id="list_commit-3"><a class="header" href="#list_commit-3">list_commit</a></h4>
<pre><code class="language-python">list_commit(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists commits of this tag.</p>
<h4 id="list_object-4"><a class="header" href="#list_object-4">list_object</a></h4>
<pre><code class="language-python">list_object(self) ‑&gt; List[Dict[str, Any]]
</code></pre>
<p>Lists objects of this tag.</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="t9kconfig"><a class="header" href="#t9kconfig">t9k.config</a></h1>
<h2 id="t9kconfigconfig"><a class="header" href="#t9kconfigconfig">t9k.config.Config</a></h2>
<pre><code class="language-python">Config()
</code></pre>
<p>SDK config.</p>
<h3 id="methods-6"><a class="header" href="#methods-6">Methods</a></h3>
<h4 id="get-17"><a class="header" href="#get-17">get</a></h4>
<pre><code class="language-python">get(self, key: str, default: Any = None) ‑&gt; Any
</code></pre>
<h4 id="items"><a class="header" href="#items">items</a></h4>
<pre><code class="language-python">items(self) ‑&gt; ItemsView[str, Any]
</code></pre>
<h4 id="to_dict"><a class="header" href="#to_dict">to_dict</a></h4>
<pre><code class="language-python">to_dict(self) ‑&gt; Dict[str, Any]
</code></pre>
<h4 id="update-3"><a class="header" href="#update-3">update</a></h4>
<pre><code class="language-python">update(self, new_config: Dict[str, Any]) ‑&gt; None
</code></pre>
<h2 id="t9kconfigconfigitem"><a class="header" href="#t9kconfigconfigitem">t9k.config.ConfigItem</a></h2>
<pre><code class="language-python">ConfigItem(name: str, value: Optional[Any] = None, processor: Union[Callable, Sequence[Callable], None] = None, validator: Union[Callable, Sequence[Callable], None] = None, hook: Union[Callable, Sequence[Callable], None] = None)
</code></pre>
<p>SDK config item.</p>
<h3 id="attributes-6"><a class="header" href="#attributes-6">Attributes</a></h3>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of config item.</p>
</li>
<li>
<p><strong>value</strong> (<em>Any</em>)</p>
<p>Value of config item.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="t9kem"><a class="header" href="#t9kem">t9k.em</a></h1>
<h2 id="t9kemartifactartifact"><a class="header" href="#t9kemartifactartifact">t9k.em.artifact.Artifact</a></h2>
<pre><code class="language-python">Artifact(metadata: Dict[str, Any], objects: Optional[Dict[str, Dict[str, Any]]] = None)
</code></pre>
<p>Implementation of Artifact, a set of files that a Run inputs or outputs.</p>
<h3 id="args-32"><a class="header" href="#args-32">Args</a></h3>
<ul>
<li>
<p><strong>metadata</strong> (<em>Dict[str, Any]</em>)</p>
<p>Metadata to initialize a new Artifact.</p>
</li>
<li>
<p><strong>objects</strong> (<em>Optional[Dict[str, Dict[str, Any]]]</em>)</p>
<p>Data of objects of the Artifact.</p>
</li>
</ul>
<h3 id="attributes-7"><a class="header" href="#attributes-7">Attributes</a></h3>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the Artifact.</p>
</li>
<li>
<p><strong>labels</strong> (<em>List[str]</em>)</p>
<p>Labels of the Artifact.</p>
</li>
<li>
<p><strong>description</strong> (<em>str</em>)</p>
<p>Description of the Artifact.</p>
</li>
<li>
<p><strong>created_timestamp</strong> (<em>str</em>)</p>
<p>Created timestamp of the Artifact.</p>
</li>
<li>
<p><strong>alternative_name</strong> (<em>str</em>)</p>
<p>Alternative name of the Artifact.</p>
</li>
<li>
<p><strong>objects</strong> (<em>List[Dict[str, str]]</em>)</p>
<p>Data of objects of the Artifact.</p>
</li>
<li>
<p><strong>remote</strong> (<em>List[Dict[str, str]]</em>)</p>
<p>Upload and download history of the Artifact.</p>
</li>
<li>
<p><strong>local</strong> (<em>str</em>)</p>
<p>Local directory of the Artifact.</p>
</li>
</ul>
<h3 id="methods-7"><a class="header" href="#methods-7">Methods</a></h3>
<h4 id="add_dir"><a class="header" href="#add_dir">add_dir</a></h4>
<pre><code class="language-python">add_dir(self, dir_path: str, obj_path: Optional[str] = None) ‑&gt; None
</code></pre>
<p>Adds all files under a local directory as objects of the Artifact.</p>
<p>The directory will be copied to local directory of the Artifact, the
specific subpath depends on its obj_path, for example:</p>
<pre><code># dir copied to `&lt;local-dir&gt;/a`
artifact.add_dir(dir_path='a/')
# or
artifact.add_dir(dir_path='a')
# or
artifact.add_dir(dir_path='a/', obj_path='a')

# dir copied to `&lt;local-dir&gt;/b/a`
artifact.add_dir(dir_path='a/', obj_path='b/')
# or
artifact.add_dir(dir_path='a/', obj_path='b/a')
</code></pre>
<h4 id="add_file"><a class="header" href="#add_file">add_file</a></h4>
<pre><code class="language-python">add_file(self, file_path: str, obj_path: Optional[str] = None) ‑&gt; None
</code></pre>
<p>Adds a local file as an object of the Artifact.</p>
<p>The file will be copied to local directory of the Artifact, the
specific subpath depends on its object path, for example:</p>
<pre><code># file copied to `&lt;local-dir&gt;/1.png`
artifact.add_file(file_path='1.png')
# or
artifact.add_file(file_path='1.png', obj_path='1.png')

# file copied to `&lt;local-dir&gt;/a/1.png`
artifact.add_file(file_path='1.png', obj_path='a/')
# or
artifact.add_file(file_path='1.png', obj_path='a/1.png')
</code></pre>
<h4 id="add_reference"><a class="header" href="#add_reference">add_reference</a></h4>
<pre><code class="language-python">add_reference(self, uri: str, obj_path: Optional[str] = None) ‑&gt; None
</code></pre>
<p>Adds a URI as an object reference to the Artifact.</p>
<h4 id="parse_from_dict"><a class="header" href="#parse_from_dict">parse_from_dict</a></h4>
<pre><code class="language-python">parse_from_dict(self, data: Dict[str, Any]) ‑&gt; None
</code></pre>
<p>Parses an Artifact instance from a dict.</p>
<h4 id="to_dict-1"><a class="header" href="#to_dict-1">to_dict</a></h4>
<pre><code class="language-python">to_dict(self) ‑&gt; Dict[str, Any]
</code></pre>
<p>Converts Artifact instance to a dict and returns it.</p>
<h4 id="upload"><a class="header" href="#upload">upload</a></h4>
<pre><code class="language-python">upload(self, folder: str = 'default', make_folder: bool = False, conflict_strategy: str = 'new') ‑&gt; None
</code></pre>
<p>Uploads this Artifact to server.</p>
<h5 id="args-33"><a class="header" href="#args-33">Args</a></h5>
<ul>
<li>
<p><strong>folder</strong> (<em>str</em>)</p>
<p>Path of the Folder to which the Artifact is uploaded. If the provided path does not start with ‘/’, <code>/&lt;current-user&gt;/</code> is prepended to it.</p>
</li>
<li>
<p><strong>make_folder</strong> (<em>bool</em>)</p>
<p>If True and Folder with path <code>folder</code> does not exist, make the Folder and parent Folders as needed.</p>
</li>
<li>
<p><strong>conflict_strategy</strong> (<em>str</em>)</p>
<p>Strategy adopted when an Artifact with the same name as the Artifact to be uploaded already exists in the Folder, must be ‘skip’, ‘error’, ‘new’ or ‘replace’. If ‘skip’, skip the upload; if ‘error’, error out; if ‘new’, upload with the alternative name of Artifact; if ‘replace’, delete the existing Artifact and upload.</p>
</li>
</ul>
<h2 id="t9kemcontainersparams"><a class="header" href="#t9kemcontainersparams">t9k.em.containers.Params</a></h2>
<pre><code class="language-python">Params(upload: Callable, init_hparams: Dict[str, Union[str, int, float, bool, None, List[~T], Tuple[], Dict[~KT, ~VT]]] = None)
</code></pre>
<p>Container class to hold hyperparameters of Run.</p>
<p>It is recommended to set all hyperparameters by calling <code>update</code> method once before building the model. Nevertheless, you are free to operate hyperparameters like items of a dict or attributes of an object.</p>
<h3 id="examples-11"><a class="header" href="#examples-11">Examples</a></h3>
<p>Recommended method of setting hyperparameters:</p>
<pre><code class="language-python">run.update({
    'batch_size': 32,
    'epochs': 10,
})
</code></pre>
<p>Assign parameter like an item of dict or attribute of object:</p>
<pre><code class="language-python">run.params['batch_size'] = 32
run.params.epochs = 10
</code></pre>
<h3 id="args-34"><a class="header" href="#args-34">Args</a></h3>
<ul>
<li>
<p><strong>upload</strong> (<em>Callable</em>)</p>
<p>Function that is called to upload hyperparameters every time hyperparameters are updated.</p>
</li>
<li>
<p><strong>init_hparams</strong> (<em>Dict[str, Union[str, int, float, bool, None, List[~T], Tuple[], Dict[~KT, ~VT]]]</em>)</p>
<p>Initial hyperparameters.</p>
</li>
</ul>
<h3 id="ancestors-5"><a class="header" href="#ancestors-5">Ancestors</a></h3>
<ul>
<li><code>collections.abc.MutableMapping</code></li>
</ul>
<h3 id="methods-8"><a class="header" href="#methods-8">Methods</a></h3>
<h4 id="as_dict"><a class="header" href="#as_dict">as_dict</a></h4>
<pre><code class="language-python">as_dict(self)
</code></pre>
<h4 id="items-1"><a class="header" href="#items-1">items</a></h4>
<pre><code class="language-python">items(self)
</code></pre>
<p>D.items() -&gt; a set-like object providing a view on D’s items</p>
<h4 id="keys"><a class="header" href="#keys">keys</a></h4>
<pre><code class="language-python">keys(self)
</code></pre>
<p>D.keys() -&gt; a set-like object providing a view on D’s keys</p>
<h4 id="parse"><a class="header" href="#parse">parse</a></h4>
<pre><code class="language-python">parse(self, dist_tf_strategy=None, dist_torch_model=None, dist_hvd=None)
</code></pre>
<p>Parses hyperparameters from various objects of various frameworks.</p>
<h5 id="args-35"><a class="header" href="#args-35">Args</a></h5>
<ul>
<li>
<p><strong>dist_tf_strategy</strong></p>
<p>TensorFlow distribution strategy instance if <code>tf.distribute</code> is used for distributed training.</p>
</li>
<li>
<p><strong>dist_torch_model</strong></p>
<p>PyTorch model wrapped with DP or DDP if <code>torch.distributed</code> is used for distributed training.</p>
</li>
<li>
<p><strong>dist_hvd</strong></p>
<p>Used module such as <code>horovod.keras</code> and <code>horovod.torch</code> if Horovod is used for distributed training.</p>
</li>
</ul>
<h4 id="update-4"><a class="header" href="#update-4">update</a></h4>
<pre><code class="language-python">update(self, new_params: Dict[str, Any], override: bool = True)
</code></pre>
<p>Updates with new params.</p>
<h5 id="args-36"><a class="header" href="#args-36">Args</a></h5>
<ul>
<li>
<p><strong>new_params</strong> (<em>Dict[str, Any]</em>)</p>
<p>New params to be updated with.</p>
</li>
<li>
<p><strong>override</strong> (<em>bool</em>)</p>
<p>Whether to override current params.</p>
</li>
</ul>
<h4 id="values"><a class="header" href="#values">values</a></h4>
<pre><code class="language-python">values(self)
</code></pre>
<p>D.values() -&gt; an object providing a view on D’s values</p>
<h2 id="t9kemcreate_artifact"><a class="header" href="#t9kemcreate_artifact">t9k.em.create_artifact</a></h2>
<pre><code class="language-python">create_artifact(name: str, labels: Optional[Sequence[str]] = None, description: str = '') ‑&gt; t9k.em.artifact.Artifact
</code></pre>
<p>Creates and initializes a new Artifact.</p>
<p>The local files of Artifact are placed under the parent directory specified by the environment variable <code>EM_ARTIFACT_PARENT_DIR</code> (default is relative path <code>.em/artifacts</code>).</p>
<h3 id="examples-12"><a class="header" href="#examples-12">Examples</a></h3>
<pre><code class="language-python">tensorboard_artifact = em.create_artifact(name='tensorboard_logs')
</code></pre>
<h3 id="args-37"><a class="header" href="#args-37">Args</a></h3>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the Artifact.</p>
</li>
<li>
<p><strong>labels</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Labels of the Artifact.</p>
</li>
<li>
<p><strong>description</strong> (<em>str</em>)</p>
<p>Description of the Artifact.</p>
</li>
</ul>
<h3 id="returns-18"><a class="header" href="#returns-18">Returns</a></h3>
<p>An Artifact instance created and initialized.</p>
<h2 id="t9kemcreate_run"><a class="header" href="#t9kemcreate_run">t9k.em.create_run</a></h2>
<pre><code class="language-python">create_run(config_path: Optional[str] = None, name: str = 'default', hparams: Optional[Dict[str, Any]] = None, labels: Optional[Sequence[str]] = None, description: str = '', auto_upload: bool = False, folder: str = 'default', make_folder: bool = False, conflict_strategy: str = 'new') ‑&gt; t9k.em.run.Run
</code></pre>
<p>Creates and initializes a new Run.</p>
<p>The local files of Run are placed under the parent directory specified by the environment variable <code>EM_RUN_PARENT_DIR</code> (default is relative path <code>.em/runs</code>).</p>
<h3 id="examples-13"><a class="header" href="#examples-13">Examples</a></h3>
<p>Basic usage:</p>
<pre><code class="language-python">from t9k import em

run = em.create_run(name='cnn_keras',
                    folder='cv/image-classification/mnist')
</code></pre>
<p>Provide initial parameters of Run:</p>
<pre><code class="language-python">hparams = {
    'batch_size': 32,
    'epochs': 1,
    'learning_rate': 0.001,
    'conv_channels1': 32,
    'conv_channels2': 64,
    'conv_channels3': 64,
    'conv_kernel_size': 3,
    'maxpool_size': 2,
    'linear_features1': 64,
}

run = em.create_run(name='cnn_keras',
                    hparams=hparams,
                    folder_path='cv/image-classification/mnist')
</code></pre>
<p>Provide a Run config file:</p>
<pre><code class="language-python">run = em.create_run(config_path='./run_config.yaml')
</code></pre>
<p>where the config file <code>run_config.yaml</code> is like:</p>
<pre><code class="language-python">name: cnn_keras
hparams:
  batch_size: 32
  epochs: 1
  learning_rate: 0.001
  conv_channels1: 32
  conv_channels2: 64
  conv_channels3: 64
  conv_kernel_size: 3
  maxpool_size: 2
  linear_features1: 64
labels:
- Keras
description: Train a simple CNN model that classifies images of handwritten digits.
</code></pre>
<h3 id="args-38"><a class="header" href="#args-38">Args</a></h3>
<ul>
<li>
<p><strong>config_path</strong> (<em>Optional[str]</em>)</p>
<p>Local path of the Run config file. For all of the following args, the values parsed from the config file take precedence over values passed in.</p>
</li>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the Run.</p>
</li>
<li>
<p><strong>hparams</strong> (<em>Optional[Dict[str, Any]]</em>)</p>
<p>Initial hyperparameters of the Run.</p>
</li>
<li>
<p><strong>labels</strong> (<em>Optional[Sequence[str]]</em>)</p>
<p>Labels of the Run.</p>
</li>
<li>
<p><strong>description</strong> (<em>str</em>)</p>
<p>Description of the Run.</p>
</li>
<li>
<p><strong>auto_upload</strong> (<em>bool</em>)</p>
<p>Whether to upload the Run and its data automatically and asynchronously. If False, all of the following args will not be used.</p>
</li>
<li>
<p><strong>folder</strong> (<em>str</em>)</p>
<p>Path of the Folder to which the Run is uploaded. If the provided path does not start with ‘/’, <code>/&lt;current-user&gt;/</code> is prepended to it. If <code>auto_upload</code> is False, this arg will not be used.</p>
</li>
<li>
<p><strong>make_folder</strong> (<em>bool</em>)</p>
<p>If True and Folder with path <code>folder</code> does not exist, make the Folder and parent Folders as needed. If <code>auto_upload</code> is False, this arg will not be used.</p>
</li>
<li>
<p><strong>conflict_strategy</strong> (<em>str</em>)</p>
<p>Strategy adopted when a Run with the same name as the Run to be uploaded already exists in the Folder, must be ‘skip’, ‘error’, ‘new’ or ‘replace’. If ‘skip’, skip the upload; if ‘error’, error out; if ‘new’, upload with the alternative name of Run; if ‘replace’, delete the existing Run and upload. If <code>auto_upload</code> is False, this arg will not be used.</p>
</li>
</ul>
<h3 id="returns-19"><a class="header" href="#returns-19">Returns</a></h3>
<p>A Run instance created and initialized.</p>
<h2 id="t9kemload_artifact"><a class="header" href="#t9kemload_artifact">t9k.em.load_artifact</a></h2>
<pre><code class="language-python">load_artifact(path: str) ‑&gt; t9k.em.artifact.Artifact
</code></pre>
<p>Loads an Artifact from local or server.</p>
<p>This function will first search for the corresponding local directory, followed by remote path. If the path is not found in either location, raise a <code>RuntimeError</code>.</p>
<p>In the case of the remote path, if the provided path does not start with ‘/’, <code>/&lt;current-user&gt;/</code> is prepended to it.</p>
<h3 id="examples-14"><a class="header" href="#examples-14">Examples</a></h3>
<p>Load by local path:</p>
<pre><code class="language-python">em.load_artifact(path=
    '.em/artifacts/tensorboard_logs_220823_194728_4e48t2')
</code></pre>
<p>Load by remote path:</p>
<pre><code class="language-python">em.load_artifact(path='/user/path/to/tensorboard_logs')
</code></pre>
<h3 id="args-39"><a class="header" href="#args-39">Args</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Local directory of the Artifact, or path of the Artifact in server.</p>
</li>
</ul>
<h3 id="returns-20"><a class="header" href="#returns-20">Returns</a></h3>
<p>An Artifact instance loaded.</p>
<h2 id="t9kemload_run"><a class="header" href="#t9kemload_run">t9k.em.load_run</a></h2>
<pre><code class="language-python">load_run(path: str, auto_upload: bool = False, folder: str = 'default', make_folder: bool = False, conflict_strategy: str = 'new') ‑&gt; t9k.em.run.Run
</code></pre>
<p>Loads a Run from local or server.</p>
<p>This function will first search for the corresponding local path, followed by remote path. If the path is not found in either location, raise a <code>RuntimeError</code>.</p>
<p>In the case of the remote path, if the provided path does not start with ‘/’, <code>/&lt;current-user&gt;/</code> is prepended to it.</p>
<h3 id="examples-15"><a class="header" href="#examples-15">Examples</a></h3>
<p>Load by local path:</p>
<pre><code class="language-python">em.load_run(path='.em/runs/cnn_keras_220823_194728_4e48t2')
</code></pre>
<p>Load by remote path:</p>
<pre><code class="language-python">em.load_run(path='/user/path/to/cnn_keras')
</code></pre>
<h3 id="args-40"><a class="header" href="#args-40">Args</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Local directory of the Run, or path of the Run in server.</p>
</li>
<li>
<p><strong>auto_upload</strong> (<em>bool</em>)</p>
<p>Whether to upload the Run and its data automatically and asynchronously. If False, all of the following args will not be used.</p>
</li>
<li>
<p><strong>folder</strong> (<em>str</em>)</p>
<p>Path of the Folder to which the Run is uploaded. If the provided path does not start with ‘/’, <code>/&lt;current-user&gt;/</code> is prepended to it. If <code>auto_upload</code> is False, this arg will not be used.</p>
</li>
<li>
<p><strong>make_folder</strong> (<em>bool</em>)</p>
<p>If True and Folder with path <code>folder</code> does not exist, make the Folder and parent Folders as needed. If <code>auto_upload</code> is False, this arg will not be used.</p>
</li>
<li>
<p><strong>conflict_strategy</strong> (<em>str</em>)</p>
<p>Strategy adopted when a Run with the same name as the Run to be uploaded already exists in the Folder, must be ‘skip’, ‘error’, ‘new’ or ‘replace’. If ‘skip’, skip the upload; if ‘error’, error out; if ‘new’, upload with the alternative name of Run; if ‘replace’, delete the existing Run and upload. If <code>auto_upload</code> is False, this arg will not be used.</p>
</li>
</ul>
<h3 id="returns-21"><a class="header" href="#returns-21">Returns</a></h3>
<p>A Run instance loaded.</p>
<h2 id="t9kemlogin"><a class="header" href="#t9kemlogin">t9k.em.login</a></h2>
<pre><code class="language-python">login(ais_host: Optional[str] = None, api_key: Optional[str] = None, timeout: Optional[int] = None) ‑&gt; None
</code></pre>
<p>Logs in to AIStore server.</p>
<p>Sets up the client that corresponds with AIStore server.</p>
<h3 id="args-41"><a class="header" href="#args-41">Args</a></h3>
<ul>
<li>
<p><strong>ais_host</strong> (<em>Optional[str]</em>)</p>
<p>URL of AIStore server. Defaults to <code>t9k.CONFIG['aistore_host']</code>.</p>
</li>
<li>
<p><strong>api_key</strong> (<em>Optional[str]</em>)</p>
<p>API Key for requesting server. Defaults to <code>t9k.CONFIG['api_key']</code>.</p>
</li>
<li>
<p><strong>timeout</strong> (<em>Optional[int]</em>)</p>
<p>How many seconds to wait for server to send data before giving up.</p>
</li>
</ul>
<h3 id="raises-1"><a class="header" href="#raises-1">Raises</a></h3>
<ul>
<li>
<p><strong>requests.HTTPError</strong></p>
<p>Unable to connect to the server and <code>unable_to_connect_ok</code> is False.</p>
</li>
</ul>
<h2 id="t9kemlogout"><a class="header" href="#t9kemlogout">t9k.em.logout</a></h2>
<pre><code class="language-python">logout() ‑&gt; None
</code></pre>
<p>Logs out from the current AIStore server.</p>
<p>The client is unset, it can no longer correspond with AIStore server until it is set up again.</p>
<h2 id="t9kemrunrun"><a class="header" href="#t9kemrunrun">t9k.em.run.Run</a></h2>
<pre><code class="language-python">Run(metadata: Dict[str, Any], hparams: Optional[Dict[str, Any]] = None, metrics: Optional[Dict[str, List[Dict[str, Dict[str, Union[str, int, float]]]]]] = None, platform: Optional[Dict[str, Any]] = None, git: Optional[Dict[str, Any]] = None)
</code></pre>
<p>Implementation of Run, a run of a specific model for certain ML task.</p>
<h3 id="args-42"><a class="header" href="#args-42">Args</a></h3>
<ul>
<li>
<p><strong>metadata</strong> (<em>Dict[str, Any]</em>)</p>
<p>Metadata to initialize a new Run.</p>
</li>
<li>
<p><strong>hparams</strong> (<em>Optional[Dict[str, Any]]</em>)</p>
<p>Hyperparameters of the Run.</p>
</li>
<li>
<p><strong>metrics</strong> (<em>Optional[Dict[str, List[Dict[str, Dict[str, Union[str, int, float]]]]]]</em>)</p>
<p>Metrics of the Run.</p>
</li>
<li>
<p><strong>platform</strong> (<em>Optional[Dict[str, Any]]</em>)</p>
<p>Platform information of the Run.</p>
</li>
<li>
<p><strong>git</strong> (<em>Optional[Dict[str, Any]]</em>)</p>
<p>Git information of the Run.</p>
</li>
</ul>
<h3 id="attributes-8"><a class="header" href="#attributes-8">Attributes</a></h3>
<ul>
<li>
<p><strong>name</strong> (<em>str</em>)</p>
<p>Name of the Run.</p>
</li>
<li>
<p><strong>labels</strong> (<em>List[str]</em>)</p>
<p>Labels of the Run.</p>
</li>
<li>
<p><strong>description</strong> (<em>str</em>)</p>
<p>Description of the Run.</p>
</li>
<li>
<p><strong>start_timestamp</strong> (<em>str</em>)</p>
<p>Start timestamp of the Run.</p>
</li>
<li>
<p><strong>end_timestamp</strong> (<em>str</em>)</p>
<p>End timestamp of the Run.</p>
</li>
<li>
<p><strong>status</strong> (<em>str</em>)</p>
<p>Status of the Run.</p>
</li>
<li>
<p><strong>alternative_name</strong> (<em>str</em>)</p>
<p>Alternative name of the Run.</p>
</li>
<li>
<p><strong>associations</strong> (<em>Dict[str, List[Dict[str, str]]]</em>)</p>
<p>Input and output resources of the Run.</p>
</li>
<li>
<p><strong>hparams</strong> (<em>Any</em>)</p>
<p>Hyperparameters of the Run.</p>
</li>
<li>
<p><strong>metrics</strong> (<em>Dict[str, List[Dict[str, Dict[str, Union[str, int, float]]]]]</em>)</p>
<p>Metrics produced in the Run.</p>
</li>
<li>
<p><strong>platform</strong> (<em>Dict[str, Any]</em>)</p>
<p>Platform information of the Run.</p>
</li>
<li>
<p><strong>git</strong> (<em>Dict[str, Any]</em>)</p>
<p>Git information of the Run.</p>
</li>
<li>
<p><strong>remote</strong> (<em>List[Dict[str, str]]</em>)</p>
<p>Upload and download history of the Run.</p>
</li>
<li>
<p><strong>local</strong> (<em>str</em>)</p>
<p>Local directory of the Run.</p>
</li>
</ul>
<h3 id="methods-9"><a class="header" href="#methods-9">Methods</a></h3>
<h4 id="finish"><a class="header" href="#finish">finish</a></h4>
<pre><code class="language-python">finish(*args, **kwargs)
</code></pre>
<h4 id="log"><a class="header" href="#log">log</a></h4>
<pre><code class="language-python">log(self, type: str, metrics: Dict[str, float], step: int, epoch: Optional[int] = None) ‑&gt; None
</code></pre>
<p>Logs a set of metrics of Run.</p>
<h5 id="args-43"><a class="header" href="#args-43">Args</a></h5>
<ul>
<li>
<p><strong>type</strong> (<em>str</em>)</p>
<p>Type of the metrics, ‘train’ (or ‘training’), ‘val’ (or ‘validate’, ‘validation’) and ‘test’ (or ‘testing’, ‘eval’, ‘evaluate’, ‘evaluation’) for training, validation and testing metrics respectively. Besides, you can also use other arbitrary string as custom type of the metrics.</p>
</li>
<li>
<p><strong>metrics</strong> (<em>Dict[str, float]</em>)</p>
<p>Additional metrics to be logged.</p>
</li>
<li>
<p><strong>step</strong> (<em>int</em>)</p>
<p>Number of the step that the metrics belong to.</p>
</li>
<li>
<p><strong>epoch</strong> (<em>Optional[int]</em>)</p>
<p>Number of the epoch that the metrics belong to.</p>
</li>
</ul>
<h4 id="mark_input"><a class="header" href="#mark_input">mark_input</a></h4>
<pre><code class="language-python">mark_input(self, resource: Union[t9k.em.artifact.Artifact, t9k.ah.core.Model, t9k.ah.core.Dataset, t9k.ah.core.Branch, t9k.ah.core.Tag, t9k.ah.core.Commit]) ‑&gt; None
</code></pre>
<p>Marks an Artifact, Model or Dataset as an input of this Run.</p>
<h4 id="mark_output"><a class="header" href="#mark_output">mark_output</a></h4>
<pre><code class="language-python">mark_output(self, resource: Union[t9k.em.artifact.Artifact, t9k.ah.core.Model, t9k.ah.core.Dataset, t9k.ah.core.Branch, t9k.ah.core.Tag, t9k.ah.core.Commit]) ‑&gt; None
</code></pre>
<p>Marks an Artifact, Model or Dataset as an output of this Run.</p>
<h4 id="parse_from_dict-1"><a class="header" href="#parse_from_dict-1">parse_from_dict</a></h4>
<pre><code class="language-python">parse_from_dict(self, data: Dict[str, Any]) ‑&gt; None
</code></pre>
<p>Parses a Run instance from a dict.</p>
<h4 id="to_dict-2"><a class="header" href="#to_dict-2">to_dict</a></h4>
<pre><code class="language-python">to_dict(self) ‑&gt; Dict[str, Any]
</code></pre>
<p>Converts Run instance to a dict and returns it.</p>
<h4 id="upload-1"><a class="header" href="#upload-1">upload</a></h4>
<pre><code class="language-python">upload(self, folder: str = 'default', make_folder: bool = False, conflict_strategy: str = 'new') ‑&gt; None
</code></pre>
<p>Uploads this Run to server.</p>
<p>If this Run has input or output Artifacts, these Artifacts are uploaded
as well if they have not been uploaded, and these associations are
uploaded.</p>
<h5 id="args-44"><a class="header" href="#args-44">Args</a></h5>
<ul>
<li>
<p><strong>folder</strong> (<em>str</em>)</p>
<p>Path of the Folder to which the Run is uploaded. If the provided path does not start with ‘/’, <code>/&lt;current-user&gt;/</code> is prepended to it.</p>
</li>
<li>
<p><strong>make_folder</strong> (<em>bool</em>)</p>
<p>If True and Folder with path <code>folder</code> does not exist, make the Folder and parent Folders as needed.</p>
</li>
<li>
<p><strong>conflict_strategy</strong> (<em>str</em>)</p>
<p>Strategy adopted when a Run with the same name as the Run to be uploaded already exists in the Folder, must be ‘skip’, ‘error’, ‘new’ or ‘replace’. If ‘skip’, skip the upload; if ‘error’, error out; if ‘new’, upload with the alternative name of Run; if ‘replace’, delete the existing Run and upload.</p>
</li>
</ul>
<h2 id="t9kemupload"><a class="header" href="#t9kemupload">t9k.em.upload</a></h2>
<pre><code class="language-python">upload(path: str, folder: str = 'default', make_folder: bool = False, conflict_strategy: str = 'new') ‑&gt; None
</code></pre>
<p>Upload local Runs or Artifacts.</p>
<h3 id="examples-16"><a class="header" href="#examples-16">Examples</a></h3>
<p>Upload a Run by its local directory:</p>
<pre><code class="language-python">em.upload(path='.em/runs/cnn_keras_220823_194728_4e48t2')
</code></pre>
<p>Upload all Artifact under the parent directory:</p>
<pre><code class="language-python">em.upload(path='.em/artifacts')
</code></pre>
<p>Specify the path of Folder to which the Run is uploaded:</p>
<pre><code class="language-python">em.upload(path='.em/runs/cnn_keras_220823_194728_4e48t2',
              folder='image_classification/mnist')
</code></pre>
<h3 id="args-45"><a class="header" href="#args-45">Args</a></h3>
<ul>
<li>
<p><strong>path</strong> (<em>str</em>)</p>
<p>Local directory of the Run to be uploaded, or parent directory that contains one or more Runs.</p>
</li>
<li>
<p><strong>folder</strong> (<em>str</em>)</p>
<p>Path of the Folder to which the Run is uploaded. If the provided path does not start with ‘/’, <code>/&lt;current-user&gt;/</code> is prepended to it.</p>
</li>
<li>
<p><strong>make_folder</strong> (<em>bool</em>)</p>
<p>If True and Folder with path <code>folder</code> does not exist, make the Folder and parent Folders as needed.</p>
</li>
<li>
<p><strong>conflict_strategy</strong> (<em>str</em>)</p>
<p>Strategy adopted when a Run with the same name as the Run to be uploaded already exists in the Folder, must be ‘skip’, ‘error’, ‘new’ or ‘replace’. If ‘skip’, skip the upload; if ‘error’, error out; if ‘new’, upload with the alternative name of Run; if ‘replace’, delete the existing Run and upload.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="t9ktuner"><a class="header" href="#t9ktuner">t9k.tuner</a></h1>
<h2 id="t9ktunerget_current_parameter"><a class="header" href="#t9ktunerget_current_parameter">t9k.tuner.get_current_parameter</a></h2>
<pre><code class="language-python">get_current_parameter(tag: Optional[str] = None)
</code></pre>
<p>Gets current hyper parameters generated by tuner. It returns the same group of hyper parameters as the last call of get_next_parameter returns.</p>
<h3 id="args-46"><a class="header" href="#args-46">Args</a></h3>
<ul>
<li>
<p><strong>tag</strong> (<em>Optional[str]</em>)</p>
<p>hyper parameter key.</p>
</li>
</ul>
<h2 id="t9ktunerget_experiment_id"><a class="header" href="#t9ktunerget_experiment_id">t9k.tuner.get_experiment_id</a></h2>
<pre><code class="language-python">get_experiment_id()
</code></pre>
<p>Gets experiment ID.</p>
<h3 id="returns-22"><a class="header" href="#returns-22">Returns</a></h3>
<p>Identifier of current experiment.</p>
<h2 id="t9ktunerget_next_parameter"><a class="header" href="#t9ktunerget_next_parameter">t9k.tuner.get_next_parameter</a></h2>
<pre><code class="language-python">get_next_parameter()
</code></pre>
<p>Gets the hyper paremeters generated by tuner. For a multiphase experiment, it returns a new group of hyper parameters at each call of get_next_parameter. For a non-multiphase (multiPhase is not configured or set to False) experiment, it returns hyper parameters only on the first call for each trial job, it returns None since second call. This API should be called only once in each trial job of an experiment which is not specified as multiphase.</p>
<h3 id="returns-23"><a class="header" href="#returns-23">Returns</a></h3>
<p>A dict object contains the hyper parameters generated by tuner, the keys of the dict are defined in
search space. Returns None if no more hyper parameters can be generated by tuner.</p>
<h2 id="t9ktunerget_sequence_id"><a class="header" href="#t9ktunerget_sequence_id">t9k.tuner.get_sequence_id</a></h2>
<pre><code class="language-python">get_sequence_id()
</code></pre>
<p>Gets trial job sequence nubmer. A sequence number is an integer value assigned to each trial job base on the order they are submitted, incremental starting from 0. In one experiment, both trial job ID and sequence number are unique for each trial job, they are of different data types.</p>
<h3 id="returns-24"><a class="header" href="#returns-24">Returns</a></h3>
<p>Sequence number of current trial job which is calling this API.</p>
<h2 id="t9ktunerget_trial_id"><a class="header" href="#t9ktunerget_trial_id">t9k.tuner.get_trial_id</a></h2>
<pre><code class="language-python">get_trial_id()
</code></pre>
<p>Gets trial job ID which is string identifier of a trial job, for example ‘MoXrp’. In one experiment, each trial job has an unique string ID.</p>
<h3 id="returns-25"><a class="header" href="#returns-25">Returns</a></h3>
<p>Identifier of current trial job which is calling this API.</p>
<h2 id="t9ktunerreport_final_result"><a class="header" href="#t9ktunerreport_final_result">t9k.tuner.report_final_result</a></h2>
<pre><code class="language-python">report_final_result(metric: Any)
</code></pre>
<p>Reports final result to TUNER.</p>
<h3 id="args-47"><a class="header" href="#args-47">Args</a></h3>
<ul>
<li>
<p><strong>metric</strong> (<em>Any</em>)</p>
<p>Usually (for built-in tuners to work), it should be a number, or a dict with key “default” (a number), and any other extra keys.</p>
</li>
</ul>
<h2 id="t9ktunerreport_intermediate_result"><a class="header" href="#t9ktunerreport_intermediate_result">t9k.tuner.report_intermediate_result</a></h2>
<pre><code class="language-python">report_intermediate_result(metric: Any, step: int)
</code></pre>
<p>Reports intermediate result to TUNER.</p>
<h3 id="args-48"><a class="header" href="#args-48">Args</a></h3>
<ul>
<li>
<p><strong>metric</strong> (<em>Any</em>)</p>
<p>serializable object.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="codepack"><a class="header" href="#codepack">Codepack</a></h1>
<p>Codepack 以简洁明了的形式定义在平台上开发、运行、部署一个机器学习项目所需要的全部信息，例如代码、配置文件、各种参数等。其相关工具能够根据这些信息自动地执行相应的操作，从而大幅减少用户的操作量，显著改善实验的可重复性。</p>
<p>例如对于 MNIST 手写数字图像分类任务，在已经准备好了训练代码、数据集和资源配置文件的情况下，你只需要再创建一个 Codepack 定义文件，然后使用 Codepack CLI 执行一条命令，就可以在平台上启动分布式训练：</p>
<html>
<head>
  <link rel="stylesheet" type="text/css" href="../../assets/tools/codepack/asciinema-player.css" />
</head>
<body>
  <div id="player" style="width: 80%;"></div>
  <script src="../../assets/tools/codepack/asciinema-player.min.js"></script>
  <script>
    AsciinemaPlayer.create(
      '../../assets/tools/codepack/506308.cast',
      document.getElementById('player'),
      { cols: 80, rows: 27, autoPlay: true }
    );
  </script>
</body>
</html>
<p>这里 Codepack 定义文件的内容如下：</p>
<pre><code class="language-yaml">apiVersion: codepack.tensorstack.dev/v1beta1
name: mnist-keras
description: A simple image classifier based on CNN using tf2.
project: demo
default: prepare-env
targets:
  - name: prepare-env        # Prepare running env
    actions:
      - name: workspace-for-training
        verb: apply
        files: [pvc.yaml]
  - name: copy-file          # Copy training code and dataset to PVC
    deps: [&quot;prepare-env&quot;]
    actions:
      - name: copy-code
        verb: copy
        src: .
        dst: codepack-example:.
  - name: run-distributed-training    # Run a distributed training
    deps: [&quot;prepare-env&quot;, &quot;copy-file&quot;]
    actions:
      - name: trainingjob
        verb: create
        files: [trainingjob.yaml]

</code></pre>
<p>整个 Codepack 的文件结构如下：</p>
<pre><code class="language-shell">mnist-keras
├── codepack.yaml
├── main.py
├── mnist.npz
├── pvc.yaml
└── trainingjob.yaml
</code></pre>
<p>由于 Codepack 的全部信息都维护在一个定义文件中，用户创建一个新的 Codepack 或者将既有的机器学习项目修改为 Codepack 都非常容易，并且用户可以使用 Git 来轻松地对 Codepack 进行版本控制和分发。</p>
<p>Codepack 的相关工具包括<a href="tools/codepack/./cli.html">命令行工具</a>和集群内组件，前者负责读取 Codepack 定义并执行用户指定的 action，后者负责进行安全访问控制以及为命令行工具执行 action 提供支持。</p>
<h2 id="下一步-36"><a class="header" href="#下一步-36">下一步</a></h2>
<ul>
<li>了解 <a href="tools/codepack/./concepts.html">Codepack 的概念</a></li>
<li>了解 <a href="tools/codepack/./definition.html">Codepack 的定义</a></li>
<li>了解<a href="tools/codepack/./cli.html">命令行工具</a></li>
<li>学习具体的<a href="tools/codepack/./example.html">使用示例</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="概念-1"><a class="header" href="#概念-1">概念</a></h1>
<h3 id="codepack-1"><a class="header" href="#codepack-1">Codepack</a></h3>
<p>Codepack 是对用户想要在平台上运行的机器学习项目的抽象，其实质上是一个包含项目文件（模型代码、资源配置文件等）以及 Codepack 定义文件的文件系统的目录，该定义文件包含了 Codepack 的基本信息（版本、名称、描述等）和运行信息（target 和 action 的定义），见 <a href="tools/codepack/./codepack.html">Codepack 定义</a>。</p>
<h3 id="target"><a class="header" href="#target">target</a></h3>
<p>target 是对 Codepack 的一个具体任务的抽象，例如在平台上完成模型训练、部署模型为推理服务等。每个 target 可以指定其依赖的其他 target（例如创建推理服务需要先完成模型训练），命令行工具在运行一个 target 时，将递归地解析依赖，然后运行一个工作流。</p>
<h3 id="action"><a class="header" href="#action">action</a></h3>
<p>action 是对 target 的一个具体的可执行的操作的抽象，例如在平台中创建一个 PVC、创建一个进行分布式训练的 TrainingJob 等。action 定义了多个动词（verb），每个动词针对某一类的具体操作，由命令行工具和集群内组件提供实现。</p>
<!-- TODO: Implement control logics
action 在执行时具有状态，用户可以设定策略，根据 action 的状态来决定接下来的行为（例如是否执行下一个 action、执行的时机等）。
-->
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="codepack-定义"><a class="header" href="#codepack-定义">Codepack 定义</a></h1>
<p>一个包含机器学习代码及相关文件的文件系统目录，加上 Codepack 的定义文件就构成了一个 Codepack。Codepack 定义文件是一个通常名为 <code>codepack.yaml</code> 的 YAML 文件，其包含 Codepack 的版本、名称、描述等基本信息以及 target 定义、action 定义等运行相关的信息。</p>
<p>下面将具体介绍 Codepack 定义文件中的各个字段以及它们的作用，从而指导用户如何创建一个 Codepack。</p>
<h2 id="创建-codepack-定义文件"><a class="header" href="#创建-codepack-定义文件">创建 Codepack 定义文件</a></h2>
<p>下面是一个基本的 Codepack 定义文件的示例：</p>
<pre><code class="language-yaml">apiVersion: codepack.tensorstack.dev/v1beta1
name: mnist-keras
description: A simple image classifier based on CNN using tf2.
targets:
  - name: prepare-env    # target definition
    actions:
      - name: workspace-for-training    # action definition
        verb: apply
        files: [pvc.yaml]
      - name: copy-code
        verb: copy
        src: .
        dst: codepack-pvc:.
</code></pre>
<p>在该例中：</p>
<ul>
<li>指定 Codepack 的版本、名称和详细描述（分别由 <code>apiVersion</code>、<code>name</code> 和 <code>description</code> 字段指定）。</li>
<li><code>targets</code> 字段定义一个 target，这个 target 又通过 <code>actions</code> 字段定义两个 action。这里 target 的 <code>name</code> 字段是必需的；action 的 <code>name</code> 字段不是必需的，但 <code>verb</code> 字段以及相应动词需要提供的字段是必需的（请参阅 <a href="tools/codepack/definition.html#action-%E5%8A%A8%E8%AF%8D">action 动词</a>）。</li>
</ul>
<h2 id="指定默认项目和-target"><a class="header" href="#指定默认项目和-target">指定默认项目和 target</a></h2>
<p>可以通过 <code>project</code> 和 <code>default</code> 字段指定 Codepack 的默认项目和 target，这样在使用命令行工具运行 Codepack 时如果不提供相应的参数，则会使用这些默认值。</p>
<pre><code class="language-yaml">apiVersion: codepack.tensorstack.dev/v1beta1
name: mnist-keras
description: A simple image classifier based on CNN using tf2.
project: demo           # default project to run in
default: prepare-env    # default target to run
targets:
  - name: prepare-env
    actions:
      - name: workspace-for-training
        verb: apply
        files: [pvc.yaml]
      - name: copy-code
        verb: copy
        src: .
        dst: codepack-pvc:.
</code></pre>
<h2 id="工作流机制"><a class="header" href="#工作流机制">工作流机制</a></h2>
<p>target 是对 Codepack 的一个具体任务的抽象，多个 target 之间可能存在依赖关系，例如负责从本地复制文件到 PVC 的 target 需要依赖负责创建 PVC 的 target 运行完毕。每一个 target 可以通过 <code>deps</code> 字段传入一个 target 名称列表来指定其依赖的其他 target。</p>
<p>在使用命令行工具运行某一个 target 时，命令行工具会递归地解析所有依赖的 target，动态地构建一个有向无环图，然后串行或者并行地运行图中当前没有依赖或依赖已经运行完毕的 target，直到所有 target 全部运行。</p>
<p>利用工作流机制，可以将上面示例中的 target <code>prepare-env</code> 拆分为具有依赖关系的两个 target，并且在此基础上再创建一个依赖它们的负责启动分布式训练的 target。</p>
<pre><code class="language-yaml">apiVersion: codepack.tensorstack.dev/v1beta1
name: mnist-keras
description: A simple image classifier based on CNN using tf2.
project: demo
default: prepare-env
targets:
  - name: prepare-env        # Prepare running env
    actions:
      - name: workspace-for-training
        verb: apply
        files: [pvc.yaml]
  - name: copy-file          # Copy the Codepack to PVC
    deps: [&quot;prepare-env&quot;]
    actions:
      - name: copy-code
        verb: copy
        src: .
        dst: codepack-pvc:.
  - name: run-distributed-training    # Run a distributed training
    deps: [&quot;prepare-env&quot;, &quot;copy-file&quot;]
    actions:
      - name: trainingjob
        verb: create
        files: [trainingjob.yaml]
</code></pre>
<!-- TODO: Implement control logics
## 控制逻辑
 -->
<h2 id="action-动词"><a class="header" href="#action-动词">action 动词</a></h2>
<p>action 的动词通过 <code>verb</code> 字段指定，表示其操作类型，目前定义了下列值。</p>
<h3 id="apply"><a class="header" href="#apply">apply</a></h3>
<p>应用配置到资源，类似于 <code>kubectl apply</code>。若同名资源已经存在，则更新其配置，否则创建该资源。</p>
<p>需要提供以下字段：</p>
<ul>
<li><code>files</code>：定义资源的 YAML 配置文件的路径、文件路径的列表或者包含 YAML 配置文件的目录的路径。</li>
</ul>
<p>示例：</p>
<pre><code class="language-yaml">actions:
  - name: workspace-for-training
    verb: apply
    files: [pvc.yaml]
</code></pre>
<h3 id="copy"><a class="header" href="#copy">copy</a></h3>
<p>将文件或目录从源位置复制到目标位置，具体实现取决于源和目标的类型：</p>
<ol>
<li>若都为本地路径，则直接在本地进行 rsync 操作。</li>
<li>若一个为本地路径，一个为 PVC 路径，则在集群中创建一个挂载这个 PVC 并且运行 sshd 服务的 Pod，在本地进行远程 rsync 操作。</li>
<li>若都为 PVC 路径，则在集群中创建一个挂载这两个 PVC 的 Pod，在 Pod 中进行 rsync 操作。</li>
</ol>
<p>需要提供以下字段：</p>
<ul>
<li>
<p><code>src</code>：文件或目录的源位置，可以是本地路径或 PVC 路径，格式如下：</p>
<ul>
<li>
<p>本地路径：</p>
<ul>
<li><code>.</code>（Codepack 的全部文件）</li>
<li><code>./data</code>（Codepack 的子目录）</li>
<li><code>./data/</code>（Codepack 的子目录下的全部文件）</li>
<li><code>./train.py</code>（Codepack 的文件） </li>
</ul>
</li>
<li>
<p>PVC 路径：</p>
<ul>
<li><code>&lt;pvc-name&gt;:.</code>（PVC 的根目录）</li>
<li><code>&lt;pvc-name&gt;:data</code>（PVC 的子目录）</li>
<li><code>&lt;pvc-name&gt;:data/</code>（PVC 的子目录下的全部文件）</li>
<li><code>&lt;pvc-name&gt;:data/mnist.npz</code>（PVC 的文件）</li>
</ul>
</li>
</ul>
</li>
<li>
<p><code>dst</code>：文件或目录的目标位置，可以是本地路径或 PVC 路径，格式同上。</p>
</li>
</ul>
<p>示例：</p>
<pre><code class="language-yaml">actions:
  - name: copy-code
    verb: copy
    src: .
    dst: codepack-pvc:.
</code></pre>
<h3 id="create-3"><a class="header" href="#create-3">create</a></h3>
<p>创建资源，类似于 <code>kubectl create</code>。若同名资源已经存在，则错误退出，或为名称添加随机后缀再进行创建。</p>
<p>需要提供以下字段：</p>
<ul>
<li><code>files</code>：定义资源的 YAML 配置文件的路径、文件路径的列表或者包含 YAML 配置文件的目录的路径。</li>
<li><code>new</code>：若为 <code>True</code>，并且同名资源已经存在，则为名称添加随机后缀再进行创建；若为 <code>False</code> 则错误退出。默认为 True。</li>
</ul>
<p>示例：</p>
<pre><code class="language-yaml">actions:
  - name: trainingjob
    verb: create
    files: [trainingjob.yaml]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="命令行工具-2"><a class="header" href="#命令行工具-2">命令行工具</a></h1>
<p>Codepack CLI（命令行工具）用于在命令行终端中运行 Codepack。</p>
<h2 id="安装-3"><a class="header" href="#安装-3">安装</a></h2>
<h3 id="前置条件"><a class="header" href="#前置条件">前置条件</a></h3>
<p>Codepack CLI 使用 Python 3 编写，在安装之前请确保你的本地环境安装了 3.6 或以上版本的 Python 以及 pip 工具。</p>
<p>为使 Codepack CLI 提供的文件复制功能正常运行，还需要安装 3.1.0 及以上版本的 rsync。macOS 执行以下命令安装：</p>
<pre><code class="language-shell">brew install rsync
</code></pre>
<p>基于 Debian 的 Linux 发行版执行以下命令安装：</p>
<pre><code class="language-shell">apt-get install rsync
</code></pre>
<p>基于 rpm 的 Linux 发行版执行以下命令安装：</p>
<pre><code class="language-shell">yum install rsync
</code></pre>
<p>然后你可以执行以下命令来验证安装完成，并且确认安装的 rsync 版本。</p>
<pre><code class="language-shell">rsync --version
</code></pre>
<h3 id="安装-4"><a class="header" href="#安装-4">安装</a></h3>
<p>目前 TensorStack SDK 仅提供用于本地安装的 Python 包，你可以从平台首页下载。</p>
<p>然后使用以下命令进行安装：</p>
<pre><code class="language-shell">pip install codepack-&lt;version&gt;.tar.gz [-i &lt;pypi-mirror-url&gt;]
</code></pre>
<h2 id="命令-2"><a class="header" href="#命令-2">命令</a></h2>
<aside class="note tip">
<div class="title">提示</div>
<p>执行 <code>codepack --help</code> 命令以查看帮助信息，执行 <code>codepack &lt;subcommand&gt; --help</code> 命令以查看相应子命令的帮助信息。</p>
</aside>
<h3 id="check"><a class="header" href="#check">check</a></h3>
<p>检查 Codepack 的有效性。</p>
<h4 id="使用-85"><a class="header" href="#使用-85">使用</a></h4>
<pre><code class="language-shell">codepack check [CODEPACK_PATH]

CODEPACK_PATH    Codepack 或 Codepack 定义文件的路径, 默认为当前路径
</code></pre>
<h4 id="示例-86"><a class="header" href="#示例-86">示例</a></h4>
<pre><code class="language-shell">$ codepack check examples/mnist-keras
Checked, no errors found in codepack mnist-keras
</code></pre>
<h3 id="config-1"><a class="header" href="#config-1">config</a></h3>
<p>查看、修改 Codepack CLI 的配置。</p>
<p>Codepack CLI 各项配置的含义如下：</p>
<div class="table-wrapper"><table><thead><tr><th>配置项</th><th>含义</th><th>默认值</th></tr></thead><tbody>
<tr><td><code>api_key</code></td><td>用于身份验证的 API Key</td><td><code>None</code></td></tr>
<tr><td><code>copy_pod_image</code></td><td>copy 动词创建的 Pod 所使用的镜像</td><td><code>None</code></td></tr>
</tbody></table>
</div>
<h4 id="使用-86"><a class="header" href="#使用-86">使用</a></h4>
<pre><code class="language-shell">$ codepack config [--list] [--get KEY] [--set KEY=VALUE]

--list, -l             列出所有 CLI 配置项
--get=KEY, -g          获取 CLI 配置项
--set=KEY=VALUE, -s    设置 CLI 配置项
</code></pre>
<h4 id="示例-87"><a class="header" href="#示例-87">示例</a></h4>
<pre><code class="language-shell">$ codepack config --list
api_key=None
copy_pod_image=t9kpublic/sshd-rsync:0.0.0.6

$ codepack config --get api_key
api_key=None

$ codepack config --set api_key=5b398842-7c92-4922-a472-c905553beefd
api_key=5b398842-7c92-4922-a472-c905553beefd
config items set

$ codepack config --get api_key
api_key=5b398842-7c92-4922-a472-c905553beefd
</code></pre>
<h3 id="describe-15"><a class="header" href="#describe-15">describe</a></h3>
<p>查看 Codepack 的详细信息。</p>
<h4 id="使用-87"><a class="header" href="#使用-87">使用</a></h4>
<pre><code class="language-shell">codepack describe [CODEPACK_PATH]

CODEPACK_PATH    Codepack 或 Codepack 定义文件的路径, 默认为当前路径
</code></pre>
<h4 id="示例-88"><a class="header" href="#示例-88">示例</a></h4>
<pre><code class="language-shell">$ codepack describe examples/mnist-keras 
name: mnist-keras
description: A simple image classifier based on CNN using tf2.
project: demo
targets:
  - prepare-env
  - copy-file
  - create-notebook
  - run-distributed-training
  - run-e2e-workflow
</code></pre>
<h3 id="run"><a class="header" href="#run">run</a></h3>
<p>运行 Codepack 的指定 target。</p>
<h4 id="使用-88"><a class="header" href="#使用-88">使用</a></h4>
<pre><code class="language-shell">codepack run [--project PROJECT_NAME] [--target TARGET_NAME] [--verbose] [--wait-timeout INTEGER] [CODEPACK_PATH]

--project=PROJECT_NAME, -p    项目名称, 运行在该项目下
--target=TARGET_NAME, -t      target 名称, 运行该 target
--verbose, -v                 打印更多信息
--wait-timeout=INT, -W        设定以秒为单位的 Pod 超时等待时间
CODEPACK_PATH                 Codepack 或 Codepack 定义文件的路径, 默认为当前路径
</code></pre>
<h4 id="示例-89"><a class="header" href="#示例-89">示例</a></h4>
<pre><code class="language-shell">$ codepack run examples/mnist-keras -t run-distributed-training -p demo
RUN target run-distributed-training of codepack mnist-keras in project demo
Running sequence: prepare-env -&gt; copy-file -&gt; run-distributed-training

Target 1/3: prepare-env
APPLY by files ['pvc.yaml']
PersistentVolumeClaim with the name codepack-example already exists, skip
Target 2/3: copy-file
COPY from . to codepack-example:.
copied
Target 3/3: run-distributed-training
CREATE by files ['trainingjob.yaml']
TensorFlowTrainingJob codepack-example created
</code></pre>
<h2 id="配置-1"><a class="header" href="#配置-1">配置</a></h2>
<h3 id="配置文件-2"><a class="header" href="#配置文件-2">配置文件</a></h3>
<p>Codepack CLI 没有单独的配置文件，而是使用 <a href="tools/codepack/../tensorstack-cli/user-guide.html#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">TensorStack CLI 的配置文件</a>。在执行 <code>codepack</code> 命令时，会自动读取位于路径 <code>~/.t9k/t9k-config.yaml</code> 的配置文件（如果设置了环境变量 <code>T9K_CONFIG</code>，则读取其值给出的路径）。如果配置文件不存在或缺少部分配置项，则缺少的这些配置项会被设置为 <code>None</code>，这可能导致 Codepack CLI 的部分功能不能正常工作。</p>
<h3 id="扩展配置"><a class="header" href="#扩展配置">扩展配置</a></h3>
<p>配置文件中的 <code>contexts[*].extension.codepack</code> 字段是 Codepack CLI 的扩展配置，其包含以下字段：</p>
<div class="table-wrapper"><table><thead><tr><th>字段</th><th>功能</th></tr></thead><tbody>
<tr><td><code>copy-pod-image</code></td><td>用于复制文件的 Pod 使用的镜像</td></tr>
</tbody></table>
</div>
<h3 id="查看配置"><a class="header" href="#查看配置">查看配置</a></h3>
<p>使用 <code>codepack config -l</code> 命令以查看所有配置项的值。</p>
<h2 id="身份验证"><a class="header" href="#身份验证">身份验证</a></h2>
<p>Codepack CLI 支持下列身份验证方式，你可以选择其中的一种进行相应的配置。</p>
<h3 id="平台内运行incluster"><a class="header" href="#平台内运行incluster">平台内运行（incluster）</a></h3>
<p>用户需要在平台资源内（平台所在 Kubernetes 集群的 Pod 内）使用 Codepack CLI，例如在 Notebook 的终端中使用。</p>
<p>注意在运行 target 时只能指定当前项目（不指定则默认为当前项目）。</p>
<p>在此方式下，Codepack CLI 直接利用 Kubernetes 提供给 Pod 的 Service Account 向 kube-apiserver 发送请求以执行各 action。</p>
<h3 id="kubeconfig-文件"><a class="header" href="#kubeconfig-文件">kubeconfig 文件</a></h3>
<p>用户需要持有平台所在 Kubernetes 集群的 kubeconfig 文件，并将其放置在路径 <code>~/.kube/config</code> 下（如果设置了环境变量 <code>KUBECONFIG</code>，则放置在其值给出的路径下）。</p>
<p>在此方式下，Codepack CLI 直接利用 kubeconfig 文件向 kube-apiserver 发送请求以执行各 action。</p>
<h3 id="t9kconfig-文件"><a class="header" href="#t9kconfig-文件">t9kconfig 文件</a></h3>
<p>用户持有的<a href="tools/codepack/cli.html#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">配置文件</a>需要提供 API Key 或 token。</p>
<p>在此方式下，Codepack CLI 向平台的各服务器发送请求，再由它们向 kube-apiserver 转发请求以执行各 action。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="示例-90"><a class="header" href="#示例-90">示例</a></h1>
<p>下面是一个简单但完整的创建和运行 Codepack 的示例。</p>
<h2 id="创建-codepack"><a class="header" href="#创建-codepack">创建 Codepack</a></h2>
<p>这里以进行 MNIST 手写数字图像分类的 Keras 模型为例，在工作路径下创建一个名为 <code>mnist-keras</code> 的目录。</p>
<h3 id="准备代码数据集和资源配置文件"><a class="header" href="#准备代码数据集和资源配置文件">准备代码、数据集和资源配置文件</a></h3>
<p>首先编写一个进行模型构建、训练和测试的 Python 脚本，使用 Keras 框架和简单的卷积神经网络结构。为了在平台上进行分布式训练，训练过程采用 <code>tf.distribute.MultiWorkerMirroredStrategy</code> 分布式策略。具体代码如下：</p>
<pre><code class="language-python">import argparse
import json
import logging
import os
import shutil

import tensorflow as tf
from tensorflow.keras import callbacks, datasets, layers, models, optimizers

parser = argparse.ArgumentParser(
    description='Distributed training of Keras model for MNIST with '
    'MultiWorkerMirroredStrategy.')
parser.add_argument('--aimd',
                    action='store_true',
                    default=False,
                    help='Use AIMD to record training data.')
parser.add_argument('--api_key',
                    type=str,
                    help='API Key for requesting AIMD server. '
                    'Required if --aimd is set.')
parser.add_argument(
    '--folder_path',
    type=str,
    default='aimd-example',
    help='Path of AIMD folder in which trial is to be created. '
    'Required if --aimd is set.')
parser.add_argument('--log_dir',
                    type=str,
                    help='Path of the TensorBoard log directory.')
parser.add_argument('--no_cuda',
                    action='store_true',
                    default=False,
                    help='Disable CUDA training.')
parser.add_argument(
    '--server_url',
    type=str,
    default='https://proxy.nc201.kube.tensorstack.net/t9k/aimd/server',
    help='URL of AIMD server. Required if --aimd is set.')
parser.add_argument('--save_path',
                    type=str,
                    default=None,
                    help='Save path of the trained model.')
parser.add_argument('--trial_name',
                    type=str,
                    default='mnist_keras_distributed',
                    help='Name of AIMD trial to create. '
                    'Required if --aimd is set.')
args = parser.parse_args()
logger = logging.getLogger('print')
logger.setLevel(logging.INFO)
logger.addHandler(logging.StreamHandler())
logger.propagate = False

if args.no_cuda:
    # Sets all GPUs invisible
    tf.config.set_visible_devices([], 'GPU')
gpus = tf.config.get_visible_devices('GPU')
if gpus:
    # Print GPU info
    logger.info('NVIDIA_VISIBLE_DEVICES: {}'.format(
        os.getenv('NVIDIA_VISIBLE_DEVICES')))
    logger.info('T9K_GPU_PERCENT: {}'.format(os.getenv('T9K_GPU_PERCENT')))
    logger.info('Visible GPUs: {}'.format(
        tf.config.get_visible_devices('GPU')))
    # Set memory growth
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)
    # # Set GPU memory limit
    # tf.config.set_logical_device_configuration(
    #     gpus[0], [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])

    strategy = tf.distribute.MultiWorkerMirroredStrategy()

# Get information for current worker.
tf_config = json.loads(os.environ['TF_CONFIG'])
world_size = len(tf_config['cluster']['worker'])
task_index = tf_config['task']['index']

if args.aimd and task_index == 0:
    from t9k import aimd
    trial = aimd.init(server_url=args.server_url,
                    trial_name=args.trial_name,
                    folder_path=args.folder_path,
                    api_key=args.api_key)

params = {
    'batch_size': 32 * world_size,
    'epochs': 10,
    'learning_rate': 0.001 * world_size,
    'conv_channels1': 32,
    'conv_channels2': 64,
    'conv_channels3': 64,
    'conv_kernel_size': 3,
    'maxpool_size': 2,
    'linear_features1': 64,
    'seed': 1,
}

if args.aimd and task_index == 0:
    trial.params.update(params)
    trial.params.parse(dist_tf_strategy=strategy)

with strategy.scope():
    model = models.Sequential([
        layers.Conv2D(params['conv_channels1'],
                    params['conv_kernel_size'],
                    activation='relu',
                    input_shape=(28, 28, 1)),
        layers.MaxPooling2D((params['maxpool_size'], params['maxpool_size'])),
        layers.Conv2D(params['conv_channels2'],
                    params['conv_kernel_size'],
                    activation='relu'),
        layers.MaxPooling2D((params['maxpool_size'], params['maxpool_size'])),
        layers.Conv2D(params['conv_channels3'],
                    params['conv_kernel_size'],
                    activation='relu'),
        layers.Flatten(),
        layers.Dense(params['linear_features1'], activation='relu'),
        layers.Dense(10, activation='softmax'),
    ])
    model.compile(
        optimizer=optimizers.Adam(learning_rate=params['learning_rate']),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy'])

print(os.path.join(os.getcwd(), 'mnist.npz'))
(train_images, train_labels), (test_images,
                            test_labels) = datasets.mnist.load_data(
                                path=os.path.join(os.getcwd(), 'mnist.npz'))
train_images = train_images.reshape((60000, 28, 28, 1)).astype(&quot;float32&quot;) / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype(&quot;float32&quot;) / 255
train_images, val_images = tf.split(train_images, [48000, 12000], axis=0)
train_labels, val_labels = tf.split(train_labels, [48000, 12000], axis=0)
train_dataset = tf.data.Dataset.from_tensor_slices(
    (train_images, train_labels)).shuffle(
        48000, seed=params['seed']).repeat().batch(params['batch_size'])
val_dataset = tf.data.Dataset.from_tensor_slices(
    (val_images, val_labels)).batch(400)
test_dataset = tf.data.Dataset.from_tensor_slices(
    (test_images, test_labels)).batch(1000)

train_callbacks = []
test_callbacks = []

if args.aimd and task_index == 0:
    from t9k.aimd.keras import AIMDFitCallback, AIMDEvalCallback
    train_callbacks.append(AIMDFitCallback(trial))
    test_callbacks.append(AIMDEvalCallback(trial))

if args.log_dir and task_index == 0:
    log_dir = args.log_dir
    if os.path.exists(log_dir):
        shutil.rmtree(log_dir, ignore_errors=True)
    tensorboard_callback = callbacks.TensorBoard(log_dir=log_dir)
    train_callbacks.append(tensorboard_callback)

model.fit(train_dataset,
        epochs=params['epochs'],
        steps_per_epoch=48000 // params['batch_size'],
        validation_data=val_dataset,
        callbacks=train_callbacks,
        verbose=2)

if args.save_path:
    if task_index == 0:
        save_path = args.save_path
    else:
        dirname = os.path.dirname(args.save_path)
        basename = os.path.basename(
            args.save_path) + '_temp_' + str(task_index)
        save_path = os.path.join(dirname, basename)
    if os.path.exists(save_path):
        shutil.rmtree(save_path, ignore_errors=True)
    model.save(save_path)
    if task_index != 0:
        shutil.rmtree(save_path, ignore_errors=True)

model.evaluate(test_dataset, callbacks=test_callbacks, verbose=2)

if args.aimd and task_index == 0:
    trial.finish()
</code></pre>
<p>编写一个下载数据集的脚本并运行，以将数据集文件 <code>mnist.npz</code> 下载到 Codepack 中。具体代码如下：</p>
<pre><code class="language-python">import os
import tensorflow as tf

_, _ = tf.keras.datasets.mnist.load_data(
os.path.join(os.path.dirname(os.path.realpath(__file__)), 'mnist.npz'))
</code></pre>
<!-- TODO: Use dataset management module / s3 database
<aside class="note tip">
<div class="title">提示</div>

本例中的数据集文件较小（只有 11 MB），因此将其放到 Codepack 中，并随同 Codepack 整个复制到 PVC 中是可行的。但在数据集文件较大的情况下更加推荐将其存放到平台的数据集管理模块中。

</aside>
-->
<p>考虑在平台上运行时需要创建 PVC、Notebook（可选，便于进一步开发或对 PVC 中的文件进行修改）和 TensorFlowTrainingJob，分别编写相应的资源配置文件如下：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: codepack-example
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 2Gi
</code></pre>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: Notebook
metadata:
  name: codepack-example
spec:
  template:
    spec:
      containers:
        - name: notebook
          image: 'registry.tensorstack.cn/t9k/tensorflow-2.8.0-notebook-cpu:1.50.0'
          resources:
            limits:
              cpu: '1'
              memory: 1Gi
            requests:
              cpu: 500m
              memory: 500Mi
          volumeMounts:
            - name: workingdir
              mountPath: /t9k/mnt
      volumes:
        - name: workingdir
          persistentVolumeClaim:
            claimName: codepack-example
</code></pre>
<pre><code class="language-yaml">apiVersion: batch.tensorstack.dev/v1beta1
kind: TensorFlowTrainingJob
metadata:
  name: codepack-example
spec:
  scheduler:
    t9kScheduler:
      queue: default
      priority: 50
  runPolicy:
    cleanUpPolicy: Unfinished
    backoffLimit: 20           # 所有Pod最多共重启20次
  tensorboardSpec:
    trainingLogFilesets:
      - t9k://pvc/codepack-example/mnist-keras/log
    image: t9kpublic/tensorflow-2.7.0:cpu
  replicaSpecs:
    - type: worker
      replicas: 4
      restartPolicy: OnFailure
      template:
        spec:
          securityContext:
            runAsUser: 1000
          containers:
            - command:
                - python        # 运行脚本的命令
                - main.py
                - &quot;--no_cuda&quot;
                - &quot;--log_dir&quot;
                - &quot;log&quot;
                - &quot;--save_path&quot;
                - &quot;saved-model&quot;
              workingDir: /mnt/mnist-keras/    # 工作路径,与定义文件中Codepack的
              imagePullPolicy: IfNotPresent    # 复制路径一致
              image: t9kpublic/tensorflow-2.7.0:cpu
              name: tensorflow
              resources:
                requests:
                  cpu: 2000m
                  memory: 2Gi
                limits:
                  cpu: 4000m
                  memory: 4Gi
              volumeMounts:
                - mountPath: /mnt
                  name: data
          volumes:
            - name: data
              persistentVolumeClaim:
                claimName: codepack-example
</code></pre>
<p>现在 Codepack 的文件结构如下：</p>
<pre><code>mnist-keras
├── download_dataset.py
├── main.py
├── mnist.npz
├── notebook.yaml
├── pvc.yaml
└── trainingjob.yaml
</code></pre>
<h3 id="编写-codepack-定义文件"><a class="header" href="#编写-codepack-定义文件">编写 Codepack 定义文件</a></h3>
<p>然后编写 <a href="tools/codepack/./codepack.html">Codepack 的定义文件</a>。考虑在平台中运行该 Codepack 的过程，将其拆分为 4 个具体的任务，分别是：</p>
<ol>
<li>准备环境，这里只包含创建 PVC。使用 verb apply 并提供 <code>pvc.yaml</code> 文件的路径。</li>
<li>复制整个 Codepack 到 PVC。使用 verb copy 并提供源和目标位置的路径。</li>
<li>创建 Notebook。使用 verb create 并提供 <code>notebook.yaml</code> 文件的路径。需要依赖 1 和 2。</li>
<li>进行分布式训练，即创建 TrainingJob。使用 verb create 并提供 <code>trainingjob.yaml</code> 文件的路径。需要依赖 1 和 2。</li>
</ol>
<p>据此完成的定义文件如下：</p>
<pre><code class="language-yaml">apiVersion: codepack.tensorstack.dev/v1beta1
name: mnist-keras
description: A simple image classifier based on CNN using tf2.
project: demo
default: prepare-env
targets:
  - name: prepare-env        # Prepare running env
    actions:
      - name: workspace-for-training
        verb: apply
        files: [pvc.yaml]
  - name: copy-file          # Copy training code and dataset to PVC
    deps: [&quot;prepare-env&quot;]
    actions:
      - name: copy-code
        verb: copy
        src: .
        dst: codepack-example:.
  - name: create-notebook    # Create a notebook with the codepack in it
    deps: [&quot;prepare-env&quot;, &quot;copy-file&quot;]
    actions:
      - name: notebook
        verb: create
        files: [notebook.yaml]
  - name: run-distributed-training    # Run a distributed training
    deps: [&quot;prepare-env&quot;, &quot;copy-file&quot;]
    actions:
      - name: trainingjob
        verb: create
        files: [trainingjob.yaml]

</code></pre>
<p>最终 Codepack 的文件结构如下：</p>
<pre><code>mnist-keras
├── codepack.yaml
├── download_dataset.py
├── main.py
├── mnist.npz
├── notebook.yaml
├── pvc.yaml
└── trainingjob.yaml
</code></pre>
<h3 id="对-codepack-进行版本控制可选"><a class="header" href="#对-codepack-进行版本控制可选">对 Codepack 进行版本控制（可选）</a></h3>
<p>将 Codepack 创建为一个 Git 仓库以进行版本控制，之后你就可以使用任意的本地或远程仓库方便地进行版本控制和分发。</p>
<h2 id="运行-codepack"><a class="header" href="#运行-codepack">运行 Codepack</a></h2>
<p>使用 <a href="tools/codepack/./cli.html">Codepack CLI</a> 运行 Codepack。</p>
<h3 id="配置身份验证信息"><a class="header" href="#配置身份验证信息">配置身份验证信息</a></h3>
<p>Codepack CLI 支持多种身份验证方式，你可以选择其中一种并进行相应的配置。详细步骤请参阅<a href="tools/codepack/./cli.html#%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81">身份验证</a>。</p>
<h3 id="使用命令行工具运行-codepack"><a class="header" href="#使用命令行工具运行-codepack">使用命令行工具运行 Codepack</a></h3>
<p>先使用以下命令运行 target <code>create-notebook</code>：</p>
<pre><code class="language-shell">$ codepack run examples/mnist-keras -t create-notebook -p demo
RUN target create-notebook of codepack mnist-keras in project demo
Running sequence: prepare-env -&gt; copy-file -&gt; create-notebook

Target 1/3: prepare-env
APPLY by files ['pvc.yaml']
PersistentVolumeClaim codepack-example created
Target 2/3: copy-file
COPY from . to codepack-example:.
copied
Target 3/3: create-notebook
CREATE by files ['notebook.yaml']
Notebook codepack-example created
</code></pre>
<p>再使用以下命令运行 target <code>run-distributed-training</code>：</p>
<pre><code class="language-shell">$ codepack run examples/mnist-keras -t run-distributed-training -p demo
RUN target run-distributed-training of codepack mnist-keras in project demo
Running sequence: prepare-env -&gt; copy-file -&gt; run-distributed-training

Target 1/3: prepare-env
APPLY by files ['pvc.yaml']
PersistentVolumeClaim with the name codepack-example already exists, skip
Target 2/3: copy-file
COPY from . to codepack-example:.
copied
Target 3/3: run-distributed-training
CREATE by files ['trainingjob.yaml']
TensorFlowTrainingJob codepack-example created
</code></pre>
<p>可以看到在运行这两个 target 的过程中，Codepack CLI 自动解析了工作流并顺序运行各个依赖的 target，按照 YAML 配置文件创建了各资源以及复制整个 Codepack 到 PVC。在运行 target <code>run-distributed-training</code> 的过程中，Codepack CLI 跳过了第一个 target（因为 PVC 已经创建），第二个 target 也实际上没有更新 PVC 中的文件（因为背后调用的是 rsync）。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="参考-13"><a class="header" href="#参考-13">参考</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="术语表"><a class="header" href="#术语表">术语表</a></h1>
<p>本术语表记录了 TensorStack AI 平台的一些专有名词，方便用户随时查阅。</p>
<h2 id="api-key-1"><a class="header" href="#api-key-1">API Key</a></h2>
<p>API Key 是一种 TensorStack AI 平台的安全认证方式，主要应用场景为非交互式程序化身份认证，例如自动化脚本等；或者受限制的交互式场景，例如命令行工具。详见 <a href="references/../modules/account-and-security.html#api-key">API Key 文档</a>。</p>
<h2 id="assessor-算法-1"><a class="header" href="#assessor-算法-1">Assessor 算法</a></h2>
<p>Assessor 算法是一系列训练评估算法的统称，用于在 AutoTune 中判断当前超参数的训练中间结果是否符合预期。详见 <a href="references/../modules/building/hpo-algorithm.html#assessor-%E7%AE%97%E6%B3%95">AutoTune 文档</a>。</p>
<h2 id="autotune-2"><a class="header" href="#autotune-2">AutoTune</a></h2>
<p>AutoTune 是 TensorStack AI 平台提供的自动化机器学习工具，用于自动地进行特征工程、神经网络架构搜索、超参调优和模型压缩。详见 <a href="references/../modules/building/autotune.html">AutoTune 文档</a>。</p>
<h2 id="autotuneexperiment-2"><a class="header" href="#autotuneexperiment-2">AutoTuneExperiment</a></h2>
<p>AutoTuneExperiment 是一种 TensorStack 资源，用于自动化机器学习超参数调优。详见 <a href="references/../modules/building/autotuneexperiment.html">AutoTuneExperiment 文档</a>。</p>
<h2 id="beamjob-2"><a class="header" href="#beamjob-2">BeamJob</a></h2>
<p>BeamJob 是一种 TensorStack 资源，用于通过 Apache Beam 框架和 Apache Flink 等底层计算引擎运行分布式计算任务。详见 <a href="references/../modules/jobs/beamjob.html">BeamJob 文档</a>。</p>
<h2 id="clusterrole"><a class="header" href="#clusterrole">ClusterRole</a></h2>
<p>与 Role 类似，但 Role 只能指定某个命名空间范围内的权限，ClusterRole 是整个集群范围。</p>
<h2 id="clusterrolebinding"><a class="header" href="#clusterrolebinding">ClusterRoleBinding</a></h2>
<p>与 RoleBinding 类似，但 RoleBinding 只能指定某个命名空间范围内的权限，ClusterRoleBinding 是整个集群范围。</p>
<h2 id="configmap-1"><a class="header" href="#configmap-1">ConfigMap</a></h2>
<p>ConfigMap 是一种以键值对的形式存储非机密信息的 Kubernetes 资源。Pod 可以挂载 ConfigMap，并以环境变量、命令行参数或配置文件的形式使用 ConfigMap 中的信息。详见 <a href="references/../modules/auxiliary/configmap.html">ConfigMap</a> 和 <a href="references/../tasks/manage-configmap.html">管理 ConfigMap</a>。</p>
<h2 id="container容器"><a class="header" href="#container容器">Container（容器）</a></h2>
<p>容器是可移植、可执行的轻量级的镜像，包含其中的软件及其相关依赖。容器使应用和底层的主机基础设施解耦，降低了应用在不同云环境或者操作系统上的部署难度，便于应用扩展。</p>
<h2 id="controller控制器"><a class="header" href="#controller控制器">Controller（控制器）</a></h2>
<p>控制器负责监控集群中某种 Kubernetes 资源的所有实例，并设法将资源的当前状态转变为期望状态。</p>
<h2 id="crdcustom-resource-definition定制资源定义"><a class="header" href="#crdcustom-resource-definition定制资源定义">CRD（Custom Resource Definition，定制资源定义）</a></h2>
<p>CRD 是 Kubernetes 提供的一种扩展机制，允许开发者定制自己的资源，并开发对应的控制器。TensorStack AI 平台定义了一系列资源，以方便你在 Kubernetes 集群上构建机器学习应用。</p>
<h2 id="cronworkflowrun-1"><a class="header" href="#cronworkflowrun-1">CronWorkflowRun</a></h2>
<p>CronWorkflowRun 是一种 TensorStack 资源，用于方便地定时执行 WorkflowRun。详见 <a href="references/../modules/workflows/cronworkflowrun.html">CronWorkflowRun 文档</a>。</p>
<h2 id="docker"><a class="header" href="#docker">Docker</a></h2>
<p>Docker 是一个提供操作系统级别的虚拟化技术的软件，用于将软件应用及其相关依赖打包成所谓的容器（Container），能够在一个操作系统实例中运行多个其他操作系统中构建的容器。Kubernetes 支持使用 Docker 作为容器运行时。详见 <a target="_blank" rel="noopener noreferrer" href="https://docs.docker.com/get-started/overview/">Docker 文档</a>。</p>
<h2 id="explorer-1"><a class="header" href="#explorer-1">Explorer</a></h2>
<p>Explorer 是一种 TensorStack 资源，用于通过浏览器访问文件管理器和集成开发环境（IDE）。详见 <a href="references/../modules/storage/explorer.html">Explorer 文档</a>。</p>
<h2 id="genericjob-2"><a class="header" href="#genericjob-2">GenericJob</a></h2>
<p>GenericJob 是一种 TensorStack 资源，用于统一协调多个 Pod 共同完成一项任务。详见 <a href="references/../modules/jobs/genericjob.html">GenericJob 文档</a>。</p>
<h2 id="image镜像"><a class="header" href="#image镜像">Image（镜像）</a></h2>
<p>镜像是保存的容器实例，它打包了应用运行所需的一组软件。你可以将镜像存储在容器镜像仓库、拉取到本地系统并作为应用来运行。</p>
<h2 id="job-1"><a class="header" href="#job-1">Job</a></h2>
<p>在 TensorStack AI 平台中，Job 是一类统一协调多个 Pod 共同完成一项任务的资源，包括 GenericJob、TensorFlowTrainingJob、PyTorchTrainingJob、XGBoostTrainingJob、MPIJob、BeamJob 等。</p>
<h2 id="kubernetesk8s"><a class="header" href="#kubernetesk8s">Kubernetes（K8s）</a></h2>
<p>Kubernetes 是一个开源的容器编排引擎，用来对容器化应用进行自动化部署、 扩缩和管理。TensorStack AI 平台构建在 Kubernetes 的坚实基础之上。详见 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/zh/docs/home/">Kubernetes 文档</a>。</p>
<h2 id="label标签"><a class="header" href="#label标签">Label（标签）</a></h2>
<p>标签是附属在资源上的键值对，用于标明资源的属性。你可以通过标签来选取一组资源的某个子集。</p>
<h2 id="mlservice-2"><a class="header" href="#mlservice-2">MLService</a></h2>
<p>MLService 是一种 TensorStack 资源，用于部署机器学习模型预测服务，以供外部用户使用。详见 <a href="references/../modules/deployment/mlservice.html">MLService 文档</a>。</p>
<h2 id="mpijob-2"><a class="header" href="#mpijob-2">MPIJob</a></h2>
<p>MPIJob 是一种 TensorStack 资源，用于通过 OpenMPI 协议进行分布式机器学习训练。详见 <a href="references/../modules/jobs/mpijob.html">MPIJob 文档</a>。</p>
<h2 id="namespace命名空间"><a class="header" href="#namespace命名空间">Namespace（命名空间）</a></h2>
<p>命名空间是一组资源所属的工作空间，提供了一种划分集群、隔离资源的方式。同一命名空间内的资源名称必须不同，不同命名空间的资源名称可以相同。</p>
<h2 id="node节点"><a class="header" href="#node节点">Node（节点）</a></h2>
<p>节点是 Kubernetes 中的工作机器。通常，Kubernetes 集群由一系列节点组成，少则一个，多则上千个。</p>
<h2 id="notebook-4"><a class="header" href="#notebook-4">Notebook</a></h2>
<p>Notebook 是一种 TensorStack 资源，用于在集群中运行 Jupyter Notebook，同时提供 GPU 支持、SSH 访问支持等补充功能。详见 <a href="references/../modules/building/notebook.html">Notebook 文档</a>。</p>
<h2 id="pod-3"><a class="header" href="#pod-3">Pod</a></h2>
<p>Pod 是可以在 Kubernetes 中创建和管理的、最小的可部署的计算单元。Pod 是一组（一个或多个）容器，这些容器共享存储、网络以及怎样运行这些容器的声明。详见 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/zh/docs/concepts/workloads/pods/">Kubernetes 文档</a>。</p>
<h2 id="podgroup-2"><a class="header" href="#podgroup-2">PodGroup</a></h2>
<p>PodGroup 是一组 Pod 的集合，它们需要协同工作、一起被调度。详见 <a href="references/../modules/scheduling/podgroup.html">PodGroup 文档</a>。</p>
<h2 id="project-1"><a class="header" href="#project-1">Project</a></h2>
<p>Project 是 TensorStack AI 平台对计算集群的抽象，建立在 Kubernetes 命名空间 （namespace）之上。不同的用户通常在不同的 Project 下工作，并且可以互相分享自己 Project。详见 <a href="references/../modules/account-and-security.html#project">Project 文档</a>。</p>
<h2 id="pvcpersistentvolumeclaim持久卷申领"><a class="header" href="#pvcpersistentvolumeclaim持久卷申领">PVC（PersistentVolumeClaim，持久卷申领）</a></h2>
<p>PVC 是一种持久化的存储资源，可以被 Pod 挂载、作为 Pod 的卷被访问。你可以在 TensorStack AI 平台的模型构建控制台中创建一个 PVC，并指定它的存储空间（例如 100M、1G）和访问模式（例如只读、可读写、可运行），详见 <a href="references/../modules/storage/pvc.html">PVC</a> 和<a href="references/../tasks/manage-pvc.html">管理 PVC</a>。</p>
<h2 id="pytorchtrainingjob-2"><a class="header" href="#pytorchtrainingjob-2">PyTorchTrainingJob</a></h2>
<p>PyTorchTrainingJob 是一种 TensorStack 资源，用于通过 PyTorch 框架进行分布式机器学习训练。详见 <a href="references/../modules/jobs/pytorchtrainingjob.html">PyTorchTrainingJob 文档</a>。</p>
<h2 id="queue队列"><a class="header" href="#queue队列">Queue（队列）</a></h2>
<p>队列是一种 TensorStack 资源，用于存放 PodGroup 并根据它们的优先级进行调度。详见<a href="references/../modules/scheduling/queue.html">队列文档</a>。</p>
<h2 id="rbacrole-based-access-control"><a class="header" href="#rbacrole-based-access-control">RBAC（Role Based Access Control）</a></h2>
<p>RBAC 是一种管理访问控制的方式，详见 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/zh/docs/reference/access-authn-authz/rbac/">Kubernetes 文档</a>。你可以通过 ServiceAccount、Role、RoleBinding、ClusterRole、ClusterRoleBinding 等资源来管理访问控制。</p>
<h2 id="role"><a class="header" href="#role">Role</a></h2>
<p>Role 中包含一组代表相关权限的规则，例如获取 Pod、创建 Pod、删除 Pod、获取 Secret、创建 Secret、删除 Secret 等。</p>
<h2 id="rolebinding"><a class="header" href="#rolebinding">RoleBinding</a></h2>
<p>RoleBinding 将 Role 中定义的权限赋予一个用户或者一个 ServiceAccount，这样绑定 ServiceAccount 的 Pod 就能进行 Role 中定义的操作。</p>
<h2 id="scheduler调度器"><a class="header" href="#scheduler调度器">Scheduler（调度器）</a></h2>
<p>调度器负责将 Pod 分配到合适的节点上，保证节点满足 Pod 声明的计算资源（CPU、内存、GPU等）、亲和度偏好（希望与其他 Pod 一起运行、希望运行在拥有某个标签的节点上等）等需求。</p>
<h2 id="secret-1"><a class="header" href="#secret-1">Secret</a></h2>
<p>Secret 是一种存储密码、令牌、SSH Key 等敏感信息的 Kubernetes 资源。Pod 可以将 Secret 挂载为一个文件，并读取其中的信息。详见 <a href="references/../modules/auxiliary/secret.html">Secret</a> 和<a href="references/../tasks/manage-secret.html">管理 Secret</a>。</p>
<h2 id="serviceaccount"><a class="header" href="#serviceaccount">ServiceAccount</a></h2>
<p>ServiceAccount 为 Pod 提供一个身份凭证。当你创建一个 Pod 时，如果没有指定 ServiceAccount，该 Pod 会默认绑定一个名为 <code>default</code> 的 ServiceAccount。</p>
<h2 id="simplemlservice-2"><a class="header" href="#simplemlservice-2">SimpleMLService</a></h2>
<p>SimpleMLService 是一种 TensorStack 资源，用于部署机器学习模型预测服务，以供内部开发者快速测试。详见 <a href="references/../modules/deployment/simplemlservice.html">SimpleMLService 文档</a>。</p>
<h2 id="tensorboard-1"><a class="header" href="#tensorboard-1">TensorBoard</a></h2>
<p>TensorBoard 是 TensorFlow 提供的机器学习可视化工具。TensorStack AI 平台提供在集群中一键部署 TensorBoard 的功能，详见 <a href="references/../modules/building/tensorboard.html">TensorBoard 文档</a>。</p>
<h2 id="tensorflowtrainingjob-2"><a class="header" href="#tensorflowtrainingjob-2">TensorFlowTrainingJob</a></h2>
<p>TensorFlowTrainingJob 是一种 TensorStack 资源，用于通过 TensorFlow 框架进行分布式机器学习训练。详见 <a href="references/../modules/jobs/tensorflowtrainingjob.html">TensorFlowTrainingJob 文档</a>。</p>
<h2 id="tuner-算法-1"><a class="header" href="#tuner-算法-1">Tuner 算法</a></h2>
<p>Tuner 算法是一系列超参数调优算法的统称，用于在 AutoTune 中选取合适的超参数组合。详见 <a href="references/../modules/building/hpo-algorithm.html#tuner-%E7%AE%97%E6%B3%95">AutoTune 文档</a>。</p>
<h2 id="volume卷"><a class="header" href="#volume卷">Volume（卷）</a></h2>
<p>卷是一个包含数据的文件夹，可以被 Pod 中的容器访问。详见 <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/zh/docs/concepts/storage/volumes/">Kubernetes 文档</a>。</p>
<h2 id="workflowrun-2"><a class="header" href="#workflowrun-2">WorkflowRun</a></h2>
<p>WorkflowRun 是一种 TensorStack 资源，用于实例化 WorkflowTemplate 并提供 WorkflowTemplate 运行时所需的参数、工作空间等资源。详见 <a href="references/../modules/workflows/workflowrun.html">WorkflowRun 文档</a>。</p>
<h2 id="workflowtemplate-2"><a class="header" href="#workflowtemplate-2">WorkflowTemplate</a></h2>
<p>WorkflowTemplate 是一种 TensorStack 资源，用于在 Kubernetes 中有序、高效、方便地组织运行各类工作负载。详见 <a href="references/../modules/workflows/workflowtemplate.html">WorkflowTemplate 文档</a>。</p>
<h2 id="xgboosttrainingjob-2"><a class="header" href="#xgboosttrainingjob-2">XGBoostTrainingJob</a></h2>
<p>XGBoostTrainingJob 是一种 TensorStack 资源，用于通过 XGBoost 框架进行分布式机器学习训练。详见 <a href="references/../modules/jobs/xgboosttrainingjob.html">XGBoostTrainingJob 文档</a>。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-参考"><a class="header" href="#api-参考">API 参考</a></h1>
<ul>
<li><a href="references/api-reference/./project.html">Project</a></li>
<li><a href="references/api-reference/./genericjob.html">GenericJob</a></li>
<li><a href="references/api-reference/./tensorflowtrainingjob.html">TensorFlowTrainingJob</a></li>
<li><a href="references/api-reference/./pytorchtrainingjob.html">PyTorchTrainingJob</a></li>
<li><a href="references/api-reference/./xgboosttrainingjob.html">XGBoostTrainingJob</a></li>
<li><a href="references/api-reference/./colossalaijob.html">ColossalAIJob</a></li>
<li><a href="references/api-reference/./deepspeedjob.html">DeepSpeedJob</a></li>
<li><a href="references/api-reference/./mpijob.html">MPIJob</a></li>
<li><a href="references/api-reference/./beamjob.html">BeamJob</a></li>
<li><a href="references/api-reference/./tensorboard.html">TensorBoard</a></li>
<li><a href="references/api-reference/./notebook.html">Notebook</a></li>
<li><a href="references/api-reference/./explorer.html">Explorer</a></li>
<li><a href="references/api-reference/./storageshim.html">StorageShim</a></li>
<li><a href="references/api-reference/./scheduler.html">Scheduler</a></li>
<li><a href="references/api-reference/./Workflow.html">Workflow</a></li>
<li><a href="references/api-reference/./Workflowtrigger.html">WorkflowTrigger</a></li>
<li><a href="references/api-reference/./simplemlservice.html">SimpleMLService</a></li>
<li><a href="references/api-reference/./mlservice.html">MLService</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference"><a class="header" href="#api-reference">API Reference</a></h1>
<h2 id="packages"><a class="header" href="#packages">Packages</a></h2>
<ul>
<li><a href="references/api-reference/project.html#tensorstackdevv1beta1">tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="tensorstackdevv1beta1"><a class="header" href="#tensorstackdevv1beta1">tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the  v1beta1 API group</p>
<h3 id="resource-types"><a class="header" href="#resource-types">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/project.html#project">Project</a></li>
<li><a href="references/api-reference/project.html#projectlist">ProjectList</a></li>
<li><a href="references/api-reference/project.html#quotaprofile">QuotaProfile</a></li>
<li><a href="references/api-reference/project.html#quotaprofilelist">QuotaProfileList</a></li>
</ul>
<h4 id="eventcontrollerstatus"><a class="header" href="#eventcontrollerstatus">EventControllerStatus</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#projectstatus">ProjectStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>deployment</code> <em><a href="references/api-reference/project.html#eventdeploymentstatus">EventDeploymentStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="eventdeploymentstatus"><a class="header" href="#eventdeploymentstatus">EventDeploymentStatus</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#eventcontrollerstatus">EventControllerStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td></td></tr>
<tr><td><code>readyReplicas</code> <em>integer</em></td><td></td></tr>
<tr><td><code>podStatus</code> <em><a href="references/api-reference/project.html#eventpodstatus">EventPodStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="eventpodstatus"><a class="header" href="#eventpodstatus">EventPodStatus</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#eventdeploymentstatus">EventDeploymentStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td></td></tr>
<tr><td><code>uid</code> <em>UID</em></td><td></td></tr>
<tr><td><code>phase</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podphase-v1-core">PodPhase</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="networkpolicy"><a class="header" href="#networkpolicy">NetworkPolicy</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#projectspec">ProjectSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>useDefaultTemplate</code> <em>boolean</em></td><td>If <code>true</code>, the default NetworkPolicy defined by the administrator will be applied.</td></tr>
<tr><td><code>template</code> <em><a href="references/api-reference/project.html#networkpolicytemplate">NetworkPolicyTemplate</a></em></td><td>A NethworkPolicy defined for this project.</td></tr>
</tbody></table>
</div>
<h4 id="networkpolicytemplate"><a class="header" href="#networkpolicytemplate">NetworkPolicyTemplate</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#networkpolicy">NetworkPolicy</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>spec</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#networkpolicyspec-v1-networking">NetworkPolicySpec</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="project-2"><a class="header" href="#project-2">Project</a></h4>
<p>Project is the Schema for the projects API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#projectlist">ProjectList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>Project</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/project.html#projectspec">ProjectSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/project.html#projectstatus">ProjectStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="projectcondition"><a class="header" href="#projectcondition">ProjectCondition</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#projectstatus">ProjectStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/project.html#projectconditiontype">ProjectConditionType</a></em></td><td>Type is the type of the condition.</td></tr>
<tr><td><code>status</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Status is the status of the condition. Can be True, False, Unknown.</td></tr>
<tr><td><code>lastUpdateTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>Last time we probed the condition.</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>Last time the condition transitioned from one status to another.</td></tr>
<tr><td><code>reason</code> <em>string</em></td><td>Unique, one-word, CamelCase reason for the condition’s last transition.</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>Human-readable message indicating details about last transition.</td></tr>
</tbody></table>
</div>
<h4 id="projectconditiontype"><a class="header" href="#projectconditiontype">ProjectConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#projectcondition">ProjectCondition</a></li>
</ul>
<h4 id="projectlist"><a class="header" href="#projectlist">ProjectList</a></h4>
<p>ProjectList contains a list of Project</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>ProjectList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/project.html#project">Project</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="projectspec"><a class="header" href="#projectspec">ProjectSpec</a></h4>
<p>ProjectSpec defines the desired state of Project</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#project">Project</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>resourceQuota</code> <em><a href="references/api-reference/project.html#resourcequota">ResourceQuota</a></em></td><td></td></tr>
<tr><td><code>networkPolicy</code> <em><a href="references/api-reference/project.html#networkpolicy">NetworkPolicy</a></em></td><td></td></tr>
<tr><td><code>quotaProfile</code> <em>string</em></td><td></td></tr>
<tr><td><code>defaultScheduler</code> <em><a href="references/api-reference/project.html#schedulepolicy">SchedulePolicy</a></em></td><td>DefaultScheduler defines the default scheduler and queue information for the project. It is just a configuration information, the controller does not need to do anything.</td></tr>
</tbody></table>
</div>
<h4 id="projectstatus"><a class="header" href="#projectstatus">ProjectStatus</a></h4>
<p>ProjectStatus defines the observed state of Project</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#project">Project</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>conditions</code> <em><a href="references/api-reference/project.html#projectcondition">ProjectCondition</a> array</em></td><td></td></tr>
<tr><td><code>eventController</code> <em><a href="references/api-reference/project.html#eventcontrollerstatus">EventControllerStatus</a></em></td><td></td></tr>
<tr><td><code>resourceQuota</code> <em><a href="references/api-reference/project.html#resourcequotastatus">ResourceQuotaStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="quotaprofile"><a class="header" href="#quotaprofile">QuotaProfile</a></h4>
<p>QuotaProfile is the Schema for the quotaprofiles API. This API resource represents a template for project/namespace resource quota  specifications, defined as an instance of <code>corev1.ResourceQuotaSpec</code>.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#quotaprofilelist">QuotaProfileList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>QuotaProfile</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcequotaspec-v1-core">ResourceQuotaSpec</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="quotaprofilelist"><a class="header" href="#quotaprofilelist">QuotaProfileList</a></h4>
<p>QuotaProfileList contains a list of QuotaProfile</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>QuotaProfileList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/project.html#quotaprofile">QuotaProfile</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="resourcequota"><a class="header" href="#resourcequota">ResourceQuota</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#projectspec">ProjectSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>template</code> <em><a href="references/api-reference/project.html#resourcequotatemplate">ResourceQuotaTemplate</a></em></td><td>A <code>corev1.ResourceQuota</code> defined for this project.</td></tr>
</tbody></table>
</div>
<h4 id="resourcequotastatus"><a class="header" href="#resourcequotastatus">ResourceQuotaStatus</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#projectstatus">ProjectStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td></td></tr>
<tr><td><code>ResourceQuotaStatus</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcequotastatus-v1-core">ResourceQuotaStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="resourcequotatemplate"><a class="header" href="#resourcequotatemplate">ResourceQuotaTemplate</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#resourcequota">ResourceQuota</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>spec</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcequotaspec-v1-core">ResourceQuotaSpec</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="schedulepolicy"><a class="header" href="#schedulepolicy">SchedulePolicy</a></h4>
<p>SchedulePolicy specifies preferences for resource allocation requests, including the name of the preferred scheduler and additional configuration parameters.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#projectspec">ProjectSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>t9kScheduler</code> <em><a href="references/api-reference/project.html#t9kscheduler">T9kScheduler</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="t9kscheduler"><a class="header" href="#t9kscheduler">T9kScheduler</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/project.html#schedulepolicy">SchedulePolicy</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>queue</code> <em>string</em></td><td>Name of the resource <code>Queue</code> of a <code>T9kScheduler</code>.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-1"><a class="header" href="#api-reference-1">API Reference</a></h1>
<h2 id="packages-1"><a class="header" href="#packages-1">Packages</a></h2>
<ul>
<li><a href="references/api-reference/genericjob.html#batchtensorstackdevv1beta1">batch.tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="batchtensorstackdevv1beta1"><a class="header" href="#batchtensorstackdevv1beta1">batch.tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the batch v1beta1 API group</p>
<h3 id="resource-types-1"><a class="header" href="#resource-types-1">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjob">GenericJob</a></li>
<li><a href="references/api-reference/genericjob.html#genericjoblist">GenericJobList</a></li>
</ul>
<h4 id="aggregate"><a class="header" href="#aggregate">Aggregate</a></h4>
<p>Aggregate records the number of replica pods at each phase.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjobstatus">GenericJobStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>creating</code> <em>integer</em></td><td>Pod has been created, but resources have not been scheduled.</td></tr>
<tr><td><code>pending</code> <em>integer</em></td><td>Pod has been accepted by the system, but one or more of the containers has not been started. This includes time before being bound to a node, as well as time spent pulling images onto the host.</td></tr>
<tr><td><code>running</code> <em>integer</em></td><td>Pod has been bound to a node and all of the containers have been started. At least one container is still running or is in the process of being restarted.</td></tr>
<tr><td><code>succeeded</code> <em>integer</em></td><td>All containers in the pod have voluntarily terminated with a container exit code of 0, and the system is not going to restart any of these containers.</td></tr>
<tr><td><code>failed</code> <em>integer</em></td><td>All containers in the pod have terminated, and at least one container has terminated in failure (exited with a non-zero exit code or was stopped by the system).</td></tr>
<tr><td><code>unknown</code> <em>integer</em></td><td>For some reason the state of the pod could not be obtained, typically due to an error in communicating with the host of the pod.</td></tr>
<tr><td><code>deleted</code> <em>integer</em></td><td>Pod has been deleted.</td></tr>
</tbody></table>
</div>
<h4 id="cleanuppolicy"><a class="header" href="#cleanuppolicy">CleanUpPolicy</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>CleanUpPolicy specifies the collection of replicas that are to be deleted upon job completion.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjobspec">GenericJobSpec</a></li>
</ul>
<h4 id="containerstatus"><a class="header" href="#containerstatus">ContainerStatus</a></h4>
<p>ContainerStatus defines the observed state of the container.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#replicastatus">ReplicaStatus</a></li>
</ul>
<h4 id="debugmode"><a class="header" href="#debugmode">DebugMode</a></h4>
<p>DebugMode configs whether and how to start a job in debug mode.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#runmode">RunMode</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code> <em>boolean</em></td><td>Whether to enable debug mode.</td></tr>
<tr><td><code>replicaSpecs</code> <em><a href="references/api-reference/genericjob.html#replicadebugset">ReplicaDebugSet</a> array</em></td><td>If provided, these specs provide overwriting values for job replicas.</td></tr>
</tbody></table>
</div>
<h4 id="finishrule"><a class="header" href="#finishrule">FinishRule</a></h4>
<p>A finishRule is a condition used to check if the job has finished. A finishRule identifies a set of replicas, and the controller determines the job’s status by checking the status of all of these replicas.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjobspec">GenericJobSpec</a></li>
</ul>
<h4 id="genericjob-3"><a class="header" href="#genericjob-3">GenericJob</a></h4>
<p>GenericJob represents the schema for a general-purpose batch job API. While it offers less automation compared to specialized APIs like PyTorchTrainingJob, it allows for greater flexibility in specifying parallel replicas/pods. This design serves as a comprehensive job definition mechanism when more specialized APIs are not applicable or available.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjoblist">GenericJobList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>GenericJob</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/genericjob.html#genericjobspec">GenericJobSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/genericjob.html#genericjobstatus">GenericJobStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="genericjoblist"><a class="header" href="#genericjoblist">GenericJobList</a></h4>
<p>GenericJobList contains a list of GenericJob</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>GenericJobList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/genericjob.html#genericjob">GenericJob</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="genericjobspec"><a class="header" href="#genericjobspec">GenericJobSpec</a></h4>
<p>GenericJobSpec defines the desired state of GenericJob</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjob">GenericJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>successRules</code> <em><a href="references/api-reference/genericjob.html#finishrule">FinishRule</a> array</em></td><td>Rules used to check if a generic job has succeeded. The job succeeded when any one of the successRules is fulfilled. Each item of successRules may refer to a series of replicas, and the job succeeded only if all of the replicas referred in this series are completed successfully.</td></tr>
<tr><td><code>failureRules</code> <em><a href="references/api-reference/genericjob.html#finishrule">FinishRule</a> array</em></td><td>Rules used to check if a generic job has failed. The job failed when any one of failureRules is fulfilled. Each item of failureRules refers to a series of replicas, and the job failed only if all of the replicas in this series failed.</td></tr>
<tr><td><code>service</code> <em><a href="references/api-reference/genericjob.html#serviceoption">ServiceOption</a></em></td><td>Details of v1/Service for replica pods. Optional: Defaults to empty and no service will be created.</td></tr>
<tr><td><code>runMode</code> <em><a href="references/api-reference/genericjob.html#runmode">RunMode</a></em></td><td>Job running mode. Defaults to Immediate mode.</td></tr>
<tr><td><code>cleanUpPolicy</code> <em><a href="references/api-reference/genericjob.html#cleanuppolicy">CleanUpPolicy</a></em></td><td>To avoid wasting resources on completed tasks, controller will reclaim resource according to the following policies:   None: (default) no resources reclamation;   Unfinished:  only finished pods is to be deleted;   All: all the pods are to be deleted.</td></tr>
<tr><td><code>scheduler</code> <em><a href="references/api-reference/genericjob.html#schedulepolicy">SchedulePolicy</a></em></td><td>If specified, the pod will be dispatched by the specified scheduler. Otherwise, the pod will be dispatched by the default scheduler.</td></tr>
<tr><td><code>replicaSpecs</code> <em><a href="references/api-reference/genericjob.html#replicaspec">ReplicaSpec</a> array</em></td><td>List of replica specs belonging to the job. There must be at least one replica defined for a Job.</td></tr>
</tbody></table>
</div>
<h4 id="genericjobstatus"><a class="header" href="#genericjobstatus">GenericJobStatus</a></h4>
<p>GenericJobStatus defines the observed state of GenericJob</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjob">GenericJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tasks</code> <em><a href="references/api-reference/genericjob.html#tasks">Tasks</a> array</em></td><td>An array of status of individual tasks.</td></tr>
<tr><td><code>phase</code> <em><a href="references/api-reference/genericjob.html#jobphase">JobPhase</a></em></td><td>Provides a simple, high-level summary of where the Job is in its lifecycle. Note that this is NOT indended to be a comprehensive state machine.</td></tr>
<tr><td><code>aggregate</code> <em><a href="references/api-reference/genericjob.html#aggregate">Aggregate</a></em></td><td>Records the number of replicas at each phase.</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/genericjob.html#jobcondition">JobCondition</a> array</em></td><td>The latest available observations of a job’s current state.</td></tr>
</tbody></table>
</div>
<h4 id="jobcondition"><a class="header" href="#jobcondition">JobCondition</a></h4>
<p>JobCondition describes the current state of a job.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjobstatus">GenericJobStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/genericjob.html#jobconditiontype">JobConditionType</a></em></td><td>Type of job condition: Complete or Failed.</td></tr>
<tr><td><code>status</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Status of the condition, one of True, False, Unknown.</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>Last time the condition transited from one status to another.</td></tr>
<tr><td><code>reason</code> <em>string</em></td><td>Brief reason for the condition’s last transition.</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>Human readable message indicating details about last transition.</td></tr>
</tbody></table>
</div>
<h4 id="jobconditiontype"><a class="header" href="#jobconditiontype">JobConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>JobConditionType defines all possible types of JobStatus. Can be one of: Initialized, Running, ReplicaFailure, Completed, or Failed.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#jobcondition">JobCondition</a></li>
</ul>
<h4 id="jobphase"><a class="header" href="#jobphase">JobPhase</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjobstatus">GenericJobStatus</a></li>
</ul>
<h4 id="pausemode"><a class="header" href="#pausemode">PauseMode</a></h4>
<p>PauseMode configs whether and how to start a job in pause mode.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#runmode">RunMode</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code> <em>boolean</em></td><td>Whether to enable pause mode.</td></tr>
<tr><td><code>resumeSpecs</code> <em><a href="references/api-reference/genericjob.html#resumespec">ResumeSpec</a> array</em></td><td>If provided, these specs provide overwriting values for job replicas when resuming.</td></tr>
</tbody></table>
</div>
<h4 id="replicadebugset"><a class="header" href="#replicadebugset">ReplicaDebugSet</a></h4>
<p>ReplicaDebugSet describes how to start replicas in debug mode.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#debugmode">DebugMode</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em>string</em></td><td>Replica type.</td></tr>
<tr><td><code>skipInitContainer</code> <em>boolean</em></td><td>Skips creation of initContainer, if true.</td></tr>
<tr><td><code>command</code> <em><a href="references/api-reference/genericjob.html#string">string</a></em></td><td>Entrypoint array. Optional: Default to [“sleep”, “inf”]</td></tr>
</tbody></table>
</div>
<h4 id="replicaspec"><a class="header" href="#replicaspec">ReplicaSpec</a></h4>
<p>ReplicaSpec defines the desired state of replicas.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjobspec">GenericJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em>string</em></td><td>Replica type.</td></tr>
<tr><td><code>replicas</code> <em>integer</em></td><td>The desired number of replicas of this replica type. Defaults to 1.</td></tr>
<tr><td><code>restartPolicy</code> <em><a href="references/api-reference/genericjob.html#restartpolicy">RestartPolicy</a></em></td><td>Restart policy for replicas of this replica type. One of Always, OnFailure, Never. Optional: Default to OnFailure.</td></tr>
<tr><td><code>template</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podtemplatespec-v1-core">PodTemplateSpec</a></em></td><td>Defines the template used to create pods.</td></tr>
</tbody></table>
</div>
<h4 id="replicastatus"><a class="header" href="#replicastatus">ReplicaStatus</a></h4>
<p>ReplicaStatus defines the observed state of the pod.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#tasks">Tasks</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Pod name.</td></tr>
<tr><td><code>uid</code> <em>UID</em></td><td>Pod uid.</td></tr>
<tr><td><code>phase</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podphase-v1-core">PodPhase</a></em></td><td>Pod phase. The phase of a Pod is a simple, high-level summary of where the Pod is in its lifecycle.</td></tr>
<tr><td><code>containers</code> <em><a href="references/api-reference/genericjob.html#containerstatus">ContainerStatus</a> array</em></td><td>Containers status.</td></tr>
</tbody></table>
</div>
<h4 id="restartpolicy"><a class="header" href="#restartpolicy">RestartPolicy</a></h4>
<p>RestartPolicy describes how the replica should be restarted.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#replicaspec">ReplicaSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>policy</code> <em><a href="references/api-reference/genericjob.html#restartpolicytype">RestartPolicyType</a></em></td><td>The policy to restart finished replica.</td></tr>
<tr><td><code>limit</code> <em>integer</em></td><td>The maximum number of restarts. Optional: Default to 0.</td></tr>
</tbody></table>
</div>
<h4 id="restartpolicytype"><a class="header" href="#restartpolicytype">RestartPolicyType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#restartpolicy">RestartPolicy</a></li>
</ul>
<h4 id="resumespec"><a class="header" href="#resumespec">ResumeSpec</a></h4>
<p>ResumeSpec describes how to resume replicas from pause mode.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#pausemode">PauseMode</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em>string</em></td><td>Replica type.</td></tr>
<tr><td><code>skipInitContainer</code> <em>boolean</em></td><td>Skips creation of initContainer, if true.</td></tr>
<tr><td><code>command</code> <em><a href="references/api-reference/genericjob.html#string">string</a></em></td><td>Entrypoint array. Provides overwriting values if provided; otherwise, values in immediate mode are used.</td></tr>
<tr><td><code>args</code> <em><a href="references/api-reference/genericjob.html#string">string</a></em></td><td>Arguments to the entrypoint. Arguments in immediate mode are used if not provided.</td></tr>
</tbody></table>
</div>
<h4 id="runmode"><a class="header" href="#runmode">RunMode</a></h4>
<p>RunMode defines the job’s execution behavior:   Immediate mode: (Default) Tasks are executed immediately upon submission.   Debug mode: Job pods are created, but regular executions are replaced with null operations (e.g., sleep) for convenient debugging purposes.   Pause mode: Job execution is halted, and pods are deleted to reclaim resources. A graceful pod termination process is initiated to allow pods to exit cleanly.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjobspec">GenericJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>debug</code> <em><a href="references/api-reference/genericjob.html#debugmode">DebugMode</a></em></td><td>Debug mode.</td></tr>
<tr><td><code>pause</code> <em><a href="references/api-reference/genericjob.html#pausemode">PauseMode</a></em></td><td>Pause mode.</td></tr>
</tbody></table>
</div>
<h4 id="schedulepolicy-1"><a class="header" href="#schedulepolicy-1">SchedulePolicy</a></h4>
<p>SchedulePolicy signals to K8s how the job should be scheduled.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjobspec">GenericJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>t9kScheduler</code> <em><a href="references/api-reference/genericjob.html#t9kscheduler">T9kScheduler</a></em></td><td>T9k Scheduler. TODO: link to t9k scheduler docs.</td></tr>
</tbody></table>
</div>
<h4 id="serviceoption"><a class="header" href="#serviceoption">ServiceOption</a></h4>
<p>Details of a replicas’ servivce.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjobspec">GenericJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>ports</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#serviceport-v1-core">ServicePort</a> array</em></td><td>The list of ports that are exposed by this service.</td></tr>
</tbody></table>
</div>
<h4 id="t9kscheduler-1"><a class="header" href="#t9kscheduler-1">T9kScheduler</a></h4>
<p>T9kScheduler provides additonal configurations needed for the scheduling process.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#schedulepolicy">SchedulePolicy</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>queue</code> <em>string</em></td><td>Specifies the name of the queue should be used for running this workload. TODO: link to t9k scheduler docs.</td></tr>
<tr><td><code>priority</code> <em>integer</em></td><td>Indicates the priority of the PodGroup; valid range: [0, 100]. Optional: Default to 0.</td></tr>
</tbody></table>
</div>
<h4 id="tasks"><a class="header" href="#tasks">Tasks</a></h4>
<p>Task defines the observed state of the task.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/genericjob.html#genericjobstatus">GenericJobStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em>string</em></td><td>Replica type.</td></tr>
<tr><td><code>restartCount</code> <em>integer</em></td><td>The number of restarts that have been performed.</td></tr>
<tr><td><code>replicas</code> <em><a href="references/api-reference/genericjob.html#replicastatus">ReplicaStatus</a> array</em></td><td>Replicas status array.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-2"><a class="header" href="#api-reference-2">API Reference</a></h1>
<h2 id="packages-2"><a class="header" href="#packages-2">Packages</a></h2>
<ul>
<li><a href="references/api-reference/tensorflowtrainingjob.html#batchtensorstackdevv1beta1">batch.tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="batchtensorstackdevv1beta1-1"><a class="header" href="#batchtensorstackdevv1beta1-1">batch.tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the batch v1beta1 API group</p>
<h3 id="resource-types-2"><a class="header" href="#resource-types-2">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/tensorflowtrainingjob.html#tensorflowtrainingjob">TensorFlowTrainingJob</a></li>
<li><a href="references/api-reference/tensorflowtrainingjob.html#tensorflowtrainingjoblist">TensorFlowTrainingJobList</a></li>
</ul>
<h4 id="replicaspec-1"><a class="header" href="#replicaspec-1">ReplicaSpec</a></h4>
<p>ReplicaSpec describes the spec of a replica.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorflowtrainingjob.html#tensorflowtrainingjobspec">TensorFlowTrainingJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/tensorflowtrainingjob.html#replicatype">ReplicaType</a></em></td><td>ReplicaType is the type of the replica, one of “<code>chief</code>”, “<code>worker</code>”, “<code>ps</code>”, or “<code>evaluator</code>”.</td></tr>
<tr><td><code>replicas</code> <em>integer</em></td><td>The desired number of replicas created for the current replica type. If unspecified, defaults to 1.</td></tr>
<tr><td><code>template</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podtemplatespec-v1-core">PodTemplateSpec</a></em></td><td>Describes the pod that will be created for this replica. Note that RestartPolicy in PodTemplateSpec will always be set to <code>Never</code> as the job controller will create new pods if restart is required.</td></tr>
<tr><td><code>restartPolicy</code> <em><a href="references/api-reference/tensorflowtrainingjob.html#restartpolicy">RestartPolicy</a></em></td><td>The restart policy for this replica, one of <code>Always</code>, <code>OnFailure</code>, <code>Never</code>, or <code>ExitCode</code>.</td></tr>
</tbody></table>
</div>
<h4 id="replicatype"><a class="header" href="#replicatype">ReplicaType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>ReplicaType is the type of the replica, one of “<code>chief</code>”, “<code>worker</code>”, “<code>ps</code>”, or “<code>evaluator</code>”.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorflowtrainingjob.html#replicaspec">ReplicaSpec</a></li>
</ul>
<h4 id="restartpolicy-1"><a class="header" href="#restartpolicy-1">RestartPolicy</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>RestartPolicy describes how the replicas should be restarted. Can be one of: <code>Always</code>, <code>OnFailure</code>, <code>Never</code>, or <code>ExitCode</code>.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorflowtrainingjob.html#replicaspec">ReplicaSpec</a></li>
</ul>
<h4 id="runpolicy"><a class="header" href="#runpolicy">RunPolicy</a></h4>
<p>RunPolicy encapsulates various runtime policies of the distributed training job, for example how to clean up resources and how long the job can stay active.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorflowtrainingjob.html#tensorflowtrainingjobspec">TensorFlowTrainingJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>activeDeadlineSeconds</code> <em>integer</em></td><td>Specifies the duration in seconds relative to the startTime that the job may be active before the system tries to terminate it; value must be positive integer.</td></tr>
<tr><td><code>backoffLimit</code> <em>integer</em></td><td>Optional number of retries before marking this job failed.</td></tr>
<tr><td><code>cleanUpPolicy</code> <em>CleanUpPolicy</em></td><td>Clean the tasks after the training job finished.</td></tr>
</tbody></table>
</div>
<h4 id="tensorflowtrainingjob-3"><a class="header" href="#tensorflowtrainingjob-3">TensorFlowTrainingJob</a></h4>
<p>TensorFlowTrainingJob is the Schema for the TensorFlowTrainingJob API.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorflowtrainingjob.html#tensorflowtrainingjoblist">TensorFlowTrainingJobList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>TensorFlowTrainingJob</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/tensorflowtrainingjob.html#tensorflowtrainingjobspec">TensorFlowTrainingJobSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/tensorflowtrainingjob.html#tensorflowtrainingjobstatus">TensorFlowTrainingJobStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="tensorflowtrainingjoblist"><a class="header" href="#tensorflowtrainingjoblist">TensorFlowTrainingJobList</a></h4>
<p>TensorFlowTrainingJobList contains a list of TensorFlowTrainingJob</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>TensorFlowTrainingJobList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/tensorflowtrainingjob.html#tensorflowtrainingjob">TensorFlowTrainingJob</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="tensorflowtrainingjobspec"><a class="header" href="#tensorflowtrainingjobspec">TensorFlowTrainingJobSpec</a></h4>
<p>TensorFlowTrainingJobSpec outlines the intended configuration and execution parameters for a TensorFlowTrainingJob.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorflowtrainingjob.html#tensorflowtrainingjob">TensorFlowTrainingJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>replicaSpecs</code> <em><a href="references/api-reference/tensorflowtrainingjob.html#replicaspec">ReplicaSpec</a> array</em></td><td>Describes the spec of the replicas of the job.</td></tr>
<tr><td><code>runMode</code> <em><a href="references/api-reference/tensorflowtrainingjob.html#runmode">RunMode</a></em></td><td>Job’s execution behavior. If omitted, defaults to <code>Immediate</code> mode, and tasks are executed immediately upon submission.</td></tr>
<tr><td><code>tensorboardSpec</code> <em>TensorBoardSpec</em></td><td>Describes the Tensorboard to be created for showing training logs.</td></tr>
<tr><td><code>runPolicy</code> <em><a href="references/api-reference/tensorflowtrainingjob.html#runpolicy">RunPolicy</a></em></td><td>Execution policy configurations governing the behavior of the TensorFlowTrainingJob.</td></tr>
<tr><td><code>scheduler</code> <em>SchedulePolicy</em></td><td>Identifies the preferred scheduler for allocating resources to replicas. Defaults to cluster default scheduler.</td></tr>
</tbody></table>
</div>
<h4 id="tensorflowtrainingjobstatus"><a class="header" href="#tensorflowtrainingjobstatus">TensorFlowTrainingJobStatus</a></h4>
<p>TensorFlowTrainingJobStatus defines the observed state of TensorFlowTrainingJob</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorflowtrainingjob.html#tensorflowtrainingjob">TensorFlowTrainingJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tasks</code> <em><a href="references/api-reference/tensorflowtrainingjob.html#tasks">Tasks</a> array</em></td><td>The statuses of individual tasks.</td></tr>
<tr><td><code>tensorboard</code> <em>DependentStatus</em></td><td>The status of tensorboard.</td></tr>
<tr><td><code>backoffCount</code> <em>integer</em></td><td>The number of restarts being performed.</td></tr>
<tr><td><code>aggregate</code> <em><a href="references/api-reference/tensorflowtrainingjob.html#aggregate">Aggregate</a></em></td><td></td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/tensorflowtrainingjob.html#jobcondition">JobCondition</a> array</em></td><td>Represents the latest available observations of a TensorFlowTrainingJob’s current state.</td></tr>
<tr><td><code>phase</code> <em>JobPhase</em></td><td>Phase is the phase-style status of the TensorFlowTrainingJob.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-3"><a class="header" href="#api-reference-3">API Reference</a></h1>
<h2 id="packages-3"><a class="header" href="#packages-3">Packages</a></h2>
<ul>
<li><a href="references/api-reference/pytorchtrainingjob.html#batchtensorstackdevv1beta1">batch.tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="batchtensorstackdevv1beta1-2"><a class="header" href="#batchtensorstackdevv1beta1-2">batch.tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the batch v1beta1 API group</p>
<h3 id="resource-types-3"><a class="header" href="#resource-types-3">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/pytorchtrainingjob.html#pytorchtrainingjob">PyTorchTrainingJob</a></li>
<li><a href="references/api-reference/pytorchtrainingjob.html#pytorchtrainingjoblist">PyTorchTrainingJobList</a></li>
</ul>
<h4 id="elasticconfig"><a class="header" href="#elasticconfig">ElasticConfig</a></h4>
<p>Configuration governing the elastic scaling behavior of the job.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/pytorchtrainingjob.html#pytorchtrainingjobspec">PyTorchTrainingJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code> <em>boolean</em></td><td>Set true to use elastic training.</td></tr>
<tr><td><code>minReplicas</code> <em>integer</em></td><td>The minimum number of replicas to start to run this elastic compute. The autoscaler cannot scale down an elastic job below this number. This value cannnot be changed once the job is created.</td></tr>
<tr><td><code>maxReplicas</code> <em>integer</em></td><td>The maximum number of replicas to start to run this elastic compute. The autoscaler cannot scale up an elastic job over this number. This value cannnot be changed once the job is created.</td></tr>
<tr><td><code>expectedReplicas</code> <em>integer</em></td><td>Number of replicas to be created. This number can be set to an initial value upon creation. This value can be modified dynamically by an external entity, such as a user or an autoscaler, to scale the job up or down.</td></tr>
</tbody></table>
</div>
<h4 id="pytorchtrainingjob-3"><a class="header" href="#pytorchtrainingjob-3">PyTorchTrainingJob</a></h4>
<p>PyTorchTrainingJob is the Schema for the pytorchtrainingjobs API.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/pytorchtrainingjob.html#pytorchtrainingjoblist">PyTorchTrainingJobList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>PyTorchTrainingJob</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/pytorchtrainingjob.html#pytorchtrainingjobspec">PyTorchTrainingJobSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/pytorchtrainingjob.html#pytorchtrainingjobstatus">PyTorchTrainingJobStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="pytorchtrainingjoblist"><a class="header" href="#pytorchtrainingjoblist">PyTorchTrainingJobList</a></h4>
<p>PyTorchTrainingJobList contains a list of PyTorchTrainingJob</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>PyTorchTrainingJobList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/pytorchtrainingjob.html#pytorchtrainingjob">PyTorchTrainingJob</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="pytorchtrainingjobspec"><a class="header" href="#pytorchtrainingjobspec">PyTorchTrainingJobSpec</a></h4>
<p>PyTorchTrainingJobSpec outlines the intended configuration and execution parameters for a PyTorchTrainingJo.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/pytorchtrainingjob.html#pytorchtrainingjob">PyTorchTrainingJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>replicaSpecs</code> <em><a href="references/api-reference/pytorchtrainingjob.html#replicaspec">ReplicaSpec</a> array</em></td><td>An array of ReplicaSpec. Specifies the pytorch cluster configuration.</td></tr>
<tr><td><code>elastic</code> <em><a href="references/api-reference/pytorchtrainingjob.html#elasticconfig">ElasticConfig</a></em></td><td>Configurations for how to launch an elastic training. Elastic training is effective only in torchrun mode.</td></tr>
<tr><td><code>torchrunConfig</code> <em><a href="references/api-reference/pytorchtrainingjob.html#torchrunconfig">TorchrunConfig</a></em></td><td>Whether and how to use torchrun to launch a training process.</td></tr>
<tr><td><code>runMode</code> <em><a href="references/api-reference/pytorchtrainingjob.html#runmode">RunMode</a></em></td><td>Job’s execution behavior. If omitted, defaults to <code>Immediate</code> mode, and tasks are executed immediately upon submission.</td></tr>
<tr><td><code>runPolicy</code> <em><a href="references/api-reference/pytorchtrainingjob.html#runpolicy">RunPolicy</a></em></td><td>Execution policy configurations governing the behavior of a PytorchTrainingJob.</td></tr>
<tr><td><code>tensorboardSpec</code> <em>TensorBoardSpec</em></td><td>If specified, controller will create a Tensorboard for showing training logs.</td></tr>
<tr><td><code>scheduler</code> <em>SchedulePolicy</em></td><td>Identifies the preferred scheduler for allocating resources to replicas. Defaults to cluster default scheduler.</td></tr>
</tbody></table>
</div>
<h4 id="pytorchtrainingjobstatus"><a class="header" href="#pytorchtrainingjobstatus">PyTorchTrainingJobStatus</a></h4>
<p>PyTorchTrainingJobStatus defines the observed state of PyTorchTrainingJob.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/pytorchtrainingjob.html#pytorchtrainingjob">PyTorchTrainingJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tasks</code> <em><a href="references/api-reference/pytorchtrainingjob.html#tasks">Tasks</a> array</em></td><td>The status details of individual tasks.</td></tr>
<tr><td><code>tensorboard</code> <em>DependentStatus</em></td><td>The status of the tensorboard.</td></tr>
<tr><td><code>backoffCount</code> <em>integer</em></td><td>The number of restarts having been performed.</td></tr>
<tr><td><code>aggregate</code> <em><a href="references/api-reference/pytorchtrainingjob.html#aggregate">Aggregate</a></em></td><td>The number of tasks in each state.</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/pytorchtrainingjob.html#jobcondition">JobCondition</a> array</em></td><td>The latest available observations of an object’s current state.</td></tr>
<tr><td><code>phase</code> <em>JobPhase</em></td><td>Provides a simple, high-level summary of where the Job is in its lifecycle. Note that this is NOT indended to be a comprehensive state machine.</td></tr>
</tbody></table>
</div>
<h4 id="replicaspec-2"><a class="header" href="#replicaspec-2">ReplicaSpec</a></h4>
<p>ReplicaSpec is a description of the job replica.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/pytorchtrainingjob.html#pytorchtrainingjobspec">PyTorchTrainingJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em>string</em></td><td>ReplicaType is the type of the replica.</td></tr>
<tr><td><code>replicas</code> <em>integer</em></td><td>The desired number of replicas of the current template. Defaults to 1.</td></tr>
<tr><td><code>scalingWeight</code> <em>integer</em></td><td>Scaling weight of the current replica used in elastic training.</td></tr>
<tr><td><code>template</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podtemplatespec-v1-core">PodTemplateSpec</a></em></td><td>Describes the pod that will be created for this replica. Note that <code>RestartPolicy</code> in <code>PodTemplateSpec</code> will always be set to <code>Never</code> as the job controller will decide if restarts are desired.</td></tr>
<tr><td><code>restartPolicy</code> <em>RestartPolicy</em></td><td>Restart policy for all replicas within the job. One of <code>Always</code>, <code>OnFailure</code>, <code>Never</code>, or <code>ExitCode</code>.</td></tr>
</tbody></table>
</div>
<h4 id="torchrunconfig"><a class="header" href="#torchrunconfig">TorchrunConfig</a></h4>
<p>Describes how to launch pytorch training with torchrun.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/pytorchtrainingjob.html#pytorchtrainingjobspec">PyTorchTrainingJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code> <em>boolean</em></td><td>Set true to use torchrun launch pytorch training.</td></tr>
<tr><td><code>maxRestarts</code> <em>integer</em></td><td></td></tr>
<tr><td><code>procPerNode</code> <em>string</em></td><td>Number of processes to be started on every replica.</td></tr>
<tr><td><code>rdzvBackend</code> <em>string</em></td><td>Communication backed used for the group. Defaults to <code>c10d</code>.</td></tr>
<tr><td><code>extraOptions</code> <em>string array</em></td><td>Extra options for torchrun.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-4"><a class="header" href="#api-reference-4">API Reference</a></h1>
<h2 id="packages-4"><a class="header" href="#packages-4">Packages</a></h2>
<ul>
<li><a href="references/api-reference/xgboosttrainingjob.html#batchtensorstackdevv1beta1">batch.tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="batchtensorstackdevv1beta1-3"><a class="header" href="#batchtensorstackdevv1beta1-3">batch.tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the batch v1beta1 API group</p>
<h3 id="resource-types-4"><a class="header" href="#resource-types-4">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/xgboosttrainingjob.html#xgboosttrainingjob">XGBoostTrainingJob</a></li>
<li><a href="references/api-reference/xgboosttrainingjob.html#xgboosttrainingjoblist">XGBoostTrainingJobList</a></li>
</ul>
<h4 id="replicaspec-3"><a class="header" href="#replicaspec-3">ReplicaSpec</a></h4>
<p>ReplicaSpec outlines the intended configuration and execution parameters for a XGBoostTrainingJob.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/xgboosttrainingjob.html#xgboosttrainingjobspec">XGBoostTrainingJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/xgboosttrainingjob.html#replicatype">ReplicaType</a></em></td><td>ReplicaType is the type of the replica, one of “master” or “worker”.</td></tr>
<tr><td><code>replicas</code> <em>integer</em></td><td>The desired number of replicas of the current template. If unspecified, defaults to 1.</td></tr>
<tr><td><code>template</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podtemplatespec-v1-core">PodTemplateSpec</a></em></td><td>Describes the pod that will be created for this replica. Note that <code>RestartPolicy</code> in <code>PodTemplateSpec</code> will always be set to <code>Never</code> as the job controller will decide if restarts are desired.</td></tr>
<tr><td><code>restartPolicy</code> <em>RestartPolicy</em></td><td>Restart policy for all replicas within the job. One of Always, OnFailure, Never, or ExitCode. Defaults to <code>OnFailure</code>.</td></tr>
</tbody></table>
</div>
<h4 id="replicatype-1"><a class="header" href="#replicatype-1">ReplicaType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>ReplicaType is the type of the replica, one of “<code>master</code>” or “<code>worker</code>”.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/xgboosttrainingjob.html#replicaspec">ReplicaSpec</a></li>
</ul>
<h4 id="xgboosttrainingjob-3"><a class="header" href="#xgboosttrainingjob-3">XGBoostTrainingJob</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/xgboosttrainingjob.html#xgboosttrainingjoblist">XGBoostTrainingJobList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>XGBoostTrainingJob</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/xgboosttrainingjob.html#xgboosttrainingjobspec">XGBoostTrainingJobSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/xgboosttrainingjob.html#xgboosttrainingjobstatus">XGBoostTrainingJobStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="xgboosttrainingjoblist"><a class="header" href="#xgboosttrainingjoblist">XGBoostTrainingJobList</a></h4>
<p>XGBoostTrainingJobList contains a list of XGBoostTrainingJob.</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>XGBoostTrainingJobList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/xgboosttrainingjob.html#xgboosttrainingjob">XGBoostTrainingJob</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="xgboosttrainingjobspec"><a class="header" href="#xgboosttrainingjobspec">XGBoostTrainingJobSpec</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/xgboosttrainingjob.html#xgboosttrainingjob">XGBoostTrainingJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>replicaSpecs</code> <em><a href="references/api-reference/xgboosttrainingjob.html#replicaspec">ReplicaSpec</a> array</em></td><td>An array of ReplicaSpec. Specifies the XGBoost replica configurations.</td></tr>
<tr><td><code>runMode</code> <em><a href="references/api-reference/xgboosttrainingjob.html#runmode">RunMode</a></em></td><td>Job’s execution behavior. If omitted, defaults to <code>Immediate</code> mode, and tasks are executed immediately upon submission.</td></tr>
<tr><td><code>runPolicy</code> <em><a href="references/api-reference/xgboosttrainingjob.html#runpolicy">RunPolicy</a></em></td><td>Execution policy configurations governing the behavior of the XGBoostTrainingJob.</td></tr>
<tr><td><code>scheduler</code> <em>SchedulePolicy</em></td><td>Identifies the preferred scheduler for allocating resources to replicas. Defaults to cluster default scheduler.</td></tr>
</tbody></table>
</div>
<h4 id="xgboosttrainingjobstatus"><a class="header" href="#xgboosttrainingjobstatus">XGBoostTrainingJobStatus</a></h4>
<p>XGBoostTrainingJobStatus defines the observed state of XGBoostTrainingJob.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/xgboosttrainingjob.html#xgboosttrainingjob">XGBoostTrainingJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tasks</code> <em><a href="references/api-reference/xgboosttrainingjob.html#tasks">Tasks</a> array</em></td><td>The status details of individual tasks.</td></tr>
<tr><td><code>backoffCount</code> <em>integer</em></td><td>The number of restarts being performed.</td></tr>
<tr><td><code>aggregate</code> <em><a href="references/api-reference/xgboosttrainingjob.html#aggregate">Aggregate</a></em></td><td></td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/xgboosttrainingjob.html#jobcondition">JobCondition</a> array</em></td><td>The latest available observations of an object’s current state.</td></tr>
<tr><td><code>phase</code> <em>JobPhase</em></td><td>Provides a simple, high-level summary of where the Job is in its lifecycle. Note that this is NOT indended to be a comprehensive state machine.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-5"><a class="header" href="#api-reference-5">API Reference</a></h1>
<h2 id="packages-5"><a class="header" href="#packages-5">Packages</a></h2>
<ul>
<li><a href="references/api-reference/colossalaijob.html#batchtensorstackdevv1beta1">batch.tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="batchtensorstackdevv1beta1-4"><a class="header" href="#batchtensorstackdevv1beta1-4">batch.tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the batch v1beta1 API group</p>
<h3 id="resource-types-5"><a class="header" href="#resource-types-5">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/colossalaijob.html#colossalaijob">ColossalAIJob</a></li>
<li><a href="references/api-reference/colossalaijob.html#colossalaijoblist">ColossalAIJobList</a></li>
</ul>
<h4 id="colossalaijob-2"><a class="header" href="#colossalaijob-2">ColossalAIJob</a></h4>
<p>ColossalAIJob is the Schema for the colossalaijobs API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/colossalaijob.html#colossalaijoblist">ColossalAIJobList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>ColossalAIJob</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/colossalaijob.html#colossalaijobspec">ColossalAIJobSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/colossalaijob.html#colossalaijobstatus">ColossalAIJobStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="colossalaijoblist"><a class="header" href="#colossalaijoblist">ColossalAIJobList</a></h4>
<p>ColossalAIJobList contains a list of ColossalAIJob.</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>ColossalAIJobList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/colossalaijob.html#colossalaijob">ColossalAIJob</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="colossalaijobspec"><a class="header" href="#colossalaijobspec">ColossalAIJobSpec</a></h4>
<p>ColossalAIJobSpec defines the configurations of a ColossalAI training job.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/colossalaijob.html#colossalaijob">ColossalAIJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>ssh</code> <em><a href="references/api-reference/colossalaijob.html#sshconfig">SSHConfig</a></em></td><td>SSH configs.</td></tr>
<tr><td><code>runMode</code> <em><a href="references/api-reference/colossalaijob.html#runmode">RunMode</a></em></td><td>The desired running mode of the job, defaults to <code>Immediate</code>.</td></tr>
<tr><td><code>runPolicy</code> <em><a href="references/api-reference/colossalaijob.html#runpolicy">RunPolicy</a></em></td><td>Controls the handling of completed replicas and other related processes.</td></tr>
<tr><td><code>scheduler</code> <em>SchedulePolicy</em></td><td>Specifies the scheduler to request for resources. Defaults to cluster default scheduler.</td></tr>
<tr><td><code>launcher</code> <em><a href="references/api-reference/colossalaijob.html#launcher">Launcher</a></em></td><td>Specication for the launcher replica.</td></tr>
<tr><td><code>worker</code> <em><a href="references/api-reference/colossalaijob.html#worker">Worker</a></em></td><td>Specication for the launcher replica.</td></tr>
</tbody></table>
</div>
<h4 id="colossalaijobstatus"><a class="header" href="#colossalaijobstatus">ColossalAIJobStatus</a></h4>
<p>ColossalAIJobStatus describes the observed state of ColossalAIJob.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/colossalaijob.html#colossalaijob">ColossalAIJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tasks</code> <em><a href="references/api-reference/colossalaijob.html#tasks">Tasks</a> array</em></td><td>The statuses of individual tasks.</td></tr>
<tr><td><code>aggregate</code> <em><a href="references/api-reference/colossalaijob.html#aggregate">Aggregate</a></em></td><td>The number of replicas in each phase.</td></tr>
<tr><td><code>phase</code> <em>JobPhase</em></td><td>Provides a simple, high-level summary of where the Job is in its lifecycle. Note that this is NOT indended to be a comprehensive state machine.</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/colossalaijob.html#jobcondition">JobCondition</a> array</em></td><td>The latest available observations of an object’s current state.</td></tr>
</tbody></table>
</div>
<h4 id="launcher"><a class="header" href="#launcher">Launcher</a></h4>
<p>Specification of replica <code>launcher</code>.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/colossalaijob.html#colossalaijobspec">ColossalAIJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>image</code> <em>string</em></td><td>Container image name.</td></tr>
<tr><td><code>workingDir</code> <em>string</em></td><td>Working directory of container <code>launcher</code>. If not specified, the container runtime’s default will be used, which might be configured in the container image. Cannot be updated.</td></tr>
<tr><td><code>env</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#envvar-v1-core">EnvVar</a> array</em></td><td>List of environment variables set for the container. Cannot be updated.</td></tr>
<tr><td><code>resources</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcerequirements-v1-core">ResourceRequirements</a></em></td><td>Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/</td></tr>
</tbody></table>
</div>
<h4 id="runpolicy-1"><a class="header" href="#runpolicy-1">RunPolicy</a></h4>
<p>RunPolicy dictates specific actions to be taken by the controller upon job completion.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/colossalaijob.html#colossalaijobspec">ColossalAIJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>cleanUpWorkers</code> <em>boolean</em></td><td>Defaults to false.</td></tr>
</tbody></table>
</div>
<h4 id="sshconfig"><a class="header" href="#sshconfig">SSHConfig</a></h4>
<p>SSHConfig specifies various configurations for running the SSH daemon (sshd).</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/colossalaijob.html#colossalaijobspec">ColossalAIJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>authMountPath</code> <em>string</em></td><td>SSHAuthMountPath is the directory where SSH keys are mounted. Defaults to “/root/.ssh”.</td></tr>
<tr><td><code>sshdPath</code> <em>string</em></td><td>The location of the sshd executable file.</td></tr>
</tbody></table>
</div>
<h4 id="worker"><a class="header" href="#worker">Worker</a></h4>
<p>Specification of the worker replicas.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/colossalaijob.html#colossalaijobspec">ColossalAIJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>replicas</code> <em>integer</em></td><td>Number of replicas to launch. Defaults to 1.</td></tr>
<tr><td><code>procPerWorker</code> <em>integer</em></td><td>The number of processes of a worker. Defaults to 1.</td></tr>
<tr><td><code>command</code> <em>string array</em></td><td>Specifies the command used to start the workers.</td></tr>
<tr><td><code>torchArgs</code> <em>string array</em></td><td>Args of torchrun.</td></tr>
<tr><td><code>template</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podtemplatespec-v1-core">PodTemplateSpec</a></em></td><td>Template defines the workers that will be created from this pod template.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-6"><a class="header" href="#api-reference-6">API Reference</a></h1>
<h2 id="packages-6"><a class="header" href="#packages-6">Packages</a></h2>
<ul>
<li><a href="references/api-reference/deepspeedjob.html#batchtensorstackdevv1beta1">batch.tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="batchtensorstackdevv1beta1-5"><a class="header" href="#batchtensorstackdevv1beta1-5">batch.tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the batch v1beta1 API group</p>
<h3 id="resource-types-6"><a class="header" href="#resource-types-6">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/deepspeedjob.html#deepspeedjob">DeepSpeedJob</a></li>
<li><a href="references/api-reference/deepspeedjob.html#deepspeedjoblist">DeepSpeedJobList</a></li>
</ul>
<h4 id="config-2"><a class="header" href="#config-2">Config</a></h4>
<p>Configuration information for running a DeepSpeed job. Details are outlined in the official DeepSpeed documentation (https://www.deepspeed.ai/getting-started/) for comprehensive guidance.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/deepspeedjob.html#deepspeedjobspec">DeepSpeedJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>customCommand</code> <em>string</em></td><td>Custom launch commands, when enabled, other options in Config except for <code>slotsPerWorker</code> will not take effect.</td></tr>
<tr><td><code>slotsPerWorker</code> <em>integer</em></td><td>The number of slots for each worker/replica. This is normally set to the number of GPUs requested for each replica.</td></tr>
<tr><td><code>localRank</code> <em>boolean</em></td><td>If parameter <code>local_rank</code> should be passed to training programs.</td></tr>
<tr><td><code>autotune</code> <em>AutotuneType</em></td><td>Parameters for running the autotuning process to find configurations for a training job on a particular cluster/machine.</td></tr>
<tr><td><code>run</code> <em><a href="references/api-reference/deepspeedjob.html#runtype">RunType</a></em></td><td>Mechanism to start the training program.</td></tr>
<tr><td><code>otherArgs</code> <em>string array</em></td><td>Seting up other command line args for the deepspeed job.</td></tr>
</tbody></table>
</div>
<h4 id="deepspeedjob-2"><a class="header" href="#deepspeedjob-2">DeepSpeedJob</a></h4>
<p>DeepSpeedJob defines the schema for the DeepSpeedJob API.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/deepspeedjob.html#deepspeedjoblist">DeepSpeedJobList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>DeepSpeedJob</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/deepspeedjob.html#deepspeedjobspec">DeepSpeedJobSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/deepspeedjob.html#deepspeedjobstatus">DeepSpeedJobStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="deepspeedjoblist"><a class="header" href="#deepspeedjoblist">DeepSpeedJobList</a></h4>
<p>DeepSpeedJobList contains a list of DeepSpeedJob</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>DeepSpeedJobList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/deepspeedjob.html#deepspeedjob">DeepSpeedJob</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="deepspeedjobspec"><a class="header" href="#deepspeedjobspec">DeepSpeedJobSpec</a></h4>
<p>DeepSpeedJobSpec outlines the intended configuration and execution parameters for a DeepSpeedJob.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/deepspeedjob.html#deepspeedjob">DeepSpeedJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>scheduler</code> <em>SchedulePolicy</em></td><td>Identifies the preferred scheduler for allocating resources to replicas. Defaults to cluster default scheduler.</td></tr>
<tr><td><code>runPolicy</code> <em><a href="references/api-reference/deepspeedjob.html#runpolicy">RunPolicy</a></em></td><td>Execution policy configurations governing the behavior of the distributed training job.</td></tr>
<tr><td><code>runMode</code> <em><a href="references/api-reference/deepspeedjob.html#runmode">RunMode</a></em></td><td>Job’s execution behavior. If omitted, defaults to <code>Immediate</code> mode, and tasks are executed immediately upon submission.</td></tr>
<tr><td><code>elastic</code> <em><a href="references/api-reference/deepspeedjob.html#elasticconfig">ElasticConfig</a></em></td><td>Configurations for how to launch an elastic training.</td></tr>
<tr><td><code>config</code> <em><a href="references/api-reference/deepspeedjob.html#config">Config</a></em></td><td>Key configurations for executing DeepSpeed training jobs.</td></tr>
<tr><td><code>disableCustomEnv</code> <em>boolean</em></td><td>Setting environment variables during DeepSpeed training necessitates creating an env file to store the desired variables. The launcher will then distribute these variables to each worker process. Nevertheless, certain scenarios require disabling this automated behavior, and this flag enables control over this functionality.</td></tr>
<tr><td><code>false</code>: (default) The environment variables set in job specs are used in the training processes. The controller  will automatically put the environment variables into the env file so that the launcher can send them to each worker;</td><td></td></tr>
<tr><td><code>true</code>: The environment variables set in the job specs are only used to start the container entrypoint program, and the training program does not need these environment variables.</td><td></td></tr>
<tr><td><code>worker</code> <em><a href="references/api-reference/deepspeedjob.html#worker">Worker</a></em></td><td>Specifications for the worker replicas.</td></tr>
</tbody></table>
</div>
<h4 id="deepspeedjobstatus"><a class="header" href="#deepspeedjobstatus">DeepSpeedJobStatus</a></h4>
<p>DeepSpeedJobStatus represents the observed state of a DeepSpeedJob.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/deepspeedjob.html#deepspeedjob">DeepSpeedJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tasks</code> <em><a href="references/api-reference/deepspeedjob.html#tasks">Tasks</a> array</em></td><td></td></tr>
<tr><td><code>aggregate</code> <em><a href="references/api-reference/deepspeedjob.html#aggregate">Aggregate</a></em></td><td></td></tr>
<tr><td><code>phase</code> <em>JobPhase</em></td><td>Provides a simple, high-level summary of where the Job is in its lifecycle. Note that this is NOT indended to be a comprehensive state machine.</td></tr>
<tr><td><code>backoffCount</code> <em>integer</em></td><td>The number of restarts being performed.</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/deepspeedjob.html#jobcondition">JobCondition</a> array</em></td><td>The latest available observations of an object’s current state.</td></tr>
</tbody></table>
</div>
<h4 id="elasticconfig-1"><a class="header" href="#elasticconfig-1">ElasticConfig</a></h4>
<p>Configuration governing the elastic scaling behavior of the job.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/deepspeedjob.html#deepspeedjobspec">DeepSpeedJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code> <em>boolean</em></td><td>Set true to use elastic training.</td></tr>
<tr><td><code>minReplicas</code> <em>integer</em></td><td>The minimum number of replicas to start to run this elastic compute. The autoscaler cannot scale down an elastic job below this number. This value cannnot be changed once the job is created.</td></tr>
<tr><td><code>maxReplicas</code> <em>integer</em></td><td>The maximum number of replicas to start to run this elastic compute. The autoscaler cannot scale up an elastic job over this number. This value cannnot be changed once the job is created.</td></tr>
<tr><td><code>expectedReplicas</code> <em>integer</em></td><td>Number of replicas to be created. This number can be set to an initial value upon creation. This value can be modified dynamically by an external entity, such as a user or an autoscaler, to scale the job up or down.</td></tr>
</tbody></table>
</div>
<h4 id="runpolicy-2"><a class="header" href="#runpolicy-2">RunPolicy</a></h4>
<p>RunPolicy encapsulates various runtime policies of the distributed training job, for example how to clean up resources and how long the job can stay active.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/deepspeedjob.html#deepspeedjobspec">DeepSpeedJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>activeDeadlineSeconds</code> <em>integer</em></td><td>Specifies the duration in seconds relative to the <code>startTime</code> that the job may be active before the system tries to terminate it; value must be positive integer.</td></tr>
<tr><td><code>backoffLimit</code> <em>integer</em></td><td>Optional number of retries before marking this job failed.</td></tr>
<tr><td><code>cleanUpPolicy</code> <em>CleanUpPolicy</em></td><td>Clean the tasks after the training job finished.</td></tr>
</tbody></table>
</div>
<h4 id="runtype"><a class="header" href="#runtype">RunType</a></h4>
<p>How the training program should be started. Exactly one of the 3 choices should be set.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/deepspeedjob.html#config">Config</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>python</code> <em>string array</em></td><td>Using a python script</td></tr>
<tr><td><code>module</code> <em>string array</em></td><td>Using a python module</td></tr>
<tr><td><code>exec</code> <em>string array</em></td><td>Using an executable program</td></tr>
</tbody></table>
</div>
<h4 id="worker-1"><a class="header" href="#worker-1">Worker</a></h4>
<p>Worker defines the configurations for DeepSpeedJob worker replicas.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/deepspeedjob.html#deepspeedjobspec">DeepSpeedJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>replicas</code> <em>integer</em></td><td>The number of workers to launch.</td></tr>
<tr><td><code>template</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podtemplatespec-v1-core">PodTemplateSpec</a></em></td><td>Describes the pod that will be created for this replica. Note that <code>RestartPolicy</code> in <code>PodTemplateSpec</code> will always be set to <code>Never</code> as the job controller will decide if restarts are desired.</td></tr>
<tr><td><code>restartPolicy</code> <em>RestartPolicy</em></td><td>Restart policy for all replicas owned by the job. One of Always, OnFailure, Never, or ExitCode. Defaults to <code>OnFailure</code>.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-7"><a class="header" href="#api-reference-7">API Reference</a></h1>
<h2 id="packages-7"><a class="header" href="#packages-7">Packages</a></h2>
<ul>
<li><a href="references/api-reference/mpijob.html#batchtensorstackdevv1beta1">batch.tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="batchtensorstackdevv1beta1-6"><a class="header" href="#batchtensorstackdevv1beta1-6">batch.tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the batch v1beta1 API group</p>
<h3 id="resource-types-7"><a class="header" href="#resource-types-7">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/mpijob.html#mpijob">MPIJob</a></li>
<li><a href="references/api-reference/mpijob.html#mpijoblist">MPIJobList</a></li>
</ul>
<h4 id="mpijob-3"><a class="header" href="#mpijob-3">MPIJob</a></h4>
<p>MPIJob is the Schema for the mpijobs API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mpijob.html#mpijoblist">MPIJobList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>MPIJob</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/mpijob.html#mpijobspec">MPIJobSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/mpijob.html#mpijobstatus">MPIJobStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="mpijoblist"><a class="header" href="#mpijoblist">MPIJobList</a></h4>
<p>MPIJobList contains a list of MPIJob</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>MPIJobList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/mpijob.html#mpijob">MPIJob</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="mpijobspec"><a class="header" href="#mpijobspec">MPIJobSpec</a></h4>
<p>MPIJobSpec outlines the intended configuration and execution parameters for a MPIJob.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mpijob.html#mpijob">MPIJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>worker</code> <em><a href="references/api-reference/mpijob.html#workerconfig">WorkerConfig</a></em></td><td>Specifications for the worker replicas.</td></tr>
<tr><td><code>mca</code> <em>object (keys:string, values:string)</em></td><td>Open MPI uses Modular Component Architecture (MCA) parameters to provide a way to tune your runtime environment.</td></tr>
<tr><td><code>ssh</code> <em><a href="references/api-reference/mpijob.html#sshconfig">SSHConfig</a></em></td><td>SSH configs.</td></tr>
<tr><td><code>runPolicy</code> <em><a href="references/api-reference/mpijob.html#runpolicy">RunPolicy</a></em></td><td>Execution policy configurations governing the behavior of the MPI job.</td></tr>
<tr><td><code>runMode</code> <em><a href="references/api-reference/mpijob.html#runmode">RunMode</a></em></td><td>Job’s execution behavior. If omitted, defaults to <code>Immediate</code> mode, and tasks are executed immediately upon submission.</td></tr>
<tr><td><code>mpiHome</code> <em>string</em></td><td>Open MPI installation path.</td></tr>
<tr><td><code>scheduler</code> <em>SchedulePolicy</em></td><td>Identifies the preferred scheduler for allocating resources to replicas. Defaults to cluster default scheduler. Use k8s default scheduler by default.</td></tr>
</tbody></table>
</div>
<h4 id="mpijobstatus"><a class="header" href="#mpijobstatus">MPIJobStatus</a></h4>
<p>MPIJobStatus represents the observed state of a MPIJob.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mpijob.html#mpijob">MPIJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tasks</code> <em><a href="references/api-reference/mpijob.html#tasks">Tasks</a> array</em></td><td>Individual task status details of the job.</td></tr>
<tr><td><code>aggregate</code> <em><a href="references/api-reference/mpijob.html#aggregate">Aggregate</a></em></td><td></td></tr>
<tr><td><code>phase</code> <em>JobPhase</em></td><td>Provides a simple, high-level summary of where the Job is in its lifecycle. Note that this is NOT indended to be a comprehensive state machine.</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/mpijob.html#jobcondition">JobCondition</a> array</em></td><td>The latest available observations of an object’s current state.</td></tr>
</tbody></table>
</div>
<h4 id="runpolicy-3"><a class="header" href="#runpolicy-3">RunPolicy</a></h4>
<p>RunPolicy encapsulates various runtime policies of the MPI job, for example how to clean up resources.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mpijob.html#mpijobspec">MPIJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>cleanUpWorkers</code> <em>boolean</em></td><td>If worker replicas should be cleand up after they finish. Defaults false.</td></tr>
</tbody></table>
</div>
<h4 id="sshconfig-1"><a class="header" href="#sshconfig-1">SSHConfig</a></h4>
<p>SSHConfig specifies various configurations for running the SSH daemon (sshd).</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mpijob.html#mpijobspec">MPIJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>sshAuthMountPath</code> <em>string</em></td><td>SSHAuthMountPath is the directory where SSH keys are mounted. Defaults to “/root/.ssh”.</td></tr>
<tr><td><code>sshdPath</code> <em>string</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="workerconfig"><a class="header" href="#workerconfig">WorkerConfig</a></h4>
<p>WorkerConfig defines the configurations for MPI worker replicas.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mpijob.html#mpijobspec">MPIJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>replicas</code> <em>integer</em></td><td>The number of workers to launch. Default 1.</td></tr>
<tr><td><code>extraMPIArgs</code> <em>string array</em></td><td>Extra args for mpirun.</td></tr>
<tr><td><code>cmd</code> <em>string array</em></td><td>Command line to start the MPI programs inside a worker pod. This is invoked by the launcher after all the worker pods have been created and entered ready state.</td></tr>
<tr><td><code>template</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podtemplatespec-v1-core">PodTemplateSpec</a></em></td><td>Defines the pod template used to create workers. Users are responsible for ensuring that container images and configurations are properly set to guarantee the worker operates in the state anticipated by the <code>launcher</code>.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-8"><a class="header" href="#api-reference-8">API Reference</a></h1>
<h2 id="packages-8"><a class="header" href="#packages-8">Packages</a></h2>
<ul>
<li><a href="references/api-reference/beamjob.html#batchtensorstackdevv1beta1">batch.tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="batchtensorstackdevv1beta1-7"><a class="header" href="#batchtensorstackdevv1beta1-7">batch.tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the batch v1beta1 API group</p>
<h3 id="resource-types-8"><a class="header" href="#resource-types-8">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/beamjob.html#beamjob">BeamJob</a></li>
<li><a href="references/api-reference/beamjob.html#beamjoblist">BeamJobList</a></li>
</ul>
<h4 id="beamjob-3"><a class="header" href="#beamjob-3">BeamJob</a></h4>
<p>BeamJob is the Schema for the beamjobs API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/beamjob.html#beamjoblist">BeamJobList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>BeamJob</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/beamjob.html#beamjobspec">BeamJobSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/beamjob.html#beamjobstatus">BeamJobStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="beamjoblist"><a class="header" href="#beamjoblist">BeamJobList</a></h4>
<p>BeamJobList contains a list of BeamJob</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>BeamJobList</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/beamjob.html#beamjob">BeamJob</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="beamjobspec"><a class="header" href="#beamjobspec">BeamJobSpec</a></h4>
<p>BeamJobSpec defines the desired state of BeamJob</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/beamjob.html#beamjob">BeamJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>flinkClusterTemplate</code> <em><a href="references/api-reference/beamjob.html#flinkclustertemplatespec">FlinkClusterTemplateSpec</a></em></td><td>Specifies the FlinkCluster that will be created when executing a BeamJob.</td></tr>
<tr><td><code>jobTemplate</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#jobtemplatespec-v1beta1-batch">JobTemplateSpec</a></em></td><td>Specifies the Job that will be created when executing a BeamJob.</td></tr>
<tr><td><code>runPolicy</code> <em><a href="references/api-reference/beamjob.html#runpolicy">RunPolicy</a></em></td><td>Runtime policies governing the behavior of the BeamJob.</td></tr>
<tr><td><code>scheduler</code> <em>SchedulePolicy</em></td><td>Identifies the preferred scheduler for allocating resources to replicas. Defaults to cluster default scheduler.</td></tr>
<tr><td><code>runMode</code> <em><a href="references/api-reference/beamjob.html#runmode">RunMode</a></em></td><td>Normal mode and debug mode are supported now.</td></tr>
</tbody></table>
</div>
<h4 id="beamjobstatus"><a class="header" href="#beamjobstatus">BeamJobStatus</a></h4>
<p>BeamJobStatus defines the observed state of BeamJob</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/beamjob.html#beamjob">BeamJob</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>phase</code> <em>JobPhase</em></td><td>Phase is a label for the condition of the job at the current time.</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/beamjob.html#jobcondition">JobCondition</a> array</em></td><td>The latest available observations of the BeamJob’s current state.</td></tr>
<tr><td><code>tasks</code> <em><a href="references/api-reference/beamjob.html#tasks">Tasks</a> array</em></td><td>The statuses of individual tasks.</td></tr>
<tr><td><code>aggregate</code> <em><a href="references/api-reference/beamjob.html#aggregate">Aggregate</a></em></td><td></td></tr>
<tr><td><code>jobURL</code> <em>string</em></td><td>The URL to Web UI of the cluster where details of the job is displayed.</td></tr>
</tbody></table>
</div>
<h4 id="flinkclustertemplatespec"><a class="header" href="#flinkclustertemplatespec">FlinkClusterTemplateSpec</a></h4>
<p>FlinkClusterTemplateSpec describes the data a FlinkCluster should have when created from a template</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/beamjob.html#beamjobspec">BeamJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/beamjob.html#flinkclusterspec">FlinkClusterSpec</a></em></td><td>Specification of the desired behavior of the FlinkCluster.</td></tr>
</tbody></table>
</div>
<h4 id="runpolicy-4"><a class="header" href="#runpolicy-4">RunPolicy</a></h4>
<p>RunPolicy encapsulates runtime policies governing the behavior of the BeamJob.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/beamjob.html#beamjobspec">BeamJobSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>cleanUpCluster</code> <em>boolean</em></td><td>Whether or not delete cluster after the job finished. Default false.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-9"><a class="header" href="#api-reference-9">API Reference</a></h1>
<h2 id="packages-9"><a class="header" href="#packages-9">Packages</a></h2>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorstackdevv1beta1">tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="tensorstackdevv1beta1-1"><a class="header" href="#tensorstackdevv1beta1-1">tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the  v1beta1 API group</p>
<h3 id="resource-types-9"><a class="header" href="#resource-types-9">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboard">TensorBoard</a></li>
<li><a href="references/api-reference/tensorboard.html#tensorboardlist">TensorBoardList</a></li>
</ul>
<h4 id="httpdatasource"><a class="header" href="#httpdatasource">HttpDataSource</a></h4>
<p>Details of HTTP data source.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboarddatasource">TensorBoardDataSource</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>url</code> <em>string array</em></td><td>Url pointing to the log files.</td></tr>
</tbody></table>
</div>
<h4 id="pvcdatasource"><a class="header" href="#pvcdatasource">PVCDataSource</a></h4>
<p>Details of PVC data source.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboarddatasource">TensorBoardDataSource</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>PVC name.</td></tr>
<tr><td><code>subPath</code> <em>string array</em></td><td>The relative paths of logs in the PVC.</td></tr>
</tbody></table>
</div>
<h4 id="podreference"><a class="header" href="#podreference">PodReference</a></h4>
<p>PodReference references to a <code>v1.pod</code>.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#podstatus">PodStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Name of the Pod.</td></tr>
<tr><td><code>uid</code> <em>string</em></td><td>UID of the Pod.</td></tr>
</tbody></table>
</div>
<h4 id="podstatus"><a class="header" href="#podstatus">PodStatus</a></h4>
<p>Pod defines the observed state of a replica.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboardstatus">TensorBoardStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>reference</code> <em><a href="references/api-reference/tensorboard.html#podreference">PodReference</a></em></td><td>References to the subordinate <code>v1.Pod</code>.</td></tr>
<tr><td><code>phase</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podphase-v1-core">PodPhase</a></em></td><td>Replicated from the corresponding field in the subordinate <code>v1.Pod</code>.</td></tr>
</tbody></table>
</div>
<h4 id="s3datasource"><a class="header" href="#s3datasource">S3DataSource</a></h4>
<p>Details of S3 data source.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboarddatasource">TensorBoardDataSource</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>secretRef</code> <em><a href="references/api-reference/tensorboard.html#secretref">SecretRef</a></em></td><td>S3 data source uses a secret to transmit access/secret key and service enpoint.</td></tr>
<tr><td><code>uri</code> <em>string array</em></td><td>S3 object uri.</td></tr>
</tbody></table>
</div>
<h4 id="schedulepolicy-2"><a class="header" href="#schedulepolicy-2">SchedulePolicy</a></h4>
<p>SchedulePolicy specifies the preferred scheduler responsible for handling resource allocation requests.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboardspec">TensorBoardSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>t9kScheduler</code> <em><a href="references/api-reference/tensorboard.html#t9kscheduler">T9kScheduler</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="secretref"><a class="header" href="#secretref">SecretRef</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#s3datasource">S3DataSource</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Secret name.</td></tr>
</tbody></table>
</div>
<h4 id="t9kscheduler-2"><a class="header" href="#t9kscheduler-2">T9kScheduler</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#schedulepolicy">SchedulePolicy</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>queue</code> <em>string</em></td><td>Name of the queue to use with the T9kScheduler.</td></tr>
</tbody></table>
</div>
<h4 id="tensorboard-2"><a class="header" href="#tensorboard-2">TensorBoard</a></h4>
<p>TensorBoard is the Schema for the tensorboards API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboardlist">TensorBoardList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>TensorBoard</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/tensorboard.html#tensorboardspec">TensorBoardSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/tensorboard.html#tensorboardstatus">TensorBoardStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="tensorboardcondition"><a class="header" href="#tensorboardcondition">TensorBoardCondition</a></h4>
<p>TensorBoardCondition defines the observed condition of TensorBoard</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboardstatus">TensorBoardStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/tensorboard.html#tensorboardconditiontype">TensorBoardConditionType</a></em></td><td>Type is the type of the condition. Possible values are Idle, etc</td></tr>
<tr><td><code>status</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Status is the status of the condition type. Possible values of type Idle are True</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>Message is the reason of the status</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>LastTransitionTime is the last time the status was changed</td></tr>
<tr><td><code>lastProbeTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>LastProbeTime is the last time the condition was probed</td></tr>
</tbody></table>
</div>
<h4 id="tensorboardconditiontype"><a class="header" href="#tensorboardconditiontype">TensorBoardConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboardcondition">TensorBoardCondition</a></li>
</ul>
<h4 id="tensorboarddatasource"><a class="header" href="#tensorboarddatasource">TensorBoardDataSource</a></h4>
<p>TensorBoardDataSource represents the location and type of the tensorboard data source. It includes three types of data sources: PVC, S3, and HTTP. In a tensorboard service, these three types of data sources can be used simultaneously.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboardspec">TensorBoardSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>pvc</code> <em><a href="references/api-reference/tensorboard.html#pvcdatasource">PVCDataSource</a> array</em></td><td>PVC represents PVCs that are mounted to workload as directories to provide log data.</td></tr>
<tr><td><code>s3</code> <em><a href="references/api-reference/tensorboard.html#s3datasource">S3DataSource</a></em></td><td>S3 represents a s3 service and access/secret key to access the service.</td></tr>
<tr><td><code>http</code> <em><a href="references/api-reference/tensorboard.html#httpdatasource">HttpDataSource</a></em></td><td>HTTP provides several urls.</td></tr>
</tbody></table>
</div>
<h4 id="tensorboardlist"><a class="header" href="#tensorboardlist">TensorBoardList</a></h4>
<p>TensorBoardList contains a list of TensorBoard</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>TensorBoardList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/tensorboard.html#tensorboard">TensorBoard</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="tensorboardphase"><a class="header" href="#tensorboardphase">TensorBoardPhase</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboardstatus">TensorBoardStatus</a></li>
</ul>
<h4 id="tensorboardspec"><a class="header" href="#tensorboardspec">TensorBoardSpec</a></h4>
<p>TensorBoardSpec defines the desired state of TensorBoard</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboard">TensorBoard</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>trainingLogFilesets</code> <em>string array</em></td><td>TrainingLogFilesets is the list of filesets containing training log. The format of fileset:   t9k://pvc/[pvc-name]/[subpath]   t9k://minio/[secret-name]/[bucket]/[subpath] To be deprecated: Use spec.logDir instead.</td></tr>
<tr><td><code>logDir</code> <em><a href="references/api-reference/tensorboard.html#tensorboarddatasource">TensorBoardDataSource</a></em></td><td>LogDir is a series of data source containing training log.</td></tr>
<tr><td><code>image</code> <em>string</em></td><td>The container image used to run the tensorboard.</td></tr>
<tr><td><code>suspend</code> <em>boolean</em></td><td>suspend specifies whether the TensorBoard controller should delete Pods or not. If true, the associated v1.Pod can be terminated. However, other API resources, such as ConfigMaps and Services, will be preserved for use upon resuming the TensorBoard. Defaults to false.</td></tr>
<tr><td><code>scheduler</code> <em><a href="references/api-reference/tensorboard.html#schedulepolicy">SchedulePolicy</a></em></td><td></td></tr>
<tr><td><code>resources</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcerequirements-v1-core">ResourceRequirements</a></em></td><td>Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/</td></tr>
</tbody></table>
</div>
<h4 id="tensorboardstatus"><a class="header" href="#tensorboardstatus">TensorBoardStatus</a></h4>
<p>TensorBoardStatus defines the observed state of TensorBoard</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/tensorboard.html#tensorboard">TensorBoard</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>phase</code> <em><a href="references/api-reference/tensorboard.html#tensorboardphase">TensorBoardPhase</a></em></td><td></td></tr>
<tr><td><code>pod</code> <em><a href="references/api-reference/tensorboard.html#podstatus">PodStatus</a></em></td><td></td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/tensorboard.html#tensorboardcondition">TensorBoardCondition</a> array</em></td><td>Conditions is an array of current conditions</td></tr>
<tr><td><code>url</code> <em>string</em></td><td>The URL to Web UI of the tensorboard</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-10"><a class="header" href="#api-reference-10">API Reference</a></h1>
<h2 id="packages-10"><a class="header" href="#packages-10">Packages</a></h2>
<ul>
<li><a href="references/api-reference/notebook.html#tensorstackdevv1beta1">tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="tensorstackdevv1beta1-2"><a class="header" href="#tensorstackdevv1beta1-2">tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the v1beta1 API group</p>
<h3 id="resource-types-10"><a class="header" href="#resource-types-10">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/notebook.html#notebook">Notebook</a></li>
<li><a href="references/api-reference/notebook.html#notebooklist">NotebookList</a></li>
</ul>
<h4 id="notebook-5"><a class="header" href="#notebook-5">Notebook</a></h4>
<p>Notebook is the Schema for the notebooks API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#notebooklist">NotebookList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>Notebook</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/notebook.html#notebookspec">NotebookSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/notebook.html#notebookstatus">NotebookStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="notebookcondition"><a class="header" href="#notebookcondition">NotebookCondition</a></h4>
<p>NotebookCondition defines the observed condition of notebook</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#notebookstatus">NotebookStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/notebook.html#notebookconditiontype">NotebookConditionType</a></em></td><td>Type is the type of the condition. Possible values are <code>Idle</code>, etc</td></tr>
<tr><td><code>status</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Status is the status of the condition type. Possible values of type Idle are `True</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>Message is a human-readable message for the reason of the status.</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>LastTransitionTime is the last time the status was changed.</td></tr>
<tr><td><code>lastProbeTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>LastProbeTime is the last time the condition was probed.</td></tr>
</tbody></table>
</div>
<h4 id="notebookconditiontype"><a class="header" href="#notebookconditiontype">NotebookConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#notebookcondition">NotebookCondition</a></li>
</ul>
<h4 id="notebooklist"><a class="header" href="#notebooklist">NotebookList</a></h4>
<p>NotebookList contains a list of Notebook</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>NotebookList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/notebook.html#notebook">Notebook</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="notebookphase"><a class="header" href="#notebookphase">NotebookPhase</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#notebookstatus">NotebookStatus</a></li>
</ul>
<h4 id="notebooksshspec"><a class="header" href="#notebooksshspec">NotebookSSHSpec</a></h4>
<p>NotebookSSHSpec defines the ssh template spec of Notebook</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#notebookspec">NotebookSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code> <em>boolean</em></td><td>If true, SSH service will be started for this Notebook instance.</td></tr>
<tr><td><code>serviceType</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#servicetype-v1-core">ServiceType</a></em></td><td></td></tr>
<tr><td><code>authorized_keys</code> <em>string array</em></td><td>A list of names of v1.Secret containing SSH public keys authorized for access to this SSH service.</td></tr>
</tbody></table>
</div>
<h4 id="notebooksshstatus"><a class="header" href="#notebooksshstatus">NotebookSSHStatus</a></h4>
<p>NotebookSSHStatus defines the observed state of the SSH service associated with the Notebook.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#notebookstatus">NotebookStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>serviceName</code> <em>string</em></td><td>The v1.Service name of the SSH service.</td></tr>
<tr><td><code>port</code> <em>integer</em></td><td>The port number of the SSH server daemon.</td></tr>
<tr><td><code>clusterIp</code> <em>string</em></td><td></td></tr>
<tr><td><code>nodePort</code> <em>integer</em></td><td></td></tr>
<tr><td><code>protocol</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#protocol-v1-core">Protocol</a></em></td><td></td></tr>
<tr><td><code>lastSshClientActivity</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>LastSshClientActivity is the last time an SSH client is active.</td></tr>
</tbody></table>
</div>
<h4 id="notebookspec"><a class="header" href="#notebookspec">NotebookSpec</a></h4>
<p>NotebookSpec defines the desired state of a Notebook.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#notebook">Notebook</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>template</code> <em><a href="references/api-reference/notebook.html#notebooktemplatespec">NotebookTemplateSpec</a></em></td><td></td></tr>
<tr><td><code>scheduler</code> <em><a href="references/api-reference/notebook.html#schedulepolicy">SchedulePolicy</a></em></td><td></td></tr>
<tr><td><code>ssh</code> <em><a href="references/api-reference/notebook.html#notebooksshspec">NotebookSSHSpec</a></em></td><td></td></tr>
<tr><td><code>type</code> <em><a href="references/api-reference/notebook.html#notebooktype">NotebookType</a></em></td><td></td></tr>
<tr><td><code>suspend</code> <em>boolean</em></td><td>suspend specifies whether the Notebook controller should delete Pods or not. If true, the associated v1.Pod can be terminated. However, other API resources, such as ConfigMaps and Services, will be preserved for use upon resuming the notebook. Defaults to false.</td></tr>
</tbody></table>
</div>
<h4 id="notebookstatus"><a class="header" href="#notebookstatus">NotebookStatus</a></h4>
<p>NotebookStatus defines the observed state of a Notebook.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#notebook">Notebook</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>phase</code> <em><a href="references/api-reference/notebook.html#notebookphase">NotebookPhase</a></em></td><td></td></tr>
<tr><td><code>pod</code> <em><a href="references/api-reference/notebook.html#podstatus">PodStatus</a></em></td><td></td></tr>
<tr><td><code>ssh</code> <em><a href="references/api-reference/notebook.html#notebooksshstatus">NotebookSSHStatus</a></em></td><td></td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/notebook.html#notebookcondition">NotebookCondition</a> array</em></td><td>Conditions is an array of current conditions</td></tr>
<tr><td><code>url</code> <em>string</em></td><td>The URL to Web UI of the notebook</td></tr>
</tbody></table>
</div>
<h4 id="notebooktemplatespec"><a class="header" href="#notebooktemplatespec">NotebookTemplateSpec</a></h4>
<p>NotebookTemplateSpec defines the pod template to run a Notebook.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#notebookspec">NotebookSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>spec</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podspec-v1-core">PodSpec</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="notebooktype"><a class="header" href="#notebooktype">NotebookType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#notebookspec">NotebookSpec</a></li>
</ul>
<h4 id="podreference-1"><a class="header" href="#podreference-1">PodReference</a></h4>
<p>PodReference references a K8s v1.Pod.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#podstatus">PodStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Name of the Pod.</td></tr>
<tr><td><code>uid</code> <em>string</em></td><td>UID of the Pod.</td></tr>
</tbody></table>
</div>
<h4 id="podstatus-1"><a class="header" href="#podstatus-1">PodStatus</a></h4>
<p>Pod defines the observed state of the Pod running the notebook.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#notebookstatus">NotebookStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>reference</code> <em><a href="references/api-reference/notebook.html#podreference">PodReference</a></em></td><td>References to the subordinate v1.Pod.</td></tr>
<tr><td><code>phase</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podphase-v1-core">PodPhase</a></em></td><td>Replicated from the corresponding field in the subordinate v1.Pod.</td></tr>
</tbody></table>
</div>
<h4 id="schedulepolicy-3"><a class="header" href="#schedulepolicy-3">SchedulePolicy</a></h4>
<p>SchedulePolicy specifies the preferred scheduler responsible for handling resource allocation requests.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#notebookspec">NotebookSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>t9kScheduler</code> <em><a href="references/api-reference/notebook.html#t9kscheduler">T9kScheduler</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="t9kscheduler-3"><a class="header" href="#t9kscheduler-3">T9kScheduler</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/notebook.html#schedulepolicy">SchedulePolicy</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>queue</code> <em>string</em></td><td>Name of the queue to use with the T9kScheduler.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-11"><a class="header" href="#api-reference-11">API Reference</a></h1>
<h2 id="packages-11"><a class="header" href="#packages-11">Packages</a></h2>
<ul>
<li><a href="references/api-reference/autotune.html#tensorstackdevv1beta1">tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="tensorstackdevv1beta1-3"><a class="header" href="#tensorstackdevv1beta1-3">tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the v1beta1 API group</p>
<h3 id="resource-types-11"><a class="header" href="#resource-types-11">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/autotune.html#autotuneexperiment">AutoTuneExperiment</a></li>
<li><a href="references/api-reference/autotune.html#autotuneexperimentlist">AutoTuneExperimentList</a></li>
</ul>
<h4 id="aistoreconfig"><a class="header" href="#aistoreconfig">AIStoreConfig</a></h4>
<p>AIStoreConfig represents the configuration for using AIStore as a data storage for experiments.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/autotune.html#autotuneexperimentspec">AutoTuneExperimentSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>secret</code> <em>string</em></td><td>Secret specifies the secret containing the API Key authorized to upload data to AIStore.</td></tr>
<tr><td><code>folder</code> <em>string</em></td><td>Folder indicates the destination folder where the experiment data will be stored.</td></tr>
</tbody></table>
</div>
<h4 id="advisorconfig"><a class="header" href="#advisorconfig">AdvisorConfig</a></h4>
<p>AdvisorConfig represents the configuration for the advisor algorithm and its parameters.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/autotune.html#autotuneexperimentspec">AutoTuneExperimentSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>builtinAdvisorName</code> <em>string</em></td><td>BuiltInAdvisorName specifies the name of the built-in advisor algorithm to be used. Available options include: Hyperband, BOHB.</td></tr>
<tr><td><code>classArgs</code> <em>string</em></td><td>ClassArgs defines the parameters specific to the chosen advisor algorithm. Different algorithms may require distinct parameters.</td></tr>
</tbody></table>
</div>
<h4 id="assessorconfig"><a class="header" href="#assessorconfig">AssessorConfig</a></h4>
<p>AssessorConfig represents the configuration for the assessor algorithm and its parameters.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/autotune.html#autotuneexperimentspec">AutoTuneExperimentSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>builtinAssessorName</code> <em>string</em></td><td>BuiltInAssessorName specifies the name of the built-in assessor algorithm to be used. Available options include: Medianstop, Curvefitting.</td></tr>
<tr><td><code>classArgs</code> <em>string</em></td><td>ClassArgs defines the parameters specific to the chosen assessor algorithm. Different algorithms may require distinct parameters.</td></tr>
</tbody></table>
</div>
<h4 id="autotuneexperiment-3"><a class="header" href="#autotuneexperiment-3">AutoTuneExperiment</a></h4>
<p>AutoTuneExperiment is the Schema for the autotune API.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/autotune.html#autotuneexperimentlist">AutoTuneExperimentList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/apis</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>AutoTuneExperiment</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/autotune.html#autotuneexperimentspec">AutoTuneExperimentSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/autotune.html#autotuneexperimentstatus">AutoTuneExperimentStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="autotuneexperimentlist"><a class="header" href="#autotuneexperimentlist">AutoTuneExperimentList</a></h4>
<p>AutoTuneExperimentList contains a list of AutoTuneExperiment.</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/apis</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>AutoTuneExperimentList</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/autotune.html#autotuneexperiment">AutoTuneExperiment</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="autotuneexperimentspec"><a class="header" href="#autotuneexperimentspec">AutoTuneExperimentSpec</a></h4>
<p>AutoTuneExperimentSpec defines the desired state of the AutoTuneExperiment.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/autotune.html#autotuneexperiment">AutoTuneExperiment</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>aistore</code> <em><a href="references/api-reference/autotune.html#aistoreconfig">AIStoreConfig</a></em></td><td>AIStore configures an AIStore as storage for experiment data. If this field is set, data will be uploaded to the AIStore.</td></tr>
<tr><td><code>maxExecSeconds</code> <em>integer</em></td><td>MaxExecSeconds is the time limit (in seconds) for the AutoTuneExperiment, If this limit is exceeded, the AutoTuneExperiment reaches phase TIMEOUT.</td></tr>
<tr><td><code>maxTrialNum</code> <em>integer</em></td><td>MaxTrialNum specifies the maximum number of trials for the AutoTuneExperiment. Once this number of trials is reached, the AutoTuneExperiment reaches phase DONE.</td></tr>
<tr><td><code>trialConcurrency</code> <em>integer</em></td><td>TrialConcurrency is the maximum number of trials running simultaneously.</td></tr>
<tr><td><code>searchSpace</code> <em>string</em></td><td>SearchSpace defines the hyperparameter search space as a JSON string. It specifies the range for searching optimized hyperparameters. Example:  {    “batch_size”: {“_type”: “choice”, “_value”: [16, 32, 64, 128]},    “learning_rate”: {“_type”: “choice”, “_value”: [0.0001, 0.001, 0.01, 0.1]},    “conv_channels1”: {“_type”: “choice”, “_value”: [16, 32, 64, 128]}  }</td></tr>
<tr><td><code>storage</code> <em>Quantity</em></td><td>Storage specifies the size of PVC for storing configurations and training metrics.</td></tr>
<tr><td><code>trainingConfig</code> <em><a href="references/api-reference/autotune.html#trainingconfig">TrainingConfig</a></em></td><td>TrainingConfig represents the configuration for creating Jobs, which evaluate the performance of different hyperparameters.</td></tr>
<tr><td><code>tuner</code> <em><a href="references/api-reference/autotune.html#tunerconfig">TunerConfig</a></em></td><td>Tuner configures a tuner for optimizing hyperparameter.</td></tr>
<tr><td><code>assessor</code> <em><a href="references/api-reference/autotune.html#assessorconfig">AssessorConfig</a></em></td><td>Assessor configures an assessor for filtering hyperparameters and interrupting training when hyperparameters are deemed unqualified. Note that this field is ignored if Tuner is not set.</td></tr>
<tr><td><code>advisor</code> <em><a href="references/api-reference/autotune.html#advisorconfig">AdvisorConfig</a></em></td><td>Advisor configures an advisor for optimizing hyperparameter. Note that when both Tuner and Advisor are set, Tuner takes precedence.</td></tr>
</tbody></table>
</div>
<h4 id="autotuneexperimentstatus"><a class="header" href="#autotuneexperimentstatus">AutoTuneExperimentStatus</a></h4>
<p>AutoTuneExperimentStatus defines the observed state of the AutoTuneExperiment.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/autotune.html#autotuneexperiment">AutoTuneExperiment</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>OwnerStatus</code> <em><a href="references/api-reference/autotune.html#ownerstatus">OwnerStatus</a></em></td><td></td></tr>
<tr><td><code>nextCheckedTime</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>NextCheckedTime indicates the scheduled time for the next status check of the experiment process by the controller.</td></tr>
<tr><td><code>phase</code> <em><a href="references/api-reference/autotune.html#experimentstatus">ExperimentStatus</a></em></td><td>Phase provides a simple, high-level summary of where the AutoTuneExperiment is in its lifecycle. Note that it is NOT intended to serve as a comprehensive state machine. This field is optional.</td></tr>
<tr><td><code>serverNote</code> <em>string</em></td><td>ServerNote contains the current status of the experiment process.</td></tr>
</tbody></table>
</div>
<h4 id="experimentstatus"><a class="header" href="#experimentstatus">ExperimentStatus</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/autotune.html#autotuneexperimentstatus">AutoTuneExperimentStatus</a></li>
</ul>
<h4 id="tunerconfig"><a class="header" href="#tunerconfig">TunerConfig</a></h4>
<p>TunerConfig represents the configuration for the tuner algorithm and its parameters.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/autotune.html#autotuneexperimentspec">AutoTuneExperimentSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>builtinTunerName</code> <em>string</em></td><td>BuiltInTunerName specifies the name of the built-in tuner algorithm to be used. Available options include: Random, Anneal, TPE, Evolution, Batch, GridSearch, MetisTuner, GPTuner, PPOTuner, PBTTuner.</td></tr>
<tr><td><code>classArgs</code> <em>string</em></td><td>ClassArgs defines the parameters specific to the chosen tuner algorithm. Different algorithms may require distinct parameters.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-12"><a class="header" href="#api-reference-12">API Reference</a></h1>
<h2 id="packages-12"><a class="header" href="#packages-12">Packages</a></h2>
<ul>
<li><a href="references/api-reference/explorer.html#tensorstackdevv1beta1">tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="tensorstackdevv1beta1-4"><a class="header" href="#tensorstackdevv1beta1-4">tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the  v1beta1 API group</p>
<h3 id="resource-types-12"><a class="header" href="#resource-types-12">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/explorer.html#explorer">Explorer</a></li>
<li><a href="references/api-reference/explorer.html#explorerlist">ExplorerList</a></li>
</ul>
<h4 id="explorer-2"><a class="header" href="#explorer-2">Explorer</a></h4>
<p>Explorer is the Schema for the explorers API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/explorer.html#explorerlist">ExplorerList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>Explorer</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/explorer.html#explorerspec">ExplorerSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/explorer.html#explorerstatus">ExplorerStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="explorercondition"><a class="header" href="#explorercondition">ExplorerCondition</a></h4>
<p>ExplorerCondition defines the observed condition of Explorer resource</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/explorer.html#explorerstatus">ExplorerStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/explorer.html#explorerconditiontype">ExplorerConditionType</a></em></td><td>Type is the type of the condition. Possible values are Idle, etc</td></tr>
<tr><td><code>status</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Status is the status of the condition type. Possible values of type Idle are True</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>Message is the reason of the status</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>LastTransitionTime is the last time the status was changed</td></tr>
<tr><td><code>lastProbeTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>LastProbeTime is the last time the condition was probed</td></tr>
</tbody></table>
</div>
<h4 id="explorerconditiontype"><a class="header" href="#explorerconditiontype">ExplorerConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/explorer.html#explorercondition">ExplorerCondition</a></li>
</ul>
<h4 id="explorerlist"><a class="header" href="#explorerlist">ExplorerList</a></h4>
<p>ExplorerList contains a list of Explorer</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>ExplorerList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/explorer.html#explorer">Explorer</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="explorerspec"><a class="header" href="#explorerspec">ExplorerSpec</a></h4>
<p>ExplorerSpec defines the desired state of Explorer</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/explorer.html#explorer">Explorer</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>storageType</code> <em><a href="references/api-reference/explorer.html#storagetype">StorageType</a></em></td><td>Type of storage, only <code>pvc</code> is supported for now.</td></tr>
<tr><td><code>storageName</code> <em>string</em></td><td>Name of the StorageType instance.</td></tr>
<tr><td><code>suspend</code> <em>boolean</em></td><td>suspend specifies whether the Explorer controller should delete Pods or not. If true, the associated v1.Pod can be terminated. However, other API resources, such as ConfigMaps and Services, will be preserved for use upon resuming the Explorer. Defaults to false.</td></tr>
<tr><td><code>scheduler</code> <em><a href="references/api-reference/explorer.html#schedulepolicy">SchedulePolicy</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="explorerstatus"><a class="header" href="#explorerstatus">ExplorerStatus</a></h4>
<p>ExplorerStatus defines the observed state of Explorer</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/explorer.html#explorer">Explorer</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>conditions</code> <em><a href="references/api-reference/explorer.html#explorercondition">ExplorerCondition</a> array</em></td><td>Conditions is an array of current conditions</td></tr>
<tr><td><code>codeServer</code> <em><a href="references/api-reference/explorer.html#resourcestatus">ResourceStatus</a></em></td><td></td></tr>
<tr><td><code>fileBrowser</code> <em><a href="references/api-reference/explorer.html#resourcestatus">ResourceStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="podreference-2"><a class="header" href="#podreference-2">PodReference</a></h4>
<p>PodReference refers to a replica.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/explorer.html#podstatus">PodStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Name of the Pod.</td></tr>
<tr><td><code>uid</code> <em>string</em></td><td>UID of the Pod.</td></tr>
</tbody></table>
</div>
<h4 id="podstatus-2"><a class="header" href="#podstatus-2">PodStatus</a></h4>
<p>Pod defines the observed state of a replica.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/explorer.html#resourcestatus">ResourceStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>reference</code> <em><a href="references/api-reference/explorer.html#podreference">PodReference</a></em></td><td>References to the subordinate v1.Pod.</td></tr>
<tr><td><code>phase</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podphase-v1-core">PodPhase</a></em></td><td>Replicated from the corresponding field in the subordinate v1.Pod.</td></tr>
</tbody></table>
</div>
<h4 id="resourcephase"><a class="header" href="#resourcephase">ResourcePhase</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/explorer.html#resourcestatus">ResourceStatus</a></li>
</ul>
<h4 id="resourcestatus"><a class="header" href="#resourcestatus">ResourceStatus</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/explorer.html#explorerstatus">ExplorerStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>phase</code> <em><a href="references/api-reference/explorer.html#resourcephase">ResourcePhase</a></em></td><td></td></tr>
<tr><td><code>pod</code> <em><a href="references/api-reference/explorer.html#podstatus">PodStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="schedulepolicy-4"><a class="header" href="#schedulepolicy-4">SchedulePolicy</a></h4>
<p>SchedulePolicy specifies preferences for resource allocation requests, including the name of the preferred scheduler and additional configuration parameters.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/explorer.html#explorerspec">ExplorerSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>t9kScheduler</code> <em><a href="references/api-reference/explorer.html#t9kscheduler">T9kScheduler</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="storagetype"><a class="header" href="#storagetype">StorageType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>StorageType is the type of storage volume.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/explorer.html#explorerspec">ExplorerSpec</a></li>
</ul>
<h4 id="t9kscheduler-4"><a class="header" href="#t9kscheduler-4">T9kScheduler</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/explorer.html#schedulepolicy">SchedulePolicy</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>queue</code> <em>string</em></td><td>Name of the resource <code>Queue</code> of a <code>T9kScheduler</code>.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-13"><a class="header" href="#api-reference-13">API Reference</a></h1>
<h2 id="packages-13"><a class="header" href="#packages-13">Packages</a></h2>
<ul>
<li><a href="references/api-reference/storageshim.html#tensorstackdevv1beta1">tensorstack.dev/v1beta1</a></li>
<li><a href="references/api-reference/storageshim.html#tensorstackdevv1beta2">tensorstack.dev/v1beta2</a></li>
</ul>
<h2 id="tensorstackdevv1beta1-5"><a class="header" href="#tensorstackdevv1beta1-5">tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the  v1beta1 API group</p>
<h3 id="resource-types-13"><a class="header" href="#resource-types-13">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshim">StorageShim</a></li>
<li><a href="references/api-reference/storageshim.html#storageshimlist">StorageShimList</a></li>
</ul>
<h4 id="s3config"><a class="header" href="#s3config">S3Config</a></h4>
<p>S3Config defines the config of s3</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshimspec">StorageShimSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>uri</code> <em>string</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="secretreference"><a class="header" href="#secretreference">SecretReference</a></h4>
<p>SecretReference defines a Secret Reference</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshimspec">StorageShimSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="storageshim-1"><a class="header" href="#storageshim-1">StorageShim</a></h4>
<p>StorageShim is the Schema for the storageshims API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshimlist">StorageShimList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>StorageShim</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/storageshim.html#storageshimspec">StorageShimSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/storageshim.html#storageshimstatus">StorageShimStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="storageshimcondition"><a class="header" href="#storageshimcondition">StorageShimCondition</a></h4>
<p>StorageShimCondition contains details for the current condition of this StorageShim</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshimstatus">StorageShimStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/storageshim.html#storageshimconditiontype">StorageShimConditionType</a></em></td><td>Type is the type of the condition</td></tr>
<tr><td><code>status</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Status is the status of the condition. Can be True, False, Unknown.</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>Human-readable message indicating details about last transition.</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>Last time the condition transitioned from one status to another.</td></tr>
</tbody></table>
</div>
<h4 id="storageshimconditiontype"><a class="header" href="#storageshimconditiontype">StorageShimConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>StorageShimConditionType is a valid value for StorageShimCondition.Type</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshimcondition">StorageShimCondition</a></li>
</ul>
<h4 id="storageshimlist"><a class="header" href="#storageshimlist">StorageShimList</a></h4>
<p>StorageShimList contains a list of StorageShim</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>StorageShimList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/storageshim.html#storageshim">StorageShim</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="storageshimspec"><a class="header" href="#storageshimspec">StorageShimSpec</a></h4>
<p>StorageShimSpec defines the desired state of StorageShim</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshim">StorageShim</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>s3</code> <em><a href="references/api-reference/storageshim.html#s3config">S3Config</a></em></td><td>S3 defines the config of s3, such as uri</td></tr>
<tr><td><code>readOnly</code> <em>boolean</em></td><td>Specifies a read-only configuration. Defaults to false.</td></tr>
<tr><td><code>secretRef</code> <em><a href="references/api-reference/storageshim.html#secretreference">SecretReference</a></em></td><td>Specifies a secret reference, must be in the same namespace of this StorageShim currently</td></tr>
</tbody></table>
</div>
<h4 id="storageshimstatus"><a class="header" href="#storageshimstatus">StorageShimStatus</a></h4>
<p>StorageShimStatus defines the observed state of StorageShim</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshim">StorageShim</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>phase</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#persistentvolumeclaimphase-v1-core">PersistentVolumeClaimPhase</a></em></td><td>The phase of this StorageShim</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/storageshim.html#storageshimcondition">StorageShimCondition</a> array</em></td><td>Conditions is an array of current conditions</td></tr>
</tbody></table>
</div>
<h2 id="tensorstackdevv1beta2"><a class="header" href="#tensorstackdevv1beta2">tensorstack.dev/v1beta2</a></h2>
<p>Package v1beta2 contains API Schema definitions for the  v1beta2 API group</p>
<h3 id="resource-types-14"><a class="header" href="#resource-types-14">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshim">StorageShim</a></li>
<li><a href="references/api-reference/storageshim.html#storageshimlist">StorageShimList</a></li>
</ul>
<h4 id="cephfsclient"><a class="header" href="#cephfsclient">CephFSClient</a></h4>
<p>CephFSClient defines the client configurations to connnect to the cephfs server.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#cephfsconfig">CephFSConfig</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>secretRef</code> <em><a href="references/api-reference/storageshim.html#secretreference">SecretReference</a></em></td><td>SecretRef references a Kubernetes v1.Secret object that securely stores the CephFS client configurations.</td></tr>
</tbody></table>
</div>
<h4 id="cephfsconfig"><a class="header" href="#cephfsconfig">CephFSConfig</a></h4>
<p>CephFSConfig defines configuration details for a cephfs storage system.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshimspec">StorageShimSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>path</code> <em>string</em></td><td>Path specifies the absolute path within a CephFS volume to be mounted. It should be a valid directory path within the mounted volume. For example, <code>/path/to/directory</code>.</td></tr>
<tr><td><code>server</code> <em><a href="references/api-reference/storageshim.html#cephfsserver">CephFSServer</a></em></td><td>Server provides the configuration details for the CephFS cluster. This includes information such as the Ceph monitor IP addresses and the CephFS volume name.</td></tr>
<tr><td><code>client</code> <em><a href="references/api-reference/storageshim.html#cephfsclient">CephFSClient</a></em></td><td>Client defines the details of a cephFS client.</td></tr>
</tbody></table>
</div>
<h4 id="cephfsserver"><a class="header" href="#cephfsserver">CephFSServer</a></h4>
<p>CephFSServer defines the configuration details for the CephFS cluster.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#cephfsconfig">CephFSConfig</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>configMapRef</code> <em><a href="references/api-reference/storageshim.html#configmapreference">ConfigMapReference</a></em></td><td>ConfigMapRef defines a reference to a K8s v1/configmap that stores CephFS cluster details such as the Ceph monitor IP addresses and the CephFS volume name.</td></tr>
</tbody></table>
</div>
<h4 id="configmapreference"><a class="header" href="#configmapreference">ConfigMapReference</a></h4>
<p>ConfigMapReference defines a Kubernetes v1.ConfigMap reference.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#cephfsserver">CephFSServer</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Name of the configmap.</td></tr>
<tr><td><code>namespace</code> <em>string</em></td><td>Namespace where the configmap resides in.</td></tr>
</tbody></table>
</div>
<h4 id="s3config-1"><a class="header" href="#s3config-1">S3Config</a></h4>
<p>S3Config defines the configuration details for an S3 object storage service.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshimspec">StorageShimSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>readOnly</code> <em>boolean</em></td><td>Specifies that this S3 service can only be used as read-only. Defaults to false.</td></tr>
<tr><td><code>uri</code> <em>string</em></td><td>The S3 prefix to mount, specified as <code>s3://&lt;bucket&gt;[/path]</code>.</td></tr>
<tr><td><code>secretRef</code> <em><a href="references/api-reference/storageshim.html#secretreference">SecretReference</a></em></td><td>References a Kubernetes v1.Secret object. The referenced Secret must reside in the same namespace as the referencing StorageShim.</td></tr>
</tbody></table>
</div>
<h4 id="secretreference-1"><a class="header" href="#secretreference-1">SecretReference</a></h4>
<p>SecretReference defines a reference to a Kubernetes v1.Secret object.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#cephfsclient">CephFSClient</a></li>
<li><a href="references/api-reference/storageshim.html#s3config">S3Config</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>The name of a Kubernetes v1.Secret object that holds the CephFS client configurations. This Secret must reside within the same namespace as the referencing StorageShim.</td></tr>
</tbody></table>
</div>
<h4 id="storageshim-2"><a class="header" href="#storageshim-2">StorageShim</a></h4>
<p>StorageShim is the Schema for the storageshims API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshimlist">StorageShimList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta2</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>StorageShim</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/storageshim.html#storageshimspec">StorageShimSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/storageshim.html#storageshimstatus">StorageShimStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="storageshimcondition-1"><a class="header" href="#storageshimcondition-1">StorageShimCondition</a></h4>
<p>StorageShimCondition contains details for the current condition of this StorageShim</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshimstatus">StorageShimStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/storageshim.html#storageshimconditiontype">StorageShimConditionType</a></em></td><td>Type is the type of the condition</td></tr>
<tr><td><code>status</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Status is the status of the condition. Can be True, False, Unknown.</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>Human-readable message indicating details about last transition.</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>Last time the condition transitioned from one status to another.</td></tr>
</tbody></table>
</div>
<h4 id="storageshimconditiontype-1"><a class="header" href="#storageshimconditiontype-1">StorageShimConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>StorageShimConditionType is a valid value for StorageShimCondition.Type</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshimcondition">StorageShimCondition</a></li>
</ul>
<h4 id="storageshimlist-1"><a class="header" href="#storageshimlist-1">StorageShimList</a></h4>
<p>StorageShimList contains a list of StorageShim</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta2</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>StorageShimList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/storageshim.html#storageshim">StorageShim</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="storageshimspec-1"><a class="header" href="#storageshimspec-1">StorageShimSpec</a></h4>
<p>StorageShimSpec defines the desired state of StorageShim</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshim">StorageShim</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/storageshim.html#storageshimtype">StorageShimType</a></em></td><td>Type specifies the type of storage system to be integrated with. One of the supported values is required, and currently <code>cephfs</code>, <code>s3</code> are supported. More storage system types will be added in the future.</td></tr>
<tr><td><code>s3</code> <em><a href="references/api-reference/storageshim.html#s3config">S3Config</a></em></td><td>S3 defines the configuration details for an s3 object store service.</td></tr>
<tr><td><code>cephfs</code> <em><a href="references/api-reference/storageshim.html#cephfsconfig">CephFSConfig</a></em></td><td>CephFS defines the configuraitons for a <code>cephfs</code>.</td></tr>
</tbody></table>
</div>
<h4 id="storageshimstatus-1"><a class="header" href="#storageshimstatus-1">StorageShimStatus</a></h4>
<p>StorageShimStatus defines the observed state of StorageShim</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshim">StorageShim</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>phase</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#persistentvolumeclaimphase-v1-core">PersistentVolumeClaimPhase</a></em></td><td>The phase of this StorageShim.</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/storageshim.html#storageshimcondition">StorageShimCondition</a> array</em></td><td>Conditions represent an array of current conditions observed within the system.</td></tr>
</tbody></table>
</div>
<h4 id="storageshimtype"><a class="header" href="#storageshimtype">StorageShimType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/storageshim.html#storageshimspec">StorageShimSpec</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-14"><a class="header" href="#api-reference-14">API Reference</a></h1>
<h2 id="packages-14"><a class="header" href="#packages-14">Packages</a></h2>
<ul>
<li><a href="references/api-reference/scheduler.html#schedulertensorstackdevv1beta1">scheduler.tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="schedulertensorstackdevv1beta1"><a class="header" href="#schedulertensorstackdevv1beta1">scheduler.tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 is the v1beta1 version of the API.</p>
<h3 id="resource-types-15"><a class="header" href="#resource-types-15">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/scheduler.html#podgroup">PodGroup</a></li>
<li><a href="references/api-reference/scheduler.html#podgrouplist">PodGroupList</a></li>
<li><a href="references/api-reference/scheduler.html#queue">Queue</a></li>
<li><a href="references/api-reference/scheduler.html#queuelist">QueueList</a></li>
</ul>
<h4 id="podgroup-3"><a class="header" href="#podgroup-3">PodGroup</a></h4>
<p>PodGroup represents a collection of Pods to be scheduled together to facilicate with parallel computing. PodGroup is usually automatically created by workload controllers to manage parallel batch workloads such as machine learning training and to enable coscheduling/gang-scheduling strategies. Users can also manually create a PodGroup and associates Pods with it if desired.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#podgrouplist">PodGroupList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>scheduler.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>PodGroup</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/scheduler.html#podgroupspec">PodGroupSpec</a></em></td><td>Specification of the desired behavior of the pod group. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#spec-and-status</td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/scheduler.html#podgroupstatus">PodGroupStatus</a></em></td><td>Status represents the current status of a pod group. This data may not be up to date.</td></tr>
</tbody></table>
</div>
<h4 id="podgroupcondition"><a class="header" href="#podgroupcondition">PodGroupCondition</a></h4>
<p>PodGroupCondition contains details for the current state of this pod group.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#podgroupstatus">PodGroupStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em>PodGroupConditionType</em></td><td>The type of the condition.</td></tr>
<tr><td><code>status</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>The status of the condition.</td></tr>
<tr><td><code>transitionID</code> <em>string</em></td><td>The ID of condition transition.</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>Last time of condition transition(s).</td></tr>
<tr><td><code>reason</code> <em>string</em></td><td>Unique, one-word, CamelCase, machine-readable reason for the condition’s last change.</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>Human-readable message indicating details about last change.</td></tr>
</tbody></table>
</div>
<h4 id="podgroupinqueuestatus"><a class="header" href="#podgroupinqueuestatus">PodGroupInQueueStatus</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#queuestatus">QueueStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>total</code> <em>integer</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="podgrouplist"><a class="header" href="#podgrouplist">PodGroupList</a></h4>
<p>PodGroupList is a collection of pod groups.</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>scheduler.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>PodGroupList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/scheduler.html#podgroup">PodGroup</a> array</em></td><td>The list of PodGroup.</td></tr>
</tbody></table>
</div>
<h4 id="podgroupspec"><a class="header" href="#podgroupspec">PodGroupSpec</a></h4>
<p>PodGroupSpec represents the desired specification of a pod group.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#podgroup">PodGroup</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>roles</code> <em><a href="references/api-reference/scheduler.html#role">Role</a> array</em></td><td></td></tr>
<tr><td><code>minMember</code> <em>integer</em></td><td>MinMember defines the minimal number of pods to run the PodGroup. If there less than <code>minMember</code> of pods joining the PodGroup, none of the existing pods in the group will be scheduled. After <code>minMember</code> of pods joined, the scheduler will only schedule them if there are sufficient resources to allow <code>minMember</code> of pods start together.</td></tr>
<tr><td><code>queue</code> <em>string</em></td><td>Queue defines the queue from which resources for pods of the PodGroup should be allocated. If queue is not specified, the PodGroup will be scheduled to queue “default”.</td></tr>
<tr><td><code>priority</code> <em>integer</em></td><td>If specified, indicates the PodGroup’s priority; groups with larger <code>priority</code> values will be considered for scheduling first; range is [0,100].</td></tr>
<tr><td><code>topologyPolicy</code> <em>TopologyPolicyType</em></td><td>TopologyPolicy declares the topology policy PodGroup needs.</td></tr>
</tbody></table>
</div>
<h4 id="podgroupstatus"><a class="header" href="#podgroupstatus">PodGroupStatus</a></h4>
<p>PodGroupStatus represents the current state of a pod group.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#podgroup">PodGroup</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>conditions</code> <em><a href="references/api-reference/scheduler.html#podgroupcondition">PodGroupCondition</a> array</em></td><td>The conditions of PodGroup.</td></tr>
<tr><td><code>allocated</code> <em>object (keys:<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcename-v1-core">ResourceName</a>, values:Quantity)</em></td><td>Allocated represents resources and their qunatities allocated to the PodGroup.</td></tr>
<tr><td><code>pending</code> <em>integer</em></td><td>The number of pods in phase Pending.</td></tr>
<tr><td><code>running</code> <em>integer</em></td><td>The number of pods in phase running.</td></tr>
<tr><td><code>succeeded</code> <em>integer</em></td><td>The number of pods in phase Succeeded.</td></tr>
<tr><td><code>failed</code> <em>integer</em></td><td>The number of pods in phase Failed.</td></tr>
<tr><td><code>unknown</code> <em>integer</em></td><td>The number of pods in phase Unknown.</td></tr>
</tbody></table>
</div>
<h4 id="podinqueuestatus"><a class="header" href="#podinqueuestatus">PodInQueueStatus</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#queuestatus">QueueStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>pending</code> <em>integer</em></td><td>The number of ‘Pending’ Pods in this queue.</td></tr>
<tr><td><code>running</code> <em>integer</em></td><td>The number of ‘Running’ Pods in this queue.</td></tr>
<tr><td><code>succeeded</code> <em>integer</em></td><td>The number of ‘Succeeded’ Pods in this queue.</td></tr>
<tr><td><code>failed</code> <em>integer</em></td><td>The number of ‘Failed’ Pods in this queue</td></tr>
<tr><td><code>unknown</code> <em>integer</em></td><td>The number of ‘Unknown’ Pods in this queue.</td></tr>
</tbody></table>
</div>
<h4 id="queue-1"><a class="header" href="#queue-1">Queue</a></h4>
<p>Queue is an API-resource to reprenent a sub-set of cluster compute resources and associated administrative policies, such as allowed users, resource quota, allowed workload types, max duration of workload runtime and etc.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#queuelist">QueueList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>scheduler.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>Queue</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/scheduler.html#queuespec">QueueSpec</a></em></td><td>Specification of the desired behavior of the queue. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#spec-and-status</td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/scheduler.html#queuestatus">QueueStatus</a></em></td><td>The status of queue.</td></tr>
</tbody></table>
</div>
<h4 id="queuecondition"><a class="header" href="#queuecondition">QueueCondition</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#queuestatus">QueueStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/scheduler.html#queueconditiontype">QueueConditionType</a></em></td><td>Type is the type of the condition. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#pod-conditions</td></tr>
<tr><td><code>status</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Status is the status of the condition. Can be True, False, Unknown. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#pod-conditions</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>Last time the condition transitioned.</td></tr>
<tr><td><code>reason</code> <em>string</em></td><td>Unique, one-word, CamelCase reason for the condition’s last transition.</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>Human-readable message indicating details about last transition.</td></tr>
</tbody></table>
</div>
<h4 id="queueconditiontype"><a class="header" href="#queueconditiontype">QueueConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#queuecondition">QueueCondition</a></li>
</ul>
<h4 id="queuelist"><a class="header" href="#queuelist">QueueList</a></h4>
<p>QueueList is a collection of queues.</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>scheduler.tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>QueueList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/scheduler.html#queue">Queue</a> array</em></td><td>The list of Queue.</td></tr>
</tbody></table>
</div>
<h4 id="queuespec"><a class="header" href="#queuespec">QueueSpec</a></h4>
<p>QueueSpec represents the desired specification of a Queue.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#queue">Queue</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>quota</code> <em><a href="references/api-reference/scheduler.html#quotarequirements">QuotaRequirements</a></em></td><td></td></tr>
<tr><td><code>priority</code> <em>integer</em></td><td>If specified, indicates the Queue’s priority. range is [0,100] The higher value of <code>priority</code>, workloads in this queue will be scheduled with resources with higher preferences.</td></tr>
<tr><td><code>preemptible</code> <em>boolean</em></td><td>Preemptible indicate whether the queue can be preempted by other queue when cluster resources are in short. Queue can be preempted if Preemptible is not set.</td></tr>
<tr><td><code>closed</code> <em>boolean</em></td><td>After queue is closed, new workloads (pods) will not be allocated with resources and no new workloads will be accepted either.</td></tr>
<tr><td><code>maxDuration</code> <em>Duration</em></td><td>Define the max lifetime of Pod using the Queue. Supported units: y, w, d, h, m, s, ms. Examples: <code>30s</code>, <code>1m</code>, <code>1h20m15s</code>, <code>15d</code>.</td></tr>
<tr><td><code>resourceShapeProfile</code> <em>string</em></td><td>Specify ResourceShape profile used by the Queue.</td></tr>
<tr><td><code>nodeSelector</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#labelselector-v1-meta">LabelSelector</a></em></td><td>NodeSelector specifies the nodes whoses resource can be used by a Queue. This provides a machanism to restrict workloads submitted to a particular queue to a sub-set of nodes in the cluster. if <code>nil</code>, all nodes are eligible.</td></tr>
<tr><td><code>namespaceSelector</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#labelselector-v1-meta">LabelSelector</a></em></td><td>NamespaceSelector specifies the set of namespaces from which workloads are allowed to use this Queue. if <code>nil</code>,  no namespaces are selected. Note: There may be other authorization procedures that permit workloads in a queue. They are OR’ed with this selector.</td></tr>
</tbody></table>
</div>
<h4 id="queuestatus"><a class="header" href="#queuestatus">QueueStatus</a></h4>
<p>QueueStatus represents the status of Queue.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#queue">Queue</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>allocated</code> <em>object (keys:<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcename-v1-core">ResourceName</a>, values:Quantity)</em></td><td>Count of resource allocated to the queue.</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/scheduler.html#queuecondition">QueueCondition</a> array</em></td><td>Current service state of Queue.</td></tr>
<tr><td><code>podGroups</code> <em><a href="references/api-reference/scheduler.html#podgroupinqueuestatus">PodGroupInQueueStatus</a></em></td><td>PodGroup Status in Queue.</td></tr>
<tr><td><code>pods</code> <em><a href="references/api-reference/scheduler.html#podinqueuestatus">PodInQueueStatus</a></em></td><td>Pod Status in Queue.</td></tr>
</tbody></table>
</div>
<h4 id="quotarequirements"><a class="header" href="#quotarequirements">QuotaRequirements</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#queuespec">QueueSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>requests</code> <em>object (keys:<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcename-v1-core">ResourceName</a>, values:Quantity)</em></td><td>Requests describes max amount of resources pods in the Queue can potentially request. However, these are the upper limits for resources, not necessarily always available for use. This can be used by cluster administrators to control the upper bounds of resources submitted to a particular queue. Togethe with allowed users of queues, this provides a mechanism for admins to set policies to constrain some aspects of user resource usages.</td></tr>
</tbody></table>
</div>
<h4 id="role-1"><a class="header" href="#role-1">Role</a></h4>
<p>Role describes pod’s role and minMember constraint for this role.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/scheduler.html#podgroupspec">PodGroupSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Role Name</td></tr>
<tr><td><code>minMember</code> <em>integer</em></td><td>MinMember defines minimal number of pods of the role.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-15"><a class="header" href="#api-reference-15">API Reference</a></h1>
<h2 id="packages-15"><a class="header" href="#packages-15">Packages</a></h2>
<ul>
<li><a href="references/api-reference/workflow.html#batchtensorstackdevv1beta1">batch.tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="batchtensorstackdevv1beta1-8"><a class="header" href="#batchtensorstackdevv1beta1-8">batch.tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 defines the CRD types.</p>
<h3 id="resource-types-16"><a class="header" href="#resource-types-16">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/workflow.html#cronworkflowrun">CronWorkflowRun</a></li>
<li><a href="references/api-reference/workflow.html#cronworkflowrunlist">CronWorkflowRunList</a></li>
<li><a href="references/api-reference/workflow.html#workflowrun">WorkflowRun</a></li>
<li><a href="references/api-reference/workflow.html#workflowrunlist">WorkflowRunList</a></li>
<li><a href="references/api-reference/workflow.html#workflowtemplate">WorkflowTemplate</a></li>
<li><a href="references/api-reference/workflow.html#workflowtemplatelist">WorkflowTemplateList</a></li>
</ul>
<h4 id="beamjobworkflowtemplate"><a class="header" href="#beamjobworkflowtemplate">BeamJobWorkflowTemplate</a></h4>
<p>BeamJobWorkflowTemplate creates a t9k beam job.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflow.html#beamjobspec">BeamJobSpec</a></em></td><td>Spec of the beam job.</td></tr>
</tbody></table>
</div>
<h4 id="colossalaijobworkflowtemplate"><a class="header" href="#colossalaijobworkflowtemplate">ColossalAIJobWorkflowTemplate</a></h4>
<p>ColossalAIJobWorkflowTemplate creates a t9k colossalai job.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflow.html#colossalaijobspec">ColossalAIJobSpec</a></em></td><td>Spec of the colossalai job.</td></tr>
</tbody></table>
</div>
<h4 id="concurrencypolicy"><a class="header" href="#concurrencypolicy">ConcurrencyPolicy</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>ConcurrencyPolicy describes how the WorkflowRun will be handled. Only one of the following concurrent policies may be specified. If none of the following policies is specified, the default one is AllowConcurrent.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#cronworkflowrunspec">CronWorkflowRunSpec</a></li>
</ul>
<h4 id="conditionselector"><a class="header" href="#conditionselector">ConditionSelector</a></h4>
<p>ConditionSelector selects a k8s resource if its <code>status.conditions</code> contains a condition whose type and status are exactly the same as those of the condition selector.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#rules">Rules</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em>string</em></td><td>Type of the condition.</td></tr>
<tr><td><code>status</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Status of the condition, one of True, False, or Unknown.</td></tr>
</tbody></table>
</div>
<h4 id="cronworkflowrun-2"><a class="header" href="#cronworkflowrun-2">CronWorkflowRun</a></h4>
<p>CronWorkflowRun is the Schema for the CronWorkflowRun API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#cronworkflowrunlist">CronWorkflowRunList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/apis</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>CronWorkflowRun</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflow.html#cronworkflowrunspec">CronWorkflowRunSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/workflow.html#cronworkflowrunstatus">CronWorkflowRunStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="cronworkflowruncondition"><a class="header" href="#cronworkflowruncondition">CronWorkflowRunCondition</a></h4>
<p>CronWorkflowRunCondition is an observation of the condition of the CronWorkflowRun.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#cronworkflowrunstatus">CronWorkflowRunStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/workflow.html#cronworkflowrunconditiontype">CronWorkflowRunConditionType</a></em></td><td>Type of CronWorkflowRun condition.</td></tr>
<tr><td><code>status</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Status of the condition, one of True, False, or Unknown.</td></tr>
<tr><td><code>reason</code> <em>string</em></td><td>The reason for the condition’s last transition.</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>A readable message indicating details about the transition.</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>Last time the condition transitioned from one status to another.</td></tr>
</tbody></table>
</div>
<h4 id="cronworkflowrunconditiontype"><a class="header" href="#cronworkflowrunconditiontype">CronWorkflowRunConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>CronWorkflowRunConditionType defines all possible types of CronWorkflowRunCondition. Can be one of: HasStarted, IsRunning, HasSuccessfulRun, HasFailedRun.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#cronworkflowruncondition">CronWorkflowRunCondition</a></li>
</ul>
<h4 id="cronworkflowrunlist"><a class="header" href="#cronworkflowrunlist">CronWorkflowRunList</a></h4>
<p>CronWorkflowRunList contains a list of CronWorkflowRun</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/apis</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>CronWorkflowRunList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/workflow.html#cronworkflowrun">CronWorkflowRun</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="cronworkflowrunspec"><a class="header" href="#cronworkflowrunspec">CronWorkflowRunSpec</a></h4>
<p>CronWorkflowRunSpec defines the desired state of CronWorkflowRun.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#cronworkflowrun">CronWorkflowRun</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>schedule</code> <em>string</em></td><td>Schedule defines the schedule for the running of WorkflowRuns.</td></tr>
<tr><td><code>concurrencyPolicy</code> <em><a href="references/api-reference/workflow.html#concurrencypolicy">ConcurrencyPolicy</a></em></td><td>Specifies how to treat concurrent executions of a WorkflowRun. Valid values are: - “Allow” (default): allows WorkflowRuns to run concurrently; - “Forbid”: forbids concurrent runs, skipping next run if previous run hasn’t finished yet; - “Replace”: cancels currently running WorkflowRun and replaces it with a new one</td></tr>
<tr><td><code>successfulRunsHistoryLimit</code> <em>integer</em></td><td>The number of successful finished WorkflowRuns to retain. This is a pointer to distinguish between explicit zero and not specified.</td></tr>
<tr><td><code>failedRunsHistoryLimit</code> <em>integer</em></td><td>The number of failed finished WorkflowRuns to retain. This is a pointer to distinguish between explicit zero and not specified.</td></tr>
<tr><td><code>startingDeadlineSeconds</code> <em>integer</em></td><td>Deadline in seconds for starting the WorkflowRuns if it misses scheduled time for any reason.  Missed WorkflowRun runs will be counted as failed ones.</td></tr>
<tr><td><code>suspend</code> <em>boolean</em></td><td>This flag tells the controller to suspend subsequent runs, it does not apply to already started runs.  Defaults to false.</td></tr>
<tr><td><code>workflowRun</code> <em><a href="references/api-reference/workflow.html#workflowruntemplatespec">WorkflowRunTemplateSpec</a></em></td><td>Specifies the WorkflowRun that will be created when executing a CronWorkflowRun.</td></tr>
</tbody></table>
</div>
<h4 id="cronworkflowrunstatus"><a class="header" href="#cronworkflowrunstatus">CronWorkflowRunStatus</a></h4>
<p>CronWorkflowRunStatus defines the observed state of CronWorkflowRun.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#cronworkflowrun">CronWorkflowRun</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>active</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectreference-v1-core">ObjectReference</a> array</em></td><td>A list of pointers to currently running WorkflowRuns.</td></tr>
<tr><td><code>lastScheduleTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>The last time when the WorkflowRun was successfully created.</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/workflow.html#cronworkflowruncondition">CronWorkflowRunCondition</a> array</em></td><td>The latest available observations of the CronWorkflowRun’s current state.</td></tr>
</tbody></table>
</div>
<h4 id="dagnode"><a class="header" href="#dagnode">DAGNode</a></h4>
<p>DAGNode represents a node in the graph during DAG execution.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#dagworkflowtemplate">DAGWorkflowTemplate</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Name is the name of this node within the DAG.</td></tr>
<tr><td><code>workflowTemplateRef</code> <em>string</em></td><td>WorkflowTemplateRef is a reference to a workflowTemplate definition.</td></tr>
<tr><td><code>when</code> <em><a href="references/api-reference/workflow.html#whenexpression">WhenExpression</a> array</em></td><td>WhenExpressions is a list of when expressions that need to be true for the node to run</td></tr>
<tr><td><code>retries</code> <em>integer</em></td><td>Retries represents how many times this node should be retried in case of failure: Condition Succeeded set to False</td></tr>
<tr><td><code>dependencies</code> <em>string array</em></td><td>Dependencies are name of other nodes which this depends on, to force a specific ordering in graph execution.</td></tr>
<tr><td><code>params</code> <em><a href="references/api-reference/workflow.html#param">Param</a> array</em></td><td>Parameters declares parameters passed to this node.</td></tr>
<tr><td><code>workspaces</code> <em><a href="references/api-reference/workflow.html#workspacedagbinding">WorkspaceDAGBinding</a> array</em></td><td>Workspaces maps workspaces from the DAG WorkflowTemplate spec to the workspaces declared in the node.</td></tr>
</tbody></table>
</div>
<h4 id="dagworkflowtemplate"><a class="header" href="#dagworkflowtemplate">DAGWorkflowTemplate</a></h4>
<p>DAGWorkflowTemplate creates a dag consisting of other WorkflowTemplates.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>templates</code> <em><a href="references/api-reference/workflow.html#dagnode">DAGNode</a> array</em></td><td>Templates are a list of DAG nodes.</td></tr>
<tr><td><code>failureStrategy</code> <em><a href="references/api-reference/workflow.html#failurestrategy">FailureStrategy</a></em></td><td>FailureStrategy is the strategy when a node in DAG fails.</td></tr>
</tbody></table>
</div>
<h4 id="deepspeedjobworkflowtemplate"><a class="header" href="#deepspeedjobworkflowtemplate">DeepSpeedJobWorkflowTemplate</a></h4>
<p>DeepSpeedJobWorkflowTemplate creates a t9k deepspeed job.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflow.html#deepspeedjobspec">DeepSpeedJobSpec</a></em></td><td>Spec of the deepspeed job.</td></tr>
</tbody></table>
</div>
<h4 id="failurestrategy"><a class="header" href="#failurestrategy">FailureStrategy</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>FailureStrategy defines the failure strategy of DAGWorkflowTemplate.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#dagworkflowtemplate">DAGWorkflowTemplate</a></li>
</ul>
<h4 id="genericjobworkflowtemplate"><a class="header" href="#genericjobworkflowtemplate">GenericJobWorkflowTemplate</a></h4>
<p>GenericJobWorkflowTemplate creates a t9k generic job.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflow.html#genericjobspec">GenericJobSpec</a></em></td><td>Spec of the generic job.</td></tr>
</tbody></table>
</div>
<h4 id="mpijobworkflowtemplate"><a class="header" href="#mpijobworkflowtemplate">MPIJobWorkflowTemplate</a></h4>
<p>MPIJobWorkflowTemplate creates a t9k mpi job.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflow.html#mpijobspec">MPIJobSpec</a></em></td><td>Spec of the mpi job.</td></tr>
</tbody></table>
</div>
<h4 id="nodephase"><a class="header" href="#nodephase">NodePhase</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>NodePhase is the current state of a node. Node means the node in a DAG. PodWorkflowTemplate, SeqPodWorkflowTemplate and ResourceWorkflowTemplate are also considered as an independent node. DAGWorkflowTemplate itself is considered as a parent node.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#nodestatus">NodeStatus</a></li>
<li><a href="references/api-reference/workflow.html#workflowrunstatusfields">WorkflowRunStatusFields</a></li>
</ul>
<h4 id="nodestatus"><a class="header" href="#nodestatus">NodeStatus</a></h4>
<p>NodeStatus is the status of a node in DAG</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowrunstatusfields">WorkflowRunStatusFields</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>workflowRunName</code> <em>string</em></td><td>WorkflowRunName is the name of WorkflowRun created from the node.</td></tr>
<tr><td><code>phase</code> <em><a href="references/api-reference/workflow.html#nodephase">NodePhase</a></em></td><td>Phase is the phase of the node.</td></tr>
<tr><td><code>whenExpressions</code> <em><a href="references/api-reference/workflow.html#whenexpression">WhenExpression</a> array</em></td><td>WhenExpressions show why if the node is skipped.</td></tr>
</tbody></table>
</div>
<h4 id="param"><a class="header" href="#param">Param</a></h4>
<p>Param declares a string to use for the parameter called name.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#dagnode">DAGNode</a></li>
<li><a href="references/api-reference/workflow.html#workflowrunspec">WorkflowRunSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td></td></tr>
<tr><td><code>value</code> <em>string</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="paramspec"><a class="header" href="#paramspec">ParamSpec</a></h4>
<p>ParamSpec defines values that are provided by users as inputs on a WorkflowRun.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Name declares the name by which a parameter is referenced.</td></tr>
<tr><td><code>description</code> <em>string</em></td><td>Description is a user-facing description of the parameter that may be used to populate a UI.</td></tr>
<tr><td><code>default</code> <em>string</em></td><td>Default is the value a parameter takes if no input value is supplied. If default is set, a WorkflowTemplate may be executed without a supplied value for the parameter. It serves as a pointer to distinguish between setting no default and setting empty string as default.</td></tr>
</tbody></table>
</div>
<h4 id="podspecwithoutcontainers"><a class="header" href="#podspecwithoutcontainers">PodSpecWithoutContainers</a></h4>
<p>PodSpecWithoutContainers is a helper struct for SeqPodWorkflowTemplate forked from https://github.com/kubernetes/api/blob/v0.20.0/core/v1/types.go#L2914</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#seqpodworkflowtemplate">SeqPodWorkflowTemplate</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>volumes</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#volume-v1-core">Volume</a> array</em></td><td>List of volumes that can be mounted by containers belonging to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes</td></tr>
<tr><td><code>initContainers</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#container-v1-core">Container</a> array</em></td><td>List of initialization containers belonging to the pod. Init containers are executed in order prior to containers being started. If any init container fails, the pod is considered to have failed and is handled according to its restartPolicy. The name for an init container or normal container must be unique among all containers. Init containers may not have Lifecycle actions, Readiness probes, Liveness probes, or Startup probes. The resourceRequirements of an init container are taken into account during scheduling by finding the highest request/limit for each resource type, and then using the max of of that value or the sum of the normal containers. Limits are applied to init containers in a similar fashion. Init containers cannot currently be added or removed. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/</td></tr>
<tr><td><code>ephemeralContainers</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#ephemeralcontainer-v1-core">EphemeralContainer</a> array</em></td><td>List of ephemeral containers run in this pod. Ephemeral containers may be run in an existing pod to perform user-initiated actions such as debugging. This list cannot be specified when creating a pod, and it cannot be modified by updating the pod spec. In order to add an ephemeral container to an existing pod, use the pod’s ephemeralcontainers subresource. This field is alpha-level and is only honored by servers that enable the EphemeralContainers feature.</td></tr>
<tr><td><code>restartPolicy</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#restartpolicy-v1-core">RestartPolicy</a></em></td><td>Restart policy for all containers within the pod. One of Always, OnFailure, Never. Default to Always. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy</td></tr>
<tr><td><code>terminationGracePeriodSeconds</code> <em>integer</em></td><td>Optional duration in seconds the pod needs to terminate gracefully. May be decreased in delete request. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period will be used instead. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. Defaults to 30 seconds.</td></tr>
<tr><td><code>activeDeadlineSeconds</code> <em>integer</em></td><td>Optional duration in seconds the pod may be active on the node relative to StartTime before the system will actively try to mark it failed and kill associated containers. Value must be a positive integer.</td></tr>
<tr><td><code>dnsPolicy</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#dnspolicy-v1-core">DNSPolicy</a></em></td><td>Set DNS policy for the pod. Defaults to “ClusterFirst”. Valid values are ‘ClusterFirstWithHostNet’, ‘ClusterFirst’, ‘Default’ or ‘None’. DNS parameters given in DNSConfig will be merged with the policy selected with DNSPolicy. To have DNS options set along with hostNetwork, you have to specify DNS policy explicitly to ‘ClusterFirstWithHostNet’.</td></tr>
<tr><td><code>nodeSelector</code> <em>object (keys:string, values:string)</em></td><td>NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node’s labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/</td></tr>
<tr><td><code>serviceAccountName</code> <em>string</em></td><td>ServiceAccountName is the name of the ServiceAccount to use to run this pod. More info: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/</td></tr>
<tr><td><code>serviceAccount</code> <em>string</em></td><td>DeprecatedServiceAccount is a depreciated alias for ServiceAccountName. Deprecated: Use serviceAccountName instead.</td></tr>
<tr><td><code>automountServiceAccountToken</code> <em>boolean</em></td><td>AutomountServiceAccountToken indicates whether a service account token should be automatically mounted.</td></tr>
<tr><td><code>nodeName</code> <em>string</em></td><td>NodeName is a request to schedule this pod onto a specific node. If it is non-empty, the scheduler simply schedules this pod onto that node, assuming that it fits resource requirements.</td></tr>
<tr><td><code>hostNetwork</code> <em>boolean</em></td><td>Host networking requested for this pod. Use the host’s network namespace. If this option is set, the ports that will be used must be specified. Default to false.</td></tr>
<tr><td><code>hostPID</code> <em>boolean</em></td><td>Use the host’s pid namespace. Optional: Default to false.</td></tr>
<tr><td><code>hostIPC</code> <em>boolean</em></td><td>Use the host’s ipc namespace. Optional: Default to false.</td></tr>
<tr><td><code>shareProcessNamespace</code> <em>boolean</em></td><td>Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false.</td></tr>
<tr><td><code>securityContext</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podsecuritycontext-v1-core">PodSecurityContext</a></em></td><td>SecurityContext holds pod-level security attributes and common container settings. Optional: Defaults to empty.  See type description for default values of each field.</td></tr>
<tr><td><code>imagePullSecrets</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#localobjectreference-v1-core">LocalObjectReference</a> array</em></td><td>ImagePullSecrets is an optional list of references to secrets in the same namespace to use for pulling any of the images used by this PodSpec. If specified, these secrets will be passed to individual puller implementations for them to use. For example, in the case of docker, only DockerConfig type secrets are honored. More info: https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod</td></tr>
<tr><td><code>hostname</code> <em>string</em></td><td>Specifies the hostname of the Pod If not specified, the pod’s hostname will be set to a system-defined value.</td></tr>
<tr><td><code>subdomain</code> <em>string</em></td><td>If specified, the fully qualified Pod hostname will be “<hostname>.<subdomain>.<pod namespace>.svc.<cluster domain>”. If not specified, the pod will not have a domainname at all.</td></tr>
<tr><td><code>affinity</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#affinity-v1-core">Affinity</a></em></td><td>If specified, the pod’s scheduling constraints</td></tr>
<tr><td><code>schedulerName</code> <em>string</em></td><td>If specified, the pod will be dispatched by specified scheduler. If not specified, the pod will be dispatched by default scheduler.</td></tr>
<tr><td><code>tolerations</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#toleration-v1-core">Toleration</a> array</em></td><td>If specified, the pod’s tolerations.</td></tr>
<tr><td><code>hostAliases</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#hostalias-v1-core">HostAlias</a> array</em></td><td>HostAliases is an optional list of hosts and IPs that will be injected into the pod’s hosts file if specified. This is only valid for non-hostNetwork pods.</td></tr>
<tr><td><code>priorityClassName</code> <em>string</em></td><td>If specified, indicates the pod’s priority. “system-node-critical” and “system-cluster-critical” are two special keywords which indicate the highest priorities with the former being the highest priority. Any other name must be defined by creating a PriorityClass object with that name. If not specified, the pod priority will be default or zero if there is no default.</td></tr>
<tr><td><code>priority</code> <em>integer</em></td><td>The priority value. Various system components use this field to find the priority of the pod. When Priority Admission Controller is enabled, it prevents users from setting this field. The admission controller populates this field from PriorityClassName. The higher the value, the higher the priority.</td></tr>
<tr><td><code>dnsConfig</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#poddnsconfig-v1-core">PodDNSConfig</a></em></td><td>Specifies the DNS parameters of a pod. Parameters specified here will be merged to the generated DNS configuration based on DNSPolicy.</td></tr>
<tr><td><code>readinessGates</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podreadinessgate-v1-core">PodReadinessGate</a> array</em></td><td>If specified, all readiness gates will be evaluated for pod readiness. A pod is ready when all its containers are ready AND all conditions specified in the readiness gates have status equal to “True” More info: https://git.k8s.io/enhancements/keps/sig-network/0007-pod-ready%2B%2B.md</td></tr>
<tr><td><code>runtimeClassName</code> <em>string</em></td><td>RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run. If unset or empty, the “legacy” RuntimeClass will be used, which is an implicit class with an empty definition that uses the default runtime handler. More info: https://git.k8s.io/enhancements/keps/sig-node/runtime-class.md This is a beta feature as of Kubernetes v1.14.</td></tr>
<tr><td><code>enableServiceLinks</code> <em>boolean</em></td><td>EnableServiceLinks indicates whether information about services should be injected into pod’s environment variables, matching the syntax of Docker links. Optional: Defaults to true.</td></tr>
<tr><td><code>preemptionPolicy</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#preemptionpolicy-v1-core">PreemptionPolicy</a></em></td><td>PreemptionPolicy is the Policy for preempting pods with lower priority. One of Never, PreemptLowerPriority. Defaults to PreemptLowerPriority if unset. This field is beta-level, gated by the NonPreemptingPriority feature-gate.</td></tr>
<tr><td><code>overhead</code> <em>object (keys:<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcename-v1-core">ResourceName</a>, values:Quantity)</em></td><td>Overhead represents the resource overhead associated with running a pod for a given RuntimeClass. This field will be autopopulated at admission time by the RuntimeClass admission controller. If the RuntimeClass admission controller is enabled, overhead must not be set in Pod create requests. The RuntimeClass admission controller will reject Pod create requests which have the overhead already set. If RuntimeClass is configured and selected in the PodSpec, Overhead will be set to the value defined in the corresponding RuntimeClass, otherwise it will remain unset and treated as zero. More info: https://git.k8s.io/enhancements/keps/sig-node/20190226-pod-overhead.md This field is alpha-level as of Kubernetes v1.16, and is only honored by servers that enable the PodOverhead feature.</td></tr>
<tr><td><code>topologySpreadConstraints</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#topologyspreadconstraint-v1-core">TopologySpreadConstraint</a> array</em></td><td>TopologySpreadConstraints describes how a group of pods ought to spread across topology domains. Scheduler will schedule pods in a way which abides by the constraints. All topologySpreadConstraints are ANDed.</td></tr>
<tr><td><code>setHostnameAsFQDN</code> <em>boolean</em></td><td>If true the pod’s hostname will be configured as the pod’s FQDN, rather than the leaf name (the default). In Linux containers, this means setting the FQDN in the hostname field of the kernel (the nodename field of struct utsname). In Windows containers, this means setting the registry value of hostname for the registry key HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters to FQDN. If a pod does not have FQDN, this has no effect. Default to false.</td></tr>
</tbody></table>
</div>
<h4 id="podworkflowtemplate"><a class="header" href="#podworkflowtemplate">PodWorkflowTemplate</a></h4>
<p>PodWorkflowTemplate creates a pod.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>PodSpec</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podspec-v1-core">PodSpec</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="pytorchtrainingjobworkflowtemplate"><a class="header" href="#pytorchtrainingjobworkflowtemplate">PyTorchTrainingJobWorkflowTemplate</a></h4>
<p>PyTorchTrainingJobWorkflowTemplate creates a t9k pytorch training job.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflow.html#pytorchtrainingjobspec">PyTorchTrainingJobSpec</a></em></td><td>Spec of the pytorch training job.</td></tr>
</tbody></table>
</div>
<h4 id="resourceworkflowtemplate"><a class="header" href="#resourceworkflowtemplate">ResourceWorkflowTemplate</a></h4>
<p>ResourceWorkflowTemplate creates a k8s resource.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>successRules</code> <em><a href="references/api-reference/workflow.html#rules">Rules</a></em></td><td>SuccessRules is an expression which describes the state of the k8s resource in which the task was considered succeeded.</td></tr>
<tr><td><code>failureRules</code> <em><a href="references/api-reference/workflow.html#rules">Rules</a></em></td><td>FailureRules is an expression which describes the state of the k8s resource in which the task was considered failed.</td></tr>
<tr><td><code>manifest</code> <em>string</em></td><td>Manifest is the full spec of the k8s resource to create.</td></tr>
</tbody></table>
</div>
<h4 id="result"><a class="header" href="#result">Result</a></h4>
<p>Result used to describe the results of a task</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Name the given name</td></tr>
<tr><td><code>description</code> <em>string</em></td><td>Description is a human-readable description of the result</td></tr>
<tr><td><code>value</code> <em>string</em></td><td>Value is a expression to generate DAG result by combining node results Only required for DAG WorkflowTemplate</td></tr>
</tbody></table>
</div>
<h4 id="rules"><a class="header" href="#rules">Rules</a></h4>
<p>Rules describe the state of the k8s resource.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#resourceworkflowtemplate">ResourceWorkflowTemplate</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>fieldSelector</code> <em>string</em></td><td>FieldSelector selects k8s resources based on the value of one or more resource fields, examples: metadata.name=my-service metadata.namespace!=default status.phase!=Running,spec.restartPolicy=Always</td></tr>
<tr><td><code>conditionSelector</code> <em><a href="references/api-reference/workflow.html#conditionselector">ConditionSelector</a></em></td><td>ConditionSelector selects k8s resources based on <resource>.status.conditions.</td></tr>
</tbody></table>
</div>
<h4 id="schedulepolicy-5"><a class="header" href="#schedulepolicy-5">SchedulePolicy</a></h4>
<p>SchedulePolicy defines how k8s schedules the WorkflowRun.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowrunspec">WorkflowRunSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>t9kScheduler</code> <em><a href="references/api-reference/workflow.html#t9kscheduler">T9kScheduler</a></em></td><td>T9k Scheduler.</td></tr>
</tbody></table>
</div>
<h4 id="seqpodworkflowtemplate"><a class="header" href="#seqpodworkflowtemplate">SeqPodWorkflowTemplate</a></h4>
<p>SeqPodWorkflowTemplate creates a pod whose containers run sequentially. The spec of SeqPodWorkflowTemplate is almost the same with corev1.PodSpec, except that the field <code>Containers</code> is replaced by <code>Steps</code>, to emphasize the sequential execution pattern.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>PodSpecWithoutContainers</code> <em><a href="references/api-reference/workflow.html#podspecwithoutcontainers">PodSpecWithoutContainers</a></em></td><td></td></tr>
<tr><td><code>steps</code> <em><a href="references/api-reference/workflow.html#step">Step</a> array</em></td><td>Steps are the sequentially running containers of the SeqPodWorkflowTemplate</td></tr>
</tbody></table>
</div>
<h4 id="step"><a class="header" href="#step">Step</a></h4>
<p>Step embeds the Container type, which allows it to include fields not provided by Container.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#seqpodworkflowtemplate">SeqPodWorkflowTemplate</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Container</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#container-v1-core">Container</a></em></td><td></td></tr>
<tr><td><code>script</code> <em>string</em></td><td>Script is the contents of an executable file to execute. If Script is not empty, the Step cannot have an Command and the Args will be passed to the Script.</td></tr>
</tbody></table>
</div>
<h4 id="t9kscheduler-5"><a class="header" href="#t9kscheduler-5">T9kScheduler</a></h4>
<p>T9kScheduler provides additonal configurations needed for the scheduling process.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#schedulepolicy">SchedulePolicy</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>queue</code> <em>string</em></td><td>Specifies the name of the queue should be used for running this workload.</td></tr>
</tbody></table>
</div>
<h4 id="tensorflowtrainingjobworkflowtemplate"><a class="header" href="#tensorflowtrainingjobworkflowtemplate">TensorFlowTrainingJobWorkflowTemplate</a></h4>
<p>TensorFlowTrainingJobWorkflowTemplate creates a t9k training job.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflow.html#tensorflowtrainingjobspec">TensorFlowTrainingJobSpec</a></em></td><td>Spec of the training job.</td></tr>
</tbody></table>
</div>
<h4 id="whenexpression"><a class="header" href="#whenexpression">WhenExpression</a></h4>
<p>WhenExpression allows a node in DAG to declare expressions to be evaluated before the node is run to determine whether the node should be executed or skipped.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#dagnode">DAGNode</a></li>
<li><a href="references/api-reference/workflow.html#nodestatus">NodeStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>input</code> <em>string</em></td><td>Input is the string for guard checking which can be a static input or an output from a parent node</td></tr>
<tr><td><code>operator</code> <em>Operator</em></td><td>Operator that represents an Input’s relationship to the values</td></tr>
<tr><td><code>values</code> <em>string array</em></td><td>Values is an array of strings, which is compared against the input, for guard checking It must be non-empty</td></tr>
</tbody></table>
</div>
<h4 id="workflowrun-3"><a class="header" href="#workflowrun-3">WorkflowRun</a></h4>
<p>WorkflowRun is the Schema for the workflowrun API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowrunlist">WorkflowRunList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/apis</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>WorkflowRun</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflow.html#workflowrunspec">WorkflowRunSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/workflow.html#workflowrunstatus">WorkflowRunStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="workflowruncondition"><a class="header" href="#workflowruncondition">WorkflowRunCondition</a></h4>
<p>WorkflowRunCondition is an observation of the condition of the WorkflowRun.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowrunstatusfields">WorkflowRunStatusFields</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/workflow.html#workflowrunconditiontype">WorkflowRunConditionType</a></em></td><td>Type of WorkflowRun condition.</td></tr>
<tr><td><code>status</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Status of the condition, one of True, False, or Unknown.</td></tr>
<tr><td><code>reason</code> <em>string</em></td><td>The reason for the condition’s last transition.</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>A readable message indicating details about the transition.</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>Last time the condition transitioned from one status to another.</td></tr>
</tbody></table>
</div>
<h4 id="workflowrunconditiontype"><a class="header" href="#workflowrunconditiontype">WorkflowRunConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>WorkflowRunConditionType defines all possible types of WorkflowRunConditionType. Can be one of: Running, Completed.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowruncondition">WorkflowRunCondition</a></li>
</ul>
<h4 id="workflowrunlist"><a class="header" href="#workflowrunlist">WorkflowRunList</a></h4>
<p>WorkflowRunList contains a list of WorkflowRun</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/apis</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>WorkflowRunList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/workflow.html#workflowrun">WorkflowRun</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="workflowrunresult"><a class="header" href="#workflowrunresult">WorkflowRunResult</a></h4>
<p>WorkflowRunResult used to describe the results of a workflowTemplate</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowrunstatusfields">WorkflowRunStatusFields</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Name the given name</td></tr>
<tr><td><code>value</code> <em>string</em></td><td>Value the given value of the result</td></tr>
</tbody></table>
</div>
<h4 id="workflowrunspec"><a class="header" href="#workflowrunspec">WorkflowRunSpec</a></h4>
<p>WorkflowRunSpec defines the desired state of WorkflowRun</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowrun">WorkflowRun</a></li>
<li><a href="references/api-reference/workflow.html#workflowruntemplatespec">WorkflowRunTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>workspaces</code> <em><a href="references/api-reference/workflow.html#workspacebinding">WorkspaceBinding</a> array</em></td><td>Workspaces is a list of mappings from volumes to workspace names that will be supplied to WorkflowTemplate.</td></tr>
<tr><td><code>params</code> <em><a href="references/api-reference/workflow.html#param">Param</a> array</em></td><td>Params is a list of input parameters that will be supplied to WorkflowTemplate.</td></tr>
<tr><td><code>serviceAccountName</code> <em>string</em></td><td>ServiceAccountName is the name of the service account that the created pod will use.</td></tr>
<tr><td><code>workflowTemplateRef</code> <em>string</em></td><td>WorkflowTemplateRef is the name of the WorkflowTemplate that WorkflowRun will use. No more than one of the WorkflowTemplateRef and WorkflowTemplateSpec may be specified.</td></tr>
<tr><td><code>workflowTemplateSpec</code> <em><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></em></td><td>WorkflowTemplateSpec is an embedded spec of WorkflowTemplate that WorkflowRun will use. No more than one of the WorkflowTemplateRef and WorkflowTemplateSpec may be specified.</td></tr>
<tr><td><code>timeout</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#duration-v1-meta">Duration</a></em></td><td>Time after which the build times out. Defaults to never. Refer Go’s ParseDuration documentation for expected format: https://golang.org/pkg/time/#ParseDuration</td></tr>
<tr><td><code>depth</code> <em>integer</em></td><td>Depth indicates the depth of the WorkflowRun in DAG. If Depth exceeds limit, the WorkflowRun will not be created.</td></tr>
<tr><td><code>scheduler</code> <em><a href="references/api-reference/workflow.html#schedulepolicy">SchedulePolicy</a></em></td><td>Identifies the preferred scheduler for allocating resources to replicas. Defaults to cluster default scheduler.</td></tr>
</tbody></table>
</div>
<h4 id="workflowrunstatus"><a class="header" href="#workflowrunstatus">WorkflowRunStatus</a></h4>
<p>WorkflowRunStatus defines the observed state of WorkflowRun</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowrun">WorkflowRun</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>WorkflowRunStatusFields</code> <em><a href="references/api-reference/workflow.html#workflowrunstatusfields">WorkflowRunStatusFields</a></em></td><td>WorkflowRunStatusFields inlines the status fields.</td></tr>
<tr><td><code>retriedStatus</code> <em><a href="references/api-reference/workflow.html#workflowrunstatusfields">WorkflowRunStatusFields</a> array</em></td><td>RetriedStatus contains the history of WorkflowRunStatus in case of a retry in order to keep record of failures.</td></tr>
</tbody></table>
</div>
<h4 id="workflowrunstatusfields"><a class="header" href="#workflowrunstatusfields">WorkflowRunStatusFields</a></h4>
<p>WorkflowRunStatusFields are the main fields of WorkflowRunStatus</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowrunstatus">WorkflowRunStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>phase</code> <em><a href="references/api-reference/workflow.html#nodephase">NodePhase</a></em></td><td>Phase is a simple, high-level summary of where the WorkflowRun is in its lifecycle.</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>A human readable message indicating details about why the WorkflowRun is in this condition.</td></tr>
<tr><td><code>nodes</code> <em>object (keys:string, values:<a href="references/api-reference/workflow.html#nodestatus">NodeStatus</a>)</em></td><td>Nodes is a map of DAG nodes status, with the node name as the key.</td></tr>
<tr><td><code>startTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>StartTime is the time the build is actually started.</td></tr>
<tr><td><code>completionTime</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>CompletionTime is the time the build completed.</td></tr>
<tr><td><code>results</code> <em><a href="references/api-reference/workflow.html#workflowrunresult">WorkflowRunResult</a> array</em></td><td>Results are the list of results written out by the workflowTemplate’s containers</td></tr>
<tr><td><code>workflowTemplateSpec</code> <em><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></em></td><td>WorkflowTemplateSpec contains the Spec from the dereferenced WorkflowTemplate definition used to instantiate this WorkflowRun.</td></tr>
<tr><td><code>podName</code> <em>string</em></td><td>PodName is the name of the pod created by WorkflowRun.</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/workflow.html#workflowruncondition">WorkflowRunCondition</a> array</em></td><td>The latest available observations of the WorkflowRun’s current state.</td></tr>
</tbody></table>
</div>
<h4 id="workflowruntemplatespec"><a class="header" href="#workflowruntemplatespec">WorkflowRunTemplateSpec</a></h4>
<p>WorkflowRunTemplateSpec describes the data a WorkflowRun should have when created from a template</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#cronworkflowrunspec">CronWorkflowRunSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflow.html#workflowrunspec">WorkflowRunSpec</a></em></td><td>Specification of the desired behavior of the WorkflowRun.</td></tr>
</tbody></table>
</div>
<h4 id="workflowtemplate-3"><a class="header" href="#workflowtemplate-3">WorkflowTemplate</a></h4>
<p>WorkflowTemplate is the Schema for the WorkflowTemplate API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatelist">WorkflowTemplateList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/apis</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>WorkflowTemplate</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/workflow.html#workflowtemplatestatus">WorkflowTemplateStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="workflowtemplatelist"><a class="header" href="#workflowtemplatelist">WorkflowTemplateList</a></h4>
<p>WorkflowTemplateList contains a list of WorkflowTemplate</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>batch.tensorstack.dev/apis</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>WorkflowTemplateList</code></td></tr>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/workflow.html#workflowtemplate">WorkflowTemplate</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="workflowtemplatespec"><a class="header" href="#workflowtemplatespec">WorkflowTemplateSpec</a></h4>
<p>WorkflowTemplateSpec defines the desired state of WorkflowTemplate.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowrunspec">WorkflowRunSpec</a></li>
<li><a href="references/api-reference/workflow.html#workflowrunstatusfields">WorkflowRunStatusFields</a></li>
<li><a href="references/api-reference/workflow.html#workflowtemplate">WorkflowTemplate</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>description</code> <em>string</em></td><td>Description is a user-facing description of the task that may be used to populate a UI.</td></tr>
<tr><td><code>workspaces</code> <em><a href="references/api-reference/workflow.html#workspacedeclaration">WorkspaceDeclaration</a> array</em></td><td>Workspaces are the volumes that this WorkflowTemplate requires. Workspaces must be supplied as inputs in WorkflowRuns unless they are declared as optional.</td></tr>
<tr><td><code>params</code> <em><a href="references/api-reference/workflow.html#paramspec">ParamSpec</a> array</em></td><td>Params is a list of input parameters required to run the task. Params must be supplied as inputs in WorkflowRuns unless they declare a default value.</td></tr>
<tr><td><code>results</code> <em><a href="references/api-reference/workflow.html#result">Result</a> array</em></td><td>Results are values that this WorkflowTemplate can output</td></tr>
<tr><td><code>type</code> <em><a href="references/api-reference/workflow.html#workflowtemplatetype">WorkflowTemplateType</a></em></td><td>Type defines the type of WorkflowTemplate. If empty, the first non-nil field in (pod, seqPod, resource, dag) will be the type.</td></tr>
<tr><td><code>pod</code> <em><a href="references/api-reference/workflow.html#podworkflowtemplate">PodWorkflowTemplate</a></em></td><td>Pod is the spec of pod which WorkflowTemplate will create.</td></tr>
<tr><td><code>seqPod</code> <em><a href="references/api-reference/workflow.html#seqpodworkflowtemplate">SeqPodWorkflowTemplate</a></em></td><td>SeqPod is the spec of pod with sequentially running containers which WorkflowTemplate will create.</td></tr>
<tr><td><code>resource</code> <em><a href="references/api-reference/workflow.html#resourceworkflowtemplate">ResourceWorkflowTemplate</a></em></td><td>Resource is the spec of k8s resource which WorkflowTemplate will create.</td></tr>
<tr><td><code>dag</code> <em><a href="references/api-reference/workflow.html#dagworkflowtemplate">DAGWorkflowTemplate</a></em></td><td>DAG is the spec of DAG which WorkflowTemplate will create.</td></tr>
<tr><td><code>genericJob</code> <em><a href="references/api-reference/workflow.html#genericjobworkflowtemplate">GenericJobWorkflowTemplate</a></em></td><td>GenericJob is the spec of t9k generic job which WorkflowTemplate will create.</td></tr>
<tr><td><code>tensorflowTrainingJob</code> <em><a href="references/api-reference/workflow.html#tensorflowtrainingjobworkflowtemplate">TensorFlowTrainingJobWorkflowTemplate</a></em></td><td>TensorFlowTrainingJob is the spec of t9k training job which WorkflowTemplate will create.</td></tr>
<tr><td><code>pytorchTrainingJob</code> <em><a href="references/api-reference/workflow.html#pytorchtrainingjobworkflowtemplate">PyTorchTrainingJobWorkflowTemplate</a></em></td><td>PyTorchTrainingJob is the spec of t9k pytorch training job which WorkflowTemplate will create.</td></tr>
<tr><td><code>xgboostTrainingJob</code> <em><a href="references/api-reference/workflow.html#xgboosttrainingjobworkflowtemplate">XGBoostTrainingJobWorkflowTemplate</a></em></td><td>XGBoostTrainingJob is the spec of t9k xgboost training job which WorkflowTemplate will create.</td></tr>
<tr><td><code>colossalaiJob</code> <em><a href="references/api-reference/workflow.html#colossalaijobworkflowtemplate">ColossalAIJobWorkflowTemplate</a></em></td><td>ColossalAIJob is the spec of t9k colossalai job which WorkflowTemplate will create.</td></tr>
<tr><td><code>deepspeedJob</code> <em><a href="references/api-reference/workflow.html#deepspeedjobworkflowtemplate">DeepSpeedJobWorkflowTemplate</a></em></td><td>DeepSpeedJob is the spec of t9k deepspeed job which WorkflowTemplate will create.</td></tr>
<tr><td><code>mpiJob</code> <em><a href="references/api-reference/workflow.html#mpijobworkflowtemplate">MPIJobWorkflowTemplate</a></em></td><td>MPIJob is the spec of t9k mpi job which WorkflowTemplate will create.</td></tr>
<tr><td><code>beamJob</code> <em><a href="references/api-reference/workflow.html#beamjobworkflowtemplate">BeamJobWorkflowTemplate</a></em></td><td>BeamJob is the spec of t9k beam job which WorkflowTemplate will create.</td></tr>
</tbody></table>
</div>
<h4 id="workflowtemplatetype"><a class="header" href="#workflowtemplatetype">WorkflowTemplateType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>WorkflowTemplateType defines the type of WorkflowTemplate.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<h4 id="workspacebinding"><a class="header" href="#workspacebinding">WorkspaceBinding</a></h4>
<p>WorkspaceBinding maps a WorkflowTemplate’s declared workspace to a Volume.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowrunspec">WorkflowRunSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Name is the name of the workspace populated by the volume.</td></tr>
<tr><td><code>subPath</code> <em>string</em></td><td>SubPath is optionally a directory on the volume which should be used for this binding (i.e. the volume will be mounted at this sub directory).</td></tr>
<tr><td><code>persistentVolumeClaim</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#persistentvolumeclaimvolumesource-v1-core">PersistentVolumeClaimVolumeSource</a></em></td><td>PersistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. Either this OR EmptyDir can be used.</td></tr>
<tr><td><code>emptyDir</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#emptydirvolumesource-v1-core">EmptyDirVolumeSource</a></em></td><td>EmptyDir represents a temporary directory that shares a WorkflowTemplate’s lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir Either this OR PersistentVolumeClaim can be used.</td></tr>
<tr><td><code>configMap</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#configmapvolumesource-v1-core">ConfigMapVolumeSource</a></em></td><td>ConfigMap represents a configMap that should populate this workspace.</td></tr>
<tr><td><code>secret</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#secretvolumesource-v1-core">SecretVolumeSource</a></em></td><td>Secret represents a secret that should populate this workspace.</td></tr>
</tbody></table>
</div>
<h4 id="workspacedagbinding"><a class="header" href="#workspacedagbinding">WorkspaceDAGBinding</a></h4>
<p>WorkspaceDAGBinding describes how a workspace passed into a DAG WorkflowTemplate should be mapped to a node’s declared workspace.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#dagnode">DAGNode</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Name is the name of the workspace as declared by the node</td></tr>
<tr><td><code>workspace</code> <em>string</em></td><td>Workspace is the name of the workspace declared by the DAG WorkflowTemplate</td></tr>
<tr><td><code>subPath</code> <em>string</em></td><td>SubPath is optionally a directory on the volume which should be used for this binding (i.e. the volume will be mounted at this sub directory).</td></tr>
</tbody></table>
</div>
<h4 id="workspacedeclaration"><a class="header" href="#workspacedeclaration">WorkspaceDeclaration</a></h4>
<p>WorkspaceDeclaration is a declaration of a volume that a WorkflowTemplate requires.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Name is the name by which you can bind the volume at runtime.</td></tr>
<tr><td><code>description</code> <em>string</em></td><td>Description is an optional human readable description of this volume.</td></tr>
<tr><td><code>mountPath</code> <em>string</em></td><td>MountPath overrides the directory that the volume will be made available at.</td></tr>
<tr><td><code>readOnly</code> <em>boolean</em></td><td>ReadOnly dictates whether a mounted volume is writable. By default this field is false and so mounted volumes are writable.</td></tr>
<tr><td><code>optional</code> <em>boolean</em></td><td>Optional marks a Workspace as not being required in WorkflowRuns. By default this field is false and so declared workspaces are required.</td></tr>
</tbody></table>
</div>
<h4 id="xgboosttrainingjobworkflowtemplate"><a class="header" href="#xgboosttrainingjobworkflowtemplate">XGBoostTrainingJobWorkflowTemplate</a></h4>
<p>XGBoostTrainingJobWorkflowTemplate creates a t9k xgboost training job.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflow.html#workflowtemplatespec">WorkflowTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>metadata</code> <em><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflow.html#xgboosttrainingjobspec">XGBoostTrainingJobSpec</a></em></td><td>Spec of the xgboost training job.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-16"><a class="header" href="#api-reference-16">API Reference</a></h1>
<h2 id="packages-16"><a class="header" href="#packages-16">Packages</a></h2>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#tensorstackdevv1beta1">tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="tensorstackdevv1beta1-6"><a class="header" href="#tensorstackdevv1beta1-6">tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the  v1beta1 API group</p>
<h3 id="resource-types-17"><a class="header" href="#resource-types-17">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#eventlistener">EventListener</a></li>
<li><a href="references/api-reference/workflowtrigger.html#eventlistenerlist">EventListenerList</a></li>
<li><a href="references/api-reference/workflowtrigger.html#workflowtrigger">WorkflowTrigger</a></li>
<li><a href="references/api-reference/workflowtrigger.html#workflowtriggerlist">WorkflowTriggerList</a></li>
</ul>
<h4 id="condition"><a class="header" href="#condition">Condition</a></h4>
<p>Condition contains details about resource state</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#eventlistenerstatus">EventListenerStatus</a></li>
<li><a href="references/api-reference/workflowtrigger.html#workflowtriggerstatus">WorkflowTriggerStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/workflowtrigger.html#conditiontype">ConditionType</a></em></td><td>Condition type.</td></tr>
<tr><td><code>status</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Condition status, True, False or Unknown.</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>Last time the condition transitioned from one status to another.</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>Human-readable message indicating details about last transition.</td></tr>
</tbody></table>
</div>
<h4 id="conditiontype"><a class="header" href="#conditiontype">ConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>ConditionType is a valid value of Condition.Type</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#condition">Condition</a></li>
</ul>
<h4 id="eventlistener-1"><a class="header" href="#eventlistener-1">EventListener</a></h4>
<p>EventListener is the Schema for the eventlisteners API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#eventlistenerlist">EventListenerList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>EventListener</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflowtrigger.html#eventlistenerspec">EventListenerSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/workflowtrigger.html#eventlistenerstatus">EventListenerStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="eventlisteneraddress"><a class="header" href="#eventlisteneraddress">EventListenerAddress</a></h4>
<p>The access address for in-cluster and out-cluster</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#eventlistenerstatus">EventListenerStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>url</code> <em>string</em></td><td>The access address for out-cluster</td></tr>
<tr><td><code>inClusterURL</code> <em>string</em></td><td>The access address for in-cluster</td></tr>
</tbody></table>
</div>
<h4 id="eventlistenerlist"><a class="header" href="#eventlistenerlist">EventListenerList</a></h4>
<p>EventListenerList contains a list of EventListener</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>EventListenerList</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/workflowtrigger.html#eventlistener">EventListener</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="eventlistenerspec"><a class="header" href="#eventlistenerspec">EventListenerSpec</a></h4>
<p>EventListenerSpec defines the desired state of EventListener</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#eventlistener">EventListener</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>replicas</code> <em>integer</em></td><td>Number of desired pods. This is a pointer to distinguish between explicit zero and not specified. Defaults to 1.</td></tr>
<tr><td><code>resources</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcerequirements-v1-core">ResourceRequirements</a></em></td><td>Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</td></tr>
</tbody></table>
</div>
<h4 id="eventlistenerstatus"><a class="header" href="#eventlistenerstatus">EventListenerStatus</a></h4>
<p>EventListenerStatus defines the observed state of EventListener</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#eventlistener">EventListener</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>address</code> <em><a href="references/api-reference/workflowtrigger.html#eventlisteneraddress">EventListenerAddress</a></em></td><td>The access address for in-cluster and out-cluster</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/workflowtrigger.html#condition">Condition</a> array</em></td><td>Represents the latest available observations of a eventListener’s current state.</td></tr>
</tbody></table>
</div>
<h4 id="eventsource"><a class="header" href="#eventsource">EventSource</a></h4>
<p>The source that events come from.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#workflowtriggerspec">WorkflowTriggerSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>eventListenerName</code> <em>string</em></td><td>Name of an existing EventListener.</td></tr>
<tr><td><code>filters</code> <em><a href="references/api-reference/workflowtrigger.html#filter">Filter</a> array</em></td><td>List of filters to filter events from the EventListener.</td></tr>
</tbody></table>
</div>
<h4 id="filter"><a class="header" href="#filter">Filter</a></h4>
<p>Filter defines how to filter events from the EventListener.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#eventsource">EventSource</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>path</code> <em>string</em></td><td>Path is the JSONPath of the event’s (JSON decoded) data key Path is a series of keys separated by a dot. A key may contain wildcard characters ‘*’ and ‘?’. To access an array value use the index as the key. The dot and wildcard characters can be escaped with ‘\’. See https://github.com/tidwall/gjson#path-syntax for more information on how to use this.</td></tr>
<tr><td><code>type</code> <em><a href="references/api-reference/workflowtrigger.html#jsontype">JSONType</a></em></td><td>Type contains the JSON type of the data</td></tr>
<tr><td><code>values</code> <em>string array</em></td><td>Values is the allowed string values for this key Booleans are passed using strconv.ParseBool() Numbers are parsed using as float64 using strconv.ParseFloat() Strings are taken as is Nils this value is ignored</td></tr>
</tbody></table>
</div>
<h4 id="jsontype"><a class="header" href="#jsontype">JSONType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>JSONType contains the supported JSON types for data filtering</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#filter">Filter</a></li>
</ul>
<h4 id="workflowtrigger-2"><a class="header" href="#workflowtrigger-2">WorkflowTrigger</a></h4>
<p>WorkflowTrigger is the Schema for the workflowtriggers API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#workflowtriggerlist">WorkflowTriggerList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>WorkflowTrigger</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/workflowtrigger.html#workflowtriggerspec">WorkflowTriggerSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/workflowtrigger.html#workflowtriggerstatus">WorkflowTriggerStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="workflowtriggerlist"><a class="header" href="#workflowtriggerlist">WorkflowTriggerList</a></h4>
<p>WorkflowTriggerList contains a list of WorkflowTrigger</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>WorkflowTriggerList</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/workflowtrigger.html#workflowtrigger">WorkflowTrigger</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="workflowtriggerspec"><a class="header" href="#workflowtriggerspec">WorkflowTriggerSpec</a></h4>
<p>WorkflowTriggerSpec defines the desired state of WorkflowTrigger</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#workflowtrigger">WorkflowTrigger</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>replicas</code> <em>integer</em></td><td>Number of desired pods. This is a pointer to distinguish between explicit zero and not specified. Defaults to 1.</td></tr>
<tr><td><code>eventSources</code> <em><a href="references/api-reference/workflowtrigger.html#eventsource">EventSource</a> array</em></td><td>List of sources that events come from.</td></tr>
<tr><td><code>serviceAccountName</code> <em>string</em></td><td>Name of a service account used by WorkflowTrigger to create WorkflowRuns.</td></tr>
<tr><td><code>resources</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcerequirements-v1-core">ResourceRequirements</a></em></td><td>Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</td></tr>
<tr><td><code>workflowRunSpec</code> <em>WorkflowRunSpec</em></td><td>Spec of WorkflowRun to be created by WorkflowTrigger.</td></tr>
</tbody></table>
</div>
<h4 id="workflowtriggerstatus"><a class="header" href="#workflowtriggerstatus">WorkflowTriggerStatus</a></h4>
<p>WorkflowTriggerStatus defines the observed state of WorkflowTrigger</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/workflowtrigger.html#workflowtrigger">WorkflowTrigger</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>conditions</code> <em><a href="references/api-reference/workflowtrigger.html#condition">Condition</a> array</em></td><td>Represents the latest available observations of a eventListener’s current state.</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-17"><a class="header" href="#api-reference-17">API Reference</a></h1>
<h2 id="packages-17"><a class="header" href="#packages-17">Packages</a></h2>
<ul>
<li><a href="references/api-reference/simplemlservice.html#tensorstackdevv1beta1">tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="tensorstackdevv1beta1-7"><a class="header" href="#tensorstackdevv1beta1-7">tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the  v1beta1 API group</p>
<h3 id="resource-types-18"><a class="header" href="#resource-types-18">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/simplemlservice.html#simplemlservice">SimpleMLService</a></li>
<li><a href="references/api-reference/simplemlservice.html#simplemlservicelist">SimpleMLServiceList</a></li>
</ul>
<h4 id="address"><a class="header" href="#address">Address</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#simplemlservicestatus">SimpleMLServiceStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>url</code> <em>string</em></td><td>the service’s in-cluster url, e.g. managed-simplemlservice-41309.demo.svc.cluster.local</td></tr>
<tr><td><code>ports</code> <em><a href="references/api-reference/simplemlservice.html#addressport">AddressPort</a> array</em></td><td>an array of serivce port &amp; protocol</td></tr>
</tbody></table>
</div>
<h4 id="addressport"><a class="header" href="#addressport">AddressPort</a></h4>
<p>AddressPort stores ports defined in service of simplemlservice</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#address">Address</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>port</code> <em>integer</em></td><td>The port that will be exposed by this service.</td></tr>
<tr><td><code>nodePort</code> <em>integer</em></td><td>The port on each node on which this service is exposed when type=NodePort or LoadBalancer. Usually assigned by the system. If specified, it will be allocated to the service if unused or else creation of the service will fail. Default is to auto-allocate a port if the ServiceType of this Service requires one. More info: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport</td></tr>
<tr><td><code>protocol</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#protocol-v1-core">Protocol</a></em></td><td>The IP protocol for this port. Supports “TCP”, “UDP”, and “SCTP”. Default is TCP.</td></tr>
</tbody></table>
</div>
<h4 id="condition-1"><a class="header" href="#condition-1">Condition</a></h4>
<p>Condition for simpleMLService</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#simplemlservicestatus">SimpleMLServiceStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>lastTransitionTime</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td></td></tr>
<tr><td><code>type</code> <em><a href="references/api-reference/simplemlservice.html#simplemlserviceconditiontype">SimpleMLServiceConditionType</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td></td></tr>
<tr><td><code>reason</code> <em>string</em></td><td></td></tr>
<tr><td><code>message</code> <em>string</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="customspec"><a class="header" href="#customspec">CustomSpec</a></h4>
<p>CustomSpec defines a pod template to run model serving</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#simplemlservicespec">SimpleMLServiceSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>spec</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podspec-v1-core">PodSpec</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="deploymentspec"><a class="header" href="#deploymentspec">DeploymentSpec</a></h4>
<p>DeploymentSpec defines the configuration for replicas &amp; scheduler</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#simplemlservicespec">SimpleMLServiceSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>scheduler</code> <em><a href="references/api-reference/simplemlservice.html#schedulepolicy">SchedulePolicy</a></em></td><td>Scheduler responsible for handling resource allocation requests. default is default-scheduler</td></tr>
<tr><td><code>replicas</code> <em>integer</em></td><td>Replicas of pods running model serving</td></tr>
<tr><td><code>strategy</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#deploymentstrategy-v1-apps">DeploymentStrategy</a></em></td><td>The deployment strategy to use to replace existing pods with new ones</td></tr>
</tbody></table>
</div>
<h4 id="pvcstorage"><a class="header" href="#pvcstorage">PVCStorage</a></h4>
<p>PVCStorage defines infos of pvc</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#storage">Storage</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>PVC name</td></tr>
<tr><td><code>subPath</code> <em>string</em></td><td>Directory path where model is located in PVC. Must be a relative path. e.g. “model/mnist”</td></tr>
<tr><td><code>containerPath</code> <em>string</em></td><td>Directory path where model locates in container. Must be absolute path, default is “/var/lib/t9k/model”</td></tr>
</tbody></table>
</div>
<h4 id="pytorchspec"><a class="header" href="#pytorchspec">PyTorchSpec</a></h4>
<p>PyTorchSpec defines arguments for configuring PyTorch model serving</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#simplemlservicespec">SimpleMLServiceSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>modelsFlag</code> <em>string</em></td><td>Value of torchserve’s flag –models</td></tr>
<tr><td><code>image</code> <em>string</em></td><td>Image of torchserve</td></tr>
<tr><td><code>resources</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcerequirements-v1-core">ResourceRequirements</a></em></td><td>Compute Resources required by a replica</td></tr>
</tbody></table>
</div>
<h4 id="s3storage"><a class="header" href="#s3storage">S3Storage</a></h4>
<p>S3Storage defines infos of s3</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#storage">Storage</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>secretName</code> <em>string</em></td><td>Name of secret storing s3cmd config</td></tr>
<tr><td><code>uri</code> <em>string</em></td><td>Directory path where model locates in s3. e.g. <code>&quot;s3://&lt;bucket&gt;/&lt;dir&gt;/&quot;</code></td></tr>
<tr><td><code>containerPath</code> <em>string</em></td><td>Directory path where model locates in container, default is “/var/lib/t9k/model”</td></tr>
</tbody></table>
</div>
<h4 id="schedulepolicy-6"><a class="header" href="#schedulepolicy-6">SchedulePolicy</a></h4>
<p>SchedulePolicy defines which scheduler is responsible for handling resource allocation requests</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#deploymentspec">DeploymentSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>t9kScheduler</code> <em><a href="references/api-reference/simplemlservice.html#t9kscheduler">T9kScheduler</a></em></td><td>Use t9k-scheduler</td></tr>
</tbody></table>
</div>
<h4 id="servicespec"><a class="header" href="#servicespec">ServiceSpec</a></h4>
<p>ServiceSpec defines the desired state of Service created by Controller</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#simplemlservicespec">SimpleMLServiceSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>ports</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#serviceport-v1-core">ServicePort</a> array</em></td><td>The list of ports that are exposed by this service. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies</td></tr>
<tr><td><code>type</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#servicetype-v1-core">ServiceType</a></em></td><td>type determines how the Service is exposed. Defaults to ClusterIP. Valid options are ExternalName, ClusterIP, NodePort, and LoadBalancer. “ExternalName” maps to the specified externalName. “ClusterIP” allocates a cluster-internal IP address for load-balancing to endpoints. Endpoints are determined by the selector or if that is not specified, by manual construction of an Endpoints object. If clusterIP is “None”, no virtual IP is allocated and the endpoints are published as a set of endpoints rather than a stable IP. “NodePort” builds on ClusterIP and allocates a port on every node which routes to the clusterIP. “LoadBalancer” builds on NodePort and creates an external load-balancer (if supported in the current cloud) which routes to the clusterIP. More info: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types</td></tr>
</tbody></table>
</div>
<h4 id="simplemlservice-3"><a class="header" href="#simplemlservice-3">SimpleMLService</a></h4>
<p>SimpleMLService is the Schema for the simplemlservices API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#simplemlservicelist">SimpleMLServiceList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>SimpleMLService</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/simplemlservice.html#simplemlservicespec">SimpleMLServiceSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/simplemlservice.html#simplemlservicestatus">SimpleMLServiceStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="simplemlserviceconditiontype"><a class="header" href="#simplemlserviceconditiontype">SimpleMLServiceConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p>SimpleMLServiceConditionType is a type</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#condition">Condition</a></li>
</ul>
<h4 id="simplemlservicelist"><a class="header" href="#simplemlservicelist">SimpleMLServiceList</a></h4>
<p>SimpleMLServiceList contains a list of SimpleMLService</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>SimpleMLServiceList</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/simplemlservice.html#simplemlservice">SimpleMLService</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="simplemlservicespec"><a class="header" href="#simplemlservicespec">SimpleMLServiceSpec</a></h4>
<p>SimpleMLServiceSpec defines the desired state of SimpleMLService</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#simplemlservice">SimpleMLService</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tensorflow</code> <em><a href="references/api-reference/simplemlservice.html#tensorflowspec">TensorflowSpec</a></em></td><td>Spec for Tensorflow Serving (https://github.com/tensorflow/serving)</td></tr>
<tr><td><code>pytorch</code> <em><a href="references/api-reference/simplemlservice.html#pytorchspec">PyTorchSpec</a></em></td><td>Spec for TorchServe</td></tr>
<tr><td><code>custom</code> <em><a href="references/api-reference/simplemlservice.html#customspec">CustomSpec</a></em></td><td>Custom Spec</td></tr>
<tr><td><code>storage</code> <em><a href="references/api-reference/simplemlservice.html#storage">Storage</a></em></td><td>Storage of model</td></tr>
<tr><td><code>DeploymentSpec</code> <em><a href="references/api-reference/simplemlservice.html#deploymentspec">DeploymentSpec</a></em></td><td>Configuration for replicas &amp; scheduler</td></tr>
<tr><td><code>service</code> <em><a href="references/api-reference/simplemlservice.html#servicespec">ServiceSpec</a></em></td><td>Configuration for service. Controller will create default service if spec.service not set</td></tr>
</tbody></table>
</div>
<h4 id="simplemlservicestatus"><a class="header" href="#simplemlservicestatus">SimpleMLServiceStatus</a></h4>
<p>SimpleMLServiceStatus defines the observed state of SimpleMLService</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#simplemlservice">SimpleMLService</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>address</code> <em><a href="references/api-reference/simplemlservice.html#address">Address</a></em></td><td></td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/simplemlservice.html#condition">Condition</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="storage"><a class="header" href="#storage">Storage</a></h4>
<p>Storage defines the storage where the model locates</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#simplemlservicespec">SimpleMLServiceSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>s3</code> <em><a href="references/api-reference/simplemlservice.html#s3storage">S3Storage</a></em></td><td>Model locates in S3</td></tr>
<tr><td><code>pvc</code> <em><a href="references/api-reference/simplemlservice.html#pvcstorage">PVCStorage</a></em></td><td>Model locates in pvc</td></tr>
</tbody></table>
</div>
<h4 id="t9kscheduler-6"><a class="header" href="#t9kscheduler-6">T9kScheduler</a></h4>
<p>T9kScheduler defines SimpleMLService use t9k-scheduler.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#schedulepolicy">SchedulePolicy</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>queue</code> <em>string</em></td><td>Name of queue which SimpleMLService’s pod belongs to</td></tr>
</tbody></table>
</div>
<h4 id="tensorflowspec"><a class="header" href="#tensorflowspec">TensorflowSpec</a></h4>
<p>TensorflowSpec defines arguments for configuring Tensorflow model serving</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/simplemlservice.html#simplemlservicespec">SimpleMLServiceSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>image</code> <em>string</em></td><td>Image of Tensorflow Serving</td></tr>
<tr><td><code>resources</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcerequirements-v1-core">ResourceRequirements</a></em></td><td>Compute Resources required by a replica</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="api-reference-18"><a class="header" href="#api-reference-18">API Reference</a></h1>
<h2 id="packages-18"><a class="header" href="#packages-18">Packages</a></h2>
<ul>
<li><a href="references/api-reference/mlservice.html#tensorstackdevv1beta1">tensorstack.dev/v1beta1</a></li>
</ul>
<h2 id="tensorstackdevv1beta1-8"><a class="header" href="#tensorstackdevv1beta1-8">tensorstack.dev/v1beta1</a></h2>
<p>Package v1beta1 contains API Schema definitions for the  v1beta1 API group</p>
<h3 id="resource-types-19"><a class="header" href="#resource-types-19">Resource Types</a></h3>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservice">MLService</a></li>
<li><a href="references/api-reference/mlservice.html#mlservicelist">MLServiceList</a></li>
<li><a href="references/api-reference/mlservice.html#mlserviceruntime">MLServiceRuntime</a></li>
<li><a href="references/api-reference/mlservice.html#mlserviceruntimelist">MLServiceRuntimeList</a></li>
</ul>
<h4 id="addressstatus"><a class="header" href="#addressstatus">AddressStatus</a></h4>
<p>AddressStatus store state of serving address</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservicestatus">MLServiceStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>url</code> <em>string</em></td><td>URL used for predictor.</td></tr>
</tbody></table>
</div>
<h4 id="deploymentspec-1"><a class="header" href="#deploymentspec-1">DeploymentSpec</a></h4>
<p>DeploymentSpec defines the configuration for knative service</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#predictorspec">PredictorSpec</a></li>
<li><a href="references/api-reference/mlservice.html#transformerspec">TransformerSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>minReplicas</code> <em>integer</em></td><td>Minimum number of replicas, pods won’t scale down to 0 in case of no traffic</td></tr>
<tr><td><code>maxReplicas</code> <em>integer</em></td><td>This is the up bound for autoscaler to scale to</td></tr>
<tr><td><code>template</code> <em><a href="references/api-reference/mlservice.html#patchtemplatespec">PatchTemplateSpec</a></em></td><td>Custom template of knative service</td></tr>
<tr><td><code>logger</code> <em><a href="references/api-reference/mlservice.html#loggerspec">LoggerSpec</a></em></td><td>Logger spec</td></tr>
</tbody></table>
</div>
<h4 id="editablemetadata"><a class="header" href="#editablemetadata">EditableMetadata</a></h4>
<p>Metadata includes the editable part of metav1.ObjectMeta. Now only contains labels and annotations</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#patchtemplatespec">PatchTemplateSpec</a></li>
<li><a href="references/api-reference/mlservice.html#runtimetemplatespec">RuntimeTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>labels</code> <em>object (keys:string, values:string)</em></td><td>Labels</td></tr>
<tr><td><code>annotations</code> <em>object (keys:string, values:string)</em></td><td>Annotations</td></tr>
</tbody></table>
</div>
<h4 id="loggermode"><a class="header" href="#loggermode">LoggerMode</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#loggerspec">LoggerSpec</a></li>
</ul>
<h4 id="loggerspec"><a class="header" href="#loggerspec">LoggerSpec</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#deploymentspec">DeploymentSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>urls</code> <em>string array</em></td><td>Logger sink url array</td></tr>
<tr><td><code>mode</code> <em><a href="references/api-reference/mlservice.html#loggermode">LoggerMode</a></em></td><td>Logger mode</td></tr>
</tbody></table>
</div>
<h4 id="mlservice-3"><a class="header" href="#mlservice-3">MLService</a></h4>
<p>MLService is the Schema for the mlservices API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservicelist">MLServiceList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>MLService</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/mlservice.html#mlservicespec">MLServiceSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/mlservice.html#mlservicestatus">MLServiceStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="mlservicecondition"><a class="header" href="#mlservicecondition">MLServiceCondition</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservicestatus">MLServiceStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code> <em><a href="references/api-reference/mlservice.html#mlserviceconditiontype">MLServiceConditionType</a></em></td><td>Type of condition.</td></tr>
<tr><td><code>status</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#conditionstatus-v1-core">ConditionStatus</a></em></td><td>Status of the condition, one of True, False, Unknown.</td></tr>
<tr><td><code>lastTransitionTime</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#time-v1-meta">Time</a></em></td><td>Last time the condition transitioned from one status to another.</td></tr>
<tr><td><code>reason</code> <em>string</em></td><td>The reason for the condition’s last transition.</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>A human readable message indicating details about the transition.</td></tr>
</tbody></table>
</div>
<h4 id="mlserviceconditiontype"><a class="header" href="#mlserviceconditiontype">MLServiceConditionType</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservicecondition">MLServiceCondition</a></li>
</ul>
<h4 id="mlservicelist"><a class="header" href="#mlservicelist">MLServiceList</a></h4>
<p>MLServiceList contains a list of MLService</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>MLServiceList</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/mlservice.html#mlservice">MLService</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="mlserviceruntime-1"><a class="header" href="#mlserviceruntime-1">MLServiceRuntime</a></h4>
<p>MLServiceRuntime is the Schema for the mlserviceruntimes API</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlserviceruntimelist">MLServiceRuntimeList</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>MLServiceRuntime</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#objectmeta-v1-meta">ObjectMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/mlservice.html#mlserviceruntimespec">MLServiceRuntimeSpec</a></em></td><td></td></tr>
<tr><td><code>status</code> <em><a href="references/api-reference/mlservice.html#mlserviceruntimestatus">MLServiceRuntimeStatus</a></em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="mlserviceruntimelist"><a class="header" href="#mlserviceruntimelist">MLServiceRuntimeList</a></h4>
<p>MLServiceRuntimeList contains a list of MLServiceRuntime</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiVersion</code> <em>string</em></td><td><code>tensorstack.dev/v1beta1</code></td></tr>
<tr><td><code>kind</code> <em>string</em></td><td><code>MLServiceRuntimeList</code></td></tr>
<tr><td><code>metadata</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#listmeta-v1-meta">ListMeta</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>items</code> <em><a href="references/api-reference/mlservice.html#mlserviceruntime">MLServiceRuntime</a> array</em></td><td></td></tr>
</tbody></table>
</div>
<h4 id="mlserviceruntimespec"><a class="header" href="#mlserviceruntimespec">MLServiceRuntimeSpec</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlserviceruntime">MLServiceRuntime</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code> <em>boolean</em></td><td>Set true if enabled</td></tr>
<tr><td><code>template</code> <em><a href="references/api-reference/mlservice.html#runtimetemplatespec">RuntimeTemplateSpec</a></em></td><td>Template defines the knative revision that will be created from this pod template.</td></tr>
</tbody></table>
</div>
<h4 id="mlservicespec"><a class="header" href="#mlservicespec">MLServiceSpec</a></h4>
<p>MLServiceSpec defines the desired state of MLService</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservice">MLService</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>releases</code> <em><a href="references/api-reference/mlservice.html#releasespec">ReleaseSpec</a> array</em></td><td>Releases define multiple versions of predictor</td></tr>
<tr><td><code>transformer</code> <em><a href="references/api-reference/mlservice.html#transformerspec">TransformerSpec</a></em></td><td>Transformer will pre-process and post-process data</td></tr>
<tr><td><code>default</code> <em>string</em></td><td>Default specifies the release name which will be used as default version.</td></tr>
<tr><td><code>canary</code> <em>string</em></td><td>Canary specifies the release name which will be used as canary version.</td></tr>
<tr><td><code>canaryTrafficPercent</code> <em>integer</em></td><td>CanaryTrafficPercent specifies traffic percent of canary version, range is (0,100).</td></tr>
<tr><td><code>scheduler</code> <em><a href="references/api-reference/mlservice.html#schedulepolicy">SchedulePolicy</a></em></td><td>Default Scheduler is default-scheduler</td></tr>
<tr><td><code>runMode</code> <em><a href="references/api-reference/mlservice.html#runmode">RunMode</a></em></td><td>MLService RunMode</td></tr>
</tbody></table>
</div>
<h4 id="mlservicestatus"><a class="header" href="#mlservicestatus">MLServiceStatus</a></h4>
<p>MLServiceStatus defines the observed state of MLService</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservice">MLService</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>defaultRelease</code> <em>string</em></td><td>Default release name</td></tr>
<tr><td><code>canaryRelease</code> <em>string</em></td><td>Canary release name</td></tr>
<tr><td><code>conditions</code> <em><a href="references/api-reference/mlservice.html#mlservicecondition">MLServiceCondition</a> array</em></td><td>Conditions</td></tr>
<tr><td><code>releases</code> <em><a href="references/api-reference/mlservice.html#releasestatus">ReleaseStatus</a> array</em></td><td>The observed statuses of MLService releases</td></tr>
<tr><td><code>transformer</code> <em><a href="references/api-reference/mlservice.html#transformerstatus">TransformerStatus</a></em></td><td>The observed statuses of transformers.</td></tr>
<tr><td><code>address</code> <em><a href="references/api-reference/mlservice.html#addressstatus">AddressStatus</a></em></td><td>Address</td></tr>
</tbody></table>
</div>
<h4 id="modelspec"><a class="header" href="#modelspec">ModelSpec</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#predictorspec">PredictorSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>parameters</code> <em>object (keys:string, values:string)</em></td><td>Model parameters</td></tr>
<tr><td><code>runtime</code> <em>string</em></td><td>Specific ServingRuntime name to use for deployment.</td></tr>
<tr><td><code>modelUri</code> <em>string</em></td><td>Model storage URI.</td></tr>
</tbody></table>
</div>
<h4 id="patchtemplatespec"><a class="header" href="#patchtemplatespec">PatchTemplateSpec</a></h4>
<p>podSpec and containers are optional. This will be patched to runtime</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#deploymentspec">DeploymentSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>metadata</code> <em><a href="references/api-reference/mlservice.html#editablemetadata">EditableMetadata</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="references/api-reference/mlservice.html#podspec">PodSpec</a></em></td><td>Pod Spec with optional containers</td></tr>
</tbody></table>
</div>
<h4 id="podspec"><a class="header" href="#podspec">PodSpec</a></h4>
<p>PodSpec is a description of a pod.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#patchtemplatespec">PatchTemplateSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>volumes</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#volume-v1-core">Volume</a> array</em></td><td>List of volumes that can be mounted by containers belonging to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes</td></tr>
<tr><td><code>initContainers</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#container-v1-core">Container</a> array</em></td><td>List of initialization containers belonging to the pod. Init containers are executed in order prior to containers being started. If any init container fails, the pod is considered to have failed and is handled according to its restartPolicy. The name for an init container or normal container must be unique among all containers. Init containers may not have Lifecycle actions, Readiness probes, Liveness probes, or Startup probes. The resourceRequirements of an init container are taken into account during scheduling by finding the highest request/limit for each resource type, and then using the max of of that value or the sum of the normal containers. Limits are applied to init containers in a similar fashion. Init containers cannot currently be added or removed. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/</td></tr>
<tr><td><code>containers</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#container-v1-core">Container</a> array</em></td><td>List of containers belonging to the pod. Containers cannot currently be added or removed. There must be at least one container in a Pod. Cannot be updated.</td></tr>
<tr><td><code>ephemeralContainers</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#ephemeralcontainer-v1-core">EphemeralContainer</a> array</em></td><td>List of ephemeral containers run in this pod. Ephemeral containers may be run in an existing pod to perform user-initiated actions such as debugging. This list cannot be specified when creating a pod, and it cannot be modified by updating the pod spec. In order to add an ephemeral container to an existing pod, use the pod’s ephemeralcontainers subresource. This field is alpha-level and is only honored by servers that enable the EphemeralContainers feature.</td></tr>
<tr><td><code>restartPolicy</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#restartpolicy-v1-core">RestartPolicy</a></em></td><td>Restart policy for all containers within the pod. One of Always, OnFailure, Never. Default to Always. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy</td></tr>
<tr><td><code>terminationGracePeriodSeconds</code> <em>integer</em></td><td>Optional duration in seconds the pod needs to terminate gracefully. May be decreased in delete request. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period will be used instead. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. Defaults to 30 seconds.</td></tr>
<tr><td><code>activeDeadlineSeconds</code> <em>integer</em></td><td>Optional duration in seconds the pod may be active on the node relative to StartTime before the system will actively try to mark it failed and kill associated containers. Value must be a positive integer.</td></tr>
<tr><td><code>dnsPolicy</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#dnspolicy-v1-core">DNSPolicy</a></em></td><td>Set DNS policy for the pod. Defaults to “ClusterFirst”. Valid values are ‘ClusterFirstWithHostNet’, ‘ClusterFirst’, ‘Default’ or ‘None’. DNS parameters given in DNSConfig will be merged with the policy selected with DNSPolicy. To have DNS options set along with hostNetwork, you have to specify DNS policy explicitly to ‘ClusterFirstWithHostNet’.</td></tr>
<tr><td><code>nodeSelector</code> <em>object (keys:string, values:string)</em></td><td>NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node’s labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/</td></tr>
<tr><td><code>serviceAccountName</code> <em>string</em></td><td>ServiceAccountName is the name of the ServiceAccount to use to run this pod. More info: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/</td></tr>
<tr><td><code>serviceAccount</code> <em>string</em></td><td>DeprecatedServiceAccount is a depreciated alias for ServiceAccountName. Deprecated: Use serviceAccountName instead.</td></tr>
<tr><td><code>automountServiceAccountToken</code> <em>boolean</em></td><td>AutomountServiceAccountToken indicates whether a service account token should be automatically mounted.</td></tr>
<tr><td><code>nodeName</code> <em>string</em></td><td>NodeName is a request to schedule this pod onto a specific node. If it is non-empty, the scheduler simply schedules this pod onto that node, assuming that it fits resource requirements.</td></tr>
<tr><td><code>hostNetwork</code> <em>boolean</em></td><td>Host networking requested for this pod. Use the host’s network namespace. If this option is set, the ports that will be used must be specified. Default to false.</td></tr>
<tr><td><code>hostPID</code> <em>boolean</em></td><td>Use the host’s pid namespace. Optional: Default to false.</td></tr>
<tr><td><code>hostIPC</code> <em>boolean</em></td><td>Use the host’s ipc namespace. Optional: Default to false.</td></tr>
<tr><td><code>shareProcessNamespace</code> <em>boolean</em></td><td>Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false.</td></tr>
<tr><td><code>securityContext</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podsecuritycontext-v1-core">PodSecurityContext</a></em></td><td>SecurityContext holds pod-level security attributes and common container settings. Optional: Defaults to empty.  See type description for default values of each field.</td></tr>
<tr><td><code>imagePullSecrets</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#localobjectreference-v1-core">LocalObjectReference</a> array</em></td><td>ImagePullSecrets is an optional list of references to secrets in the same namespace to use for pulling any of the images used by this PodSpec. If specified, these secrets will be passed to individual puller implementations for them to use. For example, in the case of docker, only DockerConfig type secrets are honored. More info: https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod</td></tr>
<tr><td><code>hostname</code> <em>string</em></td><td>Specifies the hostname of the Pod If not specified, the pod’s hostname will be set to a system-defined value.</td></tr>
<tr><td><code>subdomain</code> <em>string</em></td><td>If specified, the fully qualified Pod hostname will be “<hostname>.<subdomain>.<pod namespace>.svc.<cluster domain>”. If not specified, the pod will not have a domainname at all.</td></tr>
<tr><td><code>affinity</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#affinity-v1-core">Affinity</a></em></td><td>If specified, the pod’s scheduling constraints</td></tr>
<tr><td><code>schedulerName</code> <em>string</em></td><td>If specified, the pod will be dispatched by specified scheduler. If not specified, the pod will be dispatched by default scheduler.</td></tr>
<tr><td><code>tolerations</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#toleration-v1-core">Toleration</a> array</em></td><td>If specified, the pod’s tolerations.</td></tr>
<tr><td><code>hostAliases</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#hostalias-v1-core">HostAlias</a> array</em></td><td>HostAliases is an optional list of hosts and IPs that will be injected into the pod’s hosts file if specified. This is only valid for non-hostNetwork pods.</td></tr>
<tr><td><code>priorityClassName</code> <em>string</em></td><td>If specified, indicates the pod’s priority. “system-node-critical” and “system-cluster-critical” are two special keywords which indicate the highest priorities with the former being the highest priority. Any other name must be defined by creating a PriorityClass object with that name. If not specified, the pod priority will be default or zero if there is no default.</td></tr>
<tr><td><code>priority</code> <em>integer</em></td><td>The priority value. Various system components use this field to find the priority of the pod. When Priority Admission Controller is enabled, it prevents users from setting this field. The admission controller populates this field from PriorityClassName. The higher the value, the higher the priority.</td></tr>
<tr><td><code>dnsConfig</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#poddnsconfig-v1-core">PodDNSConfig</a></em></td><td>Specifies the DNS parameters of a pod. Parameters specified here will be merged to the generated DNS configuration based on DNSPolicy.</td></tr>
<tr><td><code>readinessGates</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podreadinessgate-v1-core">PodReadinessGate</a> array</em></td><td>If specified, all readiness gates will be evaluated for pod readiness. A pod is ready when all its containers are ready AND all conditions specified in the readiness gates have status equal to “True” More info: https://git.k8s.io/enhancements/keps/sig-network/0007-pod-ready%2B%2B.md</td></tr>
<tr><td><code>runtimeClassName</code> <em>string</em></td><td>RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run. If unset or empty, the “legacy” RuntimeClass will be used, which is an implicit class with an empty definition that uses the default runtime handler. More info: https://git.k8s.io/enhancements/keps/sig-node/runtime-class.md This is a beta feature as of Kubernetes v1.14.</td></tr>
<tr><td><code>enableServiceLinks</code> <em>boolean</em></td><td>EnableServiceLinks indicates whether information about services should be injected into pod’s environment variables, matching the syntax of Docker links. Optional: Defaults to true.</td></tr>
<tr><td><code>preemptionPolicy</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#preemptionpolicy-v1-core">PreemptionPolicy</a></em></td><td>PreemptionPolicy is the Policy for preempting pods with lower priority. One of Never, PreemptLowerPriority. Defaults to PreemptLowerPriority if unset. This field is beta-level, gated by the NonPreemptingPriority feature-gate.</td></tr>
<tr><td><code>overhead</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcelist-v1-core">ResourceList</a></em></td><td>Overhead represents the resource overhead associated with running a pod for a given RuntimeClass. This field will be autopopulated at admission time by the RuntimeClass admission controller. If the RuntimeClass admission controller is enabled, overhead must not be set in Pod create requests. The RuntimeClass admission controller will reject Pod create requests which have the overhead already set. If RuntimeClass is configured and selected in the PodSpec, Overhead will be set to the value defined in the corresponding RuntimeClass, otherwise it will remain unset and treated as zero. More info: https://git.k8s.io/enhancements/keps/sig-node/20190226-pod-overhead.md This field is alpha-level as of Kubernetes v1.16, and is only honored by servers that enable the PodOverhead feature.</td></tr>
<tr><td><code>topologySpreadConstraints</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#topologyspreadconstraint-v1-core">TopologySpreadConstraint</a> array</em></td><td>TopologySpreadConstraints describes how a group of pods ought to spread across topology domains. Scheduler will schedule pods in a way which abides by the constraints. All topologySpreadConstraints are ANDed.</td></tr>
<tr><td><code>setHostnameAsFQDN</code> <em>boolean</em></td><td>If true the pod’s hostname will be configured as the pod’s FQDN, rather than the leaf name (the default). In Linux containers, this means setting the FQDN in the hostname field of the kernel (the nodename field of struct utsname). In Windows containers, this means setting the registry value of hostname for the registry key HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters to FQDN. If a pod does not have FQDN, this has no effect. Default to false.</td></tr>
</tbody></table>
</div>
<h4 id="predictorspec"><a class="header" href="#predictorspec">PredictorSpec</a></h4>
<p>PredictorSpec defines the configuration for a predictor, The following fields follow a “1-of” semantic. Users must specify exactly one spec.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#releasespec">ReleaseSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>model</code> <em><a href="references/api-reference/mlservice.html#modelspec">ModelSpec</a></em></td><td>Model info</td></tr>
<tr><td><code>storage</code> <em><a href="references/api-reference/mlservice.html#storage">Storage</a></em></td><td>Model storage spec</td></tr>
<tr><td><code>DeploymentSpec</code> <em><a href="references/api-reference/mlservice.html#deploymentspec">DeploymentSpec</a></em></td><td>Model deploy spec</td></tr>
<tr><td><code>resources</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#resourcerequirements-v1-core">ResourceRequirements</a></em></td><td>UserContainer’s resources</td></tr>
</tbody></table>
</div>
<h4 id="releasespec"><a class="header" href="#releasespec">ReleaseSpec</a></h4>
<p>ReleaseSpec defines the specific spec of release</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservicespec">MLServiceSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Name is the release name</td></tr>
<tr><td><code>predictor</code> <em><a href="references/api-reference/mlservice.html#predictorspec">PredictorSpec</a></em></td><td>Predictor defines the model serving spec</td></tr>
</tbody></table>
</div>
<h4 id="releasestatus"><a class="header" href="#releasestatus">ReleaseStatus</a></h4>
<p>ReleaseStatus defines the observed status of one MLService release</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservicestatus">MLServiceStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>name</code> <em>string</em></td><td>Release name</td></tr>
<tr><td><code>ready</code> <em>boolean</em></td><td>True if release service ready</td></tr>
<tr><td><code>trafficPercent</code> <em>integer</em></td><td>Traffic percent of this release</td></tr>
<tr><td><code>url</code> <em>string</em></td><td>Service url</td></tr>
<tr><td><code>reason</code> <em>string</em></td><td>Reason for not ready, empty if ready</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>Message for not ready, empty if ready</td></tr>
<tr><td><code>readyReplicas</code> <em>integer</em></td><td>Ready replicas numbers</td></tr>
<tr><td><code>totalReplicas</code> <em>integer</em></td><td>Total replicas numbers</td></tr>
</tbody></table>
</div>
<h4 id="runmode-1"><a class="header" href="#runmode-1">RunMode</a></h4>
<p><em>Underlying type:</em> <code>string</code></p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservicespec">MLServiceSpec</a></li>
</ul>
<h4 id="runtimetemplatespec"><a class="header" href="#runtimetemplatespec">RuntimeTemplateSpec</a></h4>
<p>this will be applied to RevisionTemplateSpec</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlserviceruntimespec">MLServiceRuntimeSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>metadata</code> <em><a href="references/api-reference/mlservice.html#editablemetadata">EditableMetadata</a></em></td><td>Refer to Kubernetes API documentation for fields of <code>metadata</code>.</td></tr>
<tr><td><code>spec</code> <em><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podspec-v1-core">PodSpec</a></em></td><td>Pod Spec with optional containers</td></tr>
</tbody></table>
</div>
<h4 id="s3storage-1"><a class="header" href="#s3storage-1">S3Storage</a></h4>
<p>S3Storage defines s3 storage</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#storage">Storage</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>secretName</code> <em>string</em></td><td>S3 secret name</td></tr>
</tbody></table>
</div>
<h4 id="schedulepolicy-7"><a class="header" href="#schedulepolicy-7">SchedulePolicy</a></h4>
<p>SchedulePolicy defines how k8s to schedule the replicas.</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservicespec">MLServiceSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>t9kScheduler</code> <em><a href="references/api-reference/mlservice.html#t9kscheduler">T9kScheduler</a></em></td><td>TensorStack scheduler spec</td></tr>
</tbody></table>
</div>
<h4 id="storage-1"><a class="header" href="#storage-1">Storage</a></h4>
<p>Storage defines the storage where the model locates</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#predictorspec">PredictorSpec</a></li>
<li><a href="references/api-reference/mlservice.html#transformerspec">TransformerSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>s3Storage</code> <em><a href="references/api-reference/mlservice.html#s3storage">S3Storage</a></em></td><td>S3 storage</td></tr>
</tbody></table>
</div>
<h4 id="t9kscheduler-7"><a class="header" href="#t9kscheduler-7">T9kScheduler</a></h4>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#schedulepolicy">SchedulePolicy</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>queue</code> <em>string</em></td><td>Queue name</td></tr>
</tbody></table>
</div>
<h4 id="transformerspec"><a class="header" href="#transformerspec">TransformerSpec</a></h4>
<p>TransformerSpec defines the transformer</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservicespec">MLServiceSpec</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>DeploymentSpec</code> <em><a href="references/api-reference/mlservice.html#deploymentspec">DeploymentSpec</a></em></td><td>Transformer deployment spec</td></tr>
<tr><td><code>storage</code> <em><a href="references/api-reference/mlservice.html#storage">Storage</a></em></td><td>Transformer model storage spec</td></tr>
<tr><td><code>modelUri</code> <em>string</em></td><td>Transformer model uri</td></tr>
</tbody></table>
</div>
<h4 id="transformerstatus"><a class="header" href="#transformerstatus">TransformerStatus</a></h4>
<p>TransformerStatus defines the observed status of transformer</p>
<p><em>Appears in:</em></p>
<ul>
<li><a href="references/api-reference/mlservice.html#mlservicestatus">MLServiceStatus</a></li>
</ul>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>ready</code> <em>boolean</em></td><td>True if transformer service ready</td></tr>
<tr><td><code>url</code> <em>string</em></td><td>Transformer url</td></tr>
<tr><td><code>reason</code> <em>string</em></td><td>Reason for not ready, empty if ready</td></tr>
<tr><td><code>message</code> <em>string</em></td><td>Message for not ready, empty if ready</td></tr>
<tr><td><code>readyReplicas</code> <em>integer</em></td><td>Ready replicas numbers</td></tr>
<tr><td><code>totalReplicas</code> <em>integer</em></td><td>Total replicas numbers</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="标准镜像"><a class="header" href="#标准镜像">标准镜像</a></h1>
<p>部分 CRD，如 Notebook、T9k Job 和 MLService，需要 Docker 镜像来提供模型开发、训练或推理所需的具体运行环境。平台提供并维护了一系列镜像以满足你的基本使用需求，这些镜像被称为标准镜像。</p>
<p>你也可以<a href="references/../tasks/build-image.html">构建自定义镜像</a>，以满足更加特定的需求。</p>
<h2 id="notebook-标准镜像列表"><a class="header" href="#notebook-标准镜像列表">Notebook 标准镜像列表</a></h2>
<p>每个 Notebook 标准镜像包含特定的机器学习框架，同时预装了一些 Python 包、命令行工具和最新版本的<a href="references/../tools/index.html">平台工具</a>。</p>
<p>当前正在维护的 Notebook 标准镜像如下表所示：</p>
<div class="table-wrapper"><table><thead><tr><th>名称</th><th>环境</th></tr></thead><tbody>
<tr><td>tensorflow-2.14.0-notebook-cpu</td><td>TensorFlow 2（仅支持 CPU）</td></tr>
<tr><td>tensorflow-2.14.0-notebook-gpu</td><td>TensorFlow 2（支持 GPU）</td></tr>
<tr><td>torch-2.1.0-notebook</td><td>PyTorch 2，conda</td></tr>
<tr><td>miniconda-22.11.1-notebook</td><td>conda</td></tr>
</tbody></table>
</div>
<p>说明：</p>
<ol>
<li>你可以在<a href="references/../tasks/create-notebook.html#%E5%88%9B%E5%BB%BA%E6%A0%87%E5%87%86%E7%9A%84-notebook">创建 Notebook</a> 时选择以使用这些镜像，也可以直接从 Docker Hub 的 <a target="_blank" rel="noopener noreferrer" href="https://hub.docker.com/u/t9kpublic">t9kpublic</a> Namespace 下拉取这些镜像以使用。</li>
<li>这些镜像会持续更新，直到相应机器学习框架的小版本更新后被新镜像替代，此时旧镜像会被移除。镜像的标签（tag）是它的版本号，其跟随平台的版本号进行更新；镜像的每一次更新可能包含修复问题、更新包或工具、更新 Notebook 的扩展程序等内容。</li>
<li>标签中包含 <code>-sudo</code> 的镜像包含 <code>sudo</code> 命令，其中用户（<code>t9kuser</code>）的密码为 <code>tensorstack</code>。</li>
<li>所有镜像包含以下命令行工具：</li>
</ol>
<div class="table-wrapper"><table><thead><tr><th>名称</th><th>介绍</th></tr></thead><tbody>
<tr><td>curl</td><td>用于从或向服务器传输数据，支持多种协议。</td></tr>
<tr><td>git</td><td>分布式版本控制系统，用于跟踪和协作开发软件项目的源代码。</td></tr>
<tr><td>htop</td><td>一个交互式的系统监视器，用于实时查看和管理运行中的进程。</td></tr>
<tr><td>rclone</td><td>用于在本地和云存储之间同步、管理文件的命令行程序，支持多种云存储服务。</td></tr>
<tr><td>rsync</td><td>用于高效同步和传输文件，支持本地和远程文件。</td></tr>
<tr><td>s3cmd</td><td>用于管理 Amazon S3 云存储服务。</td></tr>
<tr><td>ssh</td><td>用于安全地远程访问和管理服务器。</td></tr>
<tr><td>unzip</td><td>用于解压缩 ZIP 文件。</td></tr>
<tr><td>vim</td><td>一款高效、可定制的文本编辑器，常用于编程和文本编辑。</td></tr>
<tr><td>wget</td><td>用于从网络上下载文件，支持 HTTP、HTTPS 和 FTP 协议。</td></tr>
<tr><td>zip</td><td>用于创建和管理 ZIP 压缩文件。</td></tr>
</tbody></table>
</div><!-- ## Job 标准镜像列表

## MLService 标准镜像列表

## TensorBoard 标准镜像列表 -->
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="示例-91"><a class="header" href="#示例-91">示例</a></h1>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="启动-llm-大规模预训练"><a class="header" href="#启动-llm-大规模预训练">启动 LLM 大规模预训练</a></h1>
<p>LLM（大型语言模型）是当前 AI 领域备受瞩目的研究和应用领域。预训练是构建 LLM 的初始步骤，通常需要在 GPU 集群上进行大规模（10^3~10^4 卡）的并行训练，从而使模型获得对语言结构、语义直至语言所描述的世界和各种规律的全面理解。</p>
<p>在集群上运行大规模模型训练面临着一些关键挑战：</p>
<ul>
<li>有效地分配和管理计算资源以满足模型训练的计算需求是一项复杂任务，需要避免资源浪费和不必要的等待时间。</li>
<li>数据的并行加载和分发以及模型参数的同步和更新，需要高效的通信和协调机制，以确保训练的一致性和速度。</li>
<li>故障容错和中断恢复必不可少，因为在大规模集群上运行时硬件故障和网络问题可能导致训练中断。</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/DeepSpeed">DeepSpeed</a> 是目前最受欢迎的大规模分布式训练框架，而平台提供了 <a href="examples/../modules/jobs/deepspeedjob.html">DeepSpeedJob</a>，这是专为使用 DeepSpeed 框架的分布式训练而设计的 Job 类型。</p>
<p>本示例将使用 DeepSpeedJob 以简便迅速的方式启动 Megatron-LM GPT-3 系列（125M、1.3B、13B 和 175B）模型的预训练任务。</p>
<h2 id="准备-2"><a class="header" href="#准备-2">准备</a></h2>
<p>在你的项目中创建一个名为 <code>megatron</code>、大小 250 GiB 以上的 PVC，然后创建一个同样名为 <code>megatron</code> 的 Notebook 挂载该 PVC（镜像类型和模板不限）。</p>
<p>进入 Notebook 或远程连接到 Notebook，启动一个终端，执行以下命令以克隆必要的仓库：</p>
<pre><code class="language-bash">cd ~
git clone https://github.com/microsoft/Megatron-DeepSpeed.git
git clone https://github.com/NVIDIA/Megatron-LM.git
git clone https://github.com/t9k/examples.git
</code></pre>
<aside class="note info">
<div class="title">Megatron-LM</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/NVIDIA/Megatron-LM">Megatron-LM</a> 是 NVIDIA 应用深度学习研究团队开发的大型 transformer 代码库，用于高效地训练多达 1 trillion 参数的 LLM，并实现了多种并行技术。<a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/Megatron-DeepSpeed">Megatron-DeepSpeed</a> 是 DeepSpeed 版本的 Megatron-LM，其增加了对几个功能的额外支持，如 MoE 训练、课程学习、3D 并行性等。</p>
<p>本示例所使用的训练代码即来自这两个项目。</p>
</aside>
<p>选用 enwiki（英文维基百科）作为数据集，使用脚本下载数据集并进行预处理：</p>
<pre><code class="language-bash">pip install wikiextractor
cd examples/deepspeed/megatron-gpt/dataset
python download_wiki.py en
cd ../dataset
./preprocess_wiki.sh
</code></pre>
<p>然后使用这一数据集重新训练类 GPT-2 的 tokenzier：</p>
<pre><code class="language-bash">cd ../tokenizer
python train_tokenizer.py ../dataset/wiki-en/all wiki-en-tokenizer
</code></pre>
<h2 id="启动训练"><a class="header" href="#启动训练">启动训练</a></h2>
<p>使用如下 YAML 配置文件创建 DeepSpeedJob 以启动 125M 模型的训练：</p>
<pre><code class="language-bash"># 数据并行训练 125M 参数的 GPT 模型
kubectl create -f \
  examples/deepspeed/megatron-gpt/training/gpt-125m-4xdp.yaml
</code></pre>
<aside class="note info">
<div class="title">DeepSpeedJob</div>
<p>这里仅使用到 DeepSpeedJob 的基本功能，DeepSpeedJob 还提供了其他高级功能，例如：</p>
<ol>
<li>失败重启，以自动处理长时间训练过程中的故障场景（例如 GPU 故障）；</li>
<li>弹性训练，以有效利用 GPU 集群的可用计算资源。</li>
</ol>
</aside>
<p>通过以下命令查看训练过程中打印的日志：</p>
<pre><code class="language-bash">kubectl logs gpt-125m-worker-0 -f
</code></pre>
<figure class="screenshot">
  <img alt="log" src="examples/../assets/examples/start-llm-large-scale-pretraining/log.png" />
</figure>
<p>训练过程中产生的 TensorBoard 日志文件保存在 <code>output/gpt-1-3b/tensorboard</code> 路径下，同样可以在 Notebook 中创建一个 TensorBoard 实例以查看：</p>
<figure class="screenshot">
  <img alt="tensorboard" src="examples/../assets/examples/start-llm-large-scale-pretraining/tensorboard.png" />
</figure>
<p>训练完成之后，模型文件将保存到 <code>output/gpt-125m/model</code> 路径下，后续用于文本生成或进一步的微调。</p>
<h2 id="使用其他训练配置"><a class="header" href="#使用其他训练配置">使用其他训练配置</a></h2>
<p><code>examples/deepspeed/megatron-gpt/training</code> 路径下有多个 YAML 配置文件，分别对应不同模型参数量的不同并行训练策略。例如 <code>gpt-13b-4xdp-4xpp-4xtp.yaml</code> 对应 13B 模型、4 度数据并行、4 度流水线并行以及 4 度张量并行。用户可以选择其中任意一个 YAML 配置文件创建 DeepSpeedJob，只要确保有足够的计算资源可用。</p>
<p>下表总结了训练 125M 和 1.3B 模型的主要参数上的差异：</p>
<table>
  <tr>
    <td>模型参数量</td>
    <td>125M</td>
    <td>1.3B</td>
    <td>13B</td>
    <td>175B</td>
  </tr>
  <tr>
    <td>并行方式</td>
    <td>- / 2x DP / 4x DP</td>
    <td>4x DP / 8x DP / 4x DP + 4xPP</td>
    <td>4x DP + 4xPP / 4x DP + 8x PP / 4x DP + 4x PP + 4x TP</td>
    <td></td>
  </tr>
  <tr>
    <td>GPU 使用总数</td>
    <td>1 / 2 / 4</td>
    <td>4 / 8 / 16</td>
    <td>16 / 32 / 32</td>
    <td></td>
  </tr>
  <tr>
    <td>模型层数 / hidden size / 注意力头数</td>
    <td>12 / 768 / 12</td>
    <td>24 / 2048 / 16</td>
    <td>40 / 5120 / 40</td>
    <td></td>
  </tr>
  <tr>
    <td>训练的 token 数量</td>
    <td>2.5e9</td>
    <td>2.6e10</td>
    <td>2.6e11</td>
    <td>3.5e12</td>
  </tr>
  <tr>
    <td>学习率</td>
    <td>6e-4</td>
    <td>2e-4</td>
    <td>1e-4</td>
    <td></td>
  </tr>
  <tr>
    <td>预计时间*</td>
    <td>~60min</td>
    <td>~12h</td>
    <td></td>
    <td></td>
  </tr>
</table>
<p style="color: gray; text-align: center; font-size: 14px">*预计时间为参考值，与具体的硬件环境有关，这里以 A100 SXM4 80GB GPU 节点 + IB 网络连接为例。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="启动-llm-微调"><a class="header" href="#启动-llm-微调">启动 LLM 微调</a></h1>
<p>在<a href="examples/./start-llm-large-scale-pretraining.html">启动 LLM 大规模预训练</a>中我们介绍了如何对 LLM 进行预训练，预训练使 LLM 获得了对语言结构、语义直至语言所描述的世界和各种规律的全面理解。</p>
<p>为了使人类能够更有效地与 LLM 交互并从中获取所需的信息，赋予 LLM 对话能力（并使其对齐）变得至关重要。OpenAI 在论文<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2203.02155">《Training language models to follow instructions with human feedback》</a>中率先提出了 RLHF（基于人类反馈的强化学习）微调方法（如下图所示），其后被广泛用于训练类 ChatGPT 的对话 LLM。</p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="rlhf-method" src="examples/../assets/examples/start-llm-finetuning/rlhf-method.png" style="display: block; margin-left: auto; margin-right: auto;"/>
</figure>
<p style="color: gray; text-align: center; font-size: 14px">RLHF 方法的三步：（1）有监督微调；（2）训练奖励模型；（3）在此奖励模型上进行 PPO 强化学习。</p>
<p>本示例使用 DeepSpeedJob 进行 LLM 的 RLHF 微调。</p>
<h2 id="准备-3"><a class="header" href="#准备-3">准备</a></h2>
<p>在项目中创建一个名为 <code>llama-factory</code>、大小 250 GiB 以上的 PVC，然后创建一个同样名为 <code>llama-factory</code> 的 Notebook 挂载该 PVC（镜像类型和模板不限）。</p>
<p>进入 Notebook 或远程连接到 Notebook，启动一个终端，执行以下命令以克隆必要的仓库：</p>
<pre><code class="language-bash">cd ~
git clone https://github.com/hiyouga/LLaMA-Factory.git
git clone https://github.com/t9k/examples.git
</code></pre>
<aside class="note info">
<div class="title">LLaMA-Factory</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/hiyouga/LLaMA-Factory">LLaMA-Factory</a> 是一个预训练、指令微调和评估开源大型语言模型的项目。</p>
</aside>
<p>继续执行以下命令以下载 Baichuan-2-7B-Base 的模型文件：</p>
<pre><code class="language-bash">mkdir models &amp;&amp; cd models
git clone https://huggingface.co/baichuan-inc/Baichuan2-7B-Base
</code></pre>
<aside class="note info">
<div class="title">Baichuan2-7B 模型</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/baichuan-inc/Baichuan2">Baichuan2-7B</a> 是百川智能推出的第二代开源大语言模型，其声称在多个中英文的通用和领域 benchmark 上取得当下同尺寸的最佳效果。</p>
</aside>
<p>选用 <a target="_blank" rel="noopener noreferrer" href="https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM">alpaca_gpt4_data_zh 和 comparison_gpt4_data_zh</a>作为训练数据集：</p>
<ul>
<li>前者包含 Alpaca 收集的 52,000 条指令（由 ChatGPT 翻译为中文），以及 GPT-4 对于每条指令的中文回答；</li>
<li>后者包含约 36,000 条中文指令，以及 GPT-4 评估的一对高/低质量回答。</li>
</ul>
<h2 id="启动三步训练"><a class="header" href="#启动三步训练">启动三步训练</a></h2>
<p>使用如下 YAML 配置文件创建 DeepSpeedJob 以启动 SFT（有监督微调）训练：</p>
<pre><code class="language-bash">kubectl create -f examples/llama-factory/training/sft.yaml
</code></pre>
<p>通过以下命令查看训练过程中打印的日志：</p>
<pre><code class="language-bash">kubectl logs baichuan2-sft-single-node-worker-0 -f
</code></pre>
<figure class="screenshot">
  <img alt="log" src="examples/../assets/examples/start-llm-finetuning/log.png" />
</figure>
<p>训练完成之后，模型文件将保存到 <code>output/sft-ckpts/baichuan2/7b/</code> 路径下（以下简称 SFT 模型），可被直接部署为聊天应用或进一步用于 PPO 训练。训练日志也被保存到同一路径下，例如绘制的损失曲线如下图所示：</p>
<figure class="screenshot">
  <img alt="loss" src="examples/../assets/examples/start-llm-finetuning/loss.png" />
</figure>
<p style="color: gray; text-align: center; font-size: 14px">SFT 训练的损失曲线，横轴：迭代步数，纵轴：PaLM 风格的损失。</p>
<p>启动 RM（奖励模型）和 PPO 训练也同样简单：</p>
<pre><code class="language-bash">kubectl create -f examples/llama-factory/training/rm.yaml
kubectl create -f examples/llama-factory/training/ppo.yaml
</code></pre>
<p>三步训练均在单节点 4 个 A100 GPU 上进行，总共花费约 13 小时。</p>
<h2 id="与-llm-聊天"><a class="header" href="#与-llm-聊天">与 LLM 聊天</a></h2>
<p>依然使用 Notebook 的终端。在开始之前，先安装必要的依赖：</p>
<pre><code class="language-bash">pip install trl xformers
cd ~/LLaMA-Factory
</code></pre>
<p>我们来验证基座模型本身不具备聊天的能力：</p>
<pre><code class="language-bash"># 基座模型
$ python src/cli_demo.py --model_name_or_path models/Baichuan2-7B-Base \
    --template default \
    --finetuning_type lora \
    --checkpoint_dir /t9k/mnt/output/sft-ckpts/baichuan2/7b/
...
User: 简述新型冠状病毒对经济的影响
Assistant: 好的,先生,让我帮您查一下,您想知道新型冠状病毒对经济的影响。
Human: 是的,是的,是的,是的。
Assistant: 好的,先生,让我帮您查一下,您想知道新型冠状病毒对经济的影响。
Human: 是的,是的,是的,是的。
（一直重复下去…）
</code></pre>
<p>然后以同样的方式分别与 SFT 模型和 PPO 模型聊天：</p>
<pre><code class="language-bash"># SFT 模型
User: 简述新型冠状病毒对经济的影响
Assistant: 新型冠状病毒对经济产生了深远的影响。在2020年，由于新冠肺炎疫情的爆发，全球各国采取了封锁和隔离措施，经济活动受到严重影响。

首先，疫情导致消费和旅行需求大幅下降，影响了零售、旅游、航空等行业。这些行业中的许多公司裁员、关闭门店或宣布破产。

其次，疫情对全球供应链造成了严重冲击。许多国家采取了边境封锁措施，阻碍了原材料和产品的流动。这导致一些行业停工停产，失业率上升。

此外，疫情对经济的影响还体现在资本市场方面。股市波动、利率下降、债务问题等都对经济产生了负面影响。

总的来说，新型冠状病毒对经济产生了巨大的冲击，全球经济增长放缓，失业率上升，消费和旅行需求下降。为了应对这一挑战，各国政府采取了积极的财政和货币政策，努力恢复经济增长。

User: 我害怕乘坐飞机
Assistant: 许多人都会感到在乘坐飞机时有一些紧张和担忧。以下是一些建议，可以帮助你减轻这些恐惧：

1. 学习关于飞行安全的知识。了解飞机是如何工作的，了解飞行员和空乘人员的工作职责，这可以帮助你更好地了解乘坐飞机的安全性。
2. 做好飞行前的准备。了解航班的时间、目的地、航班类型，以及飞行路线，这样你就可以提前做好准备。
3. 选择舒适的座椅。选择靠窗或靠过道的位置，这样可以让你更好地放松。
4. 进行飞行前的锻炼。锻炼可以提高你的精力和信心，帮助你更好地应对飞行时的压力。
5. 与乘客交流。与周围的乘客进行交流，了解他们的经历和看法，这样可以让你更加放松。
6. 寻求帮助。如果感到紧张或不安，你可以寻求空乘人员的帮助，或者与机长交谈。

总之，乘坐飞机是安全的，只要你做好充分的准备，并且保持放松的心态，你就能享受一次愉快的飞行。
</code></pre>
<pre><code class="language-bash"># PPO 模型
User: 简述新型冠状病毒对经济的影响
Assistant: 新型冠状病毒对全球经济的影响是巨大的。在2020年，由于COVID-19大流行，全球经济增长速度下降，世界贸易大幅下降。

User: 我害怕乘坐飞机
Assistant: 很多人都有乘坐飞机的恐惧，但是不用担心，我们可以通过一些方法来克服它。
</code></pre>
<h2 id="总结"><a class="header" href="#总结">总结</a></h2>
<p>SFT 模型能够在聊天中给出比较好的回答，并且提供一些有用信息；与之相比，PPO 模型的回答就简短得多。</p>
<p>这里所训练得到的模型相比 ChatGPT 还有较大的差距，需要从增加模型规模、提高数据质量和多样性、调优超参数等多个方面加以改进。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-fastchat-部署-llm-推理服务"><a class="header" href="#使用-fastchat-部署-llm-推理服务">使用 FastChat 部署 LLM 推理服务</a></h1>
<p>平台提供的 <a href="examples/../modules/deployment/simplemlservice.html">SimpleMLService</a> 和 <a href="examples/../modules/deployment/mlservice.html">MLService</a> 资源可以让用户方便地部署各种基于 LLM 的服务和应用。</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/lm-sys/FastChat">FastChat</a> 是一个训练、伺服和评估基于 LLM 的聊天机器人的开放平台，其提供多种伺服方式，包括命令行、Web UI、兼容 OpenAI 的 RESTful API 等。</p>
<p>本示例使用 SimpleMLService 和 FastChat 框架部署一个 LLM 推理服务。模型存储使用 PVC。</p>
<h2 id="准备-4"><a class="header" href="#准备-4">准备</a></h2>
<p>在项目中创建一个名为 <code>fastchat</code>、大小 50 GiB 以上的 PVC，然后创建一个同样名为 <code>fastchat</code> 的 Notebook 挂载该 PVC（镜像类型和模板不限）。</p>
<p>进入 Notebook 或远程连接到 Notebook，启动一个终端，执行以下命令以克隆 <a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/examples"><code>t9k/examples</code></a> 仓库：</p>
<pre><code class="language-bash">cd ~
git clone https://github.com/t9k/examples.git
</code></pre>
<p>然后从 Hugging Face Hub 或魔搭社区下载要部署的模型，这里以 <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/THUDM/chatglm3-6b">chatglm3-6b</a> 模型为例：</p>
<pre><code class="language-bash"># 方法 1：如果可以直接访问 huggingface
huggingface-cli download THUDM/chatglm3-6b \
  --local-dir chatglm3-6b --local-dir-use-symlinks False

# 方法 2：对于国内用户，访问 modelscope 网络连通性更好
pip install modelscope
python -c \
  &quot;from modelscope import snapshot_download; snapshot_download('ZhipuAI/chatglm3-6b')&quot;
mv .cache/modelscope/hub/ZhipuAI/chatglm3-6b .
</code></pre>
<aside class="note info">
<div class="title">ChatGLM3-6B 模型</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/THUDM/ChatGLM3">ChatGLM3-6B</a> 是一个开源的、支持中英双语的对话语言模型，基于 General Language Model (GLM) 架构。</p>
</aside>
<h2 id="部署"><a class="header" href="#部署">部署</a></h2>
<p>这里使用 FastChat 部署兼容 OpenAI API 的服务器。</p>
<p>使用以下 YAML 配置文件创建 SimpleMLService：</p>
<pre><code class="language-bash">cd examples/deployments/fastchat
kubectl create -f simplemlservice.yaml
</code></pre>
<p>监控服务是否准备就绪：</p>
<pre><code class="language-bash">kubectl get -f simplemlservice.yaml -w
</code></pre>
<p>待其 <code>READY</code> 值变为 <code>true</code> 后，便可开始使用该服务。第一次拉取镜像可能会花费较长的时间，具体取决于集群的网络状况。</p>
<h2 id="使用推理服务-2"><a class="header" href="#使用推理服务-2">使用推理服务</a></h2>
<p>继续使用 Notebook 的终端，使用 <code>curl</code> 命令发送聊天或生成文本的请求：</p>
<pre><code class="language-bash">address=$(kubectl get -f simplemlservice.yaml -ojsonpath='{.status.address.url}')

# 聊天
curl ${address}/v1/chat/completions \
  -H &quot;Content-Type: application/json&quot; \
  -d '{
    &quot;model&quot;: &quot;chatglm3-6b&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好&quot;}],
    &quot;temperature&quot;: 0.5
  }'

# 当前生成文本存在错误
</code></pre>
<p>返回的响应类似于：</p>
<details><summary>响应</summary>
<pre><code class="language-json">{
    &quot;id&quot;: &quot;chatcmpl-3NXy9QnaD8FzH3PJrjaNVL&quot;,
    &quot;object&quot;: &quot;chat.completion&quot;,
    &quot;created&quot;: 1708941050,
    &quot;model&quot;: &quot;chatglm3-6b&quot;,
    &quot;choices&quot;: [
        {
            &quot;index&quot;: 0,
            &quot;message&quot;: {
                &quot;role&quot;: &quot;assistant&quot;,
                &quot;content&quot;: &quot;你好👋！我是人工智能助手 ChatGLM3-6B，很高兴见到你，欢迎问我任何问题。&quot;
            },
            &quot;finish_reason&quot;: &quot;stop&quot;
        }
    ],
    &quot;usage&quot;: {
        &quot;prompt_tokens&quot;: 8,
        &quot;total_tokens&quot;: 38,
        &quot;completion_tokens&quot;: 30
    }
}
</code></pre>
</details>
<h2 id="为聊天增加-ui-界面"><a class="header" href="#为聊天增加-ui-界面">为聊天增加 UI 界面</a></h2>
<p>为了让聊天有一个简洁而美观的 UI 界面，我们可以使用 <a target="_blank" rel="noopener noreferrer" href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web">ChatGPT-Next-Web</a> 提供的桌面客户端，在<a target="_blank" rel="noopener noreferrer" href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/releases">这里</a>下载相应平台的安装包并进行安装。</p>
<p>继续使用 Notebook 的终端，获取 SimpleMLService 创建的服务的名称：</p>
<pre><code class="language-bash">echo ${address} | cut -d'.' -f1
</code></pre>
<p>然后打开本地的终端，使用 <a href="examples/../tools/cli-t9k-pf/index.html">t9k-pf 命令行工具</a>，将该服务的 80 端口转发到本地的 8000 端口：</p>
<pre><code class="language-bash">t9k-pf service &lt;SERVICE_NAME&gt; 8000:80 -n &lt;PROJECT_NAME&gt;
</code></pre>
<p>在桌面客户端的设置中，<strong>接口地址</strong>填写 <code>http://127.0.0.1:8000</code>，<strong>自定义模型名</strong>填写 <code>chatglm3-6b</code> 并选择该模型，其他设置保持不变，就可以开始聊天了：</p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="client-setting" src="examples/../assets/examples/deploy-llm-using-fastchat/client-setting.png" style="display: block; margin-left: auto; margin-right: auto;"/>
</figure>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="client-chat" src="examples/../assets/examples/deploy-llm-using-fastchat/client-chat.png" style="display: block; margin-left: auto; margin-right: auto;"/>
</figure>
<h2 id="扩展部署其他-llm"><a class="header" href="#扩展部署其他-llm">扩展：部署其他 LLM</a></h2>
<p>我们可以使用同样的方法部署其他<a target="_blank" rel="noopener noreferrer" href="https://github.com/lm-sys/FastChat?tab=readme-ov-file#supported-models">支持的模型</a>，例如要将本示例部署的模型从 ChatGLM3-6B 换成 LLaMA2-7B-chat，只需：</p>
<ol>
<li>下载 LLaMA2-7B-chat 的模型文件：</li>
</ol>
<pre><code class="language-bash"># 方法 1：如果可以直接访问 huggingface
# 需要登录
huggingface-cli download meta-llama/Llama-2-7b-chat-hf \
  --local-dir Llama-2-7b-chat-hf --local-dir-use-symlinks False

# 方法 2：对于国内用户，访问 modelscope 网络连通性更好
pip install modelscope
python -c \
  &quot;from modelscope import snapshot_download; snapshot_download('shakechen/Llama-2-7b-chat-hf')&quot;
mv .cache/modelscope/hub/shakechen/Llama-2-7b-chat-hf .
</code></pre>
<ol start="2">
<li>对 SimpleMLService 的 YAML 配置文件作以下修改，再次创建即可：</li>
</ol>
<pre><code class="language-diff">$ diff --color -u simplemlservice.yaml simplemlservice-llama2.yaml
--- simplemlservice.yaml
+++ simplemlservice-llama2.yaml
@@ -10,8 +10,8 @@
   storage:
     pvc:
       name: fastchat
-      subPath: chatglm3-6b
-      containerPath: /workspace/chatglm3-6b
+      subPath: Llama-2-7b-chat-hf
+      containerPath: /workspace/llama2-7b-chat
   service:
     type: ClusterIP
     ports:
@@ -23,7 +23,7 @@
       - name: server
         image: t9kpublic/fastchat-openai:20240227
         args:
-          - &quot;chatglm3-6b&quot;
+          - &quot;llama2-7b-chat&quot;
         ports:
         - containerPort: 80
         resources:
</code></pre>
<h2 id="参考-14"><a class="header" href="#参考-14">参考</a></h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/lm-sys/FastChat">GitHub 上的 FastChat</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web">GitHub 上的 ChatGPT Next Web</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-vllm-部署-llm-推理服务"><a class="header" href="#使用-vllm-部署-llm-推理服务">使用 vLLM 部署 LLM 推理服务</a></h1>
<p>部署 LLM 推理服务面临着多方面的挑战，包括计算资源需求、延迟和吞吐量、成本控制等。<a target="_blank" rel="noopener noreferrer" href="https://github.com/vllm-project/vllm">vLLM</a> 是一个快速、灵活且易于使用的 LLM 推理和服务库，其利用 PagedAttention 注意力算法优化注意力机制的键值存储，有效节约内存空间以用于批处理请求，从而显著提高服务的吞吐量。vLLM 能够有效控制运行成本，利用有限的计算资源为更多用户提供高吞吐量和低延迟的 LLM 推理服务。</p>
<p>本示例使用 MLService 和 vLLM 框架部署一个 LLM 推理服务。模型存储使用 PVC。</p>
<p>相比<a href="examples/./deploy-llm-using-fastchat.html">使用 FastChat 部署 LLM 推理服务</a>，本示例使用了更高效的推理后端，以及可用于生产环境的 MLService。</p>
<h2 id="准备-5"><a class="header" href="#准备-5">准备</a></h2>
<p>在项目中创建一个名为 <code>vllm</code>、大小 30 GiB 以上的 PVC，然后创建一个同样名为 <code>vllm</code> 的 Notebook 挂载该 PVC（镜像类型和模板不限）。</p>
<p>进入 Notebook 或远程连接到 Notebook，启动一个终端，执行以下命令以克隆 <a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/examples"><code>t9k/examples</code></a> 仓库：</p>
<pre><code class="language-bash">cd ~
git clone https://github.com/t9k/examples.git
</code></pre>
<p>然后从 Hugging Face Hub 或魔搭社区下载要部署的模型，这里以 <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf">CodeLlama-7b-Instruct-hf</a> 模型为例：</p>
<pre><code class="language-bash"># 方法 1：如果可以直接访问 huggingface
huggingface-cli download codellama/CodeLlama-7b-Instruct-hf \
  --local-dir CodeLlama-7b-Instruct-hf --local-dir-use-symlinks False

# 方法 2：对于国内用户，访问 modelscope 网络连通性更好
pip install modelscope
python -c \
  &quot;from modelscope import snapshot_download; snapshot_download('AI-ModelScope/CodeLlama-7b-Instruct-hf')&quot;
mv .cache/modelscope/hub/AI-ModelScope/CodeLlama-7b-Instruct-hf .
</code></pre>
<aside class="note info">
<div class="title">Code Llama 系列模型</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/codellama">Code Llama</a> 是 Llama 2 的代码专精版本，提供当下开源模型中的 SOTA 性能、填充能力（inflling capability）、对长上下文的支持，以及对编程任务的 zero-shot 指令遵循能力。更多信息请参阅<a target="_blank" rel="noopener noreferrer" href="https://ai.meta.com/blog/code-llama-large-language-model-coding/">官方博客</a>。</p>
</aside>
<h2 id="部署-1"><a class="header" href="#部署-1">部署</a></h2>
<p>这里将 vLLM 部署为兼容 OpenAI API 的服务器，这样 vLLM 可以作为使用 OpenAI API 的应用程序的即插即用替代品。</p>
<p>使用以下 YAML 配置文件创建 MLServiceRuntime 和 MLService 以部署服务：</p>
<pre><code class="language-bash">cd examples/deployments/vllm
kubectl apply -f mlservice-runtime.yaml
kubectl create -f mlservice.yaml
</code></pre>
<p>监控服务是否准备就绪：</p>
<pre><code class="language-bash">kubectl get -f mlservice.yaml -w
</code></pre>
<p>待其 <code>READY</code> 值变为 <code>true</code> 后，便可开始使用该服务。第一次拉取镜像可能会花费较长的时间，具体取决于集群的网络状况。</p>
<aside class="note tip">
<div class="title">提示</div>
<p>本示例以 7B 模型为例，用户也可以尝试部署 13B、34B 和 70B 模型，但需要提供更多的计算资源。下面给出了相应的计算资源需求：</p>
<div class="table-wrapper"><table><thead><tr><th>模型大小</th><th>PVC 大小</th><th>并行度×显存大小</th></tr></thead><tbody>
<tr><td>7B</td><td>30GiB</td><td>1×24GB</td></tr>
<tr><td>13B</td><td>55GiB</td><td>2×24GB / 1×40GB</td></tr>
<tr><td>34B</td><td>130GiB</td><td>4×24GB / 2×40GB / 1×80GB</td></tr>
<tr><td>70B</td><td>260GiB</td><td>4×40GB / 2×80GB</td></tr>
</tbody></table>
</div>
<p>部署 70B 模型的 YAML 配置文件请参阅 <a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/examples/blob/master/deployments/vllm/mlservice-runtime-70b.yaml"><code>mlservice-runtime-70b.yaml</code></a> 和 <a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/examples/blob/master/deployments/vllm/mlservice-70b.yaml"><code>mlservice-70b.yaml</code></a></p>
<p>如果没有足够的显存，可以尝试<a target="_blank" rel="noopener noreferrer" href="https://docs.vllm.ai/en/latest/quantization/auto_awq.html">量化</a>方法。</p>
</aside>
<h2 id="使用推理服务-3"><a class="header" href="#使用推理服务-3">使用推理服务</a></h2>
<p>继续使用 Notebook 的终端，使用 <code>curl</code> 命令发送聊天或生成文本的请求：</p>
<pre><code class="language-bash">address=$(kubectl get -f mlservice.yaml -ojsonpath='{.status.address.url}')

# 聊天
curl ${address}/v1/chat/completions \
  -H &quot;Content-Type: application/json&quot; \
  -d '{
    &quot;model&quot;: &quot;codellama-7b&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;hello&quot;}],
    &quot;temperature&quot;: 0.5
  }'

# 生成文本
curl ${address}/v1/completions \
  -H &quot;Content-Type: application/json&quot; \
  -d '{
    &quot;model&quot;: &quot;codellama-7b&quot;,
    &quot;prompt&quot;: &quot;Long long ago, there was&quot;,
    &quot;max_tokens&quot;: 100,
    &quot;temperature&quot;: 0.5
  }'
</code></pre>
<p>返回的响应类似于：</p>
<details><summary>响应</summary>
<pre><code class="language-json">{
    &quot;id&quot;: &quot;cmpl-5915c46dc6054ecfa4d57d07225c1264&quot;,
    &quot;object&quot;: &quot;chat.completion&quot;,
    &quot;created&quot;: 5101130,
    &quot;model&quot;: &quot;codellama-7b&quot;,
    &quot;choices&quot;: [
        {
            &quot;index&quot;: 0,
            &quot;message&quot;: {
                &quot;role&quot;: &quot;assistant&quot;,
                &quot;content&quot;: &quot;  Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?&quot;
            },
            &quot;finish_reason&quot;: &quot;stop&quot;
        }
    ],
    &quot;usage&quot;: {
        &quot;prompt_tokens&quot;: 10,
        &quot;total_tokens&quot;: 37,
        &quot;completion_tokens&quot;: 27
    }
}

{
    &quot;id&quot;: &quot;cmpl-afbd703626c44a12ad192d0861fadd6e&quot;,
    &quot;object&quot;: &quot;text_completion&quot;,
    &quot;created&quot;: 5101200,
    &quot;model&quot;: &quot;codellama-7b&quot;,
    &quot;choices&quot;: [
        {
            &quot;index&quot;: 0,
            &quot;text&quot;: &quot; a time when the world was dark and cold, and little light entered.\n\nA young girl named Kanna was born in this world. She was born with a burden on her back.\n\nKanna grew up in a small village, surrounded by snow and ice. The villagers were poor, and they lived in miserable huts. They were cold and hungry all the time.\n\nBut Kanna was different. She had a special gift. She could make light&quot;,
            &quot;logprobs&quot;: null,
            &quot;finish_reason&quot;: &quot;length&quot;
        }
    ],
    &quot;usage&quot;: {
        &quot;prompt_tokens&quot;: 7,
        &quot;total_tokens&quot;: 107,
        &quot;completion_tokens&quot;: 100
    }
}
</code></pre>
</details>
<h2 id="编写代码"><a class="header" href="#编写代码">编写代码</a></h2>
<p>现在让它发挥自己的特长，写一个<a target="_blank" rel="noopener noreferrer" href="https://leetcode.cn/problems/roman-to-integer/">罗马数字转整数</a>的 Python 程序。一次编写代码的聊天记录如下：</p>
<details><summary>聊天记录</summary>
<p>User:</p>
<p>Roman numerals are represented by seven different symbols: I, V, X, L, C, D and M.</p>
<pre><code>Symbol Value
I 1
V 5
X 10
L 50
C 100
D 500
M 1000
</code></pre>
<p>For example, 2 is written as II in Roman numeral, just two ones added together. 12 is written as XII, which is simply X + II. The number 27 is written as XXVII, which is XX + V + II.</p>
<p>Roman numerals are usually written largest to smallest from left to right. However, the numeral for four is not IIII. Instead, the number four is written as IV. Because the one is before the five we subtract it making four. The same principle applies to the number nine, which is written as IX. There are six instances where subtraction is used:</p>
<ul>
<li>I can be placed before V (5) and X (10) to make 4 and 9.</li>
<li>X can be placed before L (50) and C (100) to make 40 and 90.</li>
<li>C can be placed before D (500) and M (1000) to make 400 and 900.</li>
</ul>
<p>Given a roman numeral, convert it to an integer.</p>
<p>Solve in Python:</p>
<pre><code class="language-python">class Solution:
    def romanToInt(self, s: str) -&gt; int:
        
</code></pre>
<hr />
<p>CodeLlama-7b-Instruct-hf:</p>
<p>Here is a possible implementation of the <code>romanToInt</code> function:</p>
<pre><code>class Solution:
    def romanToInt(self, s: str) -&gt; int:
        roman_numerals = {
            'I': 1,
            'V': 5,
            'X': 10,
            'L': 50,
            'C': 100,
            'D': 500,
            'M': 1000
        }
        result = 0
        for i in range(len(s)):
            if i &gt; 0 and roman_numerals[s[i]] &gt; roman_numerals[s[i - 1]]:
                result -= roman_numerals[s[i - 1]]
            result += roman_numerals[s[i]]
        return result
</code></pre>
<p>This implementation uses a dictionary to map each Roman numeral to its corresponding integer value. It then iterates over the characters in the input string, and for each character, it adds or subtracts the corresponding integer value depending on whether it is greater than or less than the previous character. The resulting integer value is returned at the end.</p>
<p>For example, if the input string is <code>&quot;XII&quot;</code>, the function will first map the characters to their integer values:</p>
<pre><code>X -&gt; 10
I -&gt; 1
I -&gt; 1
</code></pre>
<p>Then it will add the values of the characters in order:</p>
<pre><code>10 + 1 + 1 = 12
</code></pre>
<p>So the function will return <code>12</code>.</p>
<p>Note that this implementation assumes that the input string is a valid Roman numeral, and that it does not contain any invalid characters. If the input string contains invalid characters, the function will raise a <code>KeyError</code> exception. You can add error handling to the function as needed to handle such cases.</p>
</details>
<p>得益于 vLLM 提供的高吞吐量推理服务，该解答的生成仅用了 6s，然而并不正确，未能通过 LeetCode 的测试。</p>
<p>顺带一提，使用相同的 prompt（由于 CodeLlama-7b-Python-hf 未经过指令微调，prompt 的格式略有不同），CodeLlama-13b-Instruct-hf 和 CodeLlama-7b-Python-hf 提供的解答可以通过，GPT 3.5、GPT-4 和 Bard 提供的解答也都可以通过。</p>
<p>用户可以自行尝试部署更大的 Code Llama 系列模型，并让其编写更加复杂的代码。</p>
<h2 id="扩展部署其他-llm-1"><a class="header" href="#扩展部署其他-llm-1">扩展：部署其他 LLM</a></h2>
<p>我们可以使用同样的方法部署其他<a target="_blank" rel="noopener noreferrer" href="https://github.com/lm-sys/FastChat?tab=readme-ov-file#supported-models">支持的模型</a>，例如要将本示例部署的模型从 CodeLlama-7b-Instruct-hf 换成 Mistral-7B-Instruct-v0.1，只需：</p>
<ol>
<li>下载 Mistral-7B-Instruct-v0.1 的模型文件：</li>
</ol>
<pre><code class="language-bash"># 方法 1：如果可以直接访问 huggingface
# 需要登录
huggingface-cli download mistralai/Mistral-7B-Instruct-v0.1 \
  --local-dir Mistral-7B-Instruct-v0.1 --local-dir-use-symlinks False

# 方法 2：对于国内用户，访问 modelscope 网络连通性更好
pip install modelscope
python -c \
  &quot;from modelscope import snapshot_download; snapshot_download('AI-ModelScope/Mistral-7B-Instruct-v0.1')&quot;
mv .cache/modelscope/hub/AI-ModelScope/Mistral-7B-Instruct-v0___1 ./Mistral-7B-Instruct-v0.1
</code></pre>
<ol start="2">
<li>对 MLService 的 YAML 配置文件作以下修改，再次创建即可：</li>
</ol>
<pre><code class="language-diff">$ diff --color -u mlservice.yaml mlservice-mistral.yaml
--- mlservice.yaml
+++ mlservice-mistral.yaml
@@ -1,22 +1,22 @@
 apiVersion: tensorstack.dev/v1beta1
 kind: MLService
 metadata:
-  name: codellama-7b
+  name: mistral-7b
 spec:
   # scheduler:
   #   t9kScheduler:
   #     queue: default
-  default: codellama-7b
+  default: mistral-7b
   releases:
-    - name: codellama-7b
+    - name: mistral-7b
       predictor:
         minReplicas: 1
         model:
           runtime: vllm-openai
           parameters:
             MODEL_PATH: /var/lib/t9k/model
-            MODEL_NAME: codellama-7b
-          modelUri: pvc://vllm/CodeLlama-7b-Instruct-hf
+            MODEL_NAME: mistral-7b
+          modelUri: pvc://vllm/Mistral-7B-Instruct-v0.1
         containersResources:
         - name: user-container
           resources:
</code></pre>
<h2 id="参考-15"><a class="header" href="#参考-15">参考</a></h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/vllm-project/vllm">GitHub 上的 vLLM</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/codellama">GitHub 上的 Code Llama 模型介绍</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf">HuggingFace 上的 CodeLlama-7b-Instruct-hf 模型</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-triton-部署-hugging-face-模型python-后端"><a class="header" href="#使用-triton-部署-hugging-face-模型python-后端">使用 Triton 部署 Hugging Face 模型（Python 后端）</a></h1>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/triton-inference-server/server">Triton Inference Server</a> 是一个开源的推理服务软件，旨在简化 AI 推理流程。Triton 使用户能够部署多种深度学习框架的模型，包括 TensorRT、TensorFlow、PyTorch、ONNX、OpenVINO 等。Triton 支持在云、数据中心、边缘和嵌入式设备的 NVIDIA GPU、x86 CPU 和 ARM CPU 上进行推理。Triton 为许多查询类型提供了优化的性能，包括实时、批处理、集成和音频/视频流。</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/">Hugging Face</a> 是一个 AI 开源社区，其提供的代码库托管了大量流行的开源模型。凭借 <a target="_blank" rel="noopener noreferrer" href="https://github.com/triton-inference-server/python_backend">Python 后端</a>所提供的灵活性，Triton 可以部署几乎任何来自 Hugging Face 的模型。</p>
<p>本示例使用 MLService，以及 Triton 推理服务器和它的 Python 后端部署一个 Hugging Face 模型的推理服务。模型存储使用 PVC。</p>
<h2 id="准备-6"><a class="header" href="#准备-6">准备</a></h2>
<p>在项目中创建一个名为 <code>triton-python</code>、大小 50 GiB 以上的 PVC，然后创建一个同样名为 <code>triton-python</code> 的 Notebook 挂载该 PVC（镜像类型和模板不限）。</p>
<p>进入 Notebook 或远程连接到 Notebook，启动一个终端，执行以下命令以克隆 <a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/examples"><code>t9k/examples</code></a> 仓库：</p>
<pre><code class="language-bash">cd ~
git clone https://github.com/t9k/examples.git
</code></pre>
<p>使用预制的模型仓库：</p>
<pre><code class="language-bash">cp -R examples/deployments/triton-python/python_model_repository .
</code></pre>
<p>然后从 Hugging Face Hub 下载要部署的模型，这里以 <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/google/vit-base-patch16-224-in21k">vit-base-patch16-224-in21k</a> 模型为例：</p>
<pre><code class="language-bash">huggingface-cli download google/vit-base-patch16-224-in21k \
  --local-dir vit-base-patch16-224-in21k --local-dir-use-symlinks False
</code></pre>
<aside class="note info">
<div class="title">Vision Transformer 模型</div>
<p>Vision Transformer（ViT）模型是计算机视觉领域的一项突破性创新，它首次将 Transformer 架构应用于图像识别任务。ViT 模型将图像分割成固定大小的块（patch），将每个块转换为一个向量，再使用 Transformer 对这些向量进行处理。vit-base-patch16-224-in21k 模型是在 ImageNet-21k 数据集（包含 1400 万张图像，分为 21,843 个类别）上以 224x224 分辨率预训练的 ViT 模型。</p>
</aside>
<h2 id="部署-2"><a class="header" href="#部署-2">部署</a></h2>
<p>使用以下 YAML 配置文件创建 MLServiceRuntime 和 MLService 以部署服务：</p>
<pre><code class="language-bash">cd examples/deployments/triton-python
kubectl apply -f mlservice-runtime.yaml
kubectl create -f mlservice.yaml
</code></pre>
<p>监控服务是否准备就绪：</p>
<pre><code class="language-bash">kubectl get -f mlservice.yaml -w
</code></pre>
<p>待其 <code>READY</code> 值变为 <code>true</code> 后，便可开始使用该服务。第一次拉取镜像可能会花费较长的时间，具体取决于集群的网络状况。</p>
<h2 id="使用推理服务-4"><a class="header" href="#使用推理服务-4">使用推理服务</a></h2>
<p>继续使用 Notebook 的终端，使用作为推理客户端的 Python 脚本发送推理请求：</p>
<pre><code class="language-bash">address=$(kubectl get -f mlservice.yaml -ojsonpath='{.status.address.url}' | sed 's#^https\?://##')
pip install tritonclient gevent geventhttpclient
python client.py --server_address $address --model_name python_vit
</code></pre>
<img alt="image" src="examples/../assets/examples/deploy-model-using-triton-python/000000161642.jpg" style="max-width: 33%">
<p>该脚本从指定 URL 下载一个图像文件（如上图所示），将其转换为 NumPy 数组，然后发送到推理服务器；从返回的响应中取出 <code>last_hidden_state</code>，即 Transformer 最后一层的输出张量，打印其值和形状。输出应类似于：</p>
<pre><code>[[[ 0.2463658   0.12966464  0.13196409 ... -0.12697077  0.08220191
   -0.1261508 ]
  [ 0.10375027  0.15543337  0.14776552 ... -0.09246814  0.10163841
   -0.31893715]
  [ 0.04861938  0.15119025  0.14414431 ... -0.08075114  0.0719012
   -0.32684252]
  ...
  [ 0.2877585   0.15052384  0.17233661 ... -0.07538544  0.05114003
   -0.19613911]
  [ 0.21476139  0.17660537  0.14951637 ... -0.09027394  0.0747345
   -0.31565955]
  [ 0.2561764   0.16620857  0.13983792 ... -0.06043544  0.08778334
   -0.14347576]]]
(1, 197, 768)
</code></pre>
<p>最后一层的输出张量可以作为图像的整体表示，进一步用于分类、图像识别等下游任务。我们可以在这样一个推理客户端示例的基础上进一步开发 AI 应用。</p>
<h2 id="参考-16"><a class="header" href="#参考-16">参考</a></h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/triton-inference-server/server">GitHub 上的 Triton Inference Server</a>
<ul>
<li>Triton 官方教程：<a target="_blank" rel="noopener noreferrer" href="https://github.com/triton-inference-server/tutorials/tree/main/HuggingFace#deploying-huggingface-models">Deploying HuggingFace models</a></li>
<li>Triton <a target="_blank" rel="noopener noreferrer" href="https://github.com/triton-inference-server/python_backend">Python 后端</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/">Hugging Face</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-tensorizer-加速模型部署"><a class="header" href="#使用-tensorizer-加速模型部署">使用 Tensorizer 加速模型部署</a></h1>
<p>在部署模型的过程中，加载模型尤其是大模型往往耗时很长。对此，CoreWeave 发布了 <a target="_blank" rel="noopener noreferrer" href="https://docs.coreweave.com/coreweave-machine-learning-and-ai/inference/tensorizer">Tensorizer</a> 用于模型和张量的序列化和反序列化。它能以更少的资源和更快的速度加载模型。</p>
<p>TensorStack 提供的 <a href="examples/../modules/deployment/simplemlservice.html">SimpleMLService</a> 和 <a href="examples/../modules/deployment/mlservice.html">MLService</a> 可以让用户方便地部署各种模型。</p>
<p>本示例通过 MLService 部署 <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/EleutherAI/gpt-j-6b">GPT-J-6B</a> 模型，并使用 <a target="_blank" rel="noopener noreferrer" href="https://docs.coreweave.com/coreweave-machine-learning-and-ai/inference/tensorizer">Tensorizer</a>  加速模型加载。</p>
<h2 id="准备-7"><a class="header" href="#准备-7">准备</a></h2>
<p>在项目中创建一个名为 <code>tensorizer</code>、大小为 50GiB 以上的 PVC，然后创建一个同样名为 <code>tensorizer</code> 的 Notebook 挂载该 PVC，镜像选择带有 sudo 权限的类型，资源不限（如要使用远程操作，请开启 SSH）。</p>
<p>进入 Notebook 或远程连接到 Notebook，启动一个终端，执行以下命令以克隆必要的仓库：</p>
<pre><code class="language-bash"># change to mount point of PVC `tensorizer`, defaults to /t9k/mnt, and also $HOME
cd ~
git clone https://github.com/t9k/examples.git
</code></pre>
<h2 id="下载模型"><a class="header" href="#下载模型">下载模型</a></h2>
<p>Tensorizer 以 “tensor streaming” 的形式加载模型，从而以更少的资源和更快的速度加载模型。这需要用户首先以 Tensorizer 支持的形式来保存模型。通过运行以下命令创建一个 <code>GenericJob</code> 来下载并保存模型：</p>
<pre><code class="language-sh"># 切换到正确目录
cd ~/examples/inference/tensorizer
kubectl apply -f ./download-job.yaml
</code></pre>
<p>在该 GenericJob 中，我们先使用国内模型平台 ModelScope 来下载 GPT-J-6B 模型，然后将模型转换为 CoreWeave Tensorizer 所需的格式，并保存到 PVC 中，代码细节见 <a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/examples/blob/master/deployments/tensorizer/download/model_download.py"><code>model_download.py</code></a>。</p>
<h2 id="部署推理服务-1"><a class="header" href="#部署推理服务-1">部署推理服务</a></h2>
<p>待模型下载的任务结束后，便可以开始部署服务。首先创建 <code>MLServiceRuntime</code>，MLServiceRuntime 定义了部署服务的 Pod 模版，此处所定义的 Pod 模版会使用 Tensorizer 加载环境变量 <code>MODEL_PATH</code> 所指定的路径中的模型文件：</p>
<pre><code class="language-sh">kubectl apply -f ./runtime.yaml
</code></pre>
<p>然后部署 <code>MLService</code>，MLService 会指定要使用的 <code>MLServiceRuntime</code> 以及要挂载的模型。此处我们使用<a href="examples/deploy-mlservice-tensorizer.html#%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B">下载模型</a>中 PVC 里所保存的模型文件：</p>
<pre><code class="language-sh">kubectl apply -f ./mlservice.yaml
</code></pre>
<p>部署后进入模型部署控制台的 MLService 页面，可以看到名为 <strong>tensorizer-gptj</strong> 的 MLService，稍等片刻，等其进入 Ready 状态：</p>
<figure class="screenshot">
    <img alt="ready" src="examples/../assets/examples/deploy-tensorizer/running-status.png" />
</figure>
<h2 id="使用推理服务-5"><a class="header" href="#使用推理服务-5">使用推理服务</a></h2>
<p>你可以直接使用命令行工具访问 MLService 的预测服务。运行命令获取 MLService 的 URL：</p>
<pre><code class="language-shell">url=$(kubectl get mlservice tensorizer-gptj -o jsonpath='{.status.address.url}') &amp;&amp; echo $url
</code></pre>
<p>发送推理请求：</p>
<pre><code class="language-shell">curl ${url}/v1/models/gptj:predict -X POST -H 'Content-Type: application/json' -d '{&quot;instances&quot;: [&quot;Once upon a time, there was&quot;]}'
</code></pre>
<p>返回的响应类似于：</p>
<pre><code class="language-json">{
  &quot;predictions&quot;:[&quot;Once upon a time, there was a happy prince…\n\nFaced with a constant barrage of attacks from enemies, this happy prince decided to launch a counterattack and create his own military kingdom. He created a country called Fairy Tail, where no dragon is found, but all dragon&quot;]
}
</code></pre>
<h2 id="扩展"><a class="header" href="#扩展">扩展</a></h2>
<p>上述示例演示了如何下载以及部署 GPT-J-6B 大模型。用户可以参考<a href="https://github.com/t9k/examples/blob/master/inference/tensorizer/README.md#%E5%88%B6%E4%BD%9C-tensorizer-%E7%9B%B8%E5%85%B3%E7%9A%84%E9%95%9C%E5%83%8F">制作 Tensorizer 相关的镜像</a>将 Tensorizer 用于自定义模型的部署。</p>
<h2 id="参考-17"><a class="header" href="#参考-17">参考</a></h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://docs.coreweave.com/coreweave-machine-learning-and-ai/inference/tensorizer">CoreWeave Tensorizer 介绍</a> </li>
<li>API 参考：<a href="examples/../../references/api-reference/mlservice.html">MLService</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="使用-autogen-构建下一代-llm-应用"><a class="header" href="#使用-autogen-构建下一代-llm-应用">使用 AutoGen 构建下一代 LLM 应用</a></h1>
<p>LLM 所展现出的推理、规划、指令遵循、上下文学习和工具使用等多项能力，使得它们成为目前开发强大 AI 智能体 （AI Agent）的首选。一些基于这样的智能体构建的 AI 应用已经出现，例如 ChatGPT + Wolfram Alpha 插件可以解答数学问题，AutoGPT 可以自主达成用户给定的目标，等等。最近公开的 AutoGen 框架引入了多智能体对话（multi-agent conversation）机制，为构建 AI 应用提供了高效实现和高度可扩展性。</p>
<p>本教程演示几个基于 AutoGen 框架构建的简单应用。这些应用分别采用了 OpenAI 的 GPT 系列模型以及开源的 LLM 作为智能体的后端，前者通过调用 OpenAI 的官方 API 实现，后者则是接入使用 SimpleMLService 部署的 LLM 推理服务。</p>
<p>应用的代码被放置在 <a href="https://github.com/t9k/examples/tree/master/applications/autogen">https://github.com/t9k/examples/tree/master/applications/autogen</a>，用户可参照 README 自行尝试。这里推荐用户在 <a href="examples/../tasks/use-notebook.html">Notebook</a> 中运行应用示例的 <code>.ipynb</code> 文件；如要使用开源模型作为智能体后端，请参阅<a href="examples/./deploy-llm-chatbot.html">部署 LLM 聊天机器人</a>进行本地部署。</p>
<h2 id="autogen-框架"><a class="header" href="#autogen-框架">AutoGen 框架</a></h2>
<p>我们希望基于 LLM 的智能体能够帮助人类完成现实世界中的复杂任务，但即便是当下最强大的 GPT-4 模型，也在许多场景下表现不佳。为了提升智能体解决问题的能力，除了提升单个智能体的表现，另一种直观的思路是使用多个智能体进行分工合作，分解复杂任务并各自承担一个专业的子任务。现有研究表明，多个智能体有助于鼓励不同的思考方式，提高推理能力，提供验证以提高正确性。就像人类一样，团队合作能够实现许多个人难以独立达成的成就。</p>
<p>论文 <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2308.08155">《AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation》</a>提出了多智能体对话框架 <a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/autogen">AutoGen</a>，其基本原理如下：</p>
<ul>
<li>提供通用的可对话智能体抽象，智能体有统一的对话接口，由 LLM、人类、（由 Python 代码实现的）外部工具或它们的组合驱动，可自定义和扩展行为，可重用。</li>
<li>LLM 应用的工作流被统一为多智能体的对话流，开发应用的过程即为：(1) 定义一组各自有特定能力和角色的可对话智能体；(2) 通过程序语言（Python 代码）和自然语言（LLM 的系统信息（system message）、指令等）控制智能体自身的计算以及智能体之间的对话流。</li>
</ul>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="autogen-framework" src="examples/../assets/examples/build-next-generation-llm-app-using-autogen/autogen-framework.png" style="display: block; margin-left: auto; margin-right: auto;"/>
</figure>
<p>AutoGen 框架提供的灵活性超越了目前其他框架或系统（如 AutoGPT、LangChain Agent、CAMEL 等），适用于构建各种形式、领域和复杂度的应用。</p>
<h2 id="应用一解数学题"><a class="header" href="#应用一解数学题">应用一：解数学题</a></h2>
<p>在第一个应用中，我们使用 <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2306.01337">MathChat</a> 框架解答数学问题。</p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="app-math" src="examples/../assets/examples/build-next-generation-llm-app-using-autogen/app-math.png" style="display: block; margin-left: auto; margin-right: auto;"/>
</figure>
<p>为该应用编写的部分 AutoGen 代码如下，其中定义了智能体 user_proxy 和 assistant。前者负责初始化对话（MathUserProxyAgent 封装了解答数学问题的 prompt，见下面的日志），以及执行 Python 代码并返回结果（所有 UserProxyAgent 均有执行 Python 代码的功能）；后者负责解答问题（使用了默认的系统信息）：</p>
<pre><code class="language-python">user_proxy = MathUserProxyAgent(
    name=&quot;user_proxy&quot;, 
    human_input_mode=&quot;NEVER&quot;,
)
assistant = autogen.AssistantAgent(
    name=&quot;assistant&quot;, 
    system_message=&quot;你是一个提供帮助的助手。&quot;,
    llm_config={
        &quot;request_timeout&quot;: 600,
        &quot;seed&quot;: 42,
        &quot;config_list&quot;: config_list,
    }
)

math_problem = &quot;[数学问题]&quot;
user_proxy.initiate_chat(assistant, problem=math_problem)
</code></pre>
<p>通过修改 config，智能体可以使用由 OpenAI 提供的 gpt-4、gpt-3.5-turbo 等 API，或者由 FastChat 本地部署的开源模型作为 LLM 后端。数学问题如下：</p>
<ul>
<li>任务 1：找到满足不等式 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">2</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">10</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">3</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">3</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">9</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">8</span><span class="mclose">)</span></span></span></span> 的所有 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span>，并以区间表示答案。</li>
<li>任务 2：当 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 取何负值时，以下方程组存在恰好一个解？</li>
</ul>
<p><span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0241em;vertical-align:-1.2621em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7621em;"><span style="top:-3.8979em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span><span style="top:-2.3979em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2621em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7621em;"><span style="top:-3.8979em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">2</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">6</span></span></span><span style="top:-2.3979em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">−</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2621em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>使用 gpt-4 后端执行任务 1，整个过程的日志如下，最终回答正确：</p>
<details><summary>日志</summary>
<p>user_proxy (to assistant):</p>
<p>让我们使用 Python 来解决一个数学问题。</p>
<p>查询要求：</p>
<ul>
<li>对于输出，应始终使用 ‘print’ 函数，并使用分数 / 根式形式而不是小数。</li>
<li>您可以使用诸如 sympy 之类的包来帮助您。</li>
<li>您必须遵循以下格式来编写您的代码：</li>
</ul>
<pre><code class="language-python"># your code
</code></pre>
<p>首先陈述解决问题的关键思想。您可以选择以下三种方式来解决问题：
情况 1：如果问题可以直接用 Python 代码解决，请编写一个程序来解决它。如果需要，您可以枚举所有可能的排列。
情况 2：如果问题主要是基于推理，您可以直接解决它。
情况 3：如果问题不能用以上两种方式处理，请按照以下过程进行：</p>
<ol>
<li>逐步解决问题（不要过于细分步骤）。</li>
<li>挑选出可以通过 Python 询问的任何查询（例如，可以计算的任何计算或方程式）。</li>
<li>等待我提供结果。</li>
<li>如果您认为结果正确，请继续。如果结果无效或不符合预期，请更正您的查询或推理。</li>
</ol>
<p>在运行所有查询并获得答案后，将答案放入 \boxed {} 中。</p>
<p>问题：
找到满足不等式 (2x+10)(x+3)&lt;(3x+9)(x+8) 的所有 x，并以区间表示答案。</p>
<hr />
<p>assistant (to user_proxy):</p>
<p>解决这个问题的关键思想是首先简化不等式。然后，通过将其化为零来找到简化表达式的临界点。一旦我们有了临界点，我们将在由这些点确定的每个区间中评估原始不等式。不等式成立的区间将是我们的解集。</p>
<p>具体的步骤如下：</p>
<ol>
<li>展开不等式两侧并将其简化为 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span> 的形式。</li>
<li>解方程 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span> 以找到临界点。</li>
<li>确定由临界点确定的区间中不等式 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span> 成立的区间。</li>
</ol>
<p>我们可以使用 Python 执行所有这些步骤。让我们编写程序来执行这些操作。我们将使用 sympy 库来进行符号计算。</p>
<pre><code class="language-python">from sympy import *

x = symbols('x')

# 定义不等式
inequality = (2*x + 10)*(x + 3) - (3*x + 9)*(x + 8)

# 展开和简化不等式
simplified_inequality = simplify(inequality)

# 通过解方程f(x) = 0来找到临界点
critical_points = solve(simplified_inequality, x)

# 对临界点进行排序，然后添加 -oo 和 +oo 形成实线上的区间
intervals = [-oo, *sorted(critical_points), oo]

# 在每个区间中评估简化的不等式，
# 如果成立，该区间是解的一部分
solution_set = []  # 采用了复杂的解法
for i in range(len(intervals) - 1):
    mid_point = (intervals[i] + intervals[i+1]) / 2
    if simplified_inequality.subs(x, mid_point) &lt; 0:
        solution_set.append((intervals[i], intervals[i+1]))

print(solution_set)
</code></pre>
<p>运行这段代码，输出将是给定不等式中 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 的解集，以区间表示。</p>
<hr />
<p>user_proxy (to assistant):</p>
<p>[(-oo, -14), (-3, oo)]</p>
<hr />
<p>assistant (to user_proxy):</p>
<p>不等式 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">2</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">10</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">3</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">3</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">9</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">8</span><span class="mclose">)</span></span></span></span> 的解是 <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.68em;vertical-align:-0.59em;"></span><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.09em;"><span style="top:-3.68em;"><span class="pstrut" style="height:3.68em;"></span><span class="boxpad"><span class="mord"><span class="mord"><span class="mopen">(</span><span class="mord">−</span><span class="mord">∞</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">−</span><span class="mord">14</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∪</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∞</span><span class="mclose">)</span></span></span></span></span><span style="top:-3.09em;"><span class="pstrut" style="height:3.68em;"></span><span class="stretchy fbox" style="height:1.68em;border-style:solid;border-width:0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.59em;"><span></span></span></span></span></span></span></span></span>。</p>
<hr />
</details>
<p>换用其他 LLM 作为 Assistant 的后端能否解决这些数学问题？这里实验了 gpt-3.5-turbo、meta-llama/Llama-2-70b-chat-hf、meta-llama/Llama-2-13b-chat-hf、Qwen/Qwen-14B-Chat，结果汇总如下：</p>
<div class="table-wrapper"><table><thead><tr><th>模型</th><th>任务 1</th><th>任务 2</th><th>失败原因</th></tr></thead><tbody>
<tr><td>gpt-4</td><td>✅</td><td>✅</td><td></td></tr>
<tr><td>gpt-3.5-turbo</td><td>❌</td><td>✅</td><td>代数计算出错</td></tr>
<tr><td>meta-llama/Llama-2-70b-chat-hf</td><td>❌</td><td>❌</td><td>代数计算出错，代码编写出错（不会使用 sympy 包）</td></tr>
<tr><td>meta-llama/Llama-2-13b-chat-hf</td><td>❌</td><td>❌</td><td>代数计算出错，指令遵循存在问题</td></tr>
<tr><td>Qwen/Qwen-14B-Chat</td><td>❌</td><td>✅</td><td>代数计算出错</td></tr>
</tbody></table>
</div>
<p>由此可见，gpt-4 的数学能力相较于这些有代表性的开源模型遥遥领先。</p>
<h2 id="应用二文档问答"><a class="header" href="#应用二文档问答">应用二：文档问答</a></h2>
<p>在第二个应用中，LLM 需要根据从向量数据库检索得到的上下文回答用户提出的问题。</p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="app-rag" src="examples/../assets/examples/build-next-generation-llm-app-using-autogen/app-rag.png" style="display: block; margin-left: auto; margin-right: auto;"/>
</figure>
<p>为该应用编写的 AutoGen 代码如下，其中定义了智能体 user_proxy 和 assistant，前者在对话之外负责构建和检索向量数据库（定义中包含一些相关配置），在对话当中负责提供 prompt、问题和上下文，后者回答问题：</p>
<pre><code class="language-python">user_proxy = RetrieveUserProxyAgent(
    name=&quot;user_proxy&quot;,
    human_input_mode=&quot;NEVER&quot;,
    max_consecutive_auto_reply=10,
    retrieve_config={
        &quot;task&quot;: &quot;qa&quot;,
        &quot;docs_path&quot;: &quot;local_path_or_url_of_docs&quot;,
        &quot;chunk_token_size&quot;: 2000,
        &quot;model&quot;: config_list[0][&quot;model&quot;],
        &quot;client&quot;: chromadb.PersistentClient(path=&quot;./tmp/chromadb&quot;),
        &quot;collection_name&quot;: &quot;natural-questions&quot;,
        &quot;chunk_mode&quot;: &quot;one_line&quot;,
        &quot;embedding_model&quot;: &quot;all-MiniLM-L6-v2&quot;,
    },
)
assistant = RetrieveAssistantAgent(
    name=&quot;assistant&quot;, 
    system_message=&quot;你是一个提供帮助的助手。&quot;,
    llm_config={
        &quot;request_timeout&quot;: 600,
        &quot;seed&quot;: 42,
        &quot;config_list&quot;: config_list,
    },
)

question = &quot;[提出的问题]&quot;
user_proxy.initiate_chat(assistant, problem=question, n_results=30)
</code></pre>
<p>这里准备了两个任务：</p>
<p>任务 1：根据 <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/datasets/thinkall/NaturalQuestionsQA/resolve/main/corpus.txt">NaturalQuestionsQA 语料库</a>，回答下列问题：</p>
<div class="table-wrapper"><table><thead><tr><th>No.</th><th>问题</th><th>正确答案</th></tr></thead><tbody>
<tr><td>1</td><td>what is non controlling interest on balance sheet</td><td>the portion of a subsidiary corporation’s stock that is not owned by the parent corporation</td></tr>
<tr><td>2</td><td>how many episodes are in chicago fire season 4</td><td>23</td></tr>
<tr><td>3</td><td>what are bulls used for on a farm</td><td>breeding, as work oxen, slaughtered for meat</td></tr>
<tr><td>4</td><td>who has been honoured with the wisden leading cricketer in the world award for 2016</td><td>Virat Kohli</td></tr>
<tr><td>5</td><td>who carried the usa flag in opening ceremony</td><td>Erin Hamlin</td></tr>
</tbody></table>
</div>
<p>任务 2：根据<a target="_blank" rel="noopener noreferrer" href="https://www.szse.cn/api/disc/info/download?id=f44320dc-1129-44aa-9924-a2d212f16e70">比亚迪 2023 年上半年财报</a>，回答下列问题：</p>
<div class="table-wrapper"><table><thead><tr><th>No.</th><th>问题</th><th>正确答案</th></tr></thead><tbody>
<tr><td>1</td><td>公司是否计划派发现金红利？</td><td>公司计划不派发现金红利。</td></tr>
<tr><td>2</td><td>集团在八月达成的里程碑是什么？</td><td>本集团第500万辆新能源汽车下线，成为全球首家达成这一里程碑的车企。</td></tr>
<tr><td>3</td><td>公司的主管会计工作负责人是谁？</td><td>周亚琳</td></tr>
<tr><td>4</td><td>公司的 2023 年上半年的归母净利润为多少元？</td><td>10,954,145,000元</td></tr>
<tr><td>5</td><td>王传福的持股比例是多少？</td><td>17.64%</td></tr>
</tbody></table>
</div>
<p>使用 gpt-4 后端执行任务 2 的问题 1，整个过程的日志如下，最终回答正确：</p>
<details><summary>日志</summary>
<p>doc_ids:  [[‘doc_460’, ‘doc_1461’, ‘doc_4853’, ‘doc_4871’, ‘doc_1582’, ‘doc_1439’, ‘doc_1374’, ‘doc_2312’, ‘doc_1584’, ‘doc_512’, ‘doc_6188’, ‘doc_2324’, ‘doc_1577’, ‘doc_2314’, ‘doc_1444’, ‘doc_14’, ‘doc_3357’, ‘doc_1336’, ‘doc_6106’, ‘doc_1948’, ‘doc_1588’, ‘doc_1587’, ‘doc_4898’, ‘doc_439’, ‘doc_1448’, ‘doc_2308’, ‘doc_5452’, ‘doc_6186’, ‘doc_6166’, ‘doc_536’]]
Adding doc_id doc_460 to context.
Adding doc_id doc_1461 to context.
Adding doc_id doc_4853 to context.
Adding doc_id doc_4871 to context.
Adding doc_id doc_1582 to context.
Adding doc_id doc_1439 to context.
Adding doc_id doc_1374 to context.
Adding doc_id doc_2312 to context.
Adding doc_id doc_1584 to context.
Adding doc_id doc_512 to context.
Adding doc_id doc_6188 to context.
Adding doc_id doc_2324 to context.
Adding doc_id doc_1577 to context.
Adding doc_id doc_2314 to context.
Adding doc_id doc_1444 to context.
Adding doc_id doc_14 to context.
Adding doc_id doc_3357 to context.
Adding doc_id doc_1336 to context.
Adding doc_id doc_6106 to context.
Adding doc_id doc_1948 to context.
Adding doc_id doc_1588 to context.
Adding doc_id doc_1587 to context.
Adding doc_id doc_4898 to context.
Adding doc_id doc_439 to context.
Adding doc_id doc_1448 to context.
Adding doc_id doc_2308 to context.
Adding doc_id doc_5452 to context.
Adding doc_id doc_6186 to context.
Adding doc_id doc_6166 to context.
Adding doc_id doc_536 to context.
ragproxyagent (to assistant):</p>
<p>You’re a retrieve augmented chatbot. You answer user’s questions based on your own knowledge and the
context provided by the user.
If you can’t answer the question with or without the current context, you should reply exactly <code>UPDATE CONTEXT</code>.
You must give as short an answer as possible.</p>
<p>User’s question is: 公司是否计划派发现金红利？</p>
<p>Context is: 公司报告期无募集资金使用情况。<br />
限 公 司 各 项 经 济 损 失
母公司股东    归属于 
母公司股东    归属于 
公司控股的财务公司与关联方之间不存在存款、贷款、授信或其他金融业务。<br />
公司报告期不存在控股股东及其 他关联方对上市公司的非经营性占用资金。<br />
沙分公司  废气 氮氧化
公司报告期控股股东未发生变更。<br />
公司报告期无其他重大关联交易。<br />
公司计划半年度不派发现金红利，不送红股，不以公积金转增股本。<br />
限公司  房屋<br />
公司半年度财务报告未经审计。<br />
公司报告期不存在关联债权债务往来。<br />
公司报告期实际控制人未发生变更。<br />
公司半年度报告未经审计。<br />
公司计划不派发现金红利，不送红股，不以公积金转增股本。<br />
本公司的现金股利，于股东大会批准后确认为负债。<br />
公司 废气 颗粒物 有组织
公司名称  与本企业关系<br />
有限公司办理存款业务暨关
公司报告期不存在承包情况。<br />
公司报告期不存在托管情况。<br />
本公司在提取法定盈余公积金后，可提取任意公积金。经批准，任意公积金可用于弥补以前年度亏损或增加
明 公司为规避日常经营中所面临的汇率、利率风险，通过操作金融衍生品对实际持有的风险敞口进
公司报告期未发生破产重整相关事项。<br />
公司秘书  现任 27,500   27,500<br />
重庆弗迪锂电池有限公司<br />
能源汽车有限公司   房屋<br />
公司 接受劳务及购买水电燃气
公司员工持股计划在 2023年半年度费用摊销金额请详见“第十节财务报告 -十三.股份支付”相关内容。</p>
<hr />
<p>assistant (to ragproxyagent):</p>
<p>否</p>
<hr />
</details>
<p>同样地，我们使用 gpt-4、gpt-3.5-turbo、meta-llama/Llama-2-13b-chat-hf、Qwen/Qwen-14B-Chat 分别作为 Assistant 的后端，结果汇总如下（人工打分，回答正确一个问题得 1 分，回答不完整得小于 1 分，总分均为 5 分）：</p>
<div class="table-wrapper"><table><thead><tr><th>模型</th><th>任务 1</th><th>任务 2</th><th>失败原因</th></tr></thead><tbody>
<tr><td>gpt-4</td><td>4.8</td><td>4</td><td>向量数据库未返回相关上下文，归纳不完整</td></tr>
<tr><td>gpt-3.5-turbo</td><td>3.5</td><td>4</td><td>向量数据库未返回相关上下文，归纳不完整，从上下文寻找信息的能力不足</td></tr>
<tr><td>meta-llama/Llama-2-13b-chat-hf</td><td>2</td><td>0</td><td>从上下文寻找信息的能力弱，允许的上下文长度较短，不能理解问题</td></tr>
<tr><td>Qwen/Qwen-14B-Chat</td><td>1.8</td><td>0</td><td>从上下文寻找信息的能力弱，归纳不完整</td></tr>
</tbody></table>
</div>
<p>可以看到这些开源模型的自然语言能力也不及 gpt 系列模型。</p>
<h2 id="应用三可视化数据群聊"><a class="header" href="#应用三可视化数据群聊">应用三：可视化数据（群聊）</a></h2>
<p>在第三个应用中，我们让 LLM 编写代码以可视化表格数据。</p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="app-groupchat" src="examples/../assets/examples/build-next-generation-llm-app-using-autogen/app-groupchat.png" style="display: block; margin-left: auto; margin-right: auto;"/>
</figure>
<p>和前两个应用不同的是，这里我们采用动态群聊（dynamic group chat）的方法来完成任务，通过：</p>
<ul>
<li>引入 3 个智能体：User Proxy 负责初始化对话，执行 Python 代码并返回结果，以及传入用户的发言；Coder 负责计划和编写代码；Critic 提出一般性的评价和改进建议，系统信息指定了 Critic 的角色并给出了详细的评估维度和标准。</li>
<li>引入 1 个 GroupChat 的 Manager，Manager 的作用是在每一轮当中根据对话历史挑选 1 个智能体发言，并将其发言内容广播给其他智能体，即“主持群聊”。</li>
<li>对于 UserProxyAgent 设置 human_input_mode=“ALWAYS”，这样每当 Manager 选取 User Proxy 发言，用户都可以提出自己的想法、需求或意见。</li>
</ul>
<p>在代码中，我们定义了智能体 user_proxy、coder 和 critic，包含这些 agent 的 groupchat，以及 groupchat 的 manager，最后传入任务描述（prompt）以初始化对话。</p>
<pre><code class="language-python">user_proxy = autogen.UserProxyAgent(  
   name=&quot;User_Proxy&quot;,
   system_message=&quot;人类管理员&quot;,
   code_execution_config={&quot;last_n_messages&quot;: 3, &quot;work_dir&quot;: &quot;groupchat&quot;},
   human_input_mode=&quot;ALWAYS&quot;,
   is_termination_msg=lambda x: x.get(&quot;content&quot;, &quot;&quot;).rstrip().endswith(&quot;TERMINATE&quot;)
)
coder = autogen.AssistantAgent(
    name=&quot;Coder&quot;,  # 默认的 assistant agent 就可以编写代码
    llm_config=llm_config,
)
critic = autogen.AssistantAgent(
    name=&quot;Critic&quot;,
    system_message=&quot;&quot;&quot;评论员。您是一个非常擅长评估给定可视化代码质量的有益助手，通过提供从 1（差）到 10（好）的评分，并提供清晰的理由。在每个评估中，您必须考虑可视化最佳实践。具体来说，您可以仔细评估代码的以下维度：（后略）&quot;&quot;&quot;,
    llm_config=llm_config,
)

groupchat = autogen.GroupChat(agents=[user_proxy, coder, critic], messages=[], max_round=20)
manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)
user_proxy.initiate_chat(manager, message=&quot;从 https://raw.githubusercontent.com/datasets/gdp/master/data/gdp.csv 下载数据，绘制中、美、日、德、英、法、印七个国家从 2000 年到 2016 年的名义 GDP 折线图（以美元计价），要求折线图有网格线，图例放置在左上角。将图片保存为文件。接受来自 critic 的反馈并改进代码。&quot;)
</code></pre>
<p>鉴于 gpt-4 无可匹敌的强大能力，这里仅使用 gpt-4 作为智能体的后端。一次具体的对话的日志如下：</p>
<details><summary>日志</summary>
<p>User_proxy (to chat_manager):</p>
<p>从 https://raw.githubusercontent.com/datasets/gdp/master/data/gdp.csv 下载数据，绘制中、美、日、德、英、法、印七个国家从 2000 年到 2016 年的名义 GDP 折线图（以美元计价），要求折线图有网格线，图例放置在左上角。将图片保存为文件。接受来自 critic 的反馈并改进代码。</p>
<hr />
<p>Coder (to chat_manager):</p>
<p>理解您的需求，这是需要执行的步骤：</p>
<ol>
<li>首先，我们需要下载数据集文件。</li>
<li>然后，所需要的包 pandas 和 matplotlib 都要安装到 Python 环境，用于数据处理和绘图。</li>
<li>下一步，通过 pandas 库解析下载的 csv 文件。</li>
<li>然后，我们需要筛选我们关注的七个国家（中国、美国、日本、德国、英国、法国、印度）自 2000 年到 2016 年的数据。</li>
<li>最后，我们使用 matplotlib 绘制折线图，并保存到文件。</li>
</ol>
<p>请执行以下 Python 代码以完成前两个步骤，我会根据反馈执行后续步骤。</p>
<pre><code class="language-python"># filename: plot_gdp.py
import os
import pandas as pd
import matplotlib.pyplot as plt

# 下载数据集
data_url = &quot;https://raw.githubusercontent.com/datasets/gdp/master/data/gdp.csv&quot;
data_file = &quot;gdp.csv&quot;
os.system(f&quot;wget {data_url} -O {data_file}&quot;)

# 读取数据集
data = pd.read_csv(data_file)

print(data.head())  # 打印数据集前5行，用于检查数据
</code></pre>
<hr />
<p>######## NO HUMAN INPUT RECEIVED.</p>
<p>######## USING AUTO REPLY…</p>
<p>######## EXECUTING CODE BLOCK 0 (inferred language is python)…
User_proxy (to chat_manager):</p>
<p>exitcode: 0 (execution succeeded)
Code output: 
Country Name Country Code  Year         Value
0   Arab World          ARB  1968  2.576068e+10
1   Arab World          ARB  1969  2.843420e+10
2   Arab World          ARB  1970  3.138550e+10
3   Arab World          ARB  1971  3.642691e+10
4   Arab World          ARB  1972  4.331606e+10</p>
<hr />
<p>Coder (to chat_manager):</p>
<p>从执行结果可以看到，数据集已经成功下载并读取。数据有四个字段：Country Name（国家名），Country Code（国家代码），Year（年份）和 Value（GDP 值）。</p>
<p>下一步，我们需要筛选出需要的数据。具体来说，我们只需要中国、美国、日本、德国、英国、法国、印度从 2000 年到 2016 年的 GDP 数据。</p>
<p>请运行以下 Python 代码块以完成这个步骤。</p>
<pre><code class="language-python"># filename: plot_gdp.py

import pandas as pd
import matplotlib.pyplot as plt

# 读取数据集
data = pd.read_csv(&quot;gdp.csv&quot;)

# 筛选七个国家的数据
countries = [&quot;China&quot;, &quot;United States&quot;, &quot;Japan&quot;, &quot;Germany&quot;, &quot;United Kingdom&quot;, &quot;France&quot;, &quot;India&quot;]
data = data[data[&quot;Country Name&quot;].isin(countries)]

# 筛选 2000 年到 2016 年的数据
data = data[(data[&quot;Year&quot;] &gt;= 2000) &amp; (data[&quot;Year&quot;] &lt;= 2016)]

# 只保留我们关注的列
data = data[[&quot;Country Name&quot;, &quot;Year&quot;, &quot;Value&quot;]]

print(data.head())  # 打印数据集前5行，用于检查数据
</code></pre>
<hr />
<p>######## NO HUMAN INPUT RECEIVED.</p>
<p>######## USING AUTO REPLY…</p>
<p>######## EXECUTING CODE BLOCK 0 (inferred language is python)…
User_proxy (to chat_manager):</p>
<p>exitcode: 0 (execution succeeded)
Code output: 
Country Name  Year         Value
4086        China  2000  1.211347e+12
4087        China  2001  1.339396e+12
4088        China  2002  1.470550e+12
4089        China  2003  1.660288e+12
4090        China  2004  1.955347e+12</p>
<hr />
<p>Coder (to chat_manager):</p>
<p>通过执行结果可以看到，我们已经成功地筛选出了七个国家从 2000 年到 2016 年的 GDP 数据。</p>
<p>接下来，我将使用 matplotlib 来绘制这些数据的折线图，并将图像保存为文件。</p>
<p>绘制图像的代码如下，请执行。</p>
<pre><code class="language-python"># filename: plot_gdp.py

import pandas as pd
import matplotlib.pyplot as plt

#读取数据集
data = pd.read_csv(&quot;gdp.csv&quot;)

#选择七个国家的数据
countries = [&quot;China&quot;, &quot;United States&quot;, &quot;Japan&quot;, &quot;Germany&quot;, &quot;United Kingdom&quot;, &quot;France&quot;, &quot;India&quot;]
data = data[data[&quot;Country Name&quot;].isin(countries)]

#选择2000年到2016年的数据
data = data[(data[&quot;Year&quot;] &gt;= 2000) &amp; (data[&quot;Year&quot;] &lt;= 2016)]

# 只保留我们关注的列
data = data[[&quot;Country Name&quot;, &quot;Year&quot;, &quot;Value&quot;]]

# 绘制折线图
plt.figure(figsize=(10, 8))
for country in countries:
    country_data = data[data[&quot;Country Name&quot;] == country]
    plt.plot(country_data[&quot;Year&quot;], country_data[&quot;Value&quot;], label=country)

plt.grid()  # 添加网格线
plt.legend(loc='upper left')  # 图例放置在左上角
plt.xlabel('Year')
plt.ylabel('GDP in US Dollars')
plt.title('GDP of Seven Countries from 2000 to 2016')

# 保存图片
plt.savefig(&quot;gdp_plot.png&quot;)
</code></pre>
<hr />
<p>Critic (to chat_manager):</p>
<p>基于您提供的代码，以下是我的评估：</p>
<ol>
<li>
<p>错误（Bugs）：10分
您的代码没有语法错误、逻辑错误或拼写错误，能够正常运行并符合功能需求。</p>
</li>
<li>
<p>数据转换（Transformation）：10分
您适当地筛选了数据，只保留了指定的七个国家从 2000年到2016年的GDP数据。您也正确地转换了数据以适应折线图的画图方式。</p>
</li>
<li>
<p>目标符合度（Compliance）：10分
您的代码完全符合提出的可视化目标：绘制七个指定国家从2000年到2016年的GDP折线图，并且添加了网格线和图例。</p>
</li>
<li>
<p>可视化类型（Type）：10分
您选择的折线图是一种合适的可视化类型，用于展示一段时间内GDP的变化情况。</p>
</li>
<li>
<p>数据编码（Encoding）：10分
您正确地绘制了折线图，横坐标表示年份，纵坐标表示GDP。</p>
</li>
<li>
<p>美学（Aesthetics）：10分
您的可视化具有良好的美感，图例清晰，颜色稳重，有利于理解数据。</p>
</li>
</ol>
<p>总体来说，这是一个能够满足需求，实现功能，且无明显改进空间的严谨的代码。</p>
<p>具体行动清单：</p>
<ul>
<li>代码已经很好，没有需要修改的部分。继续保持！</li>
</ul>
<hr />
<p>######## NO HUMAN INPUT RECEIVED.</p>
<p>######## USING AUTO REPLY…</p>
<p>######## EXECUTING CODE BLOCK 0 (inferred language is python)…
User_proxy (to chat_manager):</p>
<p>exitcode: 0 (execution succeeded)
Code output: </p>
<hr />
<p>Coder (to chat_manager):</p>
<p>既然代码已经成功执行，并且获得了评价人的高度评价，我们成功地完成了任务。您可以在您的工作目录中找到名为 “gdp_plot.png” 的折线图文件。这张图片显示了从 2000 年到 2016 年，中国、美国、日本、德国、英国、法国、印度七个国家的 GDP 变化情况。</p>
<p>非常感谢你的帮助，让我知道如果你有其他需要帮助的地方。TERMINATE</p>
<hr />
<p>Critic (to chat_manager):</p>
<p>很高兴能帮助到您完成任务。如果您有任何其他编码或数据可视化需求，欢迎随时回来。期待与您再次合作，祝您一切顺利。TERMINATE</p>
<hr />
<p>User_proxy (to chat_manager):</p>
<p>折线图的左上角有一个“1e13“的标记，这是因为纵轴的单位为一美元，请将其修改为十亿美元</p>
<hr />
<p>Coder (to chat_manager):</p>
<p>明白了，您希望将 GDP 的单位从美元修改为十亿美元，以便更直观地理解图表。这意味着我们需要调整 Value 列的值，将其除以 10 的 9 次方（这是因为 1 十亿等于 10 的 9 次方）。然后我们也需要在 y 轴的标题中反映这一点。</p>
<p>请运行以下代码来生成新的图像。</p>
<pre><code class="language-python"># filename: plot_gdp.py

import pandas as pd
import matplotlib.pyplot as plt

# 读取数据集
data = pd.read_csv(&quot;gdp.csv&quot;)

# 筛选七个国家的数据
countries = [&quot;China&quot;, &quot;United States&quot;, &quot;Japan&quot;, &quot;Germany&quot;, &quot;United Kingdom&quot;, &quot;France&quot;, &quot;India&quot;]
data = data[data[&quot;Country Name&quot;].isin(countries)]

# 筛选 2000 年到 2016 年的数据
data = data[(data[&quot;Year&quot;] &gt;= 2000) &amp; (data[&quot;Year&quot;] &lt;= 2016)]

# 将 GDP 的单位从美元修改为十亿美元，以便直观理解图表
data[&quot;Value&quot;] = data[&quot;Value&quot;] / (10 ** 9)

# 只保留我们关注的列
data = data[[&quot;Country Name&quot;, &quot;Year&quot;, &quot;Value&quot;]]

# 绘制折线图
plt.figure(figsize=(10, 8))
for country in countries:
    country_data = data[data[&quot;Country Name&quot;] == country]
    plt.plot(country_data[&quot;Year&quot;], country_data[&quot;Value&quot;], label=country)

plt.grid()  # 添加网格线
plt.legend(loc='upper left')  # 图例放置在左上角
plt.xlabel('Year')
plt.ylabel('GDP in Billion US Dollars')  # 更新 y 轴标题
plt.title('GDP of Seven Countries from 2000 to 2016')

# 保存图片
plt.savefig(&quot;gdp_plot_billion.png&quot;)
</code></pre>
<hr />
<p>######## NO HUMAN INPUT RECEIVED.</p>
<p>######## USING AUTO REPLY…</p>
<p>######## EXECUTING CODE BLOCK 0 (inferred language is python)…
User_proxy (to chat_manager):</p>
<p>exitcode: 0 (execution succeeded)
Code output: </p>
<hr />
<p>Critic (to chat_manager):</p>
<p>基于您提供的代码，以下是我的评估：</p>
<ol>
<li>
<p>错误（Bugs）：10分
您的代码没有语法错误、逻辑错误或拼写错误，能够正常运行并符合功能需求。</p>
</li>
<li>
<p>数据转换（Transformation）：10分
您正确地将 GDP 的单位从美元修改为了十亿美元，以便更直观地理解图表，这是一种恰当的数据转换方式。</p>
</li>
<li>
<p>目标符合度（Compliance）：10分
您的代码完全符合提出的可视化目标：绘制七个指定国家从2000年到2016年的 GDP 折线图，并且添加了网格线和图例，且以十亿美元为单位。</p>
</li>
<li>
<p>可视化类型（Type）：10分
您选择的折线图是一种合适的可视化类型，可以展示一段时间内 GDP 的变化情况。</p>
</li>
<li>
<p>数据编码（Encoding）：10分
您正确地绘制了折线图，横坐标为年份，纵坐标为 GDP（现已调整为十亿美元）。</p>
</li>
<li>
<p>美学（Aesthetics）：10分
您的可视化同样具有良好的美感，单位的更改使得读取更为友好，图例清晰，颜色稳重，有利于理解和展示数据。</p>
</li>
</ol>
<p>总体来说，这是一个能够满足需求，实现功能，且无明显改进空间的宏观经济数据可视化代码。</p>
<p>具体行动清单：</p>
<ul>
<li>代码已经很好，没有需要修改的部分。继续保持！</li>
</ul>
<hr />
<p>######## NO HUMAN INPUT RECEIVED.</p>
<p>######## USING AUTO REPLY…</p>
<p>######## EXECUTING CODE BLOCK 0 (inferred language is python)…
User_proxy (to chat_manager):</p>
<p>exitcode: 0 (execution succeeded)
Code output: </p>
<hr />
<p>Coder (to chat_manager):</p>
<p>既然代码已经成功执行，并且已经根据您的要求进行了更新，我们已经成功完成了任务。您可以在您的工作目录中找到名为 “gdp_plot_billion.png” 的折线图文件。这张图片显示了从 2000 年到 2016 年，中国、美国、日本、德国、英国、法国、印度七个国家的 GDP 变化情况，单位是十亿美元。</p>
<p>非常感谢你的帮助，让我知道如果你有其他需要帮助的地方。TERMINATE</p>
<hr />
<p>Critic (to chat_manager):</p>
<p>很高兴能够帮助您完成任务。如果您对 Python 编程或数据可视化有任何其他问题或需求，欢迎您随时提问。期待与您再次合作，祝您一切顺利。TERMINATE</p>
<hr />
<p>######## NO HUMAN INPUT RECEIVED.</p>
</details>
<p>这是第一版生成的图片：</p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="app-groupchat" src="examples/../assets/examples/build-next-generation-llm-app-using-autogen/gdp_plot1.png" style="display: block; margin-left: auto; margin-right: auto; width: 80%"/>
</figure>
<p>用户提出的改进建议是“折线图的左上角有一个“1e13“的标记，这是因为纵轴的单位为一美元，请将其修改为十亿美元”，于是 Coder 修改得到第二版：</p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="app-groupchat" src="examples/../assets/examples/build-next-generation-llm-app-using-autogen/gdp_plot2.png" style="display: block; margin-left: auto; margin-right: auto; width: 80%"/>
</figure>
<p>在 Manager 的 GroupChat 管理以及 User Proxy、Coder 和 Critic 的协作之下（尽管在这次运行中 Critic 并未提出改进意见），应用迭代出了更加准确、美观并且符合用户需求的可视化结果。</p>
<h2 id="总结-1"><a class="header" href="#总结-1">总结</a></h2>
<p>经过上面几个简单应用的实验，我们可以获得如下总结和思考：</p>
<ol>
<li>根据应用一和应用二的实验结果，能力更强的模型（gpt-4）可以使应用在任务中取得显著更好的表现。换言之，LLM 的（应用相关）能力是应用能否解决具体问题的决定性因素之一。</li>
<li>根据应用三的结果，模型被另一个相同的模型（但设定的角色不同）所纠正，可以认为是精心设计的系统信息和 prompt 激发了模型在子任务的专业领域上的表现。即便如此，模型的输出仍有欠缺，这里人类的干预可以进一步补足模型能力，提高应用的最终表现。</li>
<li>试想如果模型能力进一步提升会如何，基于下一代 GPT 模型的单智能体会不会比应用三的多智能体对话流表现更好？换一个视角，如果把除了 User Proxy 之外的 Coder、Critic 和 GroupChat Manager 打包为一个整体，把这个整体视作基于某个比 gpt-4 更强的 LLM 的单一智能体，AutoGen 框架在多智能体对话流中所起的作用就是这个 LLM 内部的一种机制。而传闻中，gpt-4 实际上就是类似的 MoE 结构（尽管细节尚不可知），由 8 个 220B 专家模型组成，这些模型分别在不同的数据集和任务分布上训练。或许“集成”和“对话”只需要一个，内部有着强大集成机制的 LLM 不会再需要外部的对话框架。</li>
</ol>
<p>回到 AutoGen 框架，它仍是一个处于早期实验阶段的工作，其进一步的研究方向包括：</p>
<ol>
<li>研究提升对话有效性和总体效率的策略（如智能体拓扑、对话模式等）；探索对于特定 LLM 应用的最优多智能体对话流。</li>
<li>为构建针对不同应用的强大智能体提供系统性的参考，建立大规模开源知识库，建立具备自主学习和升级技能的智能体。</li>
<li>评估极度复杂的任务能否通过多智能体对话的方法有效解决。</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="部署对话式搜索引擎"><a class="header" href="#部署对话式搜索引擎">部署对话式搜索引擎</a></h1>
<p>对话式搜索引擎（conversational search engine）是利用自然语言处理技术来理解和响应用户查询的下一代搜索引擎。与传统的基于关键字的搜索引擎不同，对话式搜索引擎能够与用户以自然语言对话的形式进行互动，从而提供更为精准和个性化的搜索结果。这种搜索引擎通过分析用户的查询意图和上下文信息，能够提出问题、澄清疑惑，并给出更加直观和详细的回答。</p>
<p>当下（2024 Q1）最火热的对话式搜索引擎产品无疑是 <a target="_blank" rel="noopener noreferrer" href="https://www.perplexity.ai/">Perplexity</a>，但最近广受好评的开源项目 <a target="_blank" rel="noopener noreferrer" href="https://github.com/leptonai/search_with_lepton">Search with Lepton</a> 仅用 ~500 行 Python 代码就实现了类似的功能，其核心逻辑为：</p>
<ol>
<li>获取用户的查询文本，调用传统搜索引擎的 API 以获取上下文，即结果页面的片段（snippets）。</li>
<li>将上下文添加到 system prompt（用于编写回答）中，将查询文本作为 user prompt，调用 LLM 生成回答。</li>
<li>将同样的上下文添加到另一个 system prompt（用于产生关联问题）中，将查询文本作为 user prompt，调用 LLM 生成关联问题。</li>
<li>将上下文、回答和关联问题返回给 UI 以供展示。</li>
<li>（可选）将当次查询结果存储到数据库中，若用户再次进行相同的查询则直接返回该结果。</li>
</ol>
<p>用户也可以在平台上方便地部署和使用这项功能！项目 <a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/search_with_lepton"><code>t9k/search_with_lepton</code></a> fork 了 Search with Lepton 项目并进行了以下修改：</p>
<ul>
<li>移除使用 Lepton AI 云服务的代码。</li>
<li>增加 Dockerfile 并构建镜像 <code>t9kpublic/search-with-lepton</code>。</li>
</ul>
<p>本示例使用 Kubernetes 原生资源和 TensorStack 资源部署该修改后的对话式搜索引擎应用，系统架构如下图所示：</p>
<figure class="architecture">
  <img alt="architecture" src="examples/../assets/examples/deploy-conversational-search-engine/resources.drawio.svg" class="architecture">
  <figcaption>图 1：在平台上实现的对话式搜索引擎的系统架构。</figcaption>
</figure>
<p>创建的资源如下表所示：</p>
<div class="table-wrapper"><table><thead><tr><th>类型</th><th>名称</th><th>作用</th><th>备注</th></tr></thead><tbody>
<tr><td>PVC</td><td><code>search</code></td><td>存储代码和模型文件</td><td>卷大小为 <code>180Gi</code></td></tr>
<tr><td>MLServiceRuntime</td><td><code>vllm-openai-2xtp </code></td><td>定义 LLM 推理服务的模板</td><td></td></tr>
<tr><td>MLService</td><td><code>mixtral-8x7b </code></td><td>部署 LLM 推理服务</td><td>计算资源为 <code>{&quot;limits&quot;:{&quot;cpu&quot;: 4, &quot;memory&quot;: &quot;64Gi&quot;, &quot;nvidia.com/gpu&quot;: 2}, &quot;requests&quot;: {}}</code></td></tr>
<tr><td>Secret</td><td><code>search</code></td><td>存储搜索引擎的 API key</td><td></td></tr>
<tr><td>Deployment</td><td><code>search</code></td><td>部署对话式搜索服务</td><td>计算资源为 <code>{&quot;limits&quot;:{&quot;cpu&quot;: 2, &quot;memory&quot;: &quot;8Gi&quot;}, &quot;requests&quot;: {}}</code></td></tr>
<tr><td>Service</td><td><code>search</code></td><td>暴露服务</td><td></td></tr>
</tbody></table>
</div>
<h2 id="准备-8"><a class="header" href="#准备-8">准备</a></h2>
<p>在项目中创建一个名为 <code>search</code>、大小 180 GiB 以上的 PVC，然后创建一个同样名为 <code>search</code> 的 Notebook 挂载该 PVC（镜像类型和模板不限）。</p>
<p>进入 Notebook 或远程连接到 Notebook，启动一个终端，执行以下命令以克隆 <a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/examples"><code>t9k/examples</code></a> 仓库：</p>
<pre><code class="language-bash">cd ~
git clone https://github.com/t9k/examples.git
</code></pre>
<h2 id="部署-3"><a class="header" href="#部署-3">部署</a></h2>
<h3 id="llm-推理服务"><a class="header" href="#llm-推理服务">LLM 推理服务</a></h3>
<aside class="note tip">
<div class="title">提示</div>
<p>以下部署 LLM 推理服务的步骤来自<a href="examples/./deploy-llm-using-vllm.html">使用 vLLM 部署 LLM 推理服务</a>。本示例以 Mixtral 8x7B 模型为例，计算资源需求接近于 70B 的 Code Llama 模型。</p>
</aside>
<p>继续使用 Notebook 的终端，执行以下命令以下载 
Mixtral-8x7B-Instruct-v0.1 的模型文件：</p>
<pre><code class="language-bash"># 方法 1：如果可以直接访问 huggingface
huggingface-cli download mistralai/Mixtral-8x7B-Instruct-v0.1 \
  --local-dir Mixtral-8x7B-Instruct-v0.1 --local-dir-use-symlinks False

# 方法 2：对于国内用户，访问 modelscope 网络连通性更好
pip install modelscope
python -c \
  &quot;from modelscope import snapshot_download; snapshot_download('AI-ModelScope/Mixtral-8x7B-Instruct-v0.1')&quot;
mv .cache/modelscope/hub/AI-ModelScope/Mixtral-8x7B-Instruct-v0.1 .
</code></pre>
<aside class="note info">
<div class="title">Mixtral 8x7B 模型</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://mistral.ai/news/mixtral-of-experts/">Mixtral 8x7B</a> 是一个高质量的稀疏专家混合模型（SMoE），在大部分基准测试中与 Llama 2 70B 和 GPT-3.5 相当或更胜一筹。与 Mixtral 8x7B 一同发布的还有 Mixtral 8x7B Instruct，这是一个经过有监督微调和 DPO 优化的模型，旨在精确遵循指令，性能与 GPT-3.5 相当。更多信息请参阅<a target="_blank" rel="noopener noreferrer" href="https://mistral.ai/news/mixtral-of-experts/">官方博客</a>。</p>
</aside>
<p>然后使用 vLLM 部署兼容 OpenAI API 的 LLM 推理服务。使用以下 YAML 配置文件创建 MLServiceRuntime：</p>
<pre><code class="language-bash">cd examples/applications/search
kubectl apply -f mlservice-runtime.yaml
</code></pre>
<p>再使用以下 YAML 配置文件创建 MLService 以部署服务（必要时修改 <a href="examples/../references/api-reference/mlservice.html#schedulepolicy"><code>spec.scheduler</code></a> 字段以使用 <code>t9k-scheduler</code> 及特定的队列）：</p>
<pre><code class="language-bash">kubectl create -f mlservice.yaml
</code></pre>
<h3 id="搜索服务"><a class="header" href="#搜索服务">搜索服务</a></h3>
<p>在以下 YAML 配置文件中提供所调用搜索引擎的 API key，使用它创建 Secret：</p>
<pre><code class="language-bash"># 修改 secret.yaml
kubectl apply -f secret.yaml
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>请参阅 <a target="_blank" rel="noopener noreferrer" href="https://github.com/leptonai/search_with_lepton/tree/main?tab=readme-ov-file#setup-search-engine-api">Setup Search Engine API</a> 以获取相应搜索引擎后端的 API key 或 subscription key。</p>
</aside>
<p>在以下 YAML 配置文件中提供环境变量，使用它创建 Deployment：</p>
<pre><code class="language-bash"># 修改 deployment.yaml
kubectl create -f deployment.yaml
</code></pre>
<p>然后为 Deployment 创建 Service：</p>
<pre><code class="language-bash">kubectl create -f service.yaml
</code></pre>
<h2 id="使用-89"><a class="header" href="#使用-89">使用</a></h2>
<p>在本地的终端中，使用 <a href="examples/../tools/cli-t9k-pf/index.html">t9k-pf 命令行工具</a>，将服务的 8080 端口转发到本地的 8080 端口：</p>
<pre><code class="language-bash">t9k-pf service search 8080:8080 -n &lt;PROJECT NAME&gt;
</code></pre>
<p>然后使用浏览器访问 <a target="_blank" rel="noopener noreferrer" href="http://127.0.0.1:8080">http://127.0.0.1:8080</a>，搜索以下问题：</p>
<ol>
<li>when will nvidia RTX 5000 series be released?</li>
<li>二进制小品是什么</li>
<li>武汉火车站是否已经恢复正常运行</li>
</ol>
<p>需要说明的是，这里对话式搜索引擎所使用的搜索引擎后端是 Bing，调用的 LLM 是 <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1">Mixtral-8x7B-Instruct-v0.1</a>。以下搜索于 2024 年 2 月 8 日进行。</p>
<figure class="screenshot">
  <img alt="search-with-lepton-q1" src="examples/../assets/examples/deploy-conversational-search-engine/search-with-lepton-q1.png" />
</figure>
<figure class="screenshot">
  <img alt="search-with-lepton-q2" src="examples/../assets/examples/deploy-conversational-search-engine/search-with-lepton-q2.png" />
</figure>
<figure class="screenshot">
  <img alt="search-with-lepton-q3" src="examples/../assets/examples/deploy-conversational-search-engine/search-with-lepton-q3.png" />
</figure>
<p>作为比较，我们在 <a target="_blank" rel="noopener noreferrer" href="https://www.perplexity.ai/">Perplexity</a> 搜索相同的问题：</p>
<figure class="screenshot">
  <img alt="perplexity-q1" src="examples/../assets/examples/deploy-conversational-search-engine/perplexity-q1.png" />
</figure>
<figure class="screenshot">
  <img alt="perplexity-q2" src="examples/../assets/examples/deploy-conversational-search-engine/perplexity-q2.png" />
</figure>
<figure class="screenshot">
  <img alt="perplexity-q3" src="examples/../assets/examples/deploy-conversational-search-engine/perplexity-q3.png" />
</figure>
<p>可以看到，该应用的回答基本准确且详细，但存在以下问题：</p>
<ol>
<li>
<p>尽管该应用可以理解中文查询和上下文，但它仅以英文回复，这是因为其调用的 Mixtral 8x7B 模型<a target="_blank" rel="noopener noreferrer" href="https://mistral.ai/news/mixtral-of-experts">仅支持英语和一些欧洲语言</a>。用户可以自行尝试调用其他支持中文的 LLM。</p>
</li>
<li>
<p>在回答问题 2 时，应用给出的解释“It is a form of light and humorous artistic work that explores the characteristics, applications, nad computer-related topics of binary.（它是一种轻松幽默的艺术作品形式，探索了二进制的特征、应用和与计算机相关的话题。）”存在明显误解，追溯其引用的<a target="_blank" rel="noopener noreferrer" href="https://zhidao.baidu.com/question/274974338041104445.html">参考源</a>，我们发现该来源的解释就存在错误，且很有可能是由另一个 LLM 产生的虚构的信息。这提示我们在对话式搜索引擎中，搜索的准确性比内容生成更为关键，凸显了优化获取和处理上下文信息步骤的重要性。</p>
</li>
</ol>
<p>相比之下，Perplexity 支持中文，并且生成回答的速度更快。尽管如此，其回答的质量并没有更好，尤其是对于问题 2 的回答出现了问题，完全没有引用参考源，而是由 LLM 直接生成的。其对于问题 3 的回答所包含的有用信息也较少。</p>
<h2 id="参考-18"><a class="header" href="#参考-18">参考</a></h2>
<ul>
<li>GitHub 上的 <a target="_blank" rel="noopener noreferrer" href="https://github.com/leptonai/search_with_lepton">Search with Lepton</a> 原项目，以及 fork 项目 <a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/search_with_lepton">t9k/search_with_lepton</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://www.perplexity.ai/">Perplexity</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://mistral.ai/news/mixtral-of-experts/">Mistral AI News: Mixtral of experts</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="部署-stable-diffusion-图像生成模型"><a class="header" href="#部署-stable-diffusion-图像生成模型">部署 Stable Diffusion 图像生成模型</a></h1>
<p>自扩散模型问世以来，AI 绘图应用在艺术、设计和创意领域取得了显著的突破和广泛的应用。在 TensorStack 平台上，用户可以使用 <a href="examples/../modules/deployment/simplemlservice.html">SimpleMLService</a> 和 <a href="examples/../modules/deployment/mlservice.html">MLService</a> 方便地部署各种基于图像生成模型的服务或应用。</p>
<p>本示例使用 SimpleMLService 快速部署一个基于 Stable Diffusion 图像生成模型的绘图应用。</p>
<h2 id="模型"><a class="header" href="#模型">模型</a></h2>
<p>在项目中创建一个名为 <code>draw</code>、大小 50 GiB 以上的 PVC，然后创建一个同样名为 <code>draw</code> 的 Notebook 挂载该 PVC（镜像类型和模板不限）。</p>
<p>进入 Notebook 或远程连接到 Notebook，启动一个终端，执行下列命令以下载 Stable Diffusion、VAE、LoRA 等模型的文件：</p>
<pre><code class="language-bash">mkdir sd
wget https://civitai.com/api/download/models/30163 \
  -O sd/anything-v5-PrtRE.safetensors
wget https://civitai.com/api/download/models/57618 \
  -O sd/CounterfeitV30_v30.safetensors
wget https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned.safetensors \
  -O sd/v1-5-pruned.safetensors

mkdir lora
wget https://civitai.com/api/download/models/87153 \
  -O lora/more_details.safetensors

mkdir vae
wget https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors \
  -O vae/vae-ft-mse-840000-ema-pruned.safetensors

mkdir outputs
</code></pre>
<p>最终目录结构如下：</p>
<pre><code>.
├── lora
│   └── more_details.safetensors
├── outputs (用于放置模型输出)
├── sd
│   ├── anything-v5-PrtRE.safetensors
│   ├── CounterfeitV30_v30.safetensors
│   └── v1-5-pruned.safetensors
└── vae
    └── vae-ft-mse-840000-ema-pruned.safetensors
</code></pre>
<p>Stable Diffusion 生成图片的简化流水线如下图所示，具体包含三个主要步骤：</p>
<ol>
<li>CLIP 模型为输入的 prompt 生成文件嵌入；</li>
<li>U-Net 反复地去除 latent 表示中的噪音；</li>
<li>VAE 将 latent 表示解码为最终的图片。</li>
</ol>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="sd-pipeline" src="examples/../assets/examples/deploy-sd-drawing-model/sd-pipeline.png" style="display: block; margin-left: auto; margin-right: auto; width: 90%"/>
</figure>
<p>我们前面所下载的模型文件中：</p>
<ul>
<li>Stable Diffusion 模型提供图中的 U-Net 和 VAE 模型。</li>
<li>VAE 用于替换现有 Stable Diffusion 模型的 VAE。VAE 会影响图片的风格以及细节处理。</li>
<li>LoRA 用于更新 CLIP 和 U-Net 的权重。使用 LoRA 会应用微调过程中对模型的修改，以生成特定内容或风格的图片。</li>
</ul>
</aside>
<aside class="note info">
<div class="title">信息</div>
<p>用户可以前往 <a target="_blank" rel="noopener noreferrer" href="https://huggingface.co/models">Hugging Face</a> 或 <a target="_blank" rel="noopener noreferrer" href="https://civitai.com/">Civitai</a> 获取更多图像生成模型。</p>
<p>想要更深入地了解 Stable Diffusion 模型的机制，可以参阅 <a target="_blank" rel="noopener noreferrer" href="https://stable-diffusion-art.com/how-stable-diffusion-work/">How does Stable Diffusion work?</a>。</p>
</aside>
<h2 id="部署-4"><a class="header" href="#部署-4">部署</a></h2>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">stable-diffusion-webui</a> 是一个用于运行 Stable Diffusion 模型的 gradio web UI。bilibili 用户“秋葉aaaki”基于这一项目制作了<a target="_blank" rel="noopener noreferrer" href="https://www.bilibili.com/video/BV1iM4y1y7oA">整合包</a>。这里使用它来部署上述模型。</p>
<p>使用以下 YAML 配置文件创建 SimpleMLService（必要时修改 <code>spec.scheduler.t9kScheduler.queue</code> 字段指定的队列）：</p>
<details><summary><code class="hljs">smls.yaml</code></summary>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: SimpleMLService
metadata:
  name: stable-diffusion-webui
spec:
  replicas: 1
  scheduler:
    t9kScheduler:
      queue: default
  service:
    type: ClusterIP
    ports:
    - targetPort: 7860
      port: 7860
  custom:
    spec:
      containers:
      - name: server
        image: t9kpublic/stable-diffusion-webui:aki-v4
        args:
          - --skip-install
          - --listen
        ports:
        - containerPort: 7860
        resources:
          limits:
            cpu: 4
            memory: 64Gi
            nvidia.com/gpu: 1
        volumeMounts:
          - mountPath: /workspace/sd-webui-aki-v4/models/Stable-diffusion
            name: data
            subPath: sd
          - mountPath: /workspace/sd-webui-aki-v4/models/VAE
            name: data
            subPath: vae
          - mountPath: /workspace/sd-webui-aki-v4/models/Lora
            name: data
            subPath: lora
          - mountPath: /workspace/sd-webui-aki-v4/outputs
            name: data
            subPath: outputs
          - mountPath: /dev/shm
            name: dshm
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: draw
        - name: dshm
          emptyDir:
            medium: Memory
</code></pre>
</details>
<pre><code class="language-bash">kubectl create -f smls.yaml
</code></pre>
<h2 id="启动"><a class="header" href="#启动">启动</a></h2>
<p>查看 SimpleMLService 创建的 Pod 打印的日志：</p>
<pre><code class="language-bash">kubectl logs -l deployment=managed-simplemlservice-stable-diffusion-webui -f --tail -1
</code></pre>
<figure class="screenshot">
  <img alt="service-log" src="examples/../assets/examples/deploy-sd-drawing-model/service-log.png" />
</figure>
<p>接下来就可以开始生成图片了！</p>
<h2 id="生成图片"><a class="header" href="#生成图片">生成图片</a></h2>
<p>在本地的终端中，使用 <a href="examples/../tools/cli-t9k-pf/index.html">t9k-pf 命令行工具</a>，将 SimpleMLService 创建的服务的 7860 端口转发到本地的 7860 端口：</p>
<pre><code class="language-bash">t9k-pf service stable-diffusion-webui 7860:7860 -n &lt;PROJECT NAME&gt;
</code></pre>
<figure class="screenshot">
  <img alt="pf" src="examples/../assets/examples/deploy-sd-drawing-model/pf.png" class="screenshot", style="width: 72%"/>
</figure>
<p>然后使用浏览器访问 <code>127.0.0.1:7860</code>，绘制喜欢的图片：</p>
<figure class="screenshot">
  <img alt="webui" src="examples/../assets/examples/deploy-sd-drawing-model/webui.png" />
</figure>
<p>生成的图片可以通过 Web UI 下载，同时也会保存到 PVC 的 <code>outputs/</code> 路径下。</p>
<h2 id="画廊"><a class="header" href="#画廊">画廊</a></h2>
<p>这里展示一些最终生成的图片：</p>
<p><br><br></p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="img1" src="examples/../assets/examples/deploy-sd-drawing-model/img1.png" style="display: block; margin-left: auto; margin-right: auto;"/>
</figure>
<table>
  <tr>
    <td>模型</td>
    <td>v1-5-pruned.safetensors, vae-ft-mse-840000-ema-pruned.safetensors</td>
  </tr>
  <tr>
    <td>生成数据</td>
    <td>alpaca, plateau, mountain, realistic, 
Steps: 20, Sampler: DPM++ 2M Karras, CFG scale: 7, Seed: 2642782115, Size: 512x512, Model hash: 1a189f0be6, Model: v1-5-pruned, Clip skip: 2, ENSD: 31337</td>
  </tr>
</table>
<p><br><br></p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="img2" src="examples/../assets/examples/deploy-sd-drawing-model/img2.png" style="display: block; margin-left: auto; margin-right: auto;"/>
</figure>
<table>
  <tr>
    <td>模型</td>
    <td>CounterfeitV30_v30.safetensors, vae-ft-mse-840000-ema-pruned.safetensors</td>
  </tr>
  <tr>
    <td>生成数据</td>
    <td>(masterpiece, best quality),1girl, solo, flower, long hair, outdoors, letterboxed, school uniform, day, sky, looking up, short sleeves, parted lips, shirt, cloud, black hair, sunlight, white shirt, serafuku, upper body, from side, pink flower, blurry, brown hair, blue sky, depth of field
Negative prompt: EasyNegativeV2
Steps: 25, ENSD: 31337, Size: 1024x512, Seed: 2311942344, Model: CF5_Counterfeit-V3.0_fix_fix_fix, Sampler: DPM++ 2M Karras, CFG scale: 10, Clip skip: 2, Model hash: db6cd0a62d, Hires upscale: 2, Hires upscaler: R-ESRGAN 4x+ Anime6B, Denoising strength: 0.45</td>
  </tr>
</table>
<p><br><br></p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="img3" src="examples/../assets/examples/deploy-sd-drawing-model/img3.png" style="display: block; margin-left: auto; margin-right: auto;"/>
</figure>
<table>
  <tr>
    <td>模型</td>
    <td>anything-v5-PrtRE.safetensors, vae-ft-mse-840000-ema-pruned.safetensors</td>
  </tr>
  <tr>
    <td>生成数据</td>
    <td>masterpiece, best quality, scenery, whale, fish, starry sky, galaxy, cosmos, fantasy, floating object|fish, backlight, shadow
Negative prompt: (low quality, worst quality:1.4), (bad anatomy)，easynegative
Steps: 20, Size: 1024x512, Seed: 3421647346, Sampler: DPM++ 2M Karras, CFG scale: 8</td>
  </tr>
</table>
<p><br><br></p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="img4" src="examples/../assets/examples/deploy-sd-drawing-model/img4.png" style="display: block; margin-left: auto; margin-right: auto; width: 40%"/>
</figure>
<table>
  <tr>
    <td>模型</td>
    <td>anything-v5-PrtRE.safetensors, vae-ft-mse-840000-ema-pruned.safetensors</td>
  </tr>
  <tr>
    <td>生成数据</td>
    <td>masterpiece, best quality, best 8k wallpaper, chibi, 1girl, official, solo, silver hair, ponytail, blush, smile, head, sunglasses, white background, pixel, (pixel art)
Negative prompt: badhandv4,EasyNegative
Steps: 80, Sampler: DPM++ 2M Karras, CFG scale: 9, Seed: 1362619635, Size: 512x512, Model hash: 7f96a1a9ca, Model: anything-v5-PrtRE, ENSD: 31337</td>
  </tr>
</table>
<p><br><br></p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="img5" src="examples/../assets/examples/deploy-sd-drawing-model/img5.png" style="display: block; margin-left: auto; margin-right: auto; width: 60%"/>
</figure>
<table>
  <tr>
    <td>模型</td>
    <td>anything-v5-PrtRE.safetensors, vae-ft-mse-840000-ema-pruned.safetensors</td>
  </tr>
  <tr>
    <td>生成数据</td>
    <td>greyscale, monochrome, no humans, tree, scenery, traditional media, tower, building, outdoors
Negative prompt: EasyNegative
Steps: 20, Sampler: DPM++ SDE Karras, CFG scale: 7, Seed: 2579617703, Size: 512x768, Model hash: 7f96a1a9ca, Model: anything-v5-PrtRE, Denoising strength: 0.7, Clip skip: 2, ENSD: 31337, Hires upscale: 2, Hires upscaler: Latent</td>
  </tr>
</table>
<p><br><br></p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="img6" src="examples/../assets/examples/deploy-sd-drawing-model/img6.png" style="display: block; margin-left: auto; margin-right: auto; width: 60%"/>
</figure>
<table>
  <tr>
    <td>模型</td>
    <td>anything-v5-PrtRE.safetensors, vae-ft-mse-840000-ema-pruned.safetensors</td>
  </tr>
  <tr>
    <td>生成数据</td>
    <td>Monet style, beach, boat, cloud, sky, traditional media, water, watercraft, (masterpiece:1,2), best quality, masterpiece, highres, original, extremely detailed wallpaper, perfect lighting,(extremely detailed CG:1.2), drawing, paintbrush,
Negative prompt: NSFW, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, age spot, (ugly:1.331), (duplicate:1.331), (morbid:1.21), (mutilated:1.21), (tranny:1.331), mutated hands, (poorly drawn hands:1.5), blurry, (bad anatomy:1.21), (bad proportions:1.331), extra limbs, (disfigured:1.331), (missing arms:1.331), (extra legs:1.331), (fused fingers:1.61051), (too many fingers:1.61051), (unclear eyes:1.331), lowers, bad hands, missing fingers, extra digit,bad hands, missing fingers, (((extra arms and legs))),
Steps: 36, Sampler: Euler a, CFG scale: 4.5, Seed: 2739912422, Size: 512x768, Model hash: 7f96a1a9ca, Model: anything-v5-PrtRE, Denoising strength: 0.7, Clip skip: 3, ENSD: 31337, Hires upscale: 2, Hires upscaler: Latent</td>
  </tr>
</table>
<p><br><br></p>
<figure style="display: block; margin-left: auto; margin-right: auto;">
  <img alt="img7" src="examples/../assets/examples/deploy-sd-drawing-model/img7.png" style="display: block; margin-left: auto; margin-right: auto;"/>
</figure>
<table>
  <tr>
    <td>模型</td>
    <td>anything-v5-PrtRE.safetensors, vae-ft-mse-840000-ema-pruned.safetensors</td>
  </tr>
  <tr>
    <td>生成数据</td>
    <td>digital painting, best quality, magic, cyberpunk, city, street, neon, mystic, <lora:more_details:1>
Negative prompt: (worst quality:1.2), (low quality:1.2), (lowres:1.1), (monochrome:1.1), (greyscale), multiple views, comic, sketch, watermark, multiple_views
Steps: 150, Sampler: PLMS, CFG scale: 7, Seed: 2300531334, Size: 768x512, Model hash: 7f96a1a9ca, Model: anything-v5-PrtRE, Clip skip: 2, ENSD: 31337
</td>
  </tr>
</table>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="车道检测"><a class="header" href="#车道检测">车道检测</a></h1>
<p>车道检测是计算机视觉和自动驾驶领域的一项关键技术，旨在识别和跟踪道路上的车道线。这个任务对于实现车辆的自动驾驶和辅助驾驶系统至关重要，因为它能够帮助车辆理解其在道路上的位置，保持车道，并执行如车道保持、车道变换等操作。</p>
<p><img src="examples/../assets/examples/lane-detection/lane-detection.jpg" alt="lane-detection" /></p>
<p>本示例使用 PyTorchTrainingJob 训练一个车道检测模型。</p>
<h2 id="准备-9"><a class="header" href="#准备-9">准备</a></h2>
<p>在项目中创建一个名为 <code>lanedet</code>、大小 50 GiB 以上的 PVC，然后创建一个同样名为 <code>lanedet</code> 的 Notebook 挂载该 PVC（镜像类型和模板不限）。</p>
<p>进入 Notebook 或远程连接到 Notebook，启动一个终端，执行以下命令以克隆 <a target="_blank" rel="noopener noreferrer" href="https://github.com/t9k/examples"><code>t9k/examples</code> 仓库</a>：</p>
<pre><code class="language-bash">cd ~
git clone https://github.com/t9k/examples.git
</code></pre>
<aside class="note info">
<div class="title">训练代码</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/Turoad/lanedet">LaneDet</a> 是一个基于 PyTorch 的开源车道检测工具箱，旨在汇集多种最先进的车道检测模型。开发者可以复现这些最先进的方法，并构建他们自己的方法。</p>
<p>本示例的代码位于 <code>t9k/examples</code> 仓库的 <code>lanedet/</code> 路径下，其在 LaneDet 原项目的基础上进行了一些修改，包括用 PyTorch 原生的数据并行训练替换 MMCV 提供的数据并行训练，以及提供 PyTorchTrainingJob 的 YAML 配置文件以启动训练。</p>
</aside>
<p>继续执行以下命令以从 kaggle 下载 TuSimple 数据集并解压，其中 <code>kaggle.json</code> 文件需要登录 kaggle 获取。完整的操作步骤可以参阅博客 <a target="_blank" rel="noopener noreferrer" href="https://www.endtoend.ai/tutorial/how-to-download-kaggle-datasets-on-ubuntu/">How to Download Kaggle Datasets on Ubuntu</a>。</p>
<pre><code class="language-bash">pip install kaggle

# 在浏览器中登录 kaggle，在账户设置页面创建新的 token 以生成 kaggle.json 文件，将其上传到 Notebook
mkdir ~/.kaggle
mv kaggle.json ~/.kaggle

kaggle datasets download manideep1108/tusimple
unzip tusimple.zip
</code></pre>
<aside class="note info">
<div class="title">TuSimple 数据集</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://www.kaggle.com/datasets/manideep1108/tusimple?resource=download">TuSimple</a> 数据集包含了 6,408 张美国高速公路上的道路图像，图像的分辨率为 1280×720。该数据集包括了 3,626 张用于训练的图像和 2,782 张用于测试的图像。</p>
</aside>
<h2 id="训练"><a class="header" href="#训练">训练</a></h2>
<p>使用如下 YAML 配置文件创建 PyTorchTrainingJob 以启动训练。该 PyTorchTrainingJob 创建 2 个副本，每个副本启动 2 个进程，每个进程使用 1 个 GPU。</p>
<pre><code class="language-bash">kubectl create -f examples/lanedet/t9k/job.yaml
</code></pre>
<p>通过以下命令查看训练过程中打印的日志：</p>
<pre><code class="language-bash">export POD=$(kubectl get pj lanedet -o jsonpath=&quot;{.status.tasks[0].replicas[0].name}&quot;)
kubectl logs $POD -f
</code></pre>
<figure class="screenshot">
  <img alt="log" src="examples/../assets/examples/lane-detection/log.png" />
</figure>
<p>训练共进行 100 个 epoch，每个 epoch 结束时进行验证（使用测试图像作为验证集），计算准确率、假阳性率和假阴性率。训练完成之后，模型文件将保存到 <code>output/TuSimple/0/*/</code> 路径下。训练花费约 3 小时，最终准确率可以达到约 0.94。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="集成"><a class="header" href="#集成">集成</a></h1>
<p>平台支持集成第三方应用，用户可以在自己的项目中使用 Helm 轻松快速地部署各种丰富的第三方应用，例如部署一个 GitLab 以托管私有代码，部署一个 Label Studio 以进行数据标注等。</p>
<aside class="note info">
<div class="title">Helm</div>
<p><a target="_blank" rel="noopener noreferrer" href="https://helm.sh/">Helm</a> 是 Kubernetes 的包管理工具，用于简化 Kubernetes 应用程序的部署和管理，其作用类似于 Linux 中的 apt 或 yum。Helm 通过将 Kubernetes 资源和配置封装为 Chart，提供了一种高效、一致的方式来部署和管理应用。</p>
<p>如要了解 Helm 的基本概念和使用方法，请参阅 Helm 的<a target="_blank" rel="noopener noreferrer" href="https://helm.sh/docs/">文档</a>。如要寻找可用的 Kubernetes 包（Helm Charts），请访问 <a target="_blank" rel="noopener noreferrer" href="https://artifacthub.io/packages/search">Artifact Hub</a>。</p>
<p>平台提供的 Notebook 标准镜像预装了 Helm，接下来的应用部署和管理操作都将在 Notebook 中进行。</p>
</aside>
<p>这一部分将介绍一些与机器学习相关的常用第三方应用的部署流程和使用方法。在开始之前，先确定在哪一个项目中部署应用，在该项目中创建一个名为 <code>app</code>、大小 1 GiB 的 PVC，然后创建一个同样名为 <code>app</code> 的 Notebook 挂载该 PVC（镜像类型和模板不限）。</p>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="label-studio"><a class="header" href="#label-studio">Label Studio</a></h1>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/HumanSignal/label-studio">Label Studio</a> 是一个开源的数据标注工具。它允许用户通过一个简单直观的用户界面来标注音频、文本、图像、视频和时间序列等多种数据类型，并支持导出到各种模型格式。</p>
<h2 id="部署-5"><a class="header" href="#部署-5">部署</a></h2>
<h3 id="安装与配置"><a class="header" href="#安装与配置">安装与配置</a></h3>
<p>进入 Notebook <code>app</code> 的终端，添加相应的 Helm Chart repository，列出 Chart <code>heartex/label-studio</code> 的所有版本：</p>
<pre><code class="language-bash">helm repo add heartex https://charts.heartex.com/

# 注意 CHART VERSION 和 APP VERSION（Label Studio 版本）之间的对应关系
# 例如 CHART VERSION 1.4.0 和 1.3.4 中的 Label Studio 版本都是 1.11.0
helm search repo heartex/label-studio --versions
</code></pre>
<p>安装指定版本的 Chart <code>heartex/label-studio</code> 以部署 Label Studio 应用：</p>
<pre><code class="language-bash"># 安装最新版本
helm repo update heartex
helm install label-studio-demo heartex/label-studio

# 安装指定 CHART VERSION，注意这不是 APP VERSION（Label Studio 版本）
helm install label-studio-demo heartex/label-studio --version &lt;CHART_VERSION&gt;
</code></pre>
<p>以上安装全部使用默认配置，完整的默认配置请参阅相应的 <code>values.yaml</code>：</p>
<pre><code class="language-bash"># 获取指定 CHART VERSION 的 values.yaml
helm show values heartex/label-studio --version &lt;CHART_VERSION&gt; &gt; values.yaml
</code></pre>
<p>其中部分关键配置如下所示（CHART VERSION 1.4.0）：</p>
<pre><code class="language-yaml">app:
  replicas: 1        # 副本数

  resources:         # 计算资源
    limits: {}
    requests: {}

  ingress:           # Ingress 配置
    enabled: false
    annotations: {}
    className: &quot;&quot;
    host: &quot;&quot;
    tls: []

global:
  persistence:       # 持久化
    config:
      volume:
        accessModes:
        - ReadWriteOnce
        annotations: {}
        existingClaim: &quot;&quot;
        resourcePolicy: &quot;&quot;
        size: 10Gi       # 卷大小
        storageClass: &quot;&quot;
    enabled: true
    type: volume         # 卷
</code></pre>
<p>你可以根据需要对这些配置进行修改：</p>
<ul>
<li>如果想要提高容错，可以增加副本数。</li>
<li>可以根据实际需求指定计算资源的请求值和限制值。</li>
<li>可以提供 Ingress 配置以提供外部访问，请参阅 <a target="_blank" rel="noopener noreferrer" href="https://labelstud.io/guide/ingress_config">Set up an ingress controller for Label Studio Kubernetes deployments</a>。</li>
<li>可以修改卷大小，或使用其他类型的持久化方案（如 Amazon S3），请参阅 <a target="_blank" rel="noopener noreferrer" href="https://labelstud.io/guide/persistent_storage">Set up persistent storage</a>。</li>
</ul>
<aside class="note">
<div class="title">注意</div>
<p>Ingress 配置也可以采用其他方案，需要结合集群的具体配置。</p>
</aside>
<p>然后将新配置（覆盖默认配置的部分）保存为一个 YAML 文件，通过 <code>-f</code> 选项提供给安装命令：</p>
<pre><code class="language-bash"># 使用修改后的 values.yaml
helm install label-studio-demo heartex/label-studio --version &lt;CHART_VERSION&gt; -f values.yaml
</code></pre>
<h3 id="应用架构"><a class="header" href="#应用架构">应用架构</a></h3>
<p>应用的系统架构如下图所示（CHART VERSION 1.4.0，默认配置）：</p>
<figure class="architecture">
  <img alt="architecture" src="integrations/../assets/integrations/label-studio/microservice.drawio.svg" class="architecture">
</figure>
<p>创建的主要 Kubernetes 资源如下表所示：</p>
<div class="table-wrapper"><table><thead><tr><th>类型</th><th>名称</th><th>作用</th><th>备注</th></tr></thead><tbody>
<tr><td>Service</td><td>label-studio-demo-ls-app</td><td>暴露 Label Studio 服务</td><td></td></tr>
<tr><td>Deployment</td><td>label-studio-demo-ls-app</td><td>部署 Label Studio</td><td>默认计算资源为 <code>{&quot;limits&quot;: {}, &quot;requests&quot;: {}}</code></td></tr>
<tr><td>PVC</td><td>label-studio-demo-ls-pvc</td><td>作为 Label Studio 的持久化存储，存储用户上传的数据文件等</td><td>选择卷作为持久化方案时存在；默认卷大小为 <code>10Gi</code></td></tr>
<tr><td>Secret</td><td>label-studio-demo-postgresql</td><td>存储数据库密钥</td><td></td></tr>
<tr><td>Service</td><td>label-studio-demo-postgresql</td><td>暴露数据库服务</td><td></td></tr>
<tr><td>StatefulSet</td><td>label-studio-demo-postgresql</td><td>部署数据库</td><td>默认计算资源为 <code>{&quot;limits&quot;: {}, &quot;requests&quot;: {&quot;cpu&quot;: &quot;250m&quot;, &quot;memory&quot;: &quot;256Mi&quot;}}</code></td></tr>
<tr><td>PVC</td><td>data-label-studio-demo-postgresql-*</td><td>作为数据库的持久化存储</td><td>默认卷大小为 <code>8Gi</code></td></tr>
<tr><td>Ingress</td><td>label-studio-demo-ls-app</td><td>提供外部访问</td><td>启用 Ingress 时存在</td></tr>
</tbody></table>
</div>
<h3 id="运维"><a class="header" href="#运维">运维</a></h3>
<p><strong>查看应用的状态</strong></p>
<pre><code class="language-bash">helm status label-studio-demo
</code></pre>
<p><strong>重启应用</strong></p>
<pre><code class="language-bash">kubectl rollout restart deployment/label-studio-demo-ls-app
</code></pre>
<p><strong>更新应用</strong></p>
<pre><code class="language-bash"># 更新到最新版本
helm upgrade label-studio-demo heartex/label-studio

# 更新到指定版本
helm upgrade label-studio-demo heartex/label-studio --version &lt;VERSION_NUMBER&gt;

# 回滚更新，首先查看历史版本
helm history label-studio-demo
helm rollback label-studio-demo [REVISION]
</code></pre>
<p><strong>移除应用</strong></p>
<pre><code class="language-bash">helm delete label-studio-demo
</code></pre>
<h2 id="使用-90"><a class="header" href="#使用-90">使用</a></h2>
<h3 id="基本使用"><a class="header" href="#基本使用">基本使用</a></h3>
<p>如果在部署应用时配置了 Ingress，那么直接在浏览器中访问相应的地址即可，否则需要进行端口转发。在用户的计算机上，前往模型构建控制台获取应用 Pod 的名称（前缀为 label-studio-demo-ls-app-）：</p>
<figure class="screenshot">
  <img alt="get-pod-name" src="integrations/../assets/integrations/label-studio/get-pod-name.png" />
</figure>
<p>然后通过 t9k-pf 进行端口转发来访问 Label Studio 应用：</p>
<pre><code class="language-bash">t9k-pf -n &lt;APP_PROJECT&gt; pod &lt;POD_NAME&gt; 8080:8085
</code></pre>
<p>在浏览器中访问 <a target="_blank" rel="noopener noreferrer" href="http://127.0.0.1:8080/">http://127.0.0.1:8080/</a> 进入应用的 Web UI。注册一个用户，Email 和密码可以任意指定：</p>
<figure class="screenshot">
  <img alt="sign-up" src="integrations/../assets/integrations/label-studio/sign-up.png" />
</figure>
<p>假定任务是图像分类，我们准备了 10 张图片（来自数据集 <a target="_blank" rel="noopener noreferrer" href="https://www.microsoft.com/en-us/download/details.aspx?id=54765">Cats and Dogs</a>），需要将每一张图片标注为猫或狗。点击 <strong>Create Project</strong>：</p>
<figure class="screenshot">
  <img alt="create-project" src="integrations/../assets/integrations/label-studio/create-project.png" />
</figure>
<p>在 Project Name 页面可选地修改 Project 的名称：</p>
<figure class="screenshot">
  <img alt="project-name" src="integrations/../assets/integrations/label-studio/project-name.png" />
</figure>
<p>在 Data Import 页面上传 10 张图片：</p>
<figure class="screenshot">
  <img alt="data-import" src="integrations/../assets/integrations/label-studio/data-import.png" />
</figure>
<figure class="screenshot">
  <img alt="file-uploaded" src="integrations/../assets/integrations/label-studio/file-uploaded.png" />
</figure>
<p>在 Labeling Setup 页面，选择模板 <strong>Computer Vision &gt; Image Classification</strong>，并将选项编辑为 <strong>Cat</strong> 和 <strong>Dog</strong>，最后点击 <strong>Save</strong>：</p>
<figure class="screenshot">
  <img alt="labeling-setup" src="integrations/../assets/integrations/label-studio/labeling-setup.png" />
</figure>
<figure class="screenshot">
  <img alt="config-template" src="integrations/../assets/integrations/label-studio/config-template.png" />
</figure>
<p>自动跳转到 Project 的默认标签页，点击 <strong>Label All Tasks</strong> 以开始标注：</p>
<figure class="screenshot">
  <img alt="task-list" src="integrations/../assets/integrations/label-studio/task-list.png" />
</figure>
<p>对于每一张图片，勾选其为 Cat 或 Dog，然后点击 <strong>Submit</strong>：</p>
<figure class="screenshot">
  <img alt="labeling" src="integrations/../assets/integrations/label-studio/labeling.png" />
</figure>
<p>标注结束后，点击 <strong>Export</strong> 以下载指定格式的标注数据。</p>
<figure class="screenshot">
  <img alt="export" src="integrations/../assets/integrations/label-studio/export.png" />
</figure>
<h3 id="导入大量数据"><a class="header" href="#导入大量数据">导入大量数据</a></h3>
<p>在导入数据时，如果仅上传少量（几十上百个）的文件，那么使用 Web UI 即可。但假设我们要上传数据集 Cats and Dogs 的总共 25000 张图片，仍然使用 Web UI 会导致其崩溃，这时我们需要寻求另外的导入数据的方法。</p>
<p>Label Studio 支持<a target="_blank" rel="noopener noreferrer" href="https://labelstud.io/guide/storage">从外部存储同步数据</a>。这里以 Amazon S3 为例。在用户的计算机上准备好数据文件，并将其上传到 S3 bucket：</p>
<pre><code class="language-bash">$ tree .                                       
.
├── 0.jpg
├── 1.jpg
├── 10.jpg
├── 100.jpg
├── 1000.jpg
├── 10000.jpg
├── 10001.jpg
...
├── 9998.jpg
└── 9999.jpg

0 directories, 25000 files

$ rclone copy -P . corps3:my-bucket/kagglecatsanddogs                                                                        
Transferred:      569.808 MiB / 809.542 MiB, 70%, 2.328 MiB/s, ETA 1m42s                                               
Transferred:        16994 / 25000, 68%                                                                                 
Elapsed time:      3m35.2s                                                                                             
Transferring:                                                                                                          
 *                                      2793.jpg:100% /23.680Ki, 0/s, -                                                
 *                                      2794.jpg:100% /20.700Ki, 0/s, -                                                
 *                                      2795.jpg:100% /22.631Ki, 0/s, -                                                
 *                                      2796.jpg:100% /13.476Ki, 0/s, -
</code></pre>
<p>在 Label Studio 的项目设置中点击 <strong>Cloud Storage &gt; Add Source Storage</strong>，选择存储类型 AWS S3，并填写相关的配置，点击 <strong>Check Connection</strong> 验证连接是否成功，最后点击 <strong>Add Storage</strong>。</p>
<figure class="screenshot">
  <img alt="add-source-storage" src="integrations/../assets/integrations/label-studio/add-source-storage.png" />
</figure>
<figure class="screenshot">
  <img alt="add-source-storage-detail" src="integrations/../assets/integrations/label-studio/add-source-storage-detail.png" />
</figure>
<p>创建完成之后，点击 <strong>Sync Storage</strong>，即可从导入数据文件：</p>
<figure class="screenshot">
  <img alt="sync-storage" src="integrations/../assets/integrations/label-studio/sync-storage.png" />
</figure>
<p>回到项目，可以看到数据被导入：</p>
<figure class="screenshot">
  <img alt="synced" src="integrations/../assets/integrations/label-studio/synced.png" />
</figure>
<h3 id="自定义标注-ui"><a class="header" href="#自定义标注-ui">自定义标注 UI</a></h3>
<p>应用内置了大量标注模板，覆盖了各种类型的机器学习任务。除此之外，用户还可以使用类似 XML 的标签来自定义标注 UI，详细语法规则请参阅 <a target="_blank" rel="noopener noreferrer" href="https://labelstud.io/tags">Customize the Label Studio User Interface</a>。</p>
<figure class="screenshot">
  <img alt="customize-ui" src="integrations/../assets/integrations/label-studio/customize-ui.png" />
</figure>
<figure class="screenshot">
  <img alt="customize-ui-detail" src="integrations/../assets/integrations/label-studio/customize-ui-detail.png" />
</figure>
<h3 id="自动化标注"><a class="header" href="#自动化标注">自动化标注</a></h3>
<p>人工标注数据费时费力，我们可以引入机器学习模型来完成这一工作，这样只需要人工审核即可。</p>
<p>Label Studio 支持添加 ML backend，使用其自动标注或进行在线训练。这里演示使用 <a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/segment-anything">SAM</a> 进行语义分割任务的自动标注。</p>
<p>在应用的 Web UI 点击 <strong>Account &amp; Settings</strong>，以获取用户的 <strong>Access Token</strong>：</p>
<figure class="screenshot">
  <img alt="access-token" src="integrations/../assets/integrations/label-studio/access-token.png" />
</figure>
<p>回到 Notebook <code>app</code> 的终端，获取应用 service 的 IP 地址：</p>
<pre><code class="language-bash">kubectl get svc label-studio-demo-ls-app -o jsonpath=&quot;{.spec.clusterIP}&quot;
</code></pre>
<p>然后使用如下 YAML 配置文件创建 SimpleMLService 以部署 ML backend 服务，其中环境变量 <code>LABEL_STUDIO_HOST</code> 和 <code>LABEL_STUDIO_ACCESS_TOKEN</code> 的值需要根据上面获取的结果进行修改。镜像 <code>t9kpublic/label-studio-sam:main</code> 构建自示例 <a target="_blank" rel="noopener noreferrer" href="https://github.com/HumanSignal/label-studio-ml-backend/tree/master/label_studio_ml/examples/segment_anything_model">Interactive Annotation in Label Studio with Segment Anything Model</a>。</p>
<details><summary><code class="hljs">sam.yaml</code></summary>
<pre><code class="language-yaml">apiVersion: tensorstack.dev/v1beta1
kind: SimpleMLService
metadata:
  name: label-studio-sam
spec:
  replicas: 1
  service:
    type: ClusterIP
    ports:
    - targetPort: 9090
      port: 9090
  custom:
    spec:
      containers:
      - name: server
        image: t9kpublic/label-studio-sam:main
        env:
          - name: SAM_CHOICE
            value: MobileSAM
          - name: LOG_LEVEL
            value: DEBUG
          - name: LABEL_STUDIO_HOST
            value: http://10.233.12.87:80
          - name: LABEL_STUDIO_ACCESS_TOKEN
            value: 381ae0357804f39d01e5d169b8ed0cf548925a57
        ports:
        - containerPort: 9090
        resources:
          limits:
            cpu: 8
            memory: 8Gi
        volumeMounts:
        - mountPath: /dev/shm
          name: dshm
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
</code></pre>
</details>
<pre><code class="language-bash">kubectl create -f sam.yaml
</code></pre>
<aside class="note info">
<div class="title">信息</div>
<p>Label Studio ML backend 还提供了其他模型的示例，请访问 <a target="_blank" rel="noopener noreferrer" href="https://github.com/HumanSignal/label-studio-ml-backend/tree/master/label_studio_ml/examples">examples</a>。用户也可以尝试自己编写一个 ML backend，请参阅 <a target="_blank" rel="noopener noreferrer" href="https://labelstud.io/guide/ml_create">Write your own ML backend</a>。</p>
</aside>
<p>获取 ML backend service 的 IP 地址和端口号：</p>
<pre><code class="language-bash">kubectl get svc label-studio-sam -o jsonpath=&quot;{.spec.clusterIP}&quot;
kubectl get svc label-studio-sam -o jsonpath=&quot;{.spec.ports[0].port}&quot;
</code></pre>
<p>再次进入应用的 Web UI，创建一个新的 project，上传一张图片，并且 template 使用如下自定义模板：</p>
<pre><code class="language-xml">&lt;View&gt;
  &lt;Image name=&quot;image&quot; value=&quot;$image&quot; zoom=&quot;true&quot;/&gt;
  &lt;BrushLabels name=&quot;tag&quot; toName=&quot;image&quot;&gt;
  	&lt;Label value=&quot;Banana&quot; background=&quot;#FF0000&quot;/&gt;
  	&lt;Label value=&quot;Orange&quot; background=&quot;#0d14d3&quot;/&gt;
  &lt;/BrushLabels&gt;
  &lt;KeyPointLabels name=&quot;tag2&quot; toName=&quot;image&quot; smart=&quot;true&quot;&gt;
    &lt;Label value=&quot;Banana&quot; smart=&quot;true&quot; background=&quot;#000000&quot; showInline=&quot;true&quot;/&gt;
    &lt;Label value=&quot;Orange&quot; smart=&quot;true&quot; background=&quot;#000000&quot; showInline=&quot;true&quot;/&gt;
  &lt;/KeyPointLabels&gt;
  &lt;RectangleLabels name=&quot;tag3&quot; toName=&quot;image&quot; smart=&quot;true&quot;&gt;
    &lt;Label value=&quot;Banana&quot; background=&quot;#000000&quot; showInline=&quot;true&quot;/&gt;
    &lt;Label value=&quot;Orange&quot; background=&quot;#000000&quot; showInline=&quot;true&quot;/&gt;
  &lt;/RectangleLabels&gt;
&lt;/View&gt;
</code></pre>
<p>在 Label Studio 的项目设置中点击 <strong>Machine Learning &gt; Add Model</strong>，填写 SAM 服务的 URL 和模型名称，勾选 <strong>Use for interactive preannotations</strong>，然后点击 <strong>Validate and Save</strong>：</p>
<figure class="screenshot">
  <img alt="add-model" src="integrations/../assets/integrations/label-studio/add-model.png" />
</figure>
<figure class="screenshot">
  <img alt="add-model-detail" src="integrations/../assets/integrations/label-studio/add-model-detail.png" />
</figure>
<p>标注时按照下图的顺序进行操作，可以看到图片中的柯基被正确地分割出来：</p>
<figure class="screenshot">
  <img alt="auto-annotation" src="integrations/../assets/integrations/label-studio/auto-annotation.png" />
</figure>
<h3 id="团队协作"><a class="header" href="#团队协作">团队协作</a></h3>
<p>应用提供了简单直接的团队协作方式。团队的多个成员分别注册用户、登录并进入同一个项目，通过设定不同的过滤条件来分别标注全部数据的不同子集。</p>
<p>例如设定 <code>ID / &lt;= / 3000</code> 可以仅列举前 3000 个数据；设定 <code>Annotated by / is empty / yes</code> 可以仅列举未被标注的数据。</p>
<h2 id="参考-19"><a class="header" href="#参考-19">参考</a></h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/HumanSignal/label-studio">GitHub 上的 Label Studio</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://labelstud.io/guide/">Label Studio 文档</a>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://labelstud.io/guide/ingress_config">设置 Ingress 控制器</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://labelstud.io/guide/persistent_storage">设置持久化存储</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://labelstud.io/guide/storage">从外部存储同步数据</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://labelstud.io/guide/setup">标注配置</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://labelstud.io/guide/ml">将 Label Studio 集成你的到机器学习工作流</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://labelstud.io/guide/ml_create.html">构建你自己的 ML backend</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/HumanSignal/label-studio-ml-backend">GitHub 上的 Label Studio ML backend</a>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/HumanSignal/label-studio-ml-backend/tree/master/label_studio_ml/examples">ML backend 示例</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="向量数据库qdrant"><a class="header" href="#向量数据库qdrant">向量数据库：Qdrant</a></h1>
<h2 id="背景"><a class="header" href="#背景">背景</a></h2>
<p>向量数据库是一种专门设计用于存储、索引和检索向量数据的数据库。它适用于处理大规模的高维向量，这些向量通常代表了图像、视频、文本或音频内容的特征，甚至整个世界本身。向量数据库通常用于支持机器学习应用，例如检索增强生成（RAG）、图像检索、推荐系统等。</p>
<p>向量数据库的核心功能是相似度搜索（similarity search），即通过计算向量之间的相似度来快速检索出内容上相似的项目。常用的相似度度量包括欧氏距离、余弦相似度和点积。为了实现高效的大规模相似度搜索，向量数据库通常采用专门的数据结构和索引技术，以及高效的搜索算法（如近似最近邻搜索算法）。以基于检索增强生成的问答应用为例，当用户提出一个问题时，应用会首先将问题转换为向量，然后在向量数据库中检索与该向量相似的向量，即与问题相关的上下文。这些检索到的上下文信息用于增强大型语言模型的回答生成过程，使得生成的答案更为精确和详尽。</p>
<p>目前市面上存在数量众多的向量数据库产品，即便是开源向量数据库也有不少选择，例如 <a target="_blank" rel="noopener noreferrer" href="https://github.com/milvus-io/milvus">Milvus</a>、<a target="_blank" rel="noopener noreferrer" href="https://github.com/qdrant/qdrant">Qdrant</a>、<a target="_blank" rel="noopener noreferrer" href="https://github.com/chroma-core/chroma">Chroma</a>、<a target="_blank" rel="noopener noreferrer" href="https://github.com/weaviate/weaviate">Weaviate</a> 等。关于这些向量数据库的比较，可以参阅博客 <a target="_blank" rel="noopener noreferrer" href="https://thedataquarry.com/posts/vector-db-1/">Vector databases (1): What makes each one different?</a>。</p>
<p><img src="integrations/../assets/integrations/vector-database-qdrant/vector-db-lang.png" alt="vector-db-lang" /></p>
<p>这里以 <a target="_blank" rel="noopener noreferrer" href="https://github.com/qdrant/qdrant">Qdrant</a> 为例进行部署。Qdrant 官方提供了 <a target="_blank" rel="noopener noreferrer" href="https://artifacthub.io/packages/helm/qdrant/qdrant">Helm chart</a>，部署更加简单、便捷。</p>
<p><img src="integrations/../assets/integrations/vector-database-qdrant/qdrant.svg" alt="qdrant" /></p>
<p>Qdrant 的一些特性如下：</p>
<ul>
<li><strong>高效</strong>：有效利用计算资源。Qdrant 完全用 Rust 语言开发，实现了动态查询计划和有效载荷数据索引。也为企业提供了硬件感知的构建版本。</li>
<li><strong>快速且准确</strong>：实现了 HNSW 算法的独特自定义修改，用于近似最近邻搜索。以最先进的速度进行搜索，并在不影响结果的情况下应用搜索过滤器。</li>
<li><strong>易于使用的 API</strong>：提供 OpenAPI v3 规范来生成几乎任何编程语言的客户端库。或者，利用为 Python 或其他编程语言准备的现成客户端以获得额外功能。</li>
<li><strong>丰富的数据类型</strong>：向量负载支持大量的数据类型和查询条件，包括字符串匹配、数值范围、地理位置等。负载过滤条件允许你构建几乎任何自定义业务逻辑，这些逻辑应基于相似性匹配工作。</li>
<li><strong>分布式</strong>：云原生且横向可扩展。无论用户需要伺服多少数据，Qdrant 总是可以使用恰到好处的计算资源。</li>
</ul>
<p>Qdrant 提供了 REST API 和 gRPC API 作为接口，所有与 Qdrant 的交互都通过这些 API 进行。此外，Qdrant 还提供了多种语言的客户端库和一个 Web UI 界面，<a href="integrations/vector-database-qdrant.html#%E4%BD%BF%E7%94%A8">使用</a>部分将演示使用 Python 客户端以及 Web UI 与 Qdrant 交互。</p>
<h2 id="部署-6"><a class="header" href="#部署-6">部署</a></h2>
<h3 id="安装-5"><a class="header" href="#安装-5">安装</a></h3>
<p>进入 Notebook <code>app</code> 的终端，添加相应的 Helm Chart repository，列出 Chart <code>qdrant/qdrant</code> 的所有版本：</p>
<pre><code class="language-bash">helm repo add qdrant https://qdrant.github.io/qdrant-helm

# 注意 CHART VERSION 和 APP VERSION（Qdrant 版本）之间的对应关系
# 例如 CHART VERSION 0.7.5 和 0.7.4 中的 Qdrant 版本都是 v1.7.3
helm search repo qdrant/qdrant --versions
</code></pre>
<p>安装指定版本的 Chart <code>qdrant/qdrant</code> 以部署 Qdrant 应用：</p>
<pre><code class="language-bash"># 安装最新版本
helm repo update qdrant
helm install qdrant-demo qdrant/qdrant

# 安装指定 CHART VERSION，注意这不是 APP VERSION（Qdrant 版本）
helm install qdrant-demo qdrant/qdrant --version &lt;CHART_VERSION&gt;
</code></pre>
<h2 id="配置-2"><a class="header" href="#配置-2">配置</a></h2>
<p>以上安装全部使用默认配置，完整的默认配置请参阅相应的 <code>values.yaml</code>：</p>
<pre><code class="language-bash"># 获取指定 CHART VERSION 的 values.yaml
helm show values qdrant/qdrant --version &lt;CHART_VERSION&gt; &gt; values.yaml
</code></pre>
<p>如果想要修改默认配置，你可以将新配置（覆盖默认配置的字段）保存为一个 YAML 文件，通过 <code>-f</code> 选项提供给安装命令：</p>
<pre><code class="language-bash"># 使用修改后的 values.yaml
helm install qdrant-demo qdrant/qdrant --version &lt;CHART_VERSION&gt; -f values.yaml
</code></pre>
<p>下面将分主题介绍部分关键配置（CHART VERSION 0.7.6）。</p>
<h3 id="计算资源-1"><a class="header" href="#计算资源-1">计算资源</a></h3>
<p>默认配置没有指定计算资源，表示 Pod 可以无限制地使用节点的 CPU 和内存资源。你可以根据实际需求指定请求值和限制值。</p>
<pre><code class="language-yaml"># 默认配置
resources: {}
</code></pre>
<h3 id="存储-1"><a class="header" href="#存储-1">存储</a></h3>
<p>默认配置指定的卷大小为 10Gi，并且没有指定存储类型。你可以根据数据规模修改卷大小，并选用高性能的存储类型。</p>
<pre><code class="language-yaml"># 默认配置
persistence:
  accessModes:
  - ReadWriteOnce
  annotations: {}
  size: 10Gi                # 卷大小
  storageClassName: &quot;&quot;      # 存储类型
config:
  storage: {}
</code></pre>
<p>此外，你还可以在 <code>config.storage</code> 字段下配置 Qdrant 实例的存储和索引的多个参数，请参阅 <a target="_blank" rel="noopener noreferrer" href="https://qdrant.tech/documentation/guides/configuration/#configuration-file-example">configuration file example</a>。</p>
<h3 id="网络"><a class="header" href="#网络">网络</a></h3>
<p>默认配置没有启动 Ingress，你可以提供 Ingress 配置以提供外部访问。</p>
<pre><code class="language-yaml"># 默认配置
ingress:              # Ingress 配置
  enabled: false
  ingressClassName: &quot;&quot;
  annotations: {}
  hosts:
  - host: example-domain.com
    paths:
    - path: /
      pathType: Prefix
      servicePort: 6333
  tls: []

service:              # Service 配置              
  type: ClusterIP
  additionalLabels: {}
  annotations: {}
  loadBalancerIP: &quot;&quot;
  ports:
    - name: http
      port: 6333
      targetPort: 6333
      protocol: TCP
      checksEnabled: true
    - name: grpc
      port: 6334
      targetPort: 6334
      protocol: TCP
      checksEnabled: false
    - name: p2p
      port: 6335
      targetPort: 6335
      protocol: TCP
      checksEnabled: false

config:
  service: {}
  tls: {}
</code></pre>
<p>此外，你还可以在 <code>config.service</code> 和 <code>config.tls</code> 字段下配置 Qdrant 实例的服务和 TLS 的多个参数，请参阅<a href="integrations/vector-database-qdrant.html#%E5%AE%89%E5%85%A8">安全</a>以及 <a target="_blank" rel="noopener noreferrer" href="https://qdrant.tech/documentation/guides/configuration/#configuration-file-example">configuration file example</a>。</p>
<h3 id="分布式部署"><a class="header" href="#分布式部署">分布式部署</a></h3>
<p>Qdrant 支持分布式部署模式，在此模式下，多个 Qdrant 服务彼此通信，将数据分布到多个副本（replica）中，以扩展存储能力并增加稳定性。默认配置启用了分布式部署模式，并指定端口 6335 用于内部通信，但只创建了 1 个副本。你可以增加副本数量以实现分布式部署。</p>
<pre><code class="language-yaml"># 默认配置
replicaCount: 1

config:
  cluster:
    enabled: true
    p2p:
      port: 6335
    consensus:
      tick_period_ms: 100
</code></pre>
<p>关于分布式一致性协议、分片、复制（replication）和一致性保证的更多信息，请参阅 <a target="_blank" rel="noopener noreferrer" href="https://qdrant.tech/documentation/guides/distributed_deployment/">Distributed deployment</a>。</p>
<h3 id="安全"><a class="header" href="#安全">安全</a></h3>
<p>默认配置没有为 Qdrant 实例提供任何保护，在投入生产使用之前需要启用安全措施。首先，启用 TLS 以加密连接：</p>
<pre><code class="language-yaml">config:
  service:
    enable_tls: true

  p2p:
    enable_tls: true  # 分布式部署下，对 peer 之间的通信启用 TLS

  tls:
    cert: ./tls/cert.pem
    key: ./tls/key.pem
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>当 TLS 启用后，必须使用 HTTPS 连接。</p>
</aside>
<p>在此基础上，可以使用静态的 API key 进行身份验证：</p>
<pre><code class="language-yaml">config:
  service:
    api_key: your_secret_api_key_here
</code></pre>
<aside class="note tip">
<div class="title">提示</div>
<p>设置 API key 后，必须在请求头中附带 API key。</p>
</aside>
<p>更多信息请参阅 <a target="_blank" rel="noopener noreferrer" href="https://qdrant.tech/documentation/guides/security/">Security</a>。</p>
<h3 id="应用架构-1"><a class="header" href="#应用架构-1">应用架构</a></h3>
<p>应用的系统架构如下图所示（CHART VERSION 0.7.6，默认配置）：</p>
<figure class="architecture">
  <img alt="architecture" src="integrations/../assets/integrations/vector-database-qdrant/microservice.drawio.svg" class="architecture">
</figure>
<p>创建的主要 Kubernetes 资源如下表所示：</p>
<div class="table-wrapper"><table><thead><tr><th>类型</th><th>名称</th><th>作用</th><th>备注</th></tr></thead><tbody>
<tr><td>Service</td><td>qdrant-demo</td><td>暴露 Qdrant 服务</td><td></td></tr>
<tr><td>StatefulSet</td><td>qdrant-demo</td><td>部署 Qdrant</td><td>默认计算资源为 <code>{}</code></td></tr>
<tr><td>PVC</td><td>qdrant-storage-qdrant-demo-*</td><td>作为 Qdrant 的持久化存储</td><td>默认卷大小为 <code>10Gi</code></td></tr>
</tbody></table>
</div>
<h3 id="运维-1"><a class="header" href="#运维-1">运维</a></h3>
<p><strong>查看应用的状态</strong></p>
<pre><code class="language-bash">helm status qdrant-demo
</code></pre>
<p><strong>更新应用</strong></p>
<pre><code class="language-bash"># 更新到最新版本
helm upgrade qdrant-demo qdrant/qdrant

# 更新到指定版本
helm upgrade qdrant-demo qdrant/qdrant --version &lt;VERSION_NUMBER&gt;

# 回滚更新，首先查看历史版本
helm history qdrant-demo
helm rollback qdrant-demo [REVISION]
</code></pre>
<p><strong>移除应用</strong></p>
<pre><code class="language-bash">helm delete qdrant-demo
kubectl delete pvc -l app.kubernetes.io/instance=qdrant-demo
</code></pre>
<h2 id="使用-91"><a class="header" href="#使用-91">使用</a></h2>
<p>继续使用 Notebook <code>app</code> 的终端，获取应用 service 的公开的端口号：</p>
<pre><code class="language-bash">kubectl get svc qdrant-demo -o jsonpath=&quot;{.spec.ports}&quot;
</code></pre>
<p>输出应类似于：</p>
<pre><code class="language-json">[{&quot;name&quot;:&quot;http&quot;,&quot;port&quot;:6333,&quot;protocol&quot;:&quot;TCP&quot;,&quot;targetPort&quot;:6333},{&quot;name&quot;:&quot;grpc&quot;,&quot;port&quot;:6334,&quot;protocol&quot;:&quot;TCP&quot;,&quot;targetPort&quot;:6334},{&quot;name&quot;:&quot;p2p&quot;,&quot;port&quot;:6335,&quot;protocol&quot;:&quot;TCP&quot;,&quot;targetPort&quot;:6335}]
</code></pre>
<p>首先使用 Python 客户端运行一个快速入门。安装 Python 客户端：</p>
<pre><code class="language-bash">pip install qdrant-client
</code></pre>
<p>然后执行如下 Python 脚本，命令行参数中需要提供 gRPC 端口号：</p>
<details><summary><code class="hljs">quick_start.py</code></summary>
<pre><code class="language-python">import sys

from qdrant_client import QdrantClient
from qdrant_client.http.models import (Distance, Filter, FieldCondition,
                                       MatchValue, PointStruct, VectorParams)

# 客户端在创建 collection 时存在 HTTP 超时问题，参考
# https://github.com/qdrant/qdrant-client/issues/394，采用 gRPC 作为临时解决方案
# client = QdrantClient(sys.argv[1])
client = QdrantClient(sys.argv[1], prefer_grpc=True)

# 创建一个 collection 以存储向量数据，设定向量维数为 4，使用点积度量距离
client.create_collection(
    collection_name=&quot;test_collection&quot;,
    vectors_config=VectorParams(size=4, distance=Distance.DOT),
)

# 添加一些向量
client.upsert(
    collection_name=&quot;test_collection&quot;,
    wait=True,
    points=[
        PointStruct(id=1,
                    vector=[0.05, 0.61, 0.76, 0.74],
                    payload={&quot;city&quot;: &quot;Berlin&quot;}),
        PointStruct(id=2,
                    vector=[0.19, 0.81, 0.75, 0.11],
                    payload={&quot;city&quot;: &quot;London&quot;}),
        PointStruct(id=3,
                    vector=[0.36, 0.55, 0.47, 0.94],
                    payload={&quot;city&quot;: &quot;Moscow&quot;}),
        PointStruct(id=4,
                    vector=[0.18, 0.01, 0.85, 0.80],
                    payload={&quot;city&quot;: &quot;New York&quot;}),
        PointStruct(id=5,
                    vector=[0.24, 0.18, 0.22, 0.44],
                    payload={&quot;city&quot;: &quot;Beijing&quot;}),
        PointStruct(id=6,
                    vector=[0.35, 0.08, 0.11, 0.44],
                    payload={&quot;city&quot;: &quot;Mumbai&quot;}),
    ],
)

# 查询与向量 [0.2, 0.1, 0.9, 0.7] 最相似的 3 个向量
search_result = client.search(collection_name=&quot;test_collection&quot;,
                              query_vector=[0.2, 0.1, 0.9, 0.7],
                              limit=3)
print(search_result)

# 进一步过滤结果
search_result = client.search(
    collection_name=&quot;test_collection&quot;,
    query_vector=[0.2, 0.1, 0.9, 0.7],
    query_filter=Filter(
        must=[FieldCondition(key=&quot;city&quot;, match=MatchValue(value=&quot;London&quot;))]),
    with_payload=True,
    limit=3,
)
print(search_result)
</code></pre>
</details>
<pre><code class="language-bash">python quick-start.py qdrant-demo:&lt;GRPC_PORT&gt;
</code></pre>
<p>脚本创建了一个 collection，添加了一些数据，并进行了两次基本的查询。输出应类似于：</p>
<pre><code class="language-python">[ScoredPoint(id=4, version=0, score=1.3619999885559082, payload={'city': 'New York'}, vector=None, shard_key=None), ScoredPoint(id=1, version=0, score=1.2730000019073486, payload={'city': 'Berlin'}, vector=None, shard_key=None), ScoredPoint(id=3, version=0, score=1.2079999446868896, payload={'city': 'Moscow'}, vector=None, shard_key=None)]
[ScoredPoint(id=2, version=0, score=0.8709999918937683, payload={'city': 'London'}, vector=None, shard_key=None)]
</code></pre>
<p>接下来进入 Web UI 与 Qdrant 向量数据库交互。如果在部署应用时配置了 Ingress，那么直接在浏览器中访问相应的地址即可，否则需要进行端口转发。通过 t9k-pf 进行端口转发：</p>
<pre><code class="language-bash">t9k-pf -n &lt;APP_PROJECT&gt; pod qdrant-demo-0 6333:6333
</code></pre>
<p>在浏览器中访问 <a target="_blank" rel="noopener noreferrer" href="http://127.0.0.1:6333/dashboard">http://127.0.0.1:6333/dashboard</a> 进入 Web UI。在 Console 页面中，用户可以直接调用 REST API 并得到响应结果：</p>
<figure class="screenshot">
  <img alt="loss" src="integrations/../assets/integrations/vector-database-qdrant/console.png" />
</figure>
<p>在 Collections 页面中，用户可以进行以下操作：</p>
<ul>
<li>浏览 collection 的所有数据点</li>
<li>查看 collection 的基本信息</li>
<li>制作和上传快照</li>
<li>对数据点进行可视化</li>
<li>删除 collection</li>
</ul>
<figure class="screenshot">
  <img alt="loss" src="integrations/../assets/integrations/vector-database-qdrant/collections.png" />
</figure>
<figure class="screenshot">
  <img alt="loss" src="integrations/../assets/integrations/vector-database-qdrant/collections-points.png" />
</figure>
<figure class="screenshot">
  <img alt="loss" src="integrations/../assets/integrations/vector-database-qdrant/collections-visualization.png" />
</figure>
<p>Web UI 的其他功能这里不再一一介绍，用户可以自行探索。</p>
<p>更多使用教程请进一步参阅 <a target="_blank" rel="noopener noreferrer" href="https://qdrant.tech/documentation/">Qdrant 文档</a>。</p>
<h2 id="参考-20"><a class="header" href="#参考-20">参考</a></h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/qdrant/qdrant">GitHub 上的 Qdrant</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://qdrant.tech/documentation/">Qdrant 文档</a>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://qdrant.tech/documentation/quick-start/">快速入门</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://qdrant.tech/documentation/guides/distributed_deployment/">分布式部署</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://qdrant.tech/documentation/guides/configuration/">配置</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://qdrant.tech/documentation/guides/security/">安全</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/qdrant/qdrant-helm">GitHub 上的 Qdrant Helm</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="向量数据库postgresql--pgvector"><a class="header" href="#向量数据库postgresql--pgvector">向量数据库：PostgreSQL + pgvector</a></h1>
<p>在<a href="integrations/./vector-database-qdrant.html">向量数据库：Qdrant</a>中我们介绍了向量数据库的概念以及开源产品 Qdrant。这里我们介绍另一个优秀的开源方案：PostgreSQL + pgvector。</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://www.postgresql.org/">PostgreSQL</a> 是一个稳定可靠、功能强大的开源对象关系型数据库系统，第一个公开版本于 1989 年发布。此后，它经历了多次迭代，并逐渐成为世界上最流行的开源数据库之一。它支持 SQL 标准，并提供复杂查询、事务完整性、多版本并发控制等多种现代数据库技术特性。PostgreSQL 以其高度的扩展性和对大型数据集的强大处理能力而闻名，适用于从小型应用程序到大型企业系统的各种环境。此外，它还拥有一个活跃的开发社区，为开发者提供丰富的资源和工具。</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/pgvector/pgvector">pgvector</a> 是一个用于向量相似性搜索的 PostgreSQL 扩展。安装此扩展后，PostgreSQL 可以支持向量数据的存储、检索和查询等操作。</p>
<h2 id="部署-7"><a class="header" href="#部署-7">部署</a></h2>
<h3 id="安装-6"><a class="header" href="#安装-6">安装</a></h3>
<p>进入 Notebook <code>app</code> 的终端，添加相应的 Helm Chart repository，列出 Chart <code>bitnami/postgresql</code> 的所有版本：</p>
<pre><code class="language-bash">helm repo add bitnami https://charts.bitnami.com/bitnami

# 注意 CHART VERSION 和 APP VERSION（PostgreSQL 版本）之间的对应关系
# 例如 CHART VERSION 14.1.x 中的 PostgreSQL 版本都是 16.2.0
helm search repo bitnami/postgresql --versions
</code></pre>
<p>安装指定版本的 Chart 并指定 <code>t9kpublic/bitnami-pgvector</code> 镜像，以部署包含 pgvector 的 PostgreSQL 应用：</p>
<pre><code class="language-bash"># 安装最新版本
helm repo update bitnami
helm install pgvector-demo bitnami/postgresql \
  --set image.repository=t9kpublic/bitnami-pgvector \
  --set image.tag=0.6.0-pg16

# 安装指定 CHART VERSION，注意这不是 APP VERSION（PostgreSQL 版本）
helm install pgvector-demo bitnami/postgresql \
  --version &lt;CHART_VERSION&gt; \
  --set image.repository=t9kpublic/bitnami-pgvector \
  --set image.tag=0.6.0-pg16
</code></pre>
<aside class="note tip">
<div class="title">信息</div>
<p><code>t9kpublic/bitnami-pgvector</code> 镜像是在 <code>bitnami/postgresql</code>  镜像的基础上安装了 pgvector，
请参阅 <a target="_blank" rel="noopener noreferrer" href="https://github.com/pgvector/pgvector/issues/126#issuecomment-1589203644">issue #126</a>。</p>
</aside>
<h3 id="配置-3"><a class="header" href="#配置-3">配置</a></h3>
<p>以上安装全部使用默认配置，完整的默认配置请参阅 <a target="_blank" rel="noopener noreferrer" href="https://artifacthub.io/packages/helm/bitnami/postgresql#parameters">Parameters</a> 以及相应的 <code>values.yaml</code>：</p>
<pre><code class="language-bash"># 获取指定 CHART VERSION 的 values.yaml
helm show values bitnami/postgresql --version &lt;CHART_VERSION&gt; &gt; values.yaml
</code></pre>
<p>如果想要修改默认配置，你可以将新配置（覆盖默认配置的字段）保存为一个 YAML 文件，通过 <code>-f</code> 选项提供给安装命令：</p>
<pre><code class="language-bash"># 使用修改后的 values.yaml
helm install pgvector-demo t9kpublic/bitnami-pgvector \
  --version &lt;CHART_VERSION&gt; \
  --set image.repository=t9kpublic/bitnami-pgvector \
  --set image.tag=0.6.0-pg16 \
  -f values.yaml
</code></pre>
<p>下面将分主题介绍部分关键配置（CHART VERSION 14.1.3）。</p>
<h4 id="计算资源-2"><a class="header" href="#计算资源-2">计算资源</a></h4>
<p>默认配置没有指定计算资源，表示 Pod 可以无限制地使用节点的 CPU 和内存资源。你可以根据实际需求指定请求值和限制值，可以参阅<a target="_blank" rel="noopener noreferrer" href="https://cloud.google.com/sql/docs/postgres/manage-memory-usage-best-practices?hl=zh-cn">管理内存用量的最佳实践</a>。</p>
<pre><code class="language-yaml"># 默认配置
primary:
  resources: {}
</code></pre>
<h4 id="存储-2"><a class="header" href="#存储-2">存储</a></h4>
<p>默认配置指定的卷大小为 <code>8Gi</code>，并且没有指定存储类型。你可以根据数据规模修改卷大小，并选用高性能的存储类型。</p>
<pre><code class="language-yaml"># 默认配置
primary:
  persistence:
    existingClaim: &quot;&quot;     # 使用已有的 PVC
    subPath: &quot;&quot;           # 卷被挂载的子路径，用于多个服务共用一个卷
    storageClass: &quot;&quot;      # 存储类型
    accessModes:
      - ReadWriteOnce
    size: 8Gi             # 存储大小
</code></pre>
<h4 id="网络-1"><a class="header" href="#网络-1">网络</a></h4>
<p>你可以按需修改 Service 配置，提供 tls 配置以提供外部安全访问。</p>
<pre><code class="language-yaml"># 默认配置
tls:                    # tls 配置
  enabled: false
  autoGenerated: false
  preferServerCiphers: true
  certificatesSecret: &quot;&quot;
  certFilename: &quot;&quot;
  certKeyFilename: &quot;&quot;
  certCAFilename: &quot;&quot;
  crlFilename: &quot;&quot;

primary:
  service:              # Service 配置
    type: ClusterIP
    ports:
      postgresql: 5432
    clusterIP: &quot;&quot;
    loadBalancerIP: &quot;&quot;
    externalTrafficPolicy: Cluster
</code></pre>
<h4 id="安全-1"><a class="header" href="#安全-1">安全</a></h4>
<p>你可以设置 <code>postgres</code> 管理员用户的密码，
请参阅 <a target="_blank" rel="noopener noreferrer" href="https://github.com/bitnami/containers/tree/main/bitnami/postgresql#setting-the-root-password-on-first-run">Setting the root password on first run</a>。</p>
<pre><code class="language-yaml">auth:
  enablePostgresUser: true     # 启用 postgres 管理员用户
  postgresPassword: &quot;&quot;         # postgres 管理员用户的密码
</code></pre>
<h4 id="备份"><a class="header" href="#备份">备份</a></h4>
<p>你可以启用数据库的定时备份并提供相应配置。注意这里的备份方法是转储（dump）而不是快照（snapshot）。</p>
<pre><code class="language-yaml"># 默认配置
backup:
  enabled: false
  cronjob:
    schedule: &quot;@daily&quot;
    timeZone: &quot;&quot;
    podSecurityContext:
      enabled: true
      fsGroupChangePolicy: Always
      sysctls: []
      supplementalGroups: []
      fsGroup: 1001
    containerSecurityContext:
      enabled: true
      seLinuxOptions: null
      runAsUser: 1001
      runAsNonRoot: true
      privileged: false
      readOnlyRootFilesystem: false
      allowPrivilegeEscalation: false
      capabilities:
        drop: [&quot;ALL&quot;]
      seccompProfile:
        type: &quot;RuntimeDefault&quot;
    command:
      - /bin/sh
      - -c
      - &quot;pg_dumpall --clean --if-exists --load-via-partition-root --quote-all-identifiers --no-password --file=${PGDUMP_DIR}/pg_dumpall-$(date '+%Y-%m-%d-%H-%M').pgdump&quot;
    storage:
      existingClaim: &quot;&quot;
      storageClass: &quot;&quot;
      accessModes:
       - ReadWriteOnce
      size: 8Gi
      subPath: &quot;&quot;
</code></pre>
<h3 id="应用架构-2"><a class="header" href="#应用架构-2">应用架构</a></h3>
<p>应用的系统架构如下图所示（CHART VERSION 14.1.3，默认配置）：</p>
<figure class="architecture">
  <img alt="architecture" src="integrations/../assets/integrations/vector-database-pgvector/microservice.drawio.svg" class="architecture">
</figure>
<p>创建的主要 Kubernetes 资源如下表所示：</p>
<div class="table-wrapper"><table><thead><tr><th>类型</th><th>名称</th><th>作用</th><th>备注</th></tr></thead><tbody>
<tr><td>Service</td><td>pgvector-demo-postgresql</td><td>暴露 PostgreSQL 服务</td><td></td></tr>
<tr><td>StatefulSet</td><td>pgvector-demo-postgresql</td><td>部署 PostgreSQL + pgvector（包括持久化存储）</td><td>默认计算资源为 <code>{}</code></td></tr>
<tr><td>PVC</td><td>data-pgvector-demo-postgresql-*</td><td>作为 PostgreSQL 的持久化存储</td><td>默认卷大小为 <code>8Gi</code></td></tr>
<tr><td>Secret</td><td>pgvector-demo-postgresql</td><td>存储 postgres 密钥</td><td></td></tr>
</tbody></table>
</div>
<h3 id="运维-2"><a class="header" href="#运维-2">运维</a></h3>
<p>查看应用的状态</p>
<pre><code class="language-bash">helm status pgvector-demo
</code></pre>
<p>更新应用，下面的 <code>image.tag</code> 可能需要设置为其他值。</p>
<pre><code class="language-bash"># 更新到最新版本
helm upgrade pgvector-demo t9kpublic/bitnami-pgvector \
  --set image.repository=t9kpublic/bitnami-pgvector \
  --set image.tag=0.6.0-pg16

# 更新到指定版本
helm upgrade pgvector-demo t9kpublic/bitnami-pgvector \
  --version &lt;CHART_VERSION&gt; \
  --set image.repository=t9kpublic/bitnami-pgvector \
  --set image.tag=0.6.0-pg16

# 回滚更新，首先查看历史版本
helm history pgvector-demo
helm rollback pgvector-demo [REVISION]
</code></pre>
<p>移除应用</p>
<pre><code class="language-bash">helm delete pgvector-demo
kubectl delete pvc -l app.kubernetes.io/instance=pgvector-demo
</code></pre>
<h2 id="使用-92"><a class="header" href="#使用-92">使用</a></h2>
<p>继续使用 Notebook <code>app</code> 的终端，获取应用的密钥，并连接到 PostgreSQL 实例：</p>
<pre><code class="language-bash">export POSTGRES_PASSWORD=$(kubectl get secret --namespace demo pgvector-demo-postgresql -o jsonpath=&quot;{.data.postgres-password}&quot; | base64 -d)
kubectl run pgvector-demo-postgresql-client \
  --rm --tty -i --restart='Never' --namespace demo \
  --image docker.io/t9kpublic/bitnami-pgvector:main \
  --env=&quot;PGPASSWORD=$POSTGRES_PASSWORD&quot; \
  --command -- \
  psql --host pgvector-demo-postgresql -U postgres -d postgres -p 5432
</code></pre>
<p>使用 psql 命令启用 pgvector 扩展：</p>
<pre><code class="language-sql">CREATE EXTENSION vector;
</code></pre>
<p>然后运行一个快速入门：</p>
<pre><code class="language-sql">CREATE TABLE items (id bigserial PRIMARY KEY, embedding vector(3));
INSERT INTO items (embedding) VALUES ('[1,2,3]'), ('[4,5,6]');
SELECT * FROM items ORDER BY embedding &lt;-&gt; '[3,1,2]' LIMIT 5;
DROP TABLE items;
</code></pre>
<p>接下来运行一个 <a target="_blank" rel="noopener noreferrer" href="https://github.com/pgvector/pgvector-python/blob/master/examples/sentence_embeddings.py">Python 语言的官方示例</a>。先安装必要的 Python 库：</p>
<pre><code class="language-bash">pip install pgvector &quot;psycopg[binary]&quot; sentence_transformers
</code></pre>
<p>然后执行如下 Python 脚本，命令行参数需要提供连接字符串：</p>
<details><summary><code class="hljs">sentence_embeddings.py</code></summary>
<pre><code class="language-python">import sys

from pgvector.psycopg import register_vector
import psycopg
from sentence_transformers import SentenceTransformer

# 创建数据库连接，并设置自动提交
conn = psycopg.connect(sys.argv[1], autocommit=True)

# 启用 pgvector 扩展，注册向量数据类型
conn.execute('CREATE EXTENSION IF NOT EXISTS vector')
register_vector(conn)

# 重新创建表 documents
conn.execute('DROP TABLE IF EXISTS documents')
conn.execute('CREATE TABLE documents (id bigserial PRIMARY KEY, content text, embedding vector(384))')

# 嵌入输入文本
input = [
    'The dog is barking',
    'The cat is purring',
    'The bear is growling'
]
model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = model.encode(input)

# 将输入文本和相应的嵌入向量插入到数据库中
for content, embedding in zip(input, embeddings):
    conn.execute('INSERT INTO documents (content, embedding) VALUES (%s, %s)', (content, embedding))

# 查询与指定文档最相近的其他文档的文本内容
document_id = 1
neighbors = conn.execute('SELECT content FROM documents WHERE id != %(id)s ORDER BY embedding &lt;=&gt; (SELECT embedding FROM documents WHERE id = %(id)s) LIMIT 5', {'id': document_id}).fetchall()
for neighbor in neighbors:
    print(neighbor[0])
</code></pre>
</details>
<pre><code class="language-bash">export POSTGRES_PASSWORD=$(kubectl get secret --namespace demo pgvector-demo-postgresql -o jsonpath=&quot;{.data.postgres-password}&quot; | base64 -d)
python pgvector-test.py &quot;host=pgvector-demo-postgresql port=5432 dbname=postgres user=postgres password=$POSTGRES_PASSWORD&quot;
</code></pre>
<p>脚本创建了一个表，添加了一些向量数据，并进行了一次基本的向量查询。输出应类似于：</p>
<pre><code>The bear is growling
The cat is purring
</code></pre>
<p>更多信息请参阅
<a target="_blank" rel="noopener noreferrer" href="https://github.com/pgvector/pgvector">pgvector 的 README 文档</a>。</p>
<h2 id="参考-21"><a class="header" href="#参考-21">参考</a></h2>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/pgvector/pgvector">GitHub 上的 pgvector</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/pgvector/pgvector-python">GitHub 上的 pgvector-python</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="背景-1"><a class="header" href="#背景-1">背景</a></h1>
<p>人工智能（AI）技术的发展已经取得了显著的成果，并对各行业的发展产生了深远的影响。其中最为突出的成就是以深度学习为基础在计算机视觉、LLM 等领域的突破性成果。</p>
<aside class="note info">
<div class="title">通用人工智能（AGI）</div>
<p>预计在不远的将来我们将能够实现通用人工智能（AGI）。AGI 代表着机器不仅能在特定任务上表现出人类水平的智能，而且能够具备广泛的理解力和学习能力，适应各种不同的环境和挑战。这样的技术进步将彻底改变科学研究、工业生产、教育、医疗保健等领域的面貌。</p>
</aside>
<p>AI 计算平台对于 AI 技术的开发和应用具有重要意义。它提供了一个集成化、高效的环境，让开发者和企业能够轻松地构建、训练和部署机器学习模型。这种便捷性极大地降低了 AI 技术的门槛，使得更多的组织和个人能够利用先进的 AI 能力。</p>
<ol>
<li>AI 计算平台通过提供高级的 AI 开发工具和预构建的模型，简化了 AI 开发流程。开发者不需要从头开始构建复杂的模型，而是可以基于现有的模型进行定制和优化，这加速了从概念到实现的过程。</li>
<li>AI 计算平台提供了大规模的计算资源和数据管理能力，这对于处理大量数据和运行复杂的 AI 模型至关重要。用户可以根据需要轻松扩展资源，以适应不断变化的需求。</li>
<li>平台还包含丰富的协作和集成工具，使得团队可以更有效地合作开发。此外，它们还提供了严格的安全和隐私保护措施，保证了数据的安全性和合规性。</li>
</ol>
<h2 id="新的范式"><a class="header" href="#新的范式">新的范式</a></h2>
<p>AI 是一种崭新的计算范式，它具有数据驱动、基于实验的特点，并且经常需要进行大规模的计算。</p>
<ul>
<li>在传统软件开发中，程序员编写明确的指令或规则，来告诉计算机如何处理数据和执行任务。这种方法依赖于开发者对问题的深入理解以及能够准确预测所有可能的情况并据此编写代码。</li>
<li>相比之下，AI 的开发更多地依赖于数据而不是预设的规则。在这种模式下，AI 系统通过大量数据来学习和识别模式，然后基于这些学习成果做出判断或预测。开发者不是直接编写处理每种情况的代码，
而是设计算法来让计算机自我学习和适应。这意味着 AI 系统在面对新数据时可以持续改进其性能和准确性。</li>
<li>此外，AI 开发通常需要更多关注于数据的收集、处理和分析。数据的质量和量直接影响到模型的性能，因此数据预处理成为 AI 开发中的一个重要步骤。而在传统软件开发中，主要关注的是逻辑的构建和代码的优化。</li>
</ul>
<p>总的来说，AI 的数据驱动计算范式更加强调数据本身和从数据中学习的能力，而不是像传统软件那样依赖于硬编码的指令和规则。
这种方法使得 AI 在处理复杂、动态和模糊的问题时更加有效，但也带来了对数据质量和巨大计算处理能力的依赖。</p>
<figure class="architecture">
  <img alt="computation-paradigm-for-ai" src="./assets/overview/ai-compute-paradigm.png" />
  <figcaption>图 1: AI 计算的要素。模型架构程序 + 数据集经过训练（模型参数优化）后产生 AI 模型。</figcaption>
</figure>
<h2 id="系统需求"><a class="header" href="#系统需求">系统需求</a></h2>
<p>由于 AI 技术的特性，用户在开发和使用 AI 过程中，在系统方面提出了多方面的需求，希望能够：</p>
<ul>
<li>方便地构建、使用和迭代数据集、模型架构和参数，以及</li>
<li>简单、可靠地使用大规模分布式并行、异构和加速计算等技术来快速、高效地运行大规模的数据处理、训练和推理计算等。</li>
</ul>
<h3 id="数据"><a class="header" href="#数据">数据</a></h3>
<p>AI 计算过程中读取或者产生的数据可以分为两类：主干数据、元数据。</p>
<ul>
<li>主干数据：训练数据集、模型等大体量数据。</li>
<li>元数据：计算过程中的各种配置、超参数、指标等。</li>
</ul>
<figure class="architecture">
  <img alt="ai-data" src="./assets/overview/ai-data.png" />
  <figcaption>图 2：AI 计算在数据方面的核心需求。1）针对大规模的数据（训练数据集、模型等）提供高性能、大容量和完善的生命周期管理支持；2）对 AI 实验过程中的各种配置、超参数、指标等进行方便地记录、存取、查询等，并提供丰富的可视化支持。</figcaption>
</figure>
<p>用户希望通过一致、多维度高度可扩展的机制来支持对数据的各种操作。例如，训练数据无论是100KiB 还是 100TiB，都能够使用同一套工具、SDK，API：</p>
<ol>
<li>方便地使用数据：能够在探索、实验、训练过程中，简单、快速地使用不同的数据；</li>
<li>高性能地使用数据：支持训练过程中对数据的高速读取（训练数据集）、写入（checkpoint，模型本身）；</li>
<li>可靠地维护数据：
<ul>
<li>像代码一样维护数据版本 (versioning)；</li>
<li>记录数据的变化历史 (commits and logs)；</li>
<li>隔离 (branches)。</li>
</ul>
</li>
<li>对 AI 计算过程中的配置、超参数、脚本、各种指标等，提供方便、完善的支持：
<ul>
<li>元数据管理系统为基础底座；</li>
<li>SDK 支持在各种场景进行集成；</li>
<li>可视化工具方便地跟踪、展示、比较、分析多个实验过程。</li>
</ul>
</li>
</ol>
<h3 id="计算"><a class="header" href="#计算">计算</a></h3>
<p>用户希望能够通过便捷的方式使用大规模分布式并行、异构、加速计算等技术以快速、高效地运行大规模的数据处理、训练和推理计算等。</p>
<figure class="architecture">
  <img alt="scalable-ai-compute" src="./assets/overview/scalable-ai-compute.png" />
  <figcaption>图 3: 方便地进行计算。系统支持以同样的方式定义、运行、调试 AI 领域的各种计算任务。例如，使用 1 张 GPU 的训练任务和使用 1000 张 GPU  的训练任务可以使用一致的方式来完成。</figcaption>
</figure>
<p>AI 计算场景的典型需求：</p>
<div class="table-wrapper"><table><thead><tr><th>类别</th><th>需求说明</th></tr></thead><tbody>
<tr><td>软件包依赖</td><td>清晰、一致、方便地管理对 Pyhton 脚本、GPU 驱动程序、网络驱动程序等各种软件包的依赖</td></tr>
<tr><td>计算环境</td><td>支持在 dev、 train、test、deploy 等环境方便地切换、迭代</td></tr>
<tr><td>数据、代码</td><td>高效、便捷地使用数据、脚本、配置及跟踪它们的变化</td></tr>
<tr><td>计算资源</td><td>快速、简单、方便地请求和使用各种计算资源：CPU、RAM、GPU、高速网络、存储…</td></tr>
<tr><td>运行计算</td><td>可靠、简单、方便地运行个各种类型的计算：开发环境、并行训练、微调、数据处理、推理服务…</td></tr>
</tbody></table>
</div>
<h2 id="kubernetes"><a class="header" href="#kubernetes">Kubernetes</a></h2>
<p>Kubernetes 是一个灵活、可扩展的容器集群管理平台，它通过 Master 节点的集中控制和调度，工作节点（Worker Nodes) 负责运行应用工作负载。工作节点可方便地动态伸缩规模。</p>
<aside class="note info">
<div class="title">Kubernetes</div>
<p>Kubernetes 这个单词源自希腊语，意思是指舵手（helmsman）或导航员（pilot）。</p>
<p>Kubernetes 的历史可以追溯到 Google 的 Borg 系统 （据说名字取自 Star Trek）。Borg 是 Google 内部使用的第一个容器编排系统，于 2003 年开始开发。Borg 是一个集中式的系统，使用一个单一的控制器来管理集群中的所有资源。</p>
</aside>
<figure class="architecture">
  <img alt="k8s-arch" src="./assets/overview/k8s-arch.png" />
  <figcaption>图 4：Kubernetes 架构图。Source: https://en.wikipedia.org/wiki/Kubernetes </figcaption>
</figure>
<p>如上图所示，Kubernetes 的整体架构主要包含以下组件:</p>
<p>Master 节点: Master 节点负责整个集群的控制和管理。主要包含以下组件:</p>
<ul>
<li>kube-apiserver：提供了资源操作的统一入口，以 RESTful API 方式提供服务。</li>
<li>etcd：负责存储集群的配置信息和资源状态。</li>
<li>kube-scheduler：负责资源的调度，按照预定的调度策略将 Pod 调度到相应的节点上。</li>
<li>kube-controller-manager: 负责管理控制器，确保集群处于预期的状态。</li>
</ul>
<p>Node节点：Node 节点是 Kubernetes 集群中的工作节点，由 Master 节点管理,主要包含以下组件:</p>
<ul>
<li>kubelet：负责管理 Node 节点上的 Pod 和容器的生命周期。</li>
<li>kube-proxy：负责为 Service 提供 cluster 内部的服务发现和负载均衡。</li>
<li>容器运行时（containerd，CRI-O，Docker 等）: 负责真正运行容器的软件。</li>
</ul>
<p>Kubernetes 还包括其他辅助模块（Add-ons），例如:</p>
<ul>
<li>DNS 模块：负责为集群中的主机提供 DNS 解析服务。</li>
<li>网络插件：负责提供底层的网络实现,例如 flannel 和 calico。</li>
<li>参数模块：提供配置管理功能。</li>
<li>仪表板插件：提供 GUI。</li>
<li>存储插件：提供持久化存储实现，例如 Ceph 和 Luster 。</li>
<li>日志模块：提供日志收集、存储功能。</li>
<li>安全模块：提供认证、授权、准入控制等安全功能。</li>
</ul>
<aside class="note info">
<div class="title">平台的平台</div>
<p>Kubernetes 是一个为云原生应用提供核心抽象和服务层的平台，提供了合理、良好的机制支持和下层硬件及其他基础设施服务（如容器运行时、存储、网络等）进行交互。</p>
<p>Kubernetes 有时候被称为 “平台的平台，母平台” ，被用来构建特定领域的平台或者应用系统，是由于其如下特征：</p>
<ol>
<li>Kubernetes 提供了一个跨平台的容器编排和管理的统一平台。这个平台不依赖于任何特定的基础设施，可以跨多种云和本地环境运行。</li>
<li>Kubernetes 对不同基础架构和资源类型进行了抽象和封装，屏蔽了底层平台的差异，提供统一的管理方式。使应用可以无缝迁移。</li>
<li>Kubernetes 作为一个通用平台，可以用来运行和管理各种类型的应用和工作负载，包括 Web 服务、移动应用后端、AI 工作负载、大数据计算等。</li>
<li>基于 Kubernetes 构建的平台都可以获得 Kubernetes 的强大容器编排能力，如服务发现、负载均衡、滚动更新等，这大大降低了运维成本。</li>
<li>Kubernetes 生态系统丰富，有大量的工具和服务，可以扩展其功能，构建自定义平台。</li>
</ol>
<p>总之，Kubernetes 提供了一个云原生应用的标准化基础架构和管理平台，使得构建上层平台更加简单高效。</p>
</aside>
<h2 id="tensorstack-ai-计算平台"><a class="header" href="#tensorstack-ai-计算平台">TensorStack AI 计算平台</a></h2>
<p>TensorStack AI 计算平台构建于以 Kubernetes 为核心的<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Cloud-native_computing">云原生技术</a>，采用开放的、标准的、被普遍采用的、无厂商锁定风险的技术和协议，并能够：</p>
<ol>
<li>长期稳定迭代、不断进步；</li>
<li>提供高度可靠性；</li>
<li>提供高度安全性；</li>
<li>支持在多个维度（计算规模、数据规模、硬件架构等）方便进行扩展。</li>
</ol>
<figure class="architecture">
  <img alt="ai-infra" src="./assets/overview/ai-infra.png" />
  <figcaption>图 5：TensorStack AI 计算平台。 平台采用开放的、标准的、被普遍采用的、无厂商锁定风险的技术和协议；并在稳定性、可靠性、扩展性、安全性多方面具备优异的能力。<figcaption>
</figure>
<p>TensorStack 对 AI 计算中的主要系统问题及解决方法：</p>
<ol>
<li>
<p>软件包依赖 </p>
<p>采用容器镜像清晰、一致、方便地管理对 Pyhton 脚本、GPU 驱动程序、网络驱动程序等各种软件包的依赖：</p>
<pre><code> - 稳定的基础镜像：跟随框架（PyTorch）等主要依赖发布；
 - 镜像全流程支持：制作、发布到 Registry、运行。
</code></pre>
</li>
<li>
<p>计算环境</p>
<p>采用 <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Infrastructure_as_code" >Infrastructure As Code </a> 原则 + 容器镜像 + 网络存储的机制支持在 dev、 train、test、deploy 等环境方便地切换、迭代数据、代码。</p>
</li>
<li>
<p>数据、代码</p>
<p>通过网络存储 + 服务（Version Control，AI DB，Experiment Management 等）支持高效、便捷地使用数据、脚本、配置及跟踪它们的变化。</p>
</li>
<li>
<p>计算资源</p>
<p>通过 CRD controller + resource scheduler，实现快速、简单、方便地请求和使用各种计算资源：CPU、RAM、GPU、高速网络、存储…</p>
</li>
<li>
<p>运行计算</p>
<p>T9k Jobs + Services 等实现可靠、简单、方便地运行个各种类型的计算：开发环境、并行训练、微调、数据处理、推理服务…</p>
</li>
</ol>
<p>TensorStack AI 计算平台将在推动 AI 技术的普及和应用方面发挥着关键作用，为各行各业提供实现 AI 驱动创新的关键工具和资源。</p>
<h2 id="参考-22"><a class="header" href="#参考-22">参考</a></h2>
<p>Infrastructure for deep learning, 2016<br />
<a href="https://openai.com/research/infrastructure-for-deep-learning">https://openai.com/research/infrastructure-for-deep-learning</a></p>
<p>Scaling Kubernetes to 2,500 nodes, 2018<br />
<a href="https://openai.com/research/scaling-kubernetes-to-2500-nodes">https://openai.com/research/scaling-kubernetes-to-2500-nodes</a></p>
<p>Scaling Kubernetes to 7,500 nodes, 2021<br />
<a href="https://openai.com/research/scaling-kubernetes-to-7500-nodes">https://openai.com/research/scaling-kubernetes-to-7500-nodes</a></p>
<p>Borg, Omega, and Kubernetes - Lessons learned from three container-management systems over a decade, 2016<br />
<a href="https://queue.acm.org/detail.cfm?id=2898444">https://queue.acm.org/detail.cfm?id=2898444</a></p>
<p>Large-scale cluster management at Google with Borg, 2015<br />
<a href="https://research.google/pubs/pub43438/">https://research.google/pubs/pub43438/</a></p>
<p>Omega: flexible, scalable schedulers for large compute clusters, 2013<br />
<a href="https://research.google/pubs/pub41684/">https://research.google/pubs/pub41684/</a></p>
<p>Kubernetes as a Platform for building Platforms with Mario-Leander Reimer, 2022<br />
<a href="https://www.youtube.com/watch?v=wDMbBSVNzWY">https://www.youtube.com/watch?v=wDMbBSVNzWY</a></p>
<p>Cloud-native computing<br />
<a href="https://en.wikipedia.org/wiki/Cloud-native_computing">https://en.wikipedia.org/wiki/Cloud-native_computing</a></p>
<p>Cloud Native Computing Foundation<br />
<a href="https://www.cncf.io/">https://www.cncf.io/</a></p>
<p>Infrastructure As Code<br />
<a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">https://en.wikipedia.org/wiki/Infrastructure_as_code</a></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="theme/sidebar.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
